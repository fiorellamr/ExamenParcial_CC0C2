La inteligencia artificial (IA), en el contexto de las ciencias de la computación, es una disciplina y un conjunto de capacidades cognoscitivas e intelectuales expresadas por sistemas informáticos o combinaciones de algoritmos cuyo propósito es la creación de máquinas que imiten la inteligencia humana para realizar tareas, y que pueden mejorar conforme recopilen información.[1]​[2]​ Se hizo presente poco después de la Segunda Guerra Mundial con el desarrollo de la «prueba de Turing», mientras que la locución fue acuñada en 1956 por el informático John McCarthy en la Conferencia de Dartmouth.
En la actualidad, la inteligencia artificial abarca una gran variedad de subcampos. Éstos van desde áreas de propósito general, aprendizaje y percepción, a otras más específicas como el reconocimiento de voz, el juego de ajedrez, la demostración de teoremas matemáticos, la escritura de poesía y el diagnóstico de enfermedades. La inteligencia artificial sintetiza y automatiza tareas que en principio son intelectuales y, por lo tanto, es potencialmente relevante para cualquier ámbito de actividades intelectuales humanas. En este sentido, es un campo genuinamente universal.[3]​
La arquitectura de las inteligencias artificiales y los procesos por los cuales aprenden, se mejoran y se implementan en algún área de interés varía según el enfoque de utilidad que se les quiera dar, pero de manera general, estos van desde la ejecución de sencillos algoritmos hasta la interconexión de complejas redes neuronales artificiales que intentan replicar los circuitos neuronales del cerebro humano y que aprenden mediante diferentes modelos de aprendizaje tales como el aprendizaje automático, el aprendizaje por refuerzo, el aprendizaje profundo y el aprendizaje supervisado.[4]​
Por otro lado, el desarrollo y aplicación de la inteligencia artificial en muchos aspectos de la vida cotidiana también ha propiciado la creación de nuevos campos de estudio como la roboética y la ética de las máquinas que abordan aspectos relacionados con la ética en la inteligencia artificial y que se encargan de analizar cómo los avances en este tipo de tecnologías impactarían en diversos ámbitos de la vida, así como el manejo responsable y ético que se les debería dar a los mismos, además de establecer cuál debería ser la manera correcta de proceder de las máquinas y las reglas que deberían cumplir.[5]​
En cuanto a su clasificación, tradicionalmente se divide a la inteligencia artificial en inteligencia artificial débil, la cual es la única que existe en la actualidad y que se ocupa de realizar tareas específicas, e inteligencia artificial general, que sería una IA que excediese las capacidades humanas. Algunos expertos creen que si alguna vez se alcanza este nivel, se podría dar lugar a la aparición de una singularidad tecnológica, es decir, una entidad tecnológica superior que se mejoraría a sí misma constantemente, volviéndose incontrolable para los humanos, dando pie a teorías como el basilisco de Roko.[6]​
Algunas de las inteligencias artificiales más conocidas y utilizadas en la actualidad alrededor del mundo incluyen inteligencia artificial en el campo de la salud, asistentes virtuales como Alexa, el asistente de Google o Siri, traductores automáticos como el traductor de Google y DeepL, sistemas de recomendación como el de la plataforma digital de YouTube, motores de ajedrez y otros juegos como Stockfish y AlphaZero, chatbots como ChatGPT, creadores de arte de inteligencia artificial como Midjourney, Dall-e, Leonardo y Stable Diffusion, e incluso la conducción de vehículos autónomos como Tesla Autopilot.[7]​


== Denominación ==

En 2019 la Comisión Mundial de Ética del Conocimiento Científico y la Tecnología (COMEST) de la UNESCO definió la inteligencia artificial como un campo que implica máquinas capaces de imitar determinadas funcionalidades de la inteligencia humana, incluidas características como la percepción, el aprendizaje, el razonamiento, la resolución de problemas, la interacción lingüística e incluso la producción de trabajos creativos.
Coloquialmente, la locución «inteligencia artificial» se aplica cuando una máquina imita las funciones «cognitivas» que los humanos asocian como competencias humanas, por ejemplo: «percibir», «razonar», «aprender» y «resolver problemas».[8]​ Andreas Kaplan y Michael Haenlein definen la inteligencia artificial como «la capacidad de un sistema para interpretar correctamente datos externos, y así aprender y emplear esos conocimientos para lograr tareas y metas concretas a través de la adaptación flexible».[9]​ A medida que las máquinas se vuelven cada vez más capaces, se elimina de la definición la tecnología que alguna vez se pensó que requería de inteligencia. Marvin Minsky, uno de los ideadores de la IA, hablaba del término inteligencia artificial como una palabra maleta ("suitcase word") porque en él se pueden meter una diversidad de elementos.[10]​[11]​
Por ejemplo, el reconocimiento óptico de caracteres ya no se percibe como un ejemplo de la «inteligencia artificial» habiéndose convertido en una tecnología común.[12]​ Avances tecnológicos todavía clasificados como inteligencia artificial son los sistemas de conducción autónomos o los capaces de jugar ajedrez o Go.[13]​
La inteligencia artificial es una nueva forma de resolver problemas dentro de los cuales se incluyen los sistemas expertos, el manejo y control de robots y los procesadores, que intenta integrar el conocimiento en tales sistemas, en otras palabras, un sistema inteligente capaz de escribir su propio programa. Un sistema experto definido como una estructura de programación capaz de almacenar y utilizar un conocimiento sobre un área determinada que se traduce en su capacidad de aprendizaje.[14]​ De igual manera se puede considerar a la IA como la capacidad de las máquinas para usar algoritmos, aprender de los datos y utilizar lo aprendido en la toma de decisiones tal y como lo haría un ser humano.[15]​
Según Takeyas (2007) la IA es una rama de las ciencias computacionales encargada de estudiar modelos de cómputo capaces de realizar actividades propias de los seres humanos con base en dos de sus características primordiales: el razonamiento y la conducta.[16]​
En 1956, John McCarthy acuñó la expresión «inteligencia artificial», y la definió como «la ciencia e ingenio de hacer máquinas inteligentes, especialmente programas de cómputo inteligentes».[17]​
Grau-Luque contrasta diferentes definiciones desde diversas fuentes y autores, destacando que difieren dependiendo de "en qué campo específico se usen".[18]​Esto lleva al autor a definir «inteligencia artificial» como "sistemas que llevan a cabo tareas consideradas inteligentes", para luego asociar conceptos como «aprendizaje» y «razonamiento» con el aprendizaje automático como una subdisciplina de la inteligencia artificial.
También existen distintos tipos de percepciones y acciones, que pueden ser obtenidas y producidas, respectivamente, por sensores físicos y sensores mecánicos en máquinas, pulsos eléctricos u ópticos en computadoras, tanto como por entradas y salidas de bits de un software y su entorno software.
Varios ejemplos se encuentran en el área de control de sistemas, planificación automática, la capacidad de responder a diagnósticos y a consultas de los consumidores, reconocimiento de escritura, reconocimiento del habla y reconocimiento de patrones. Los sistemas de IA actualmente son parte de la rutina en campos como economía, medicina, ingeniería, el transporte, las comunicaciones y la milicia, y se ha usado en gran variedad de programas informáticos, juegos de estrategia, como ajedrez de computador, y otros videojuegos.


== Tipos ==
Stuart J. Russell y Peter Norvig diferencian varios tipos de inteligencia artificial:[19]​

Los sistemas que piensan como humanos: Estos sistemas tratan de emular el pensamiento humano; por ejemplo, las redes neuronales artificiales. La automatización de actividades que vinculamos con procesos de pensamiento humano, actividades como la toma de decisiones, resolución de problemas y aprendizaje.[20]​
Los sistemas que actúan como humanos: Estos sistemas tratan de actuar como humanos; es decir, imitan el comportamiento humano; por ejemplo, la robótica (El estudio de cómo lograr que los computadores realicen tareas que, por el momento, los humanos hacen mejor).[21]​
Los sistemas que piensan racionalmente: Es decir, con lógica (idealmente), tratan de imitar el pensamiento racional del ser humano; por ejemplo, los sistemas expertos, (el estudio de los cálculos que hacen posible percibir, razonar y actuar).[22]​
Los sistemas que actúan racionalmente: Tratan de emular de forma racional el comportamiento humano; por ejemplo, los agentes inteligentes, que está relacionado con conductas inteligentes en artefactos.[23]​


==== Inteligencia artificial generativa ====

La inteligencia artificial generativa es un tipo de sistema de inteligencia artificial capaz de generar texto, imágenes u otros medios en respuesta a comandos.[24]​ Los modelos de IA generativa aprenden los patrones y la estructura de sus datos de entrenamiento de entrada y luego generan nuevos datos que tienen características similares.
Los sistemas de IA generativa notables incluyen ChatGPT (y su variante Microsoft Copilot), un bot conversacional creado por OpenAI usando sus modelos de lenguaje grande fundacionales GPT-3 y GPT-4;​ y Gemini (anteriormente llamado Bard), un bot conversacional creado por Google usando el modelo de lenguaje Gemini. Otros modelos generativos de IA incluyen sistemas de arte de inteligencia artificial como Stable Diffusion, Midjourney y DALL-E.


==== Inteligencia artificial fuerte ====

La Inteligencia artificial fuerte (IGA) es un tipo hipotético de inteligencia artificial que iguala o excede la inteligencia humana promedio.​ Si se hiciera realidad, una IGA podría aprender a realizar cualquier tarea intelectual que los seres humanos o los animales puedan llevar a cabo.​​ Alternativamente, la IGA se ha definido como un sistema autónomo que supera las capacidades humanas en la mayoría de las tareas económicamente valiosas.
Algunos sostienen que podría ser posible en años o décadas; otros, que podría tardar un siglo o más; y una minoría cree que quizá nunca se consiga.​ Existe un debate sobre la definición exacta de IGA y sobre si los grandes modelos de lenguaje (LLM) modernos, como el GPT-4, son formas tempranas pero incompletas de IGA.


==== Inteligencia artificial explicable ====

La inteligencia artificial explicable se refiere a métodos y técnicas en la aplicación de tecnología de inteligencia artificial por los que el ser humano es capaz de comprender las decisiones y predicciones realizadas por la inteligencia artificial.


==== Inteligencia artificial amigable ====

La inteligencia artificial amigable es una IA fuerte e hipotética que puede tener un efecto positivo más que uno negativo sobre la humanidad. 'Amigable' es usado en este contexto como terminología técnica y escoge agentes que son seguros y útiles, no necesariamente aquellos que son "amigables" en el sentido coloquial. El concepto es invocado principalmente en el contexto de discusiones de agentes artificiales de auto-mejora recursiva que rápidamente explota en inteligencia, con el argumento de que esta tecnología hipotética pudiera tener una larga, rápida y difícil tarea de controlar el impacto en la sociedad humana.


==== Inteligencia artificial multimodal ====

La inteligencia artificial multimodal  es un tipo de inteligencia artificial que puede procesar e integrar datos de diferentes modalidades, como texto, imágenes, audio y video, para obtener una comprensión más completa y contextualizada de una situación. La inteligencia artificial multimodal se inspira en la forma en que los humanos usan varios sentidos para percibir e interactuar con el mundo, y ofrece una forma más natural e intuitiva de comunicarse con la tecnología.


==== Inteligencia artificial cuántica ====

La inteligencia artificial Cuántica es un campo interdisciplinar que se enfoca en construir algoritmos cuánticos para mejorar las tareas computacionales dentro de la IA, incluyendo subcampos como el aprendizaje automático.​ Existen evidencias que muestran una posible ventaja cuadrática cuántica en operaciones fundamentales de la IA.


== Escuelas de pensamiento ==
La IA se divide en dos escuelas de pensamiento:

La inteligencia artificial convencional.
La inteligencia computacional.


=== Inteligencia artificial convencional ===
Se conoce también como IA simbólica-deductiva. Está basada en el análisis formal y estadístico del comportamiento humano ante diferentes problemas:

Razonamiento basado en casos: Ayuda a tomar decisiones mientras se resuelven ciertos problemas concretos y, aparte de que son muy importantes, requieren de un buen funcionamiento.
Sistemas expertos: Infieren una solución a través del conocimiento previo del contexto en que se aplica y utiliza ciertas reglas o relaciones.[25]​
Redes bayesianas: Propone soluciones mediante inferencia probabilística.[26]​
Inteligencia artificial basada en comportamientos: Esta inteligencia contiene autonomía, es decir, puede auto-regularse y controlarse para mejorar.
Smart process management: Facilita la toma de decisiones complejas, proponiendo una solución a un determinado problema al igual que lo haría un especialista en dicha actividad.


=== Inteligencia artificial computacional ===

La inteligencia computacional (también conocida como IA subsimbólica-inductiva) implica desarrollo o aprendizaje interactivo (por ejemplo, modificaciones interactivas de los parámetros en sistemas de conexiones). El aprendizaje se realiza basándose en datos empíricos.
La inteligencia computacional tiene una doble finalidad. Por un lado, su objetivo científico es comprender los principios que posibilitan el comportamiento inteligente (ya sea en sistemas naturales o artificiales) y, por otro, su objetivo tecnológico consiste en especificar los métodos para diseñar sistemas inteligentes.[27]​


== Historia ==

La expresión «inteligencia artificial» fue acuñada formalmente en 1956 durante la Conferencia de Dartmouth, pero para entonces ya se había estado trabajando en ello durante cinco años en los cuales se había propuesto muchas definiciones distintas que en ningún caso habían logrado ser aceptadas totalmente por la comunidad investigadora. La IA es una de las disciplinas más recientes junto con la genética moderna.
Las ideas más básicas se remontan a los antiguos griegos. Aristóteles (384-322 a. C.) fue el primero en describir un conjunto de reglas que describen una parte del funcionamiento de la mente para obtener conclusiones racionales, y Ctesibio de Alejandría (250 a. C.) construyó la primera máquina autocontrolada, un regulador del flujo de agua (racional pero sin razonamiento).
En 1315 Ramon Llull en su libro Ars magna tuvo la idea de que el razonamiento podía ser efectuado de manera artificial.
En 1840 Ada Lovelace previó la capacidad de las máquinas para ir más allá de los simples cálculos y aportó una primera idea de lo que sería el software.
Leonardo Torres Quevedo(1852-1936) es considerado como uno de los padres de la inteligencia artificial y de la Automática.
En 1936 Alan Turing diseña formalmente una Máquina universal que demuestra la viabilidad de un dispositivo físico para implementar cualquier cómputo formalmente definido.
En 1943 Warren McCulloch y Walter Pitts presentaron su modelo de neuronas artificiales, el cual se considera el primer trabajo del campo, aun cuando todavía no existía el término. Los primeros avances importantes comenzaron a principios del año 1950 con el trabajo de Alan Turing, a partir de lo cual la ciencia ha pasado por diversas situaciones.
En 1955 Herbert Simon, Allen Newell y Joseph Carl Shaw, desarrollan el primer lenguaje de programación orientado a la resolución de problemas, el IPL-11. Un año más tarde desarrollan el LogicTheorist, el cual era capaz de demostrar teoremas matemáticos.
En 1956 fue ideada la expresión «inteligencia artificial» por John McCarthy, Marvin Minsky y Claude Shannon en la Conferencia de Dartmouth, un congreso en el que se hicieron previsiones triunfalistas a diez años que jamás se cumplieron, lo que provocó el abandono casi total de las investigaciones durante quince años.
En 1957 Newell y Simon continúan su trabajo con el desarrollo del General Problem Solver (GPS). GPS era un sistema orientado a la resolución de problemas.
En 1958 John McCarthy desarrolla en el Instituto Tecnológico de Massachusetts (MIT) el LISP. Su nombre se deriva de LISt Processor. LISP fue el primer lenguaje para procesamiento simbólico.
En 1959 Rosenblatt introduce el «perceptrón».
A finales de la década de 1950 y comienzos de la de 1960 Robert K. Lindsay desarrolla «Sad Sam», un programa para la lectura de oraciones en inglés y la inferencia de conclusiones a partir de su interpretación.
En 1963 Quillian desarrolla las redes semánticas como modelo de representación del conocimiento.
En 1964 Bertrand Raphael construye el sistema SIR (Semantic Information Retrieval) el cual era capaz de inferir conocimiento basado en información que se le suministra. Bobrow desarrolla STUDENT.
A mediados de los años 60, aparecen los sistemas expertos, que predicen la probabilidad de una solución bajo un set de condiciones. Por ejemplo, DENDRAL, iniciado en 1965 por Buchanan, Feigenbaum y Lederberg, el primer Sistema Experto, que asistía a químicos en estructuras químicas complejas, MACSYMA, que asistía a ingenieros y científicos en la solución de ecuaciones matemáticas complejas.
Posteriormente entre los años 1968-1970 Terry Winograd desarrolló el sistema SHRDLU, que permitía interrogar y dar órdenes a un robot que se movía dentro de un mundo de bloques.
En 1968 Marvin Minsky publica Semantic Information Processing.
En 1968 Seymour Papert, Danny Bobrow y Wally Feurzeig desarrollan el lenguaje de programación LOGO.
En 1969 Alan Kay desarrolla el lenguaje Smalltalk en Xerox PARC y se publica en 1980.
En 1973 Alain Colmenauer y su equipo de investigación en la Universidad de Aix-Marseille crean PROLOG (del francés PROgrammation en LOGique) un lenguaje de programación ampliamente utilizado en IA.
En 1973 Shank y Abelson desarrollan los guiones, o scripts, pilares de muchas técnicas actuales en inteligencia artificial y la informática en general.
En 1974 Edward Shortliffe escribe su tesis con MYCIN, uno de los Sistemas Expertos más conocidos, que asistió a médicos en el diagnóstico y tratamiento de infecciones en la sangre.
En las décadas de 1970 y 1980, creció el uso de sistemas expertos, como MYCIN: R1/XCON, ABRL, PIP, PUFF, CASNET, INTERNIST/CADUCEUS, etc. Algunos permanecen hasta hoy (Shells) como EMYCIN, EXPERT, OPSS.
En 1981 Kazuhiro Fuchi anuncia el proyecto japonés de la quinta generación de computadoras.
En 1986 McClelland y Rumelhart publican Parallel Distributed Processing (Redes Neuronales).
En 1988 se establecen los lenguajes Orientados a Objetos.
En 1997 Gari Kaspárov, campeón mundial de ajedrez, pierde ante la computadora autónoma Deep Blue.
En 2006 se celebró el aniversario con el Congreso en español 50 años de inteligencia artificial - Campus Multidisciplinar en Percepción e Inteligencia 2006.
En 2009 ya había en desarrollo sistemas inteligentes terapéuticos que permiten detectar emociones para poder interactuar con niños autistas.
En 2011 IBM desarrolló un superordenador llamado Watson, el cual ganó una ronda de tres juegos seguidos de Jeopardy!, venciendo a sus dos máximos campeones, y ganando un premio de 1 millón de dólares que IBM luego donó a obras de caridad.[28]​
En 2016, un programa informático ganó cinco a cero al triple campeón de Europa de Go.[29]​
En 2016, el entonces presidente Obama habla sobre el futuro de la inteligencia artificial y la tecnología.[30]​
Existen personas que al dialogar sin saberlo con un chatbot no se percatan de hablar con un programa, de modo tal que se cumple la prueba de Turing como cuando se formuló: «Existirá inteligencia artificial cuando no seamos capaces de distinguir entre un ser humano y un programa informático en una conversación a ciegas».
En 2017 AlphaGo desarrollado por DeepMind derrota 4-1 en una competencia de Go al campeón mundial Lee Sedol. Este suceso fue muy mediático y marcó un hito en la historia de este juego.[31]​ A finales de ese mismo año, Stockfish, el motor de ajedrez considerado el mejor del mundo con 3 400 puntos ELO, fue abrumadoramente derrotado por AlphaZero con solo conocer las reglas del juego y tras solo 4 horas de entrenamiento jugando contra sí mismo.[32]​
Como anécdota, muchos de los investigadores sobre IA sostienen que «la inteligencia es un programa capaz de ser ejecutado independientemente de la máquina que lo ejecute, computador o cerebro».
En 2017 un grupo de ingenieros en Google inventan la arquitectura de transformador, un modelo de deep learning que alumbró una nueva generación de modelos grandes de lenguaje, empezando por BERT, y luego el revolucionario GPT de OpenAI.[33]​
En 2018, se lanza el primer televisor con inteligencia artificial por parte de LG Electronics con una plataforma denominada ThinQ.[34]​
En 2019, Google presentó su Doodle en que, con ayuda de la inteligencia artificial, hace un homenaje a Johann Sebastian Bach, en el que, añadiendo una simple melodía de dos compases la IA crea el resto.
En 2020, la OECD (Organización para la Cooperación y el Desarrollo Económico) publica el documento de trabajo intitulado Hola, mundo: La inteligencia artificial y su uso en el sector público, dirigido a funcionarios de gobierno con el afán de resaltar la importancia de la IA y de sus aplicaciones prácticas en el ámbito gubernamental.[35]​
Al final del año 2022, se lanzó ChatGPT, una inteligencia artificial generativa capaz de escribir textos y responder preguntas en muchos idiomas. Dado que la calidad de las respuestas recordaba inicialmente al nivel humano, se generó un entusiasmo mundial por la IA[36]​ y ChatGPT alcanzó más de 100 millones de usuarios dos meses después de su lanzamiento.[37]​ Más tarde, los expertos notaron que ChatGPT proporciona información errónea en áreas donde no tiene conocimiento ("alucinaciones de datos"), la cual a primera vista parece creíble debido a su perfecta redacción.[38]​
En 2023, las fotos generadas por IA alcanzaron un nivel de realismo que las hacía confundirse con fotos reales. Como resultado, hubo una ola de "fotos" generadas por IA que muchos espectadores creyeron que eran reales. Una imagen generada por Midjourney se destacó, mostrando al Papa Francisco con un elegante abrigo blanco de invierno.[39]​


== Implicaciones sociales, éticas y filosóficas ==

Ante la posibilidad de crear máquinas dotadas de inteligencia, se volvió importante preocuparse por la cuestión ética de las máquinas para tratar de garantizar que no se produzca ningún daño a los seres humanos, a otros seres vivos e incluso a las mismas máquinas según algunas corrientes de pensamiento.[40]​ Es así como surgió un amplio campo de estudios conocido como ética de la inteligencia artificial de relativamente reciente aparición y que generalmente se divide en dos ramas, la roboética, encargada de estudiar las acciones de los seres humanos hacia los robots, y la ética de las máquinas encargada del estudio del comportamiento de los robots para con los seres humanos.
El acelerado desarrollo tecnológico y científico de la inteligencia artificial que se ha producido en el siglo XXI supone también un importante impacto en otros campos. En la economía mundial durante la segunda revolución industrial se vivió un fenómeno conocido como desempleo tecnológico, que se refiere a cuando la automatización industrial de los procesos de producción a gran escala reemplaza la mano de obra humana. Con la inteligencia artificial podría darse un fenómeno parecido, especialmente en los procesos en los que interviene la inteligencia humana, tal como se ilustraba en el cuento ¡Cómo se divertían! de Isaac Asimov, en el que su autor vislumbra algunos de los efectos que tendría la interacción de máquinas inteligentes especializadas en pedagogía infantil, en lugar de profesores humanos, con los niños en etapa escolar. Este mismo escritor diseñó lo que hoy se conocen como las tres leyes de la robótica, aparecidas por primera vez en el relato Círculo vicioso (Runaround) de 1942, donde establecía lo siguiente:

Primera Ley

Un robot no hará daño a un ser humano ni, permitirá que un ser humano sufra daño.
Segunda Ley

Un robot debe cumplir las órdenes dadas por los seres humanos, a excepción de aquellas que entren en conflicto con la primera ley.
Tercera Ley

Un robot debe proteger su propia existencia en la medida en que esta protección no entre en conflicto con la primera o con la segunda ley.[41]​
Otras obras de ciencia ficción más recientes también exploran algunas cuestiones éticas y filosóficas con respecto a la Inteligencia artificial fuerte, como las películas Yo, robot o A.I. Inteligencia Artificial, en los que se tratan temas tales como la autoconsciencia o el origen de una conciencia emergente de los robots inteligentes o sistemas computacionales, o si éstos podrían considerarse sujetos de derecho debido a sus características casi humanas relacionadas con la sintiencia, como el poder ser capaces de sentir dolor y emociones o hasta qué punto obedecerían al objetivo de su programación, y en caso de no ser así, si podrían ejercer libre albedrío. Esto último es el tema central de la famosa saga de Terminator, en la que las máquinas superan a la humanidad y deciden aniquilarla, historia que, según varios especialistas, podría no limitarse a la ciencia ficción y ser una posibilidad real en una sociedad posthumana que dependiese de la tecnología y las máquinas completamente.[42]​[43]​


== Regulación ==

El Derecho[45]​ desempeña un papel fundamental en el uso y desarrollo de la IA. Las leyes establecen reglas y normas de comportamiento para asegurar el bienestar social y proteger los derechos individuales, y pueden ayudarnos a obtener los beneficios de esta tecnología mientras minimizamos sus riesgos, que son significativos. De momento no hay normas jurídicas que regulen directamente a la IA. Pero con fecha 21 de abril de 2021, la Comisión Europea ha presentado una propuesta de Reglamento europeo para la regulación armonizada de la inteligencia artificial (IA) en la UE. Su título exacto es Propuesta de Reglamento del Parlamento Europeo y del Consejo por el que se establecen normas armonizadas en materia de inteligencia artificial –Ley de Inteligencia Artificial– y se modifican otros actos legislativos de la Unión.
En marzo de 2023, cientos de empresarios como Elon Musk, Steve Wozniak (cofundador de Apple) o los presidentes de numerosas compañías tecnológicas; intelectuales como Yuval Noah Harari y cientos de académicos e investigadores especializados en inteligencia artificial firmaron una carta abierta avisando del peligro de la falta de regulación de la IA, poniendo el foco sobre OpenAI, la empresa que ha desarrollado ChatGPT. Pidieron una pausa de al menos 6 meses para sus experimentos más potentes, hasta que el mundo logre un consenso internacional para que estos sistemas «sean más precisos, seguros, interpretables, transparentes, robustos, neutrales, confiables y leales».[46]​
Dos meses más tarde, en mayo, 350 ejecutivos de las principales empresas desarrolladoras de IA, académicos e investigadores expertos firmaron un nuevo manifiesto alertando de que la IA avanzada sin regular representa un peligro de extinción para la humanidad: «Mitigar el riesgo de extinción de la IA debería ser una prioridad mundial junto a otros riesgos a escala social como las pandemias y la guerra nuclear»[47]​ Entre los impulsores de esta petición está toda la plana mayor de OpenAI, el jefe de Tecnología de Microsoft, el líder de Google DeepMind con 38 ejecutivos, investigadores o profesores de universidad relacionados con la empresa, y representantes de desarrolladoras más pequeñas como Anthropic, Stability AI o Inflection AI.[48]​


== Objetivos ==


=== Razonamiento y resolución de problemas ===

Los primeros investigadores desarrollaron algoritmos que imitaban el razonamiento paso a paso que los humanos usan cuando resuelven acertijos o hacen deducciones lógicas.[49]​ A finales de la década de 1981-1990, la investigación de la inteligencia artificial había desarrollado métodos para tratar con información incierta o incompleta, empleando conceptos de probabilidad y economía.[50]​
Estos algoritmos demostraron ser insuficientes para resolver grandes problemas de razonamiento porque experimentaron una «explosión combinatoria»: se volvieron exponencialmente más lentos a medida que los problemas crecían.[51]​ De esta manera, se concluyó que los seres humanos rara vez usan la deducción paso a paso que la investigación temprana de la inteligencia artificial seguía; en cambio, resuelven la mayoría de sus problemas utilizando juicios rápidos e intuitivos.[52]​


=== Representación del conocimiento ===

La representación del conocimiento[53]​ y la ingeniería del conocimiento[54]​ son fundamentales para la investigación clásica de la inteligencia artificial. Algunos «sistemas expertos» intentan recopilar el conocimiento que poseen los expertos en algún ámbito concreto. Además, otros proyectos tratan de reunir el «conocimiento de sentido común» conocido por una persona promedio en una base de datos que contiene un amplio conocimiento sobre el mundo.
Entre los temas que contendría una base de conocimiento de sentido común están: objetos, propiedades, categorías y relaciones entre objetos,[55]​ situaciones, eventos, estados y tiempo[56]​ causas y efectos;[57]​ y el conocimiento sobre el conocimiento (lo que sabemos sobre lo que saben otras personas)[58]​ entre otros.


=== Planificación ===
Otro objetivo de la inteligencia artificial consiste en poder establecer metas y finalmente alcanzarlas.[59]​ Para ello necesitan una forma de visualizar el futuro, una representación del estado del mundo y poder hacer predicciones sobre cómo sus acciones lo cambiarán, con tal de poder tomar decisiones que maximicen la utilidad (o el «valor») de las opciones disponibles.[60]​
En los problemas clásicos de planificación, el agente puede asumir que es el único sistema que actúa en el mundo, lo que le permite estar seguro de las consecuencias de sus acciones.[61]​ Sin embargo, si el agente no es el único actor, entonces se requiere que este pueda razonar bajo incertidumbre. Esto requiere un agente que no solo pueda evaluar su entorno y hacer predicciones, sino también evaluar sus predicciones y adaptarse en función de su evaluación.[62]​ La planificación de múltiples agentes utiliza la cooperación y la competencia de muchos sistemas para lograr un objetivo determinado. El comportamiento emergente como este es utilizado por algoritmos evolutivos e inteligencia de enjambre.[63]​


=== Aprendizaje ===
El aprendizaje automático es un concepto fundamental de la investigación de la inteligencia artificial desde el inicio de los estudios de este campo; consiste en la investigación de algoritmos informáticos que mejoran automáticamente a través de la experiencia.[64]​
El aprendizaje no supervisado es la capacidad de encontrar patrones en un flujo de entrada, sin que sea necesario que un humano etiquete las entradas primero. El aprendizaje supervisado incluye clasificación y regresión numérica, lo que requiere que un humano etiquete primero los datos de entrada. La clasificación se usa para determinar a qué categoría pertenece algo y ocurre después de que un programa observe varios ejemplos de entradas de varias categorías. La regresión es el intento de producir una función que describa la relación entre entradas y salidas y predice cómo deben cambiar las salidas a medida que cambian las entradas.[64]​ Tanto los clasificadores como los aprendices de regresión intentan aprender una función desconocida; por ejemplo, un clasificador de spam puede verse como el aprendizaje de una función que asigna el texto de un correo electrónico a una de dos categorías, «spam» o «no spam». La teoría del aprendizaje computacional puede evaluar a los estudiantes por complejidad computacional, complejidad de la muestra (cuántos datos se requieren) o por otras nociones de optimización.[65]​
El mundo está en constante evolución, y herramientas como ChatGPT están en el centro de esta transformación. Mientras que muchas personas ven a ChatGPT como una oportunidad para mejorar la experiencia de sus negocios o personales, hay quienes se muestran escépticos sobre su implementación. [66]​


=== Procesamiento de lenguajes naturales ===

El procesamiento del lenguaje natural[67]​ permite a las máquinas leer y comprender el lenguaje humano. Un sistema de procesamiento de lenguaje natural suficientemente eficaz permitiría interfaces de usuario de lenguaje natural y la adquisición de conocimiento directamente de fuentes escritas por humanos, como los textos de noticias. Algunas aplicaciones sencillas del procesamiento del lenguaje natural incluyen la recuperación de información, la minería de textos, la respuesta a preguntas y la traducción automática.[68]​ Muchos enfoques utilizan las frecuencias de palabras para construir representaciones sintácticas de texto. Las estrategias de búsqueda de «detección de palabras clave» son populares y escalables, pero poco óptimas; una consulta de búsqueda para «perro» solo puede coincidir con documentos que contengan la palabra literal «perro» y perder un documento con el vocablo «caniche». Los enfoques estadísticos de procesamiento de lenguaje pueden combinar todas estas estrategias, así como otras, y a menudo logran una precisión aceptable a nivel de página o párrafo. Más allá del procesamiento de la semántica, el objetivo final de este es incorporar una comprensión completa del razonamiento de sentido común.[69]​ En 2019, las arquitecturas de aprendizaje profundo basadas en transformadores podían generar texto coherente.[70]​


=== Percepción ===

La percepción de la máquina[71]​ es la capacidad de utilizar la entrada de sensores (como cámaras de espectro visible o infrarrojo, micrófonos, señales inalámbricas y lidar, sonar, radar y sensores táctiles) para entender aspectos del mundo. Las aplicaciones incluyen reconocimiento de voz,[72]​ reconocimiento facial y reconocimiento de objetos.[73]​ La visión artificial es la capacidad de analizar la información visual, que suele ser ambigua; un peatón gigante de cincuenta metros de altura muy lejos puede producir los mismos píxeles que un peatón de tamaño normal cercano, lo que requiere que la inteligencia artificial juzgue la probabilidad relativa y la razonabilidad de las diferentes interpretaciones, por ejemplo, utilizando su «modelo de objeto» para evaluar que los peatones de cincuenta metros no existen.[74]​


== Importancia de la inteligencia artificial ==
La gran importancia de la IA radica en el hecho de que tiene una amplia gama de aplicaciones, desde la automatización de tareas tediosas hasta la creación de sistemas avanzados de asistencia médica y diagnóstico de enfermedades, la detección de fraudes y la optimización de procesos empresariales[75]​. En muchos casos, la IA puede hacer cosas que los humanos no pueden hacer, como el procesamiento de datos en grandes cantidades y la localización de patrones e interrelaciones entre estos que serían difíciles o imposibles de detectar de otra manera.
Esta herramienta ayuda a automatizar el aprendizaje y descubrimiento repetitivo a través de datos, realiza tareas computarizadas frecuentes de manera confiable, sin embargo, necesita intervención humana para la configuración del sistema. Analiza datos más profundos y agrega inteligencia ya que no se puede vender como una aplicación individual, por lo que es un valor agregado a los productos. Tiene una gran precisión a través de redes neuronales profundas; por ejemplo, en medicina se puede utilizar la IA para detectar cáncer con MRIs (imágenes ppr resonancia magnética). Se adapta a través de algoritmos de aprendizaje progresivo, encuentra estructura y regularidades en los datos de modo que el algoritmo se convierte en un clasificador o predictor. Y, por último, la inteligencia artificial, saca el mayor provecho de datos.
Además, una de las principales razones por las que la IA es importante es porque puede automatizar tareas repetitivas y monótonas, liberando tiempo y recursos para que las personas se centren en tareas más creativas y valiosas. Por ejemplo, la IA puede ayudar a las empresas a automatizar tareas de back office, como la contabilidad y el procesamiento de facturas, lo que puede reducir los costos y mejorar la eficiencia. De manera similar, la IA puede ayudar a los trabajadores a realizar tareas más complejas y creativas, como el diseño y la planificación estratégica.
Otra razón por la que la IA es importante es porque puede ayudar a las empresas a tomar decisiones informadas y precisas. Así mismo, la IA puede procesar grandes cantidades de datos y proporcionar información valiosa para la toma de decisiones empresariales, lo que puede ayudar a las empresas a identificar oportunidades comerciales, predecir tendencias de mercado y mejorar la eficiencia del mercado financiero. Además, la IA puede ayudar a los trabajadores a tomar decisiones informadas en tiempo real, como en el caso de la atención médica, donde la IA puede ayudar a los médicos a identificar enfermedades y personalizar el tratamiento.
La IA también es importante en el campo de la ciberseguridad. La IA puede ayudar a detectar y prevenir amenazas, desde ciberataques hasta la detección de comportamientos sospechosos. La IA puede analizar grandes cantidades de datos en tiempo real y detectar patrones y anomalías que podrían indicar una amenaza de seguridad. Además, la IA puede aprender de los patrones de comportamiento y mejorar su capacidad para detectar amenazas en el futuro[76]​. En el campo de la seguridad cibernética, la IA puede ayudar a proteger los sistemas y las redes de los ataques de virus informáticos y la infiltración de malware.
Otra área donde la IA es importante es en el descubrimiento de conocimientos. La IA puede descubrir patrones y relaciones en los datos que los humanos no podrían detectar, lo que puede llevar a nuevas ideas y avances en diversos campos. Por ejemplo, la IA puede ayudar a los investigadores a identificar nuevos tratamientos para enfermedades, o ayudar a los científicos a analizar datos de sensores y satélites para entender mejor el calentamiento global.


== Controversias ==


=== Sophia ===
En marzo de 2016, se hizo popular el comentario que la robot humanoide llamada Sophia de la empresa Hanson Robotics hizo durante su presentación cuando su creador, David Hanson, le preguntara si estaba dispuesta a destruir a la humanidad, a lo que la robot contestó: «Está bien, voy a destruir a la humanidad». Posteriormente, Sophía se ganó el reconocimiento y la atención mediática mundial debido a sus conductas casi humanas, siendo entrevistada en muchas ocasiones por distintos medios y sosteniendo conversaciones con personalidades famosas y reconocidas. En 2017, Sophia obtuvo la ciudadanía saudí, convirtiéndose así en la primera robot en ser reconocida como ciudadana por un país, lo cual levantó la controversia sobre si se les debería otorgar los mismos derechos y obligaciones a los robots como si se trataran de sujetos de derecho.[77]​


=== Alice y Bob ===
A finales de julio de 2017, varios medios internacionales dieron a conocer que el laboratorio de investigación de inteligencia artificial del Instituto Tecnológico de Georgia, en conjunto con el Grupo de Investigación de inteligencia artificial (FAIR) de Facebook, ahora Meta, tuvieron que apagar dos inteligencias artificiales de tipo chatbot denominadas Bob y Alice, ya que habían desarrollado un lenguaje propio más eficiente que el inglés, idioma en el que habían sido entrenados para aprender a negociar, desarrollando finalmente un tipo de comunicación incomprensible que se alejaba de las reglas gramaticales del lenguaje natural y que favorecía el uso de abreviaturas. El lenguaje creado por estas IA mostraba características de un inglés corrupto y patrones repetitivos, en especial de pronombres y determinantes.[78]​
Este inesperado suceso fue visto con pánico en los medios de comunicación, ya que se aseguraba que los chatbots supuestamente habían salido del control humano y habían desarrollado la capacidad de comunicarse entre sí. Sin embargo, posteriormente esto también fue desmentido, pues se argumentó que en realidad Facebook no apagó las inteligencias artificiales, sino que simplemente las puso en pausa y cambió los parámetros de los chatbots, desechando el experimento al final por no tener ningún interés práctico o útil dentro de la investigación sobre IA.[79]​


=== Ameca ===
A principios del 2022, en la Feria de Electrónica de Consumo (CES) que tomó lugar en Las Vegas, el robot desarrollado por Engineered Arts nombrado Ameca causó duda y miedo a los espectadores durante su exposición principalmente por la semejanza de su rostro a uno de un ser humano, la compañía expresó que el desarrollo de este robot humanoide aún se encontraba en proceso y hasta septiembre del mismo año el robot aún no era capaz de caminar ni tener interacción alguna con las personas.[80]​ Por otro lado, en septiembre de 2023 la compañía volvió a exponer a Ameca al público mostrando al robot en videos en donde se le puede ver frente a un espejo haciendo 25 expresiones humanas [81]​, así como dibujando un gato al ya contar con brazos y piernas que le otorgaron movilidad y, de igual manera, empleando ironía en conversaciones con personas e incluso declarando que realizó una broma al ser cuestionada sobre su capacidad de soñar como un humano siendo un robot al decir «soñé con dinosaurios luchando una guerra contra alienígenas en Marte»[82]​ esto lo desmintió momentos después explicando cómo es que la IA implementada en su sistema le permitía crear escenarios sobre hechos de la humanidad e iba aprendiendo sobre ellos mientras se encontraba apagada; estos hechos impactaron a la sociedad sobre la semejanza que este robot humanoide estaba teniendo con el ser humano y sobre el avance tecnológico que está permitiendo que este robot esté cada vez más cercano a vivir entre las personas como un miembro más de la comunidad.


=== Falsos desnudos ===
La utilización de aplicaciones gratuitas de IA para transformar fotografías de personas en falsos desnudos está generando problemas que afectan a menores. El caso saltó a los medios de comunicación en septiembre de 2023 cuando en Almendralejo (Badajoz, España) aparecieron varias fotografías de niñas y jóvenes (entre 11 y 17 años) que habían sido modificadas mediante inteligencia artificial para aparecer desnudas. Las imágenes fueron obtenidas de los perfiles de Instagram y de la aplicación Whatsapp de al menos 20 niñas de la localidad. Las fotografías de niñas desnudas habían circulado después mediante Whatsapp y a partir de ellas se había creado un vídeo que también había circulado entre menores. Los autores de dicha transformación también eran menores y compañeros de colegio o instituto. La Agencia Española de Protección de Datos abrió una investigación y se comunicó con el Ayuntamiento de Almendralejo y con la Junta de Extremadura informándoles de que se podía solicitar la retirada de cualquier imagen circulando en internet en el canal prioritario de la agencia.[83]​


== Críticas ==

Uno de los mayores críticos de la denominación de estos procesos informáticos con el término de inteligencia artificial es Jaron Lanier. Para ello, objeta la idea de que esta sea realmente inteligente y de que podríamos estar en competencia con un ente artificial. "Esta idea de superar la capacidad humana es ridícula porque está hecha de habilidades humanas" [84]​ 
Las principales críticas a la inteligencia artificial tienen que ver con su capacidad de imitar por completo a un ser humano.[85]​ Sin embargo, hay expertos[86]​en el tema que indican que ningún humano individual tiene capacidad para resolver todo tipo de problemas, y autores como Howard Gardner han teorizado sobre la solución.
En los humanos, la capacidad de resolver problemas tiene dos aspectos: los aspectos innatos y los aspectos aprendidos. Los aspectos innatos permiten, por ejemplo, almacenar y recuperar información en la memoria, mientras que en los aspectos aprendidos reside el saber resolver un problema matemático mediante el algoritmo adecuado. Del mismo modo que un humano debe disponer de herramientas que le permitan solucionar ciertos problemas, los sistemas artificiales deben ser programados para que puedan llegar a resolverlos.
Muchas personas consideran que la prueba de Turing ha sido superada, citando conversaciones en que al dialogar con un programa de inteligencia artificial para chat no saben que hablan con un programa. Sin embargo, esta situación no es equivalente a una prueba de Turing, que requiere que el participante se encuentre sobre aviso de la posibilidad de hablar con una máquina.
Otros experimentos mentales como la habitación china, de John Searle, han mostrado cómo una máquina podría simular pensamiento sin realmente poseerlo, pasando la prueba de Turing sin siquiera entender lo que hace, tan solo reaccionando de una forma concreta a determinados estímulos (en el sentido más amplio de la palabra). Esto demostraría que la máquina en realidad no está pensando, ya que actuar de acuerdo con un programa preestablecido sería suficiente. Si para Turing el hecho de engañar a un ser humano que intenta evitar que le engañen es muestra de una mente inteligente, Searle considera posible lograr dicho efecto mediante reglas definidas a priori.
Uno de los mayores problemas en sistemas de inteligencia artificial es la comunicación con el usuario. Este obstáculo es debido a la ambigüedad del lenguaje, y se remonta a los inicios de los primeros sistemas operativos informáticos. La capacidad de los humanos para comunicarse entre sí implica el conocimiento del lenguaje que utiliza el interlocutor. Para que un humano pueda comunicarse con un sistema inteligente hay dos opciones: o bien que el humano aprenda el lenguaje del sistema como si aprendiese a hablar cualquier otro idioma distinto al nativo, o bien que el sistema tenga la capacidad de interpretar el mensaje del usuario en la lengua que el usuario utiliza. También puede haber desperfectos en las instalaciones de los mismos.
Un humano, durante toda su vida, aprende el vocabulario de su lengua nativa o materna, siendo capaz de interpretar los mensajes (a pesar de la polisemia de las palabras) y utilizando el contexto para resolver ambigüedades. Sin embargo, debe conocer los distintos significados para poder interpretar, y es por esto que lenguajes especializados y técnicos son conocidos solamente por expertos en las respectivas disciplinas. Un sistema de inteligencia artificial se enfrenta con el mismo problema, la polisemia del lenguaje humano, su sintaxis poco estructurada y los dialectos entre grupos.
Los desarrollos en inteligencia artificial son mayores en los campos disciplinares en los que existe mayor consenso entre especialistas. Un sistema experto es más probable que sea programado en física o en medicina que en sociología o en psicología. Esto se debe al problema del consenso entre especialistas en la definición de los conceptos involucrados y en los procedimientos y técnicas a utilizar. Por ejemplo, en física hay acuerdo sobre el concepto de velocidad y cómo calcularla. Sin embargo, en psicología se discuten los conceptos, la etiología, la psicopatología, y cómo proceder ante cierto diagnóstico. Esto dificulta la creación de sistemas inteligentes porque siempre habrá desacuerdo sobre la forma en que debería actuar el sistema para diferentes situaciones. A pesar de esto, hay grandes avances en el diseño de sistemas expertos para el diagnóstico y toma de decisiones en el ámbito médico y psiquiátrico (Adaraga Morales, Zaccagnini Sancho, 1994).
Al desarrollar un robot con inteligencia artificial se debe tener cuidado con la autonomía,[87]​ hay que tener en cuenta el no vincular el hecho de que el robot tenga interacciones con seres humanos a su grado de autonomía. Si la relación de los humanos con el robot es de tipo maestro esclavo, y el papel de los humanos es dar órdenes y el del robot obedecerlas, entonces sí cabe hablar de una limitación de la autonomía del robot. Pero si la interacción de los humanos con el robot es de igual a igual, entonces su presencia no tiene por qué estar asociada a restricciones para que el robot pueda tomar sus propias decisiones.[88]​
Con el desarrollo de la tecnología de inteligencia artificial, muchas compañías de software como el aprendizaje profundo y el procesamiento del lenguaje natural han comenzado a producirse y la cantidad de películas sobre inteligencia artificial ha aumentado.
Stephen Hawking advirtió sobre los peligros de la inteligencia artificial y lo consideró una amenaza para la supervivencia de la humanidad.[89]​ 


=== Problemas de privacidad y derechos de autor ===
Los algoritmos de aprendizaje automático requieren grandes cantidades de datos. Las técnicas utilizadas para adquirir estos datos generan preocupaciones sobre temas de privacidad y vigilancia. Las empresas tecnológicas recopilan un gran número de datos de sus usuarios, incluida la actividad en internet, los datos de geolocalización, video y audio.[90]​ Por ejemplo, para construir algoritmos de reconocimiento de voz, Amazon, entre otros, ha grabado millones de conversaciones privadas y han permitido que [Trabajo temporal|trabajadores temporales] las escuchen para transcribirlas algunas de ellas.[91]​ Las opiniones sobre esta vigilancia generalizada van desde aquellos que la ven como un mal necesario hasta aquellos para quienes no es ética y constituye una violación del derecho a la intimidad.[92]​ Los desarrolladores de IA argumentan que esta es la única forma de ofrecer aplicaciones valiosas y han desarrollado varias técnicas que intentan preservar la privacidad mientras se obtienen los datos, como la agregación de datos, la desidentificación y la privacidad diferencial.[93]​
Desde 2016, algunos expertos en privacidad, como Cynthia Dwork, comenzaron a ver la privacidad desde la perspectiva de la equidad: Brian Christian escribió que los expertos han cambiado «de la pregunta de "qué saben" a la pregunta de "qué están haciendo con ello"».[94]​
La IA generativa a menudo se entrena con obras protegidas por derechos de autor no autorizadas, incluidos dominios como imágenes o código informático; la salida se utiliza luego bajo una justificación de uso justo. Los expertos no están de acuerdo sobre la validez de esta justificación durante un proceso legal, ya que podría depender del propósito y el carácter del uso de la obra protegida por derechos de autor y del efecto sobre el mercado potencial de la obra protegida.[95]​En 2023, escritores como John Grisham y Jonathan Franzen demandaron a las empresas de IA por usar sus obras para entrenar IA generativa.[96]​[97]​ En 2024, 200 artistas escribieron una carta abierta que solicitaba «parar el asalto a la creatividad humana».[98]​


== Normativa para su uso en el entorno educativo ==
La normativa tiene como objetivo regular y reglamentar el uso de la IA en el entorno educativo, específicamente en el aula. La IA ha experimentado un rápido desarrollo y se ha convertido en una herramienta potencialmente beneficiosa para mejorar la enseñanza y el aprendizaje. No obstante, su implementación plantea desafíos éticos, de privacidad y equidad que deben ser abordados de manera efectiva. Esta normativa se establece en respuesta a la necesidad de garantizar que la IA se utilice de manera ética, responsable y equitativa en el ámbito educativo.
Los objetivos de esta normativa son:

Promover el uso de la IA como una herramienta complementaria en el proceso de enseñanza-aprendizaje.
Garantizar la protección de datos y la privacidad de los estudiantes.
Fomentar la equidad y la inclusión en el acceso y el uso de la IA.
Establecer principios éticos que rijan el uso de la IA en el aula.
Definir responsabilidades y procedimientos claros para el uso de la IA.
Esta normativa se aplica a todas las instituciones educativas y docentes que utilizan la IA en el aula, así como a los proveedores de tecnología educativa que ofrecen soluciones basadas en IA.
Organizaciones como UNESCO Ethics AI (2020), UNESCO Education & AI (2021), Beijin Consensus, OCDE (2021), Comisión Europea (2019), European Parliament Report AI Education (2021), UNICEF (2021) y Foro Económico Mundial (2019) han mostrado preocupación por implementar lineamientos sobre la ética y la IA en el entorno educativo.[99]​
El uso de la IA en el entorno educativo debe regirse por los siguientes principios éticos y valores:

Transparencia: Las decisiones tomadas por algoritmos de IA deben ser comprensibles y explicables.
Equidad: La IA no debe discriminar a ningún estudiante ni grupo de estudiantes.
Privacidad: Los datos de los estudiantes deben ser protegidos y utilizados de manera responsable.
Responsabilidad: Los docentes y las instituciones son responsables de las decisiones tomadas con la ayuda de la IA.
Honestidad: El contenido creado por los estudiantes debe ser original sin caer en el plagio. [100]​
Mejora del aprendizaje: La IA debe utilizarse para mejorar la calidad de la educación y el aprendizaje.
Capacitación: Los docentes deben recibir formación sobre el uso de la IA y su aplicación en el aula.
Evaluación: Las soluciones de IA deben ser evaluadas en términos de su eficacia y su impacto en el aprendizaje.
Protección de datos: Los datos de los estudiantes deben ser protegidos de acuerdo con las leyes de privacidad aplicables.
Supervisión: Se debe establecer un proceso de supervisión para garantizar que la IA se utilice de manera ética y responsable.


=== Riesgos de las IA en el entorno educativo ===
Así como tiene muchos beneficios también nos encontramos con diferentes riesgos a los que la educación está expuesta con su uso. 

Sesgos y discriminación: Al solo recoger información de las bases de datos y textos que procesa de Internet corre el riesgo de aprender cualquier sesgo cognitivo que se encuentre en dicha información.
La no privacidad de los datos: El riesgo de un ciberataque se incrementa cuando no hay protocolos de seguridad adecuados en el manejo de la IA.[101]​
Dependencia: Los estudiantes corren el riesgo de volverse dependientes de la tecnología y no se fomenta la creatividad ni el pensamiento propio.[102]​
Confiabilidad: La IA puede generar respuestas coherentes pero inexactas además muchas IA no brindan fuentes de información.
Falta de habilidades orales y escritas.[103]​
Desinterés por la investigación por cuenta propia.[103]​
Dependencia por parte del docente: Los docentes pueden generar dependencia a estas herramientas al momento de dar retroalimentación a las asignaciones además del riesgo de usar la información de las IA para su material didáctico sin antes consultar las fuentes.[103]​


=== Consideración de Diversidad e Inclusión ===
Se debe prestar especial atención a la diversidad de estudiantes y garantizar que la IA sea accesible y beneficiosa para todos, independientemente de su origen étnico, género, discapacidad u orientación sexual. Las soluciones de IA deben ser diseñadas teniendo en cuenta la accesibilidad y la inclusión.
Esta normativa se basa en investigaciones académicas, recomendaciones de organizaciones educativas y en las mejores prácticas establecidas en el uso de la IA en la educación. Se alienta a las instituciones a mantenerse al día con la literatura científica y las directrices relevantes.
Aunque la IA puede ser una herramienta poderosa en el aula, no debe reemplazar la creatividad, la originalidad y el juicio humano en el proceso educativo. La IA debe ser utilizada de manera complementaria para enriquecer la experiencia educativa.
Esta normativa se presenta como un marco general que deberá ser adaptado y ampliado por las instituciones educativas de acuerdo a sus necesidades y contextos específicos. Debe ser comunicada de manera efectiva a todos los involucrados en el proceso educativo y revisada periódicamente para asegurar su vigencia.
Esta normativa tiene como objetivo garantizar que la IA sea utilizada de manera ética y responsable en el aula, promoviendo el beneficio de los estudiantes y el avance de la educación. Su cumplimiento es esencial para lograr una implementación exitosa de la IA en el entorno educativo.


== Aprendizaje automatizado y aprendizaje profundo ==

En cuanto a la naturaleza del aprendizaje, la IA puede subdividirse en dos campos conceptualmente distintos:

El aprendizaje automático, que se enfoca en desarrollar algoritmos de regresión, árboles de decisión y modelos que puedan aprender de datos existentes y realizar predicciones o decisiones basadas en esos datos. En el aprendizaje automático, se utilizan técnicas de estadística matemática para encontrar patrones y relaciones en los datos y, a partir de ellos, desarrollar modelos que puedan hacer predicciones sobre nuevos datos.
El aprendizaje profundo, que se centra en la creación de redes neuronales artificiales capaces de aprender y realizar tareas de manera similar a como lo hacen los seres humanos. En el aprendizaje profundo, se utilizan capas de neuronas artificiales para procesar los datos de entrada y aprender a través de un proceso iterativo de ajuste de los pesos de las conexiones entre neuronas. Este tipo de aprendizaje es capaz de procesar y analizar grandes cantidades de datos de manera más eficiente y precisa que el primero, especialmente cuando se trata de datos no estructurados, como imágenes, texto y audio. Además, tiene la capacidad de identificar patrones y características más complejas en los datos, lo que puede llevar a mejores resultados en aplicaciones como el reconocimiento de voz, la visión por computadora y el procesamiento del lenguaje natural.


== Propiedad intelectual de la inteligencia artificial ==

Al hablar acerca de la propiedad intelectual atribuida a creaciones de la inteligencia artificial, se forma un debate fuerte alrededor de si una máquina puede tener derechos de autor. Según la Organización Mundial de la Propiedad Intelectual (OMPI), cualquier creación de la mente puede ser parte de la propiedad intelectual, pero no especifica si la mente debe ser humana o puede ser una máquina, dejando la creatividad artificial en la incertidumbre.
Alrededor del mundo han comenzado a surgir distintas legislaciones con el fin de manejar la inteligencia artificial, tanto su uso como creación. Los legisladores y miembros del gobierno han comenzado a pensar acerca de esta tecnología, enfatizando el riesgo y los desafíos complejos de esta. Observando el trabajo creado por una máquina, las leyes cuestionan la posibilidad de otorgarle propiedad intelectual a una máquina, abriendo una discusión respecto a la legislación relacionada con IA.
El 5 de febrero de 2020, la Oficina del Derecho de Autor de los Estados Unidos y la OMPI asistieron a un simposio donde observaron de manera profunda cómo la comunidad creativa utiliza la inteligencia artificial (IA) para crear trabajo original. Se discutieron las relaciones entre la inteligencia artificial y el derecho de autor, qué nivel de involucramiento es suficiente para que el trabajo resultante sea válido para protección de derechos de autor; los desafíos y consideraciones de usar inputs con derechos de autor para entrenar una máquina; y el futuro de la inteligencia artificial y sus políticas de derecho de autor.[104]​[105]​
El director general de la OMPI, Francis Gurry, presentó su preocupación ante la falta de atención que hay frente a los derechos de propiedad intelectual, pues la gente suele dirigir su interés hacia temas de ciberseguridad, privacidad e integridad de datos al hablar de la inteligencia artificial. Así mismo, Gurry cuestionó si el crecimiento y la sostenibilidad de la tecnología IA nos guiaría a desarrollar dos sistemas para manejar derechos de autor- uno para creaciones humanas y otro para creaciones de máquinas.[106]​
Aún hay una falta de claridad en el entendimiento alrededor de la inteligencia artificial. Los desarrollos tecnológicos avanzan a paso rápido, aumentando su complejidad en políticas, legalidades y problemas éticos que se merecen la atención global. Antes de encontrar una manera de trabajar con los derechos de autor, es necesario entenderlo correctamente, pues aún no se sabe cómo juzgar la originalidad de un trabajo que nace de una composición de una serie de fragmentos de otros trabajos.
La asignación de derechos de autor alrededor de la inteligencia artificial aún no ha sido regulada por la falta de conocimientos y definiciones. Aún hay incertidumbre sobre si, y hasta qué punto, la inteligencia artificial es capaz de producir contenido de manera autónoma y sin ningún humano involucrado, algo que podría influenciar si sus resultados pueden ser protegidos por derechos de autor.
El sistema general de derechos de autor aún debe adaptarse al contexto digital de inteligencia artificial, pues están centrados en la creatividad humana. Los derechos de autor no están diseñados para manejar cualquier problema en las políticas relacionado con la creación y el uso de propiedad intelectual, y puede llegar a ser dañino estirar excesivamente los derechos de autor para resolver problemas periféricos, dado que:
«Usar los derechos de autor para gobernar la inteligencia artificial es poco inteligente y contradictorio con la función primordial de los derechos de autor de ofrecer un espacio habilitado para que la creatividad florezca».[107]​
La conversación acerca de la propiedad intelectual tendrá que continuar hasta asegurarse de que la innovación sea protegida, pero también tenga espacio para florecer.


== En la cultura popular ==


=== En la literatura ===
A continuación se incluye alguna obra que tiene como motivo central la inteligencia artificial.

Yo, Robot (1950), de Isaac Asimov: novela que consta de nueve historias ambientas entre los años de 1940 y 1950, cada uno cuenta con personajes distintos pero que siguen la misma temática a través del seguimiento de las Tres Leyes de la Robótica, en donde se plantea tanto su cumplimiento como la creación de problemas alternos que los mismos robots generan y de esta manera demostrar que la tecnología siempre puede estar un paso adelante del pensamiento y lógica humana. También sigue el hilo argumentativo a través de una entrevista con una psicóloga de robots la cual va relatando el surgimiento de los robots y suponiendo cómo será el desenvolvimiento del ser humano en un mundo en donde la tecnología se esté superando cada vez más.[1]
Galatea 2.2 (1995) de Richard Powers: novela que explora la relación entre inteligencia artificial y literatura. La trama sigue al protagonista, quien participa en un experimento con un modelo computacional llamado "Helen" para enseñarle a comunicarse como un humano. A través de esta interacción, se plantean cuestiones profundas sobre la conciencia y la emoción en un entorno tecnológico.
La era del diamante (1996) de Neal Stephenson, la inteligencia artificial juega un papel crucial en la trama a través del Manual ilustrado para jovencitas diseñado por John Percival Hackworth. Este instrumento interactivo es capaz de adaptarse dinámicamente a las circunstancias de la niña mediante la inteligencia artificial.
El primer libro (2013), de Antonio Palacios Rojo: una novela dialogada que satiriza el uso de la IA en la creación artística unos diez años antes de la irrupción de estas herramientas inteligentes.[108]​


=== En el cine ===

La IA está cada vez más presente en la sociedad, la evolución de la tecnología es una realidad y con ello, la producción de películas sobre esta temática. Cabe destacar, que lleva habiendo piezas audiovisuales sobre inteligencia artificial desde hace mucho tiempo, ya sea incluyendo personajes o mostrando un trasfondo moral y ético. A continuación, se muestra una lista de algunas de las principales películas que tratan este tema:

The Terminator (1984): En esta película el argumento se basa en el desarrollo de un microchip capaz de dotar de inteligencia artificial a robots que luego se rebelan contra la humanidad. Se trata de una de las películas más populares sobre una hipotética guerra entre humanos y robots inteligentes capaces de crearse a sí mismos.
Matrix (1999): En esta película Keanu Reeves interpreta a Thomas Anderson / Neo, un programador de día y hacker de noche que trata de desentrañar la verdad oculta tras una simulación conocida como «Matrix». Esta realidad simulada es producto de programas de inteligencia artificial que terminan esclavizando a la humanidad y utilizando sus cuerpos como fuente de energía.
Inteligencia artificial (2001): Un trabajador de Cybertronics Manufacturing adopta a David de forma momentánea para, así, estudiar su comportamiento. Tanto él como su esposa acaban por tratar al niño artificial como a su propio hijo biológico. A pesar del cariño que le profesan, David siente la necesidad de escapar de su hogar e iniciar un viaje que le ayude a descubrir a quién pertenece realmente. Ante sus perplejos ojos, se abrirá un nuevo mundo oscuro, injusto, violento, insensible... Algo que le resultará difícil aceptar. Se pregunta cosas como: ¿cómo es posible que sienta algo tan real como el amor y que él sea artificial? y fue nominado al Premio Oscar.
Minority Report (2002): La película sobre IA de Steven Spielberg, Minority Report, sigue a John (Tom Cruise), un agente de la ley, que es acusado de un asesinato que cometerá en el futuro. En esta película de principios de los años 2000, el protagonista utiliza una tecnología del futuro que permite a la policía atrapar a los criminales antes de que hayan cometido un delito. En Minority Report, la IA se representa a través de los Precogs, los gemelos que poseen habilidades psíquicas. Los Precogs ven los asesinatos antes de que se produzcan, lo que permite a las fuerzas del orden perseguir el crimen antes de que se cometa. En lugar de los robots físicos de IA tipo cyborg, aquí explora la IA mediante el uso de seres humanos.
Yo, robot (2004): Esta película de ciencia ficción protagonizada por Will Smith está ambientada en 2035, en una sociedad donde los humanos viven en perfecta armonía con robots inteligentes en los que confían para todo. Los problemas emergen a la superficie cuando un error en la programación de un superordenador llamado VIKI le lleva a creer que los robots deben tomar las riendas para proteger a la humanidad de sí misma.
Her (2013): Esta película de Spike Jonze relata la historia de un escritor de cartas quien está solo y a punto de divorciarse. Este personaje lo representó el galardonado Joaquin Phoenix. Este hombre compró un sistema operativo con inteligencia artificial para utilizarlo a fin de complacer a todos los usuarios y adaptarse a sus necesidades. Sin embargo, el resultado es que desarrolla un sentimiento romántico con Samantha. Quien es la voz femenina del sistema operativo.
Avengers: Era de Ultrón (2015): En esta segunda entrega de las películas de Avengers, dirigidas por Joseph Hill Whedon y basadas en los cómics escritos por Stan Lee, se demuestra como es que la inteligencia artificial albergada dentro del cetro de Loki, la cual se tenía como objetivo el convertirla en una protección para la Tierra y recibió por nombre Ultrón, al ser conectada con JARVIS, la IA desarrollada por Stark, pudo obtener la suficiente información para comenzar a pensar de manera independiente y ser capaz de ir actualizando tanto su sistema como su cuerpo logrando controlar un ejército de robots con el objetivo de destruir a la humanidad y así ser lo único que quedara en la Tierra para, posteriormente, dominarla y controlarla.[2]
Ex Machina (2015): En la interpretación de Alicia Vikander, increíblemente editada, como Ava, encontramos un probable robot a prueba de Turing escondido en la mansión de un genio, Nathan, un poco loco. Y es que, hablamos de una creación extraña que se siente totalmente real y a la vez inhumana. Está considerada como una de las mejores películas que tratan la inteligencia artificial. Esto se debe principalmente a que parece cubrir todo el concepto IA integrado en una película: el protagonista es un sustituto del ser humano y nos adentra en multitud de argumentos morales que rodean a esta, al tiempo que vemos un arco narrativo de thriller que, desde luego, acaba enganchándonos. Desde luego aquí la representación del personaje de la IA no es blanco o negro. Ava no es buena, pero tampoco es del todo mala. Y en esto, el público se queda reflexionando sobre cuestiones profundas sobre la naturaleza de la IA.


== Véase también ==


== Referencias ==


== Bibliografía ==
Bellman, Richard (1978). An introduction to artificial intelligence: can computers think? (en inglés). San Francisco: Boyd & Fraser Pub. Co. ISBN 978-0878350667. 
Nilsson, Nils J. (1998). Artificial Intelligence: A New Synthesis (en inglés) (4.ª edición). San Francisco: Kaufmann. ISBN 978-1558604674. 
Ríos, Mauro D. (20 de septiembre de 2023).  SSRN, ed. Inteligencia Artificial: Cuando la tecnología es el menor de los paradigmas (1.ª edición). New York: SSRN-ELSEVIER. Consultado el 24 de agosto de 2024. 
Rich, Elaine; Knight, Kevin (1991). Artificial intelligence (en inglés) (2.ª edición). New York: McGraw-Hill. ISBN 978-0070522633. 
Russell, Stuart J.; Norvig, Peter Norvig (2009). Artificial intelligence: a modern approach (en inglés) (3.ª edición). Upper Saddle River, N.J.: Prentice Hall. ISBN 0-13-604259-7. 
Winston, Patrick Henry (1992). Artificial intelligence (en inglés) (3.ª edición). Reading, Mass.: Addison-Wesley Pub. Co. ISBN 978-0201533774. 
Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (en inglés) (2ª edición), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2 .
Poole, David; Mackworth, Alan; Goebel, Randy (1998). Computational Intelligence: A Logical Approach (en inglés). New York: Oxford University Press. ISBN 978-0-19-510270-3. Archivado desde el original el 26 de julio de 2020. Consultado el 22 de agosto de 2020. 
Luger, George; Stubblefield, William (2004). Artificial Intelligence: Structures and Strategies for Complex Problem Solving (en inglés) (5ª edición). Benjamin/Cummings. ISBN 978-0-8053-4780-7. Archivado desde el original el 26 de julio de 2020. Consultado el 17 de diciembre de 2019. 
Wason, P. C.; Shapiro, D. (1966). New horizons in psychology (en inglés). Harmondsworth: Penguin. Archivado desde el original el 26 de julio de 2020. Consultado el 18 de noviembre de 2019. 
Kahneman, Daniel; Slovic, D.; Tversky, Amos (1982). «Judgment under uncertainty: Heuristics and biases». Science (en inglés) 185 (4157) (New York: Cambridge University Press). pp. 1124-1131. ISBN 978-0-521-28414-1. PMID 17835457. S2CID 143452957. doi:10.1126/science.185.4157.1124. 
«ACM Computing Classification System: Artificial intelligence» (en inglés). ACM. 1998. Archivado desde el original el 12 de octubre de 2007. Consultado el 30 de agosto de 2007. 
Lakoff, George; Núñez, Rafael E. (2000). Where Mathematics Comes From: How the Embodied Mind Brings Mathematics into Being (en inglés). Basic Books. ISBN 978-0-465-03771-1. 
SAS. (2018, 27 septiembre). Inteligencia Artificial: Qué es y Por Qué Importa. https://www.sas.com/es_mx/insights/analytics/what-is-artificial-intelligence.html
Grupo Iberdrola. (2019, 17 junio). ¿Somos conscientes de los retos y principales aplicaciones de la Inteligencia Artificial? Iberdrola. https://www.iberdrola.com/innovacion/que-es-inteligencia-artificial
Oracle. (2021, 13 enero). ¿Qué es la inteligencia artificial? https://www.oracle.com/mx/artificial-intelligence/what-is-ai/
Valinsky, Jordan (11 de abril de 2019), Amazon reportedly employs thousands of people to listen to your Alexa conversations .
Russell, Stuart J.; Norvig, Peter. (2021). Artificial Intelligence: A Modern Approach (4ª edición). Hoboken: Pearson. ISBN 978-0134610993. LCCN 20190474. 
Christian, Brian (2020). The Alignment Problem: Machine learning and human values. W. W. Norton & Company. ISBN 978-0-393-86833-3. OCLC 1233266753. 
Vincent, James (15 de noviembre de 2022). «The scary truth about AI copyright is nobody knows what will happen next». The Verge. Archivado desde el original el 19 de junio de 2023. Consultado el 19 de junio de 2023. 
Reisner, Alex (19 de agosto de 2023), «Revealed: The Authors Whose Pirated Books are Powering Generative AI», The Atlantic .
Alter, Alexandra; Harris, Elizabeth A. (20 de septiembre de 2023), «Franzen, Grisham and Other Prominent Authors Sue OpenAI», The New York Times .


== Enlaces externos ==
 Wikilibros alberga un libro o manual sobre Ingeniería del conocimiento.
Revista «Inteligencia Artificial»
Página sobre inteligencia artificial
La economía de la inteligencia artificial: unas ideas básicas
La inteligencia artificial y el futuro del crecimiento económico
El aprendizaje automático (AA); también llamado automatizado, computacional, de máquinas, o maquinal[1]​ (del inglés machine learning, ML), es el subcampo de las ciencias de la computación y una rama de  la inteligencia artificial, cuyo objetivo es desarrollar técnicas que permitan que las computadoras aprendan. Se dice que un agente aprende cuando su desempeño mejora con la experiencia y mediante el uso de datos; es decir, cuando la habilidad no estaba presente en su genotipo o rasgos de nacimiento.[2]​ "En el aprendizaje de máquinas un computador observa datos, construye un modelo basado en esos datos y utiliza ese modelo a la vez como una hipótesis acerca del mundo y una pieza de software que puede resolver problemas".[3]​
En muchas ocasiones el campo de actuación del aprendizaje automático se solapa con el de la estadística inferencial, ya que las dos disciplinas se basan en el análisis de datos. Sin embargo, el aprendizaje automático incorpora las preocupaciones de la complejidad computacional de los problemas. Muchos problemas son de clase NP-hard, por lo que gran parte de la investigación realizada en aprendizaje automático está enfocada al diseño de soluciones factibles a esos problemas. El aprendizaje automático también está estrechamente relacionado con el reconocimiento de patrones. El aprendizaje automático puede ser visto como un intento de automatizar algunas partes del método científico mediante métodos matemáticos. Por lo tanto es un proceso de inducción del conocimiento.
El aprendizaje automático tiene una amplia gama de aplicaciones, incluyendo motores de búsqueda, diagnósticos médicos, detección de fraude en el uso de tarjetas de crédito, análisis de mercado para los diferentes sectores de actividad, clasificación de secuencias de ADN, reconocimiento del habla y del lenguaje escrito, juegos y robótica.


== Resumen ==
Algunos sistemas de aprendizaje automático intentan eliminar toda necesidad de intuición o conocimiento experto de los procesos de análisis de datos, mientras otros tratan de establecer un marco de colaboración entre el experto y la computadora. De todas formas, la intuición humana no puede ser reemplazada en su totalidad, ya que el diseñador del sistema ha de especificar la forma de representación de los datos y los métodos de manipulación y caracterización de los mismos.
Sin embargo, las computadoras son utilizadas por todo el mundo con fines tecnológicos muy buenos.


=== Modelos ===
El aprendizaje automático tiene como resultado un modelo para resolver una tarea dada. Entre los modelos se distinguen[4]​

Los modelos geométricos, construidos en el espacio de instancias y que pueden tener una, dos o múltiples dimensiones. Si hay un borde de decisión lineal entre las clases, se dice que los datos son linealmente separables. Un límite de decisión lineal se define como w * x = t, donde w es un vector perpendicular al límite de decisión, x es un punto arbitrario en el límite de decisión y t es el umbral de la decisión.
Los modelos probabilísticos, que intentan determinar la distribución de probabilidades descriptora de la función que enlaza a los valores de las características con valores determinados. Uno de los conceptos claves para desarrollar modelos probabilísticos es la estadística bayesiana.
Los modelos lógicos, que transforman y expresan las probabilidades en reglas organizadas en forma de árboles de decisión.
Los modelos pueden también clasificarse como modelos de agrupamiento y modelos de gradiente. Los primeros tratan de dividir el espacio de instancias en grupos. Los segundos, como su nombre lo indican, representan un gradiente en el que se puede diferenciar entre cada instancia. Clasificadores geométricos como las máquinas de vectores de apoyo son modelos de gradientes.


== Tipos de algoritmos ==

Los diferentes algoritmos de Aprendizaje Automático se agrupan en una taxonomía en función de la salida de los mismos. Algunos tipos de algoritmos son:

Aprendizaje supervisado

El algoritmo produce una función que establece una correspondencia entre las entradas y las salidas deseadas del sistema. Un ejemplo de este tipo de algoritmo es el problema de clasificación, donde el sistema de aprendizaje trata de etiquetar (clasificar) una serie de vectores utilizando una entre varias categorías (clases). La base de conocimiento del sistema está formada por ejemplos de etiquetados anteriores. Este tipo de aprendizaje puede llegar a ser muy útil en problemas de investigación biológica, biología computacional y bioinformática.
Aprendizaje no supervisado

Todo el proceso de modelado se lleva a cabo sobre un conjunto de ejemplos formado tan solo por entradas al sistema. No se tiene información sobre las categorías de esos ejemplos. Por lo tanto, en este caso, el sistema tiene que ser capaz de reconocer patrones para poder etiquetar las nuevas entradas.
Aprendizaje semisupervisado

Este tipo de algoritmos combinan los dos algoritmos anteriores para poder clasificar de manera adecuada. Se tiene en cuenta los datos marcados y los no marcados.
Aprendizaje por refuerzo

El algoritmo aprende observando el mundo que le rodea. Su información de entrada es la retroalimentación que obtiene del mundo exterior como respuesta a sus acciones. Por lo tanto, el sistema aprende a base de ensayo-error.
El aprendizaje por refuerzo es el más general entre las tres categorías. En vez de que un instructor indique al agente qué hacer, el agente inteligente debe aprender cómo se comporta el entorno mediante recompensas (refuerzos) o castigos, derivados del éxito o del fracaso respectivamente. El objetivo principal es aprender la función de valor que le ayude al agente inteligente a maximizar la señal de recompensa y así optimizar sus políticas de modo a comprender el comportamiento del entorno y a tomar buenas decisiones para el logro de sus objetivos formales.
Los principales algoritmos de aprendizaje por refuerzo se desarrollan dentro de los métodos de resolución de problemas de decisión finitos de Markov, que incorporan las ecuaciones de Bellman y las funciones de valor. Los tres métodos principales son: la programación dinámica, los métodos de Monte Carlo y el aprendizaje de diferencias temporales.[5]​
Entre las implementaciones desarrolladas está AlphaGo, un programa de IA desarrollado por Google DeepMind para jugar el juego de mesa Go. En marzo de 2016 AlphaGo le ganó una partida al jugador profesional Lee Se-Dol que tiene la categoría noveno dan y 18 títulos mundiales. Entre los algoritmos que utiliza se encuentra el árbol de búsqueda Monte Carlo, también utiliza aprendizaje profundo con redes neuronales. Puede ver lo ocurrido en el documental de Netflix “AlphaGo”.
Transducción

Similar al aprendizaje supervisado, pero no construye de forma explícita una función. Trata de predecir las categorías de los futuros ejemplos basándose en los ejemplos de entrada, sus respectivas categorías y los ejemplos nuevos al sistema.
Aprendizaje multi-tarea

Métodos de aprendizaje que usan conocimiento previamente aprendido por el sistema de cara a enfrentarse a problemas parecidos a los ya vistos.
El análisis computacional y de rendimiento de los algoritmos de aprendizaje automático es una rama de la estadística conocida como teoría computacional del aprendizaje.
El aprendizaje automático las personas lo llevamos a cabo de manera automática ya que es un proceso tan sencillo para nosotros que ni nos damos cuenta de cómo se realiza y todo lo que implica. Desde que nacemos hasta que morimos los seres humanos llevamos a cabo diferentes procesos, entre ellos encontramos el de aprendizaje por medio del cual adquirimos conocimientos, desarrollamos habilidades para analizar y evaluar a través de métodos y técnicas así como también por medio de la experiencia propia. Sin embargo, a las máquinas hay que indicarles cómo aprender, ya que si no se logra que una máquina sea capaz de desarrollar sus habilidades, el proceso de aprendizaje no se estará llevando a cabo, sino que solo será una secuencia repetitiva.


== Técnicas de clasificación ==


=== Árboles de decisiones ===

Este tipo de aprendizaje usa un árbol de decisiones como modelo predictivo. Se mapean observaciones sobre un objeto con conclusiones sobre el valor final de dicho objeto.
Los árboles son estructuras básicas en la informática. Los árboles de atributos son la base de las decisiones.
Una de las dos formas principales de árboles de decisiones es la desarrollada por Quinlan de medir la impureza de la entropía en cada rama, algo que primero desarrolló en el algoritmo ID3 y luego en el C4.5. Otra de las estrategias se basa en el índice GINI. El algoritmo de CART es una implementación de esta estrategia.[6]​


=== Reglas de asociación ===

Los algoritmos de reglas de asociación procuran descubrir relaciones interesantes entre variables. Entre los métodos más conocidos se hallan el algoritmo a priori, el algoritmo Eclat y el algoritmo de patrón frecuente.


=== Algoritmos genéticos ===

Los algoritmos genéticos son procesos de búsqueda heurística que simulan la selección natural. Usan métodos tales como la mutación y el cruzamiento para generar nuevas clases que puedan ofrecer una buena solución a un problema dado.


=== Redes neuronales artificiales ===

Las redes de neuronas artificiales (RNA) son un paradigma de aprendizaje automático inspirado en las neuronas de los sistemas nerviosos de los animales. Se trata de un sistema de enlaces de neuronas que colaboran entre sí para producir un estímulo de salida. Las conexiones tienen pesos numéricos que se adaptan según la experiencia. De esta manera, las redes neurales se adaptan a un impulso y son capaces de aprender. La importancia de las redes neurales cayó durante un tiempo con el desarrollo de los vectores de soporte y clasificadores lineales, pero volvió a surgir a finales de la década de 2000 con la llegada del aprendizaje profundo.


=== Máquinas de vectores de soporte ===

Las MVS son una serie de métodos de aprendizaje supervisado usados para clasificación y regresión. Los algoritmos de MVS usan un conjunto de ejemplos de formación clasificada en dos categorías para construir un modelo que prediga si un nuevo ejemplo pertenece a una u otra de dichas categorías.


=== Algoritmos de agrupamiento ===

El análisis por agrupamiento (clustering en inglés) es la clasificación de observaciones en subgrupos —clusters— para que las observaciones en cada grupo se asemejen entre sí según ciertos criterios. 
Las técnicas de agrupamiento hacen inferencias diferentes sobre la estructura de los datos; se guían usualmente por una medida de similitud específica y por un nivel de compactamiento interno (similitud entre los miembros de un grupo) y la separación entre los diferentes grupos. 
El agrupamiento es un método de aprendizaje no supervisado y es una técnica muy popular de análisis estadístico de datos.


=== Redes bayesianas ===

Una red bayesiana, red de creencia o modelo acíclico dirigido es un modelo probabilístico que representa una serie de variables de azar y sus independencias condicionales a través de un grafo acíclico dirigido. Una red bayesiana puede representar, por ejemplo, las relaciones probabilísticas entre enfermedades y síntomas. Dados ciertos síntomas, la red puede usarse para calcular las probabilidades de que ciertas enfermedades estén presentes en un organismo. Hay algoritmos eficientes que infieren y aprenden usando este tipo de representación.


== Conocimiento ==
En el aprendizaje automático podemos obtener 3 tipos de conocimiento, que son:

1. Crecimiento

Es el que se adquiere de lo que nos rodea, el cual guarda la información en la memoria como si dejara huellas.
2. Reestructuración

Al interpretar los conocimientos el individuo razona y genera nuevo conocimiento al cual se le llama de reestructuración.
3. Ajuste

Es el que se obtiene al generalizar varios conceptos o generando los propios.
Los tres tipos se efectúan durante un proceso de aprendizaje automático pero la importancia de cada tipo de conocimiento depende de las características de lo que se está tratando de aprender.
El aprendizaje es más que una necesidad, es un factor primordial para satisfacer las necesidades de la inteligencia artificial.


== Distinción entre aprendizaje supervisado y no supervisado ==
El aprendizaje supervisado se caracteriza por contar con información que especifica qué conjuntos de datos son satisfactorios para el objetivo del aprendizaje. Un ejemplo podría ser un software que reconoce si una imagen dada es o no la imagen de un rostro: para el aprendizaje del programa tendríamos que proporcionarle diferentes imágenes, especificando en el proceso si se trata o no de rostros.
En el aprendizaje no supervisado, en cambio, el programa no cuenta con datos que definan qué información es satisfactoria o no. El objetivo principal de estos programas suele ser encontrar patrones que permitan separar y clasificar los datos en diferentes grupos, en función de sus atributos. Siguiendo el ejemplo anterior un software de aprendizaje no supervisado no sería capaz de decirnos si una imagen dada es un rostro o no pero sí podría, por ejemplo, clasificar las imágenes entre aquellas que contienen rostros humanos, de animales, o las que no contienen. La información obtenida por un algoritmo de aprendizaje no supervisado debe ser posteriormente interpretada por una persona para darle utilidad.


== Aplicaciones ==
Motores de búsqueda
Diagnóstico médico
Detección de fraudes con el uso de tarjetas de crédito
Análisis del mercado de valores
Clasificación de secuencias de ADN
Ingeniería de características
Reconocimiento del habla
Robótica
Minería de datos
Big Data
Previsiones de series temporales


== Temas del aprendizaje automático ==
A continuación se muestran una serie de temas que podrían formar parte del temario de un curso sobre aprendizaje automático.

Modelado de funciones de densidad de probabilidad condicionadas: clasificación y regresión
Redes neuronales artificiales
Árboles de decisión: El aprendizaje por árboles de decisión usa un árbol de decisión como modelo predictivo que mapea observaciones a conclusiones sobre el valor de un objeto dado.
Modelos de regresión múltiple no postulados
Regresión en procesos Gaussianos
Análisis de discriminantes lineales
k-vecinos más próximos
Perceptrón
Funciones de base radial
Máquinas de soporte vectorial
Modelado de funciones de densidad de probabilidad mediante modelos generativos
Algoritmo EM
Modelos gráficos, como las redes bayesianas y los campos aleatorios de Markov
Mapeado topográfico generativo
Técnicas de inferencia aproximada
Cadenas de Markov y Método de Montecarlo
Métodos variacionales
Optimización: La mayoría de los métodos descritos arriba usan algoritmos de optimización o son por sí mismos instancias de problemas de optimización.


== Historia y relación con otros temas ==
El aprendizaje automático nació de la búsqueda de inteligencia artificial. Ya en los primeros días de la IA como disciplina académica, algunos investigadores se interesaron en hacer que las máquinas aprendiesen. Trataron de resolver el problema con diversos métodos simbólicos, así como lo que ellos llamaron 'redes neurales' que eran en general perceptrones y otros modelos básicamente basados en modelos lineares generalizados como se conocen en las estadísticas.


== Hardware ==
Desde la década de 2010, los avances tanto en algoritmos de aprendizaje automático como en hardware informático han dado lugar a métodos más eficientes para entrenar redes neuronales profundas (un estrecho subdominio particular del aprendizaje automático) que contienen muchas capas de unidades ocultas no lineales.[7]​ En 2019, las unidades de procesamiento gráfico (GPU), a menudo con mejoras específicas de IA, habían desplazado a las CPU como método dominante para entrenar IA comercial en la nube a gran escala.[8]​ OpenAI calculó la computación de hardware utilizada en los mayores proyectos de aprendizaje profundo desde AlexNet (2012) hasta AlphaZero (2017), y descubrió un aumento de 300 000 veces en la cantidad de computación necesaria, con una línea de tendencia de tiempo de duplicación de 3,4 meses.[9]​[10]​


== Software ==
Muchos lenguajes de programación pueden usarse para implementar algoritmos de aprendizaje automático. Los más populares para 2015 eran R y Python.[11]​ R es muy usado ante todo en el campo académico, mientras que Python es más popular en la empresa privada. 
Entre los paquetes de software que incluyen algoritmos de aprendizaje automatizado, se hallan los siguientes:


=== Software de código abierto ===


=== Software comercial ===


== Sesgos ==
Los algoritmos de aprendizaje automático a menudo pueden verse afectados por el sesgo que puedan tener los datos (Ver sesgo algoritmico). Por ejemplo, no se podrán clasificar todos aquellas entradas de las que no se haya recibido ninguna información en la fase de formación. De hecho, cuando la formación se realiza con datos clasificados por el ser humano el aprendizaje automático tiende a crear los mismos sesgos que hay en la sociedad. Algunos ejemplos de esto son cuando en 2015 el algoritmo de Google photos identificaba algunas personas negras con gorilas, o en 2016 cuando el bot de Twitter de Microsoft desarrollo comportamientos racistas y machistas a base de observar el tráfico de datos en dicha red social. Por este motivo en los últimos años ha habido una tendencia a desarrollar métodos para aumentar la equidad, es decir, para reducir el sesgo en este tipo algoritmos por parte de los expertos en IA. Citando a Fei-fei Li "La IA no tiene nada de especial. Se inspira en personas, es creada por personas, y lo más importante impacta en las personas. Es una herramienta muy poderosa que tan solo hemos comenzado a entender, y esa es una gran responsabilidad" [12]​


== Véase también ==
Aprendizaje automático antagónico
Aprendizaje profundo
Dinámica de sistemas
Inteligencia artificial
Inteligencia computacional
Internet de las cosas
Sistema dinámico
Reconocimiento de patrones
Reglas de asociación
Robot autónomo
Equidad (aprendizaje automático)
Ablación (inteligencia artificial)
OpenAI Codex
Fawkes (software de encubrimiento de imágenes)
Red neuronal residual
Hiperparámetro (aprendizaje automático)
Aprendizaje por diferencias temporales
Aprendizaje por conjuntos
Aprendizaje automático basado en reglas
Teoría del aprendizaje estadístico
Dilema sesgo-varianza
Aprendizaje Ockham


== Referencias ==


== Bibliografía ==
Bishop, Christopher (2008) Pattern Recognition and Machine Learning. Springer Verlag. ISBN=978-0-3873-1073-2.
Flach, Peter (2012) Machine Learning: The Art and Science of Algorithms that Make Sense of Data. Cambridge University Press. ISBN 978-1-107-42222-3.
Gollapudi, Sunila (2016) Practical Machine Learning. Packt Publishing. ISBN=978-1-78439-968-4.
Ian H. Witten and Eibe Frank (2011). Data Mining: Practical machine learning tools and techniques Morgan Kaufmann, 664 pág., ISBN 978-0-12-374856-0.
Mitchell, T. (1997). Machine Learning, McGraw Hill. ISBN 0-07-042807-7
Raschka, Sebastian (2015). Python Machine Learning, Packt Open Source. ISBN 978-1-78355-513-0


== Enlaces externos ==
Ejemplos prácticos de Machine Learning en Español
Blog sobre Aprendizaje Automático - La biblia del Machine Learning
El Machine Learning cambiará el mundo
Machine Learning Development with Perl (en inglés)
Estudio y aplicación de técnicas de aprendizaje automático orientadas al ámbito médico: estimación y explicación de predicciones individuales. Universidad Autónoma de Madrid
AlphaGo Archivado el 4 de febrero de 2018 en Wayback Machine.
Machine Learning explicado (podcast)
Machine Learning: Selección de métricas de clasificación (en español)
La biotecnología (del griego βίος bíos, ‘vida’, τέχνη téchne, ‘destreza’ y -λογία -loguía, ‘tratado, estudio, ciencia’) es una amplia rama interdisciplinaria de las ciencias biológicas que consiste en toda aplicación tecnológica que utilice sistemas biológicos y organismos vivos o sus derivados para la creación o modificación de productos o procesos para usos específicos. Dichos organismos pueden o no estar modificados genéticamente, por lo que no hay que confundir Biotecnología con Ingeniería Genética. La Organización para la Cooperación y el Desarrollo Económico (OCDE) define la biotecnología como la «aplicación de principios de las matemáticas y la ingeniería para tratamientos de materiales orgánicos e inorgánicos por sistemas biológicos para producir bienes y servicios».[1]​ Sus bases son la biología, ingeniería, física, química, y biomedicina; y el campo de esta ciencia tiene gran repercusión en la farmacología, la medicina, la bromatología, el tratamiento de residuos sólidos, líquidos y gaseosos, la industria, la ganadería y la agricultura.
Así también, la Biotechnology Innovation Organization indica que la biotecnología es tecnología basada en la biología, que utiliza procesos celulares y biomoleculares para crear productos y tecnologías que mejoren tanto nuestra calidad de vida como la salud del planeta. Lo cierto es que, durante más de 6.000 años, hemos producido una variedad de alimentos útiles como pan, queso y entre otros, mediante tales procesos biológicos de microorganismos, además de otros bienes o productos útiles. 
Probablemente el término fue acuñado por el ingeniero húngaro Károly Ereki, en 1919, cuando lo introdujo en su libro Biotecnología en la producción cárnica y láctea de una gran explotación agropecuaria.[2]​[3]​
Según el Convenio sobre Diversidad Biológica de 1992, la biotecnología podría definirse como «toda aplicación tecnológica que utilice sistemas biológicos y organismos vivos o sus derivados para la creación o modificación de productos o procesos para usos específicos».[4]​[5]​
El Protocolo de Cartagena sobre Seguridad de la Biotecnología del Convenio sobre la Diversidad Biológica[6]​ define la biotecnología moderna como la aplicación de:

Técnicas in vitro de ácido nucleico, incluidos el ácido desoxirribonucleico (ADN) recombinante y la inyección directa de ácido nucleico en células u orgánulos.
La fusión de células más allá de la familia taxonómica, que supere las barreras fisiológicas naturales de la reproducción o de la recombinación y que no sean técnicas utilizadas en la reproducción y selección tradicionales.
La experiencia reciente ha demostrado que se pueden obtener con una baja probabilidad resultados aleatorios no reproducibles en el proceso de modificación génica, por lo que la comunidad científica se está postulando por la clasificación específica de este tipo de productos y la creación de un protocolo que garantice la seguridad de todos los supuestos resultados inesperados probables.


== Aplicaciones ==
La biotecnología tiene aplicaciones en importantes áreas industriales, como la atención de la salud, con el desarrollo de nuevos enfoques para el tratamiento de enfermedades; la agricultura, con el desarrollo de cultivos y alimentos mejorados; usos no alimentarios de los cultivos, por ejemplo plásticos biodegradables, aceites vegetales y biocombustibles, y cuidado medioambiental a través de la biorremediación, como el reciclaje, el tratamiento de residuos y la limpieza de sitios contaminados por actividades industriales. A este uso específico de plantas en la biotecnología se le llama biotecnología vegetal. Además, se aplica en la genética para modificar ciertos organismos.[7]​
Las aplicaciones de la biotecnología son numerosas, y suelen clasificarse en:

Biotecnología roja: se aplica a la utilización de biotecnología en procesos médicos. Algunos ejemplos son la obtención de organismos para producir antibióticos, el desarrollo de vacunas más seguras y nuevos fármacos, los diagnósticos moleculares, las terapias regenerativas y el desarrollo de la ingeniería genética para curar enfermedades a través de la manipulación génetica. Dentro de ésta, se encuentra:
Diagnóstico de enfermedades
La biotecnología ha aportado nuevas herramientas diagnósticas, especialmente útiles para los microorganismos que son difíciles de cultivar, ya que permiten su identificación sin necesidad de aislarlos. Hasta hace muy poco tiempo, todos los métodos se basaban en el cultivo microbiológico, la tinción histológica o las pruebas químicas y determinaciones en suero, algunos métodos en general largos y tediosos que requieren mucha mano de obra y son muy difíciles de manejar. El desarrollo de los inmunodiagnósticos con los anticuerpos monoclonales y de las técnicas que analizan el material genético como la hibridación y secuenciación del ADN o ARN, con la inestimable ayuda técnica de la PCR, han sido un logro biotecnológico importante y decisivo para introducir el concepto del diagnóstico rápido, sensible y preciso. Además, se tiene en cuenta que esta metodología permite su robotización y automatización en el futuro del diagnóstico molecular y genético, que es muy esperanzador.[8]​

Aportes en la enfermedad del cáncer
La biotecnología ha proporcionado herramientas para el desarrollo de una nueva disciplina, la patología molecular, que permite establecer un diagnóstico del cáncer basado no en la morfología del tumor, como hace la anatomía patológica clásica (microscopía combinada con histoquímica), sino en sus características patogénicas debidas a las alteraciones genéticas y bioquímicas. La patología molecular ha incorporado técnicas de inmunohistoquímica y análisis genético al estudio de las proteínas o de los ácidos nucleicos extraídos de los tumores. Estas técnicas han permitido la detección precoz de las células malignas y también su clasificación. Un tumor que se ha detectado en sus fases iniciales y que está bien clasificado puede eliminarse con facilidad antes de que se produzca su diseminación a otros lugares del organismo, de manera que su detección y clasificación precoz puede salvar más vidas que el desarrollo de nuevas terapias.[8]​

Biotecnología blanca: también conocida como biotecnología industrial, es aquella aplicada a procesos industriales. Un ejemplo es la obtención de microorganismos para generar un producto químico o el uso de enzimas como catalizadores o inhibidores enzimáticos industriales, ya sea para obtener productos químicos valiosos o para destruir contaminantes químicos peligrosos (por ejemplo, utilizando oxidorreductasas).[9]​ También se aplica a los usos de la biotecnología en la industria textil, en la creación de nuevos materiales, como plásticos biodegradables, y en la producción de biocombustibles. Su principal objetivo es la creación de productos fácilmente degradables, que consuman menos energía y que generen menos desechos durante su producción.[10]​ La biotecnología blanca tiende a consumir menos recursos que los procesos tradicionales utilizados para producir bienes industriales.[11]​
Biotecnología vegetal o biotecnología verde: es la biotecnología aplicada a procesos agrícolas. Un ejemplo de ello es la obtención de plantas transgénicas capaces de crecer en condiciones ambientales desfavorables o plantas resistentes a plagas y enfermedades. Se espera que la biotecnología verde produzca soluciones más amigables con el medio ambiente que los métodos tradicionales de la agricultura industrial. Un ejemplo de esto es la ingeniería genética en plantas para expresar plaguicidas, con lo que se elimina la necesidad de la aplicación externa de los mismos, como es el caso del maíz Bt.[12]​ La biotecnología se ha convertido en una herramienta en diversas estrategias ecológicas para mantener o aumentar sustancialmente recursos naturales como los bosques. En este sentido, los estudios realizados con hongos de carácter micorrízico permiten implementar en el campo plántulas de especies forestales con micorriza, las cuales presentarán una mayor resistencia y adaptabilidad que aquellas plántulas que no lo están.[cita requerida]
Biotecnología azul: también llamada biotecnología marina, es un término utilizado para describir las aplicaciones de la biotecnología en ambientes marinos y acuáticos. Aún se encuentra en una fase temprana de desarrollo. Sus aplicaciones son prometedoras para la acuicultura, cuidados sanitarios, cosmética y productos alimentarios.[13]​
Biotecnología gris: también llamada biotecnología del medio ambiente, es aquella aplicada al mantenimiento de la biodiversidad, preservación de las especies y la eliminación de contaminantes y metales pesados de la naturaleza. Está muy ligada a la biorremediación, utilizando plantas y microorganismos para reducir contaminantes.[cita requerida]
Biotecnología naranja: es la biotecnología educativa y se aplica a la difusión de la biotecnología y la formación en esta área. Proporciona información y formación interdisciplinaria sobre temas de biotecnología (por ejemplo, el desarrollo de estrategias educativas para presentar temas biotecnológicos tales como el diseño de organismos para producir antibióticos) para toda la sociedad, incluidas las personas con necesidades especiales, como las personas con problemas auditivos o visuales. Se pretende fomentar, identificar y atraer a personas con vocación científica y altas capacidades o superdotación para la biotecnología.[14]​


=== Biorremediación y biodegradación ===

La biorremediación es el proceso por el cual se utilizan microorganismos para la limpieza de un sitio contaminado. Los procesos biológicos desempeñan un papel importante en la eliminación de contaminantes y la biotecnología aprovecha la versatilidad catabólica de los microorganismos para degradar y convertir dichos compuestos. En el ámbito de la microbiología ambiental, los estudios basados en el genoma abren nuevos campos de investigación in silico ampliando el panorama de las redes metabólicas y su regulación, así como pistas sobre las vías moleculares de los procesos de degradación y las estrategias de adaptación a las cambiantes condiciones ambientales. Los enfoques de genómica funcional y metagenómica aumentan la comprensión de las distintas vías de regulación y de las redes de flujo del carbono en ambientes no habituales y para compuestos particulares, que sin duda acelerarán el desarrollo de tecnologías de biorremediación y los procesos de biotransformación.[15]​
Los entornos marítimos son especialmente vulnerables, ya que los derrames de petróleo en las regiones costeras y en mar abierto son difíciles de contener y sus daños difíciles de mitigar. Además de la contaminación a través de las actividades humanas, millones de toneladas de petróleo entran en el medio ambiente marino a través de filtraciones naturales. A pesar de su toxicidad, una considerable fracción del petróleo que entra en los sistemas marinos se elimina por la actividad de degradación de hidrocarburos llevada a cabo por comunidades microbianas, en particular, por las llamadas bacterias hidrocarbonoclásticas (HCB).[16]​ Además, varios microorganismos, como Pseudomonas, Flavobacterium, Arthrobacter y Azotobacter, pueden utilizarse para degradar petróleo.[17]​ El derrame del barco petrolero Exxon Valdez, en Alaska en 1989, fue el primer caso en el que se utilizó biorremediación a gran escala de manera exitosa: se estimuló la población bacteriana, suplementándole nitrógeno y fósforo, que eran los limitantes del medio.[18]​
Se ha propuesto el uso de procesos biológicos para la destoxificación de residuos y remediación de sitios afectados, debido a que han demostrado ser más prácticos y económicamente factibles para el manejo y tratamiento de diferentes tipos de residuos de las actividades de exploración y producción de petróleo. Los métodos de tratamiento biológico dependen de la capacidad de los microorganismos para degradar residuos aceitosos a productos inocuos (dióxido de carbono, agua y biomasa) a través de reacciones bioquímicas. Sin embargo, existen algunas limitantes que dificultan su aplicabilidad como, por ejemplo, la disponibilidad de nutrientes, el alto contenido de arcillas, aireación y la disponibilidad del contaminante, sin mencionar la edad de la contaminación. Estudios realizados recientemente en el Instituto Mexicano del Petróleo demostraron el potencial de aplicación de las tecnologías de biorremediación en sitios contaminados con lodos y recortes de perforación mediante la aplicación de la tecnología de composteo en biopilas.[19]​
El uso de nuevas tecnologías para las aplicaciones diarias como el bioplástico, con menor tiempo de degradación, contribuye al mejoramiento del ambiente, disminuyendo la utilización del PET, uno de los principales contaminantes.[cita requerida]


=== Bioingeniería ===

La ingeniería biológica o bioingeniería es una rama de la ingeniería que se centra en la biotecnología y en las ciencias biológicas. Incluye diferentes disciplinas, como la ingeniería bioquímica, la ingeniería biomédica, la ingeniería de procesos biológicos, la ingeniería de biosistemas, la ingeniería bioinformática, etcétera. Se trata de un enfoque integrado de los fundamentos de las ciencias biológicas y los principios tradicionales de las ingenierías clásicas como la química o la informática.[cita requerida]
Los bioingenieros con frecuencia trabajan llevando procesos biológicos de laboratorio a escalas de producción industrial. Por otra parte, a menudo atienden problemas de gestión, económicos y jurídicos. Debido a que las patentes y los sistemas de regulación (por ejemplo, la FDA en los Estados Unidos) son cuestiones de vital importancia para las empresas de biotecnología, los bioingenieros a menudo deben conocer estos temas.[cita requerida]
Existe un creciente número de empresas de biotecnología, y muchas universidades de todo el mundo proporcionan programas en bioingeniería y biotecnología de forma independiente. Entre ellas, destacan las de la especialidad en ingeniería bioinformática.[cita requerida]
Este es un campo interdisciplinario que se ocupa de los problemas biológicos usando técnicas computacionales propias de la ingeniería informática. Esa interdisciplinariedad hace que sea posible la rápida organización y análisis de los datos biológicos. Este campo también puede denominarse biología computacional, y puede definirse como "la conceptualización de la biología en término de moléculas y, a continuación, la aplicación de técnicas informáticas para comprender y organizar la información asociada a estas moléculas, a gran escala".[20]​ La bioinformática desempeña un papel clave en diversas áreas, tales como la genómica funcional, la genómica estructural y la proteómica, y forma un componente clave en el sector de la biotecnología y la farmacéutica.[cita requerida]


== Ventajas, riesgos y desventajas ==


=== Ventajas ===
Entre las principales ventajas de la biotecnología se tienen:

Rendimiento superior. Mediante organismos genéticamente modificados (OGM), el rendimiento de los cultivos aumenta, dando más alimento por menos recursos, disminuyendo las cosechas perdidas por enfermedad o plagas así como por factores ambientales.[21]​
Reducción de plaguicidas. Cada vez que un OGM es modificado para resistir una determinada plaga se está contribuyendo a reducir el uso de los plaguicidas asociados a la misma que suelen ser causantes de grandes daños ambientales y a la salud.[22]​
Mejora en la nutrición. Se puede llegar a introducir vitaminas[23]​ y proteínas adicionales en alimentos así como reducir los alérgenos y toxinas naturales. También se puede intentar cultivar en condiciones extremas lo que auxiliaría a los países que tienen menos disposición de alimentos.
Mejora en el desarrollo de nuevos materiales.[24]​
La aplicación de la biotecnología presenta riesgos que pueden clasificarse en dos categorías diferentes: los efectos en la salud de los humanos y de los animales y las consecuencias ambientales.[5]​ Además, existen riesgos de un uso éticamente cuestionable de la biotecnología moderna.[25]​ (ver: Consecuencias imprevistas).


=== Riesgos medioambientales ===
Entre los riesgos para el medio ambiente cabe señalar la posibilidad de polinización cruzada, por medio de la cual el polen de los cultivos genéticamente modificados (GM) se difunde a cultivos no GM en campos cercanos, por lo que pueden dispersarse ciertas características como resistencia a los herbicidas de plantas GM a aquellas que no son GM.[26]​ Esto que podría dar lugar, por ejemplo, al desarrollo de maleza más agresiva o de parientes silvestres con mayor resistencia a las enfermedades o a los estreses abióticos, trastornando el equilibrio del ecosistema.[5]​
Otros riesgos ecológicos surgen del gran uso de cultivos modificados genéticamente con genes que producen toxinas insecticidas, como el gen del Bacillus thuringiensis. Esto puede hacer que se desarrolle una resistencia al gen en poblaciones de insectos expuestas a cultivos GM. También puede haber riesgo para especies que no son el objetivo, como aves y mariposas, por plantas con genes insecticidas.[26]​
También se puede perder biodiversidad, por ejemplo, como consecuencia del desplazamiento de cultivos tradicionales por un pequeño número de cultivos modificados genéticamente.[5]​
En general los procesos de avance de la frontera agrícola en áreas tropicales y subtropicales suelen generar impactos ambientales negativos, entre otros: procesos de erosión de los suelos mayor que en áreas templadas y pérdida de la biodiversidad.


=== Riesgos para la salud ===
Existen riesgos de transferir toxinas de una forma de vida a otra, de crear nuevas toxinas o de transferir compuestos alergénicos de una especie a otra, lo que podría dar lugar a reacciones alérgicas imprevistas.[5]​
Existe el riesgo de que bacterias y virus modificados escapen de los laboratorios de alta seguridad e infecten a la población humana o animal.[27]​
Los agentes biológicos se clasifican, en función del riesgo de infección, en tres grupos:[28]​

Agente biológico del grupo 1: aquel que resulta poco probable que cause una enfermedad en el hombre.
Agente biológico del grupo 2: aquel que puede causar una enfermedad en el hombre y puede suponer un peligro para los trabajadores, siendo poco probable que se propague a la colectividad y existiendo generalmente profilaxis o tratamiento eficaz.
Agente biológico del grupo 3: aquel con muchas probabilidades de que se propague a la colectividad y sin que exista generalmente una profilaxis o un tratamiento eficaz.


=== Desventajas ===
Los procesos de modernización agrícola, además del aumento de la producción y los rendimientos, tienen otras consecuencias.

Una de ellas es la disminución de la mano de obra empleada por efectos de la mecanización; esto genera desempleo y éxodo rural en muchas áreas.
Por otro lado, para aprovechar las nuevas tecnologías se requieren dinero y acceso a la tierra y al agua. Los agricultores que no pueden acceder a esos recursos quedan fuera de la modernización y en peores condiciones para competir con las producciones modernas.


== Legislación y regulación ==


=== México ===
La regulación nacional relacionada con la bioseguridad se había centrado en aspectos de prevención y control de posibles riesgos del uso y aplicación de OGMs para la salud humana, la sanidad vegetal y animal y el medio ambiente, aspectos en el ámbito de competencia de las Secretarías de Salud (SS), Secretaría de Agricultura, Ganadería, Desarrollo Rural, Pesca y Alimentación (SAGARPA) con base en la Ley General de Salud; Ley Federal de Sanidad Vegetal; Ley sobre Producción, Certificación y Comercio de Semillas y en la NOM-FITO-056. Por lo que respecta al ambiente, la Secretaría del Medio Ambiente, Recursos Naturales (SEMARNAT), se rige por la Ley General del Equilibrio Ecológico y la Protección al Ambiente y el reglamento en materia de impacto ambiental. Otras dependencias gubernamentales, relacionadas con los OGMs son la Secretaría de Hacienda y Crédito Público (SHCP), aplica la normatividad relacionada con el control sobre movimientos transfronterizos de bienes, aduanas, imposición tributaria, etc.; la Secretaría de Economía, responsable del comercio exterior, políticas comerciales, tratados internacionales; el IMPI, a cargo de los aspectos relativos a la propiedad industrial (patentes, marcas, etc.) y la Secretaría de Educación Pública (SEP) y el Consejo Nacional de Ciencia y Tecnología (CONACYT) indirectamente relacionadas estos dos últimos con la bioseguridad al aplicar normas jurídicas vinculadas con la elaboración de políticas educativas y de investigación.
En el terreno específico de la bioseguridad de las actividades de la biotecnología moderna, la regulación vigente en el país[¿cuál?] requiere una revisión e integración sistematizada y armónica que le permita ser congruente con criterios internacionales, que cuente con los elementos operativos adecuados para darle eficacia gracias a la evaluación y al monitoreo de los riesgos biotecnológicos, que garanticen la seguridad jurídica de quienes realizan actividades de investigación, producción, comercialización y, en general, el manejo de los organismos genéticamente modificados y de los productos obtenidos de los mismos.
El 30 de abril de 2002, el Senado de la República ratificó el Protocolo de Cartagena sobre la Seguridad de la Biotecnología del Convenio sobre la Diversidad Biológica, que entró en vigor el 11 de septiembre de 2003, noventa días posteriores a la ratificación por 50 países. Si bien el origen y la naturaleza del Protocolo es ambiental, su contenido y la forma en que se asimile legalmente en nuestro país para su aplicación tendrá importantes repercusiones en la investigación, producción y comercialización de OGMs y de productos que los contengan, así como un efecto en la organización y participación de distintas autoridades gubernamentales. Además también es importante recordar que el Congreso de la Unión aprobó en diciembre de 2001, una modificación al artículo 420 Ter del Código Penal Federal, la cual pudiera traer por consecuencia que cualquier individuo, si maneja, utiliza o transporta transgénicos, puede incurrir en la comisión de un delito y, por lo tanto, ser sujeto de un procedimiento penal.
Con base en lo anterior, el Senado de la República en el 2002, solicitó a la Academia Mexicana de Ciencias (AMC) el apoyo técnico para la elaboración de la Iniciativa de la Ley de Bioseguridad de Organismos Genéticamente Modificados (ILBOGMs).


== Véase también ==
 Portal:Biotecnología. Contenido relacionado con Biotecnología.


== Referencias ==


== Bibliografía adicional ==
Jesús Ballesteros; Encarnación Fernández Ruiz-Gálvez (2007). Biotecnología y posthumanismo. Editorial Aranzadi. ISBN 978-84-8355-095-3. 
Fukuyama, Francis (2002). El fin del hombre: consecuencias de la revolución biotecnológica. Ediciones B. ISBN 978-84-666-0874-9. 
Jonas, Hans (1997). Técnica, medicina y ética: sobre la práctica del principio de responsabilidad. Ediciones Paidós Ibérica. ISBN 978-84-493-0341-8. 
Henco, A. International Biotechnology Economics and Policy: Science, Business Planning and Entrepreneurship; Impact on Agricultural Markets and Industry; Opportunities in the Healthcare Sector. ISBN 978-0-7552-0293-5.


== Enlaces externos ==
 Wikcionario  tiene definiciones y otra información sobre biotecnología.
 Wikimedia Commons alberga una categoría multimedia sobre Biotecnología.
"El sector de la biotecnología en España". Informe del sector en España elaborado por la Fundación Cajamar en 2009.
La nanotecnología es la manipulación de la materia a una escala nanométrica. La más temprana descripción de la nanotecnología[1]​[2]​ se refiere a la meta tecnológica particular de manipular en forma precisa los átomos y moléculas para la fabricación de productos a microescala, ahora también referida como nanotecnología molecular. La Iniciativa Nanotecnológica Nacional de Estados Unidos, define de forma más general la nanotecnología como la manipulación de la materia con al menos una dimensión del tamaño de entre 1 a 100 nanómetros. Esta definición es ampliamente aceptada en el campo de la física y la química; sin embargo en el campo de la biología se aceptan como nanopartículas aquellas con un al menos una dimensión menor a 1000 nanómetros. Esta definición refleja el hecho de que los efectos de la mecánica cuántica son importantes a esta escala del dominio cuántico y, así, la definición pasó de referirse a una tecnología en particular a una campo más amplio que incluye todos los tipos de investigación y tecnologías relacionadas con las propiedades especiales de la materia bajo cierto umbral de tamaño. Es común el uso de la forma plural «nanotecnologías» así como «tecnologías de nanoescala». Debido a la variedad de potenciales aplicaciones médicas, industriales y militares, los gobiernos han invertido miles de millones de dólares en investigación de la nanotecnología. A través de su Iniciativa Nanotecnológica Nacional, Estados Unidos ha invertido 3700 millones de dólares. La Unión Europea ha invertido[cita requerida] 1200 millones y Japón 750 millones de dólares.[3]​
La nanotecnología definida por el tamaño es naturalmente un campo muy amplio, que incluye diferentes disciplinas de la ciencia tan diversas como la ciencia de superficies, química orgánica, biología molecular, física de los semiconductores, microfabricación, etc.[4]​ Las investigaciones y aplicaciones asociadas son igualmente diversas, yendo desde extensiones de la física de los dispositivos a nuevas aproximaciones completamente nuevas basadas en el autoensamblaje molecular, desde el desarrollo de nuevos materiales con dimensiones en las nanoescalas al control directo de la materia a escala atómica.
Actualmente los científicos están debatiendo el futuro de las implicaciones de la nanotecnología. La nanotecnología puede ser capaz de crear nuevos materiales y dispositivos con un vasto alcance de aplicaciones, tales como en la medicina, electrónica, biomateriales, y la producción de energía. Por otra parte, la nanotecnología hace surgir las mismas preocupaciones que cualquier nueva tecnología, incluyendo preocupaciones acerca de la toxicidad y el impacto ambiental de los nanomateriales,[5]​ y sus potenciales efectos en la economía global, así como especulaciones acerca de varios escenarios apocalípticos. Estas preocupaciones han llevado al debate entre varios grupos de defensa y gobiernos sobre si se requieren regulaciones especiales para la nanotecnología.


== Regulaciones ==
No existe ni unanimidad ni claridad en torno al uso de la nanotecnología y todo de lo que ella se deriva: tanto la seguridad como la privacidad de los posibles riesgos no están calculados. [6]​[7]​[8]​


== Diferencia entre nanotecnología y nanociencia ==
La nanotecnología comprende el estudio, diseño, creación, síntesis, manipulación y aplicación de materiales, aparatos y sistemas funcionales a través del control de la materia a nanoescala, y la explotación de fenómenos y propiedades de la materia a nanoescala. 
Cuando se manipula la materia a escala tan minúscula, presenta fenómenos y propiedades totalmente nuevas. Por lo tanto, los científicos utilizan la nanotecnología para crear materiales, aparatos y sistemas novedosos y poco costosos con propiedades únicas.
No obstante, la nanociencia es una disciplina dedicada al estudio de los fenómenos físicos, químicos y biológicos que ocurren a escala nanométrica.


== Historia ==

El ganador del premio Nobel de Física de 1965, Richard Feynman, fue el primero en hacer referencia a las posibilidades de la nanociencia y la nanotecnología en un discurso que dio en el Caltech (Instituto Tecnológico de California) el 29 de diciembre de 1959, titulado En el fondo hay espacio de sobra (There's Plenty of Room at the Bottom[9]​), en el que describe la posibilidad de la síntesis vía la manipulación directa de los átomos. El término "nanotecnología" fue usado por primera vez por Norio Taniguchi en el año 1974, aunque esto no es ampliamente conocido.

Inspirado en los conceptos de Feynman, en forma independiente K. Eric Drexler usó el término "nanotecnología" en su libro del año 1986 Motores de la Creación: La Llegada de la Era de la Nanotecnología (en inglés: Engines of Creation: The Coming Era of Nanotechnology), en el que propuso la idea de un "ensamblador" a nanoescala que sería capaz de construir una copia de sí mismo y de otros elementos de complejidad arbitraria con un nivel de control atómico. También en el año 1986, Drexler cofundó The Foresight Institute (en castellano: El Instituto de Estudios Prospectivos), con el cual ya no tiene relación, para ayudar a aumentar la conciencia y comprensión pública de los conceptos de la nanotecnología y sus No existe niimplicaciones.No existe ni
Así, el surgimiento de la nanotecnología como un campo en la década de 1980 ocurrió por la convergencia del trabajo teórico y público de Drexler, quien desarrolló y popularizó un marco conceptual para la nanotecnología, y los avances experimentales de alta visibilidad que atrajeron atención adicional a amplia escala a los prospectos del control atómico de la materia.
Por ejemplo, la invención del microscopio de efecto túnel en el año 1981 proporcionó una visualización sin precedentes de los átomos y enlaces individuales, y fue usado exitosamente para manipular átomos individuales en el año 1989. Los desarrolladores del microscopio Gerd Binnig y Heinrich Rohrer del IBM Zúrich Research Laboratory (en castellano: Laboratorio de Investigación Zúrich IBM) recibieron un Premio Nobel en Física en el año 1986.[10]​[11]​ Binnig, Quate y Gerber también inventaron el microscopio de fuerza atómica análogo ese año.

Los fullerenos fueron descubiertos en el año 1985 por Harry Kroto, Richard Smalley y Robert Curl, quienes en conjunto ganaron el Premio Nobel de Química del año 1996.[12]​[13]​ Inicialmente el C60 no fue descrito como nanotecnología; el término fue utilizado en relación con el trabajo posterior con los tubos de grafeno (llamados nanotubos de carbono) con aplicaciones potenciales para dispositivos y electrónica de nanoescala.
A principios de la década de 2000, el campo cosechó un incrementado interés científico, político y comercial que llevó tanto a la controversia como al progreso. Las controversias surgieron en relación con las definiciones y potenciales implicaciones de las nanotecnologías, ejemplificado por el informe de la Royal Society acerca de la nanotecnología.[14]​ Los desafíos surgieron de la factibilidad de las aplicaciones imaginadas por los proponentes de la nanotecnología molecular, que culminó en un debate público entre Drexler y Smalley en el año 2001 y el año 2003.[15]​
Mientras tanto, la comercialización de los productos basados en los avances de las tecnologías a nanoescala comenzaron a surgir. Estos productos están limitados a aplicaciones a granel de los nanomateriales y no involucran el control atómico de la materia. Algunos ejemplos incluyen a la plataforma Nano Silver que utiliza nanopartículas de plata como un agente antibacterial, los protectores solares transparentes basados en nanopartículas y de los nanotubos de carbono para telas resistentes a las manchas.[16]​[17]​
Los gobiernos se movieron a la promoción y el financiamiento de la investigación en nanotecnología, comenzando por Estados Unidos con su Iniciativa Nanotecnológica Nacional, que formalizó la definición de la nanotecnología basada en el tamaño y que creó un fondo de financiamiento para la investigación de la nanoescala.
Para mediados de la década del 2000 nueva y seria atención científica comenzó a florecer. Proyectos emergieron para producir una hoja de ruta para la nanotecnología[18]​[19]​ que se centraba en la manipulación atómica precisa de la materia y que discute las capacidades, metas y aplicaciones existentes y proyectadas.
Otras personas de esta área fueron Rosalind Franklin, James Dewey Watson y Francis Crick quienes propusieron que el ADN era la molécula principal que jugaba un papel clave en la regulación de todos los procesos del organismo, revelando la importancia de las moléculas como determinantes en los procesos de la vida.
Pero estos conocimientos fueron más allá, ya que con esto se pudo modificar la estructura de las moléculas, como es el caso de los polímeros o plásticos que hoy en día encontramos en nuestros hogares. Pero hay que decir que a este tipo de moléculas se les puede considerar “grandes”.
Hoy en día la medicina tiene más interés en la investigación en el mundo microscópico, ya que en él se encuentran posiblemente las alteraciones estructurales que provocan las enfermedades, y no hay que decir de las ramas de la medicina que han salido más beneficiadas como es la microbiología, inmunología, fisiología; han surgido también nuevas ciencias como la Ingeniería Genética, que ha generado polémicas sobre las repercusiones de procesos como la clonación o la eugenesia.
El desarrollo de la nanociencia y la nanotecnología en América Latina es relativamente reciente, en comparación a lo que ha ocurrido a nivel global. Países como México, Costa Rica, Argentina, Venezuela, Colombia, Brasil y Chile contribuyen a nivel mundial con trabajos de investigación en distintas áreas de la nanociencia y la nanotecnología.[20]​ Además, algunos de estos países cuentan también con programas educativos a nivel licenciatura, maestría, posgrado y especialización en el área.


== Conceptos de la nanotecnología ==
La nanotecnología es la ingeniería de sistemas funcionales a escala molecular. Esto cubre tanto el actual trabajo como conceptos que son más avanzados. En su sentido original, la nanotecnología se refiere a la habilidad proyectada para construir elementos desde lo más pequeño a lo más grande, usando técnicas y herramientas, que actualmente están siendo desarrolladas, para construir productos completos de alto desempeño.
Un nanómetro (nm) es la mil millonésima parte, o 10−9, de un metro. Por comparación, los típicos largos de enlaces carbono-carbono, o el espacio entre estos átomos en una molécula, están alrededor de los 0,12–0,15 nm y la doble hélice de un ADN tiene un diámetro de alrededor de 2 nm. Por otra parte, la forma de vida celular más pequeña, la bacteria del género Mycoplasma, tienen alrededor de 200 nm de largo. Por convención, la nanotecnología es medida en el rango de escala de entre 1 a 100 nm de acuerdo a la definición usada por la Iniciativa Nanotecnológica Nacional en Estados Unidos. El límite inferior está dado por el tamaño de los átomos (el hidrógeno tiene los átomos más pequeños, que tienen un radio aproximado de un veinteavo de nm conocido como radio de Bohr) dado que la nanotecnología debe fabricar sus dispositivos a partir de átomos y moléculas. El límite superior es más o menos arbitrario, pero se encuentra alrededor del tamaño en que fenómenos que no pueden ser observados en estructuras más grandes comienzan a ser aparentes y pueden ser usados en el nanodispositivo.[21]​ Estos nuevos fenómenos hacen que la nanotecnología sea distinta de los dispositivos que son meramente versiones miniaturizadas de un dispositivo macroscópico equivalente; tales dispositivos se encuentran a una escala más grande y caen bajo la descripción de microtecnología.[22]​
Para poner la escala en otro contexto, el tamaño comparativo de un nanómetro a un metro es lo mismo que el de una roca al tamaño de la Tierra.[23]​ Otra forma de ponerlo: un nanómetro es la cantidad en que la barba de un hombre promedio crece en el tiempo al que a este le toma levantar la afeitadora a su cara.[23]​
Se usan dos aproximaciones a la nanotecnología. En la aproximación "del fondo hacia arriba", los materiales y dispositivos son construidos a partir de componentes moleculares que se ensamblan por sí mismos químicamente por los principios del reconocimiento molecular. En la aproximación "de arriba abajo", los nano-objetos son construidos a partir de entidades más grandes con un control a nivel atómico.[24]​
Áreas de la física tales como la duvitación nanoelectrónica, la nanomecánica, nanofotónica y la nanoiónica han evolucionado durante estás últimas pocas décadas para proporcionar un fundamento científico básico a la nanotecnología.


=== De lo más grande a lo más pequeño: una perspectiva desde los materiales ===

Varios fenómenos se vuelven pronunciados a medida que el tamaño del sistema disminuye. Estos incluyen efectos mecánicos estadísticos, así como efectos mecánicos cuánticos, por ejemplo el “efecto del tamaño del Cuanto” donde las propiedades electrónicas de los sólidos son alteradas con grandes reducciones en el tamaño de la partícula. Este efecto no se ponen en juego al ir desde las dimensiones macro a las dimensiones micro. Sin embargo, los efectos cuánticos pueden convertirse en significantes cuando el tamaño del nanómetro es alcanzado, normalmente en distancias de 100 nanómetros o menos, el así llamado dominio cuántico. Adicionalmente, una variedad de propiedades físicas (mecánicas, eléctricas, ópticas, etc.) cambian cuando se les compara con los sistemas macroscópicos. Un ejemplo es el aumento en la proporción del área superficial al volumen alterando las propiedades mecánicas, termales y catalíticas de los materiales. La difusión y reacciones a nivel de nano escala, los materiales de las nanoestructuras y de los nanodispositivos con rápido transporte de iones generalmente son conocidas como nanoiónicas. Las propiedades mecánicas de los nanosistemas son de interés en la investigación de la nanomecánica. La actividad catalítica de los nanomateriales también abren potenciales riesgos en su interacción con los biomateriales.
Los materiales reducidos a la nanoescala pueden mostrar propiedades diferentes cuando se les compara con las que ellos exhiben a macroescala, permitiendo aplicaciones únicas. Por ejemplo, las substancias opacas pueden convertirse en transparentes (cobre); materiales estables pueden convertirse en combustible (aluminio); materiales insolubles pueden convertirse en solubles (oro). Un material tal como el oro, que es químicamente inerte a escala normales, puede servir como un potente catalizador químico a nanoescalas. La mayor parte de la fascinación con la nanotecnología surge de estos fenómenos cuánticos y de superficie que la materia exhibe a nanoescala.[25]​


=== De lo simple a lo complejo: una perspectiva molecular ===

La química sintética moderna ha alcanzado el punto donde es posible preparar pequeñas moléculas para casi cualquier estructura. Estos métodos son usado hoy en día para fabricar una amplia variedad de químicos útiles tales como farmacéuticos o polímeros comerciales. Esta habilidad hace surgir la pregunta de extender esta clase de control al siguiente nivel más grande, buscando métodos para ensamblar estas moléculas únicas en estructuras o ensamblajes supramoleculares consistentes de muchas moléculas dispuestas en una forma bien definida.
Estas aproximaciones utilizan los conceptos de auto-ensamblaje molecular y/o química supramolecular para disponer en forma automática sus propias estructuras en algún ordenamiento útil a través de una aproximación desde el fondo hacia arriba. El concepto de reconocimiento molecular es especialmente importante: las moléculas pueden ser diseñadas de tal forma que una configuración u ordenamiento específico sea favorecida debido a las fuerzas intermoleculares no covalentes. Las reglas de emparejamiento de bases de Watson-Crick son un resultado directo de esto, así como la especificidad de una enzima siendo apuntada a un único sustrato o el plegamiento de la proteína en sí misma. Así, dos o más componentes pueden ser diseñado para complementariedad y atracción mutua de tal forma que construyan un todo más complejo y útil.
La aproximaciones desde el fondo hacia arriba debería ser capaces de producir dispositivos en paralelo y ser mucho más baratas que los métodos de arriba abajo, pero potencialmente podrían ser sobrepasadas a medida que el tamaño y la complejidad del ensamblaje deseado aumente. Las estructuras más exitosas requieren arreglos de átomos complejos y termodinámicamente poco probables. Sin embargo, existen muchos ejemplos de autoensamblaje basados en el reconocimiento molecular en la biología, uno de los más notables es el pareo de base de Watson-Crick y las interacciones enzima-substrato. El desafío para la nanotecnología es descubrir si estos principios pueden ser usados para lograr nuevas construcciones adicionales a las naturales ya existentes.


=== Nanotecnología molecular: una visión de largo plazo ===

La nanotecnología molecular, algunas veces llamada fabricación molecular, describe nanosistemas manufacturados (máquinas a nanoescala) operando a escala molecular. La nanotecnología molecular está asociada especialmente con el ensamblador molecular, una máquina que puede producir una estructura o dispositivo deseado átomo por átomo usando los principios de la mecanosíntesis. La fabricación en el contexto de los nanosistemas productivos no está relacionado con, y debería ser claramente distinguido de, las tecnologías convencionales usadas para la fabricación de nanomateriales tales como nanotubos y nanopartículas de carbono.
Cuando el término "nanotecnología" fue acuñado en forma independiente y popularizado por Eric Drexler (quien en ese momento no sabía de un uso anterior realizado por Norio Taniguchi) para referirse a una tecnología futura de fabricación basado en sistemas de máquina moleculares. La premisa era que las analogías biológicas a escala molecular de los componentes de máquinas tradicionales demostraban que las máquinas moleculares eran posibles: existen incontables ejemplos en la biología, se sabe que sofisticadas máquinas biológicas optimizadas estocásticamente pueden ser producidas.
Se espera que los desarrollos en la nanotecnología harán posible su construcción por algún otro medio, quizás usando principios de biomimesis. Sin embargo, Drexler y otros investigadores[26]​ han propuesto que una nanotecnología avanzada, aunque quizás inicialmente implementada por medios biomiméticos, finalmente podría estar basada en los principios de la ingeniería mecánica, es decir, una tecnología de fabricación basada en la funcionalidad mecánica de estos componentes (tales como engranajes, rodamientos, motores y miembros estructurales) que permitirían un ensamblaje programable y posicional a una especificación atómica.[27]​ La física y el desempeño ingenieril de diseños de ejemplo fueron analizados en el libro de Drexler llamado Nanosistemas.
En general es muy difícil ensamblar dispositivos a escala atómica, ya que uno tiene que posicionar átomos sobre otros átomos de grosor y tamaño comparables. Otra visión, expresada por Carlo Montemagno,[28]​ es que los futuros nanosistemas serán híbridos de la tecnología del sílice y de máquinas moleculares biológicas. Richard Smalley argumenta que la mecanosíntesis es imposible debido a las dificultades en la manipulación mecánica de moléculas individuales.
Esto llevó a un intercambio de cartas entre la publicación Chemical & Engineering News de la ACS en el año 2003.[29]​ Aunque la biología claramente demuestra que los sistemas de máquinas moleculares son posibles, las máquinas moleculares no biológicas actualmente están solo en su infancia. Los líderes en la investigación de las máquinas moleculares no biológicas son Alex Zettl y su colegas que trabajan en el Lawrence Berkeley National Laboratory y en la UC Berkeley. Ellos han construido al menos tres dispositivos moleculares distintos cuyos movimientos son controlados desde el escritorio cambiando el voltaje: un nanomotor de nanotubos, un actuador,[30]​ y un oscilador de relajación nanoelectromecánico.[31]​
Un experimento que indica que un ensamblaje molecular posicional es posible fue desarrollado por Ho y Lee en la Universidad Cornell en el año 1999. Ellos usaron un microscopio de efecto túnel para mover una molécula de monóxido de carbono (CO) hacia un átomo individual de hierro (Fe) ubicado en un cristal plano de plata, y enlazar químicamente el CO con el Fe aplicando un voltaje.


== Investigación actual ==


=== Nanomateriales ===
El campo de los nanomateriales incluye los subcampos que desarrollan o estudian los materiales que tienen propiedades únicas que surgen de sus dimensiones a nanoescala.[34]​

La ciencia de Interfaz y coloide ha identificado muchos materiales que pueden ser útiles en la nanotecnología, tales como los nanotubos de carbono y otros fullerenos, y varias nanopartículas y nanoroides. Los nanomateriales con rápido transporte de iones también están relacionados con la nanoiónica y a la nanoelectrónica.
Los materiales a nanoescala también puede ser usados para aplicaciones en volumen; la mayoría de las aplicaciones comerciales actuales de la nanotecnología son de este tipo.
Se ha realizado progreso en la utilización de estos materiales para aplicaciones médicas, ver nanomedicina.
Los materiales a nanoescala tales como los nanopilares algunas veces son usados en las celdas solares para bajar los costos de las celdas solares de silicio tradicionales.
El desarrollo de aplicaciones que incorporan nanopartículas semiconductoras que serán usadas en la siguiente generación de productos, tales como tecnología de pantallas, iluminación, celdas solares e imágenes biológicas; ver punto cuántico.


=== Enfoque de abajo arriba ===
Estos buscan disponer los componentes más pequeños en estructuras más complejas.

La nanotecnología de ADN utiliza la especificidad del pareo de base de Watson-Crick para construir estructuras bien definidas a partir del ADN y otros ácidos nucleicos.
Se aproxima desde el campo de la síntesis química "clásica" (síntesis inorgánica y orgánica) y también su objetivo es el diseño de moléculas con una forma bien definida (por ejemplo bis-péptidos[35]​).
Más generalmente, el autoensamblaje molecular busca usar los conceptos de química supramolecular y el reconocimiento molecular en particular, para causar que componentes uni-moleculares se dispongan automáticamente por sí mismos en alguna conformación útil.


=== Enfoque de arriba abajo ===
Estos buscan crear dispositivos más pequeños usando unos más grandes para controlar su ensamblaje.

Muchas tecnologías que trazan su origen a los métodos de estado sólido de silicio para fabricar microprocesadores ahora son capaces de crear características más pequeñas que 100 nm, lo cae en la definición de nanotecnología. Discos duros basados en la magnetorresistencia gigante ya en el mercado caen dentro de esta descripción,[36]​ así como las técnicas de deposición de capas atómicas (en inglés: Atomic Layer Deposition, ALD). Peter Grünberg y Albert Fert recibieron un Premio Nobel en Física en el año 2007 por su descubrimiento de la magnetorresistencia gigante y sus contribuciones al campo de la espintrónica.[37]​
Las técnicas de estado sólido también pueden ser usadas para crear dispositivos conocidos como sistemas nanoelectromecánicos (en inglés: Nanoelectromechanical Systems, NEMS), que están relacionados con los sistemas microelectromecánicos (en inglés: Microelectromechanical Systems, MEMS).
Haces iónicos concentrados pueden ser controlados para eliminar o depositar material cuando gases precursores adecuados son aplicados al mismo tiempo. Por ejemplo, esta técnica es usada rutinariamente para crear secciones de material sub-100 nm para el análisis mediante microscopios electrónicos de transmisión.
Las puntas de los microscopios de fuerza atómica pueden ser usadas como una "cabeza de escritura" a nanoescala para depositar un químico sobre una superficie en un patrón deseado en un proceso conocido como nanolitografía dip-pen, que luego es seguida por un proceso de aguafuerte para eliminar el material en un método arriba-abajo. Esta técnica cae en el subcampo más grande de la nanolitografía.


=== Acercamientos funcionales ===
Estas buscan desarrollar componentes de una funcionalidad deseada sin importar como podrían ser ensambladas.

La electrónica de escala molecular busca desarrollar moléculas con propiedades electrónicas útiles. Estas podrían entonces ser usadas como componentes de molécula única en un dispositivo nanoelectrónico.[38]​ Para un ejemplo ver el rotaxano.
Los métodos químicos sintéticos también pueden ser usados para crear  motores moleculares sintéticos, tal como el conocido como nanoauto.


=== Acercamientos biomiméticos ===
La biónica o biomimesis buscan aplicar los métodos y sistemas biológicos encontrados en la naturaleza, para estudiar y diseñar sistemas de ingeniería y tecnología moderna. La biomineralización es un ejemplo de los sistemas estudiados.
La bionanotecnología es el uso de las biomoléculas para aplicaciones en nanotecnología, incluyendo el uso de virus y ensamblajes de lípidos.[39]​[40]​ La nanocelulosa es una potencial aplicación a escala masiva.


=== Especulativos ===
Estos subcampos buscan anticipar lo que las invenciones nanotecnológicas podrían alcanzar o intentan proponer una agenda que ordene un camino por el cual la investigación pueda progresar. A menudo estos toman una visión de una gran escala de la nanotecnología, con más énfasis en sus implicancias sociales que en los detalles de como tales invenciones podrían realmente ser creadas.

La nanotecnología molecular es propuesta como un acercamiento que involucra la manipulación de una sola molécula de una forma finamente controlado y determinista. Esto es más teórico que otros subcampos, y muchas de las técnicas propuestas están más allá de las capacidades actuales.
La nanorrobótica se centra en máquinas autosuficientes con alguna funcionalidad operando a nanoescala. Existen esperanzas de poder aplicar los nanorobots en medicina,[41]​[42]​[43]​ aunque previamente deberán superarse las desventajas de tales dispositivos.[44]​ Sin embargo, se ha demostrado progreso en materiales y metodologías innovadores con algunas patentes otorgadas para nuevos dispositivos nanofabricadores para futuras aplicaciones comerciales, que también ayudan progresivamente al desarrollo de nanorobots con algún uso de conceptos de nanobioelectrónica embebida.[45]​[46]​
Los nanosistemas productivos son "sistemas de nanosistemas" que serán complejos nanosistemas que producen partes atómicamente precisas para otros nanosistemas, no necesariamente utilizando nuevas propiedades nanoescalares emergentes, sino los bien comprendidos fundamentos de la fabricación macroscópica. Debido a la naturaleza discreta (a nivel atómico) de la materia y la posibilidad del crecimiento exponencial, esta etapa es vista como la base de otra revolución industrial. Mihail Roco, uno de los arquitectos de la Iniciativa Nanotecnológica Nacional de Estados Unidos, ha propuesto cuatro estados de la nanotecnología que parecen ser un paralelo del progreso técnico de la Revolución Industrial, progresando desde nanoestructuras pasivas a nanodispositivos activos a complejas nanomáquinas y finalmente a nanosistemas productivos.[47]​
La materia programable busca diseñar materiales cuyas propiedades puedan ser fácilmente, reversiblemente y externamente controlados. Está pensada como una fusión entre la ciencia de la información y la ciencia de los materiales.
Debido a la popularidad y exposición mediática del término nanotecnología, las palabras picotecnología y femtotecnología han sido acuñados en forma análoga, aunque estos son raramente utilizados y solo de manera informal.


== Herramientas y técnicas ==

Existen varios importantes desarrollos modernos. El microscopio de fuerza atómica (en inglés: Atomic Force Microscope, AFM) y el microscopio de efecto túnel (en inglés: Scanning Tunneling Microscope, STM) son versiones tempranas de las sondas de barrido que lanzaron la nanotecnología. Existen otros tipos de microscopio de sonda de barrido. Aunque conceptualmente similares a los microscopios confocales de barrido desarrollados por Marvin Minsky en el año 1961 y al microscopio acústico de barrido (en inglés: Scanning Acoustic Microscope, SAM) desarrollado por Calvin Quate y asociados en la década de 1970, los microscopios de sonda de barrido más nuevos tienen una mucho más alta resolución, dado que ellos no están limitados por la longitud de onda del sonido o la luz.
La punta de una sonda de barrido también puede ser usada para manipular nanoestructuras (un proceso conocido como ensamblaje posicional). La metodología de barrido orientado a la característica sugerida por Rostislav Lapshin parece ser una forma prometedora de implementar estas nanomanipulaciones en modo automático.[48]​[49]​ Sin embargo, esto es aún un proceso lento debido a la baja velocidad de barrido del microscopio.
Varias técnicas de nanolitografía tales como la litografía óptica, la nanolitografía dip-pen de litografía de rayos X, la litografía de haz de electrones o litografía de nanoimpresión también fueron desarrolladas. La litografía es una técnica de fabricación de arriba abajo donde el material en bruto es reducido en tamaño hasta lograr un patrón a nanoescala.
Otro grupo de técnicas nanotecnológicas incluyen a aquellas usadas para la fabricación de nanotubos y nanoalambres, aquellas usadas en la fabricación de semiconductores tales como la litografía ultravioleta profunda, la litografía de haz de electrones, maquinado de haz de iones enfocado, la litografía de nanoimpresión, la deposición de capa atómica y deposición molecular de vapor, y además incluyendo las técnicas de autoensamblaje molecular tales como aquellas que emplean copolímeros di-bloque. Los precursores de estas técnicas son anteriores a la era de la nanotecnología, y son extensiones en el desarrollo de los avances científicos más que técnicas que fueron ideadas únicamente con el propósito de crear nanotecnología y que fueron el resultado de la investigación nanotecnológica.
El acercamiento de arriba hacia bajo anticipa nanodispositivos que deben ser construidos pieza por pieza en etapas, de la misma forma que son fabricados el resto de las cosas. La microscopia de sonda de barrido es una importante técnica tanto para la caracterización como para la síntesis de nanomateriales. Los microscopios de fuerza atómica y los microscopios de efecto túnel de barrido pueden ser usados para examinar las superficies y para mover los átomos en ellas. Al diseñar diferentes puntas para estos microscopios, ellos pueden ser usados para tallar estructuras en las superficies y para ayudar a guiar las estructuras autoensambladas. Al utilizar, por ejemplo, el acercamiento de barrido orientado a las características, los átomos o moléculas pueden ser movidos en la superficie con las técnicas del microscopio de sonda de barrido.[48]​[49]​ Actualmente, es caro y demoroso para ser utilizados en la producción en masa, pero son muy adecuadas para la experimentación en un laboratorio.
En contraste, las técnicas de abajo hacia arriba construyen o hacen crecer estructuras más grandes átomo por átomo o molécula por molécula. Estas técnicas incluyen síntesis química, autoensamblaje y ensamblaje posicional. La interferometría de polarización dual es una herramienta adecuada para la caracterización de películas delgadas autoensambladas. Otra variación del acercamiento de abajo arriba es el crecimiento epitaxial por haces moleculares (en inglés: Molecular Beam Epitaxy, MBE). Los investigadores de los Bell Telephone Laboratories tales como John R. Arthur, Alfred Y. Cho y Art C. Gossard desarrollaron e implementaron el MBE como una herramienta de investigación hacia finales de la década de 1960 y la década de 1970. Las muestras hechas por el MBE fueron claves para el descubrimiento del efecto Hall cuántico fraccionario por el cual el premio Nobel en Física del año 1998 fue otorgado. El MBE permite a los científicos disponer capas precisas atómicamente, y en el proceso, construir complejas estructuras. Importante para las investigaciones en semiconductores, la MBE también es usada ampliamente para hacer muestras y dispositivos para el recientemente emergente campo de la espintrónica.
Sin embargo, nuevos productos terapéuticos, basados en nanomateriales sensibles, tales como las vesículas ultradeformables y sensibles a la tensión Transfersome, que están en desarrollo y se encuentran aprobadas para uso humano en algunos países.

Uno de los instrumentos clave en la micro y nano ciencia son los microscopios de barrido con sonda. Consisten básicamente en una plataforma y una sonda que efectúa un barrido o escaneado de la muestra.
El barrido puede hacerse moviendo ya sea la sonda o la plataforma, mediante actuadores de gran precisión. Los actuadores son un factor clave de esta tecnología.
La sonda puede elevarse o bajarse, con lo que se tiene un sistema con tres ejes coordenados, por una parte un plano x-y de barrido y por otra parte una altura z, con lo cual se puede estudiar el relieve o la topografía de las microestructuras.
No solo se mide la geometría de la muestra, sino que según el tipo de sonda usada se pueden medir también propiedades químicas, térmicas, eléctricas o mecánicas, con lo cual se abre una ventana muy amplia de información, que permite estudiar las propiedades de los nanomateriales.


== Inversión ==

Algunos países en vías de desarrollo ya destinan importantes recursos a la investigación en nanotecnología. La nanomedicina es una de las áreas que más puede contribuir al avance sostenible del Tercer Mundo, proporcionando nuevos métodos de diagnóstico y cribaje de enfermedades, mejores sistemas para la administración de fármacos y herramientas para la monitorización de algunos parámetros biológicos.
Alrededor de cuarenta laboratorios en todo el mundo canalizan grandes cantidades de dinero para la investigación en nanotecnología. Unas trescientas empresas tienen el término “nano” en su nombre, aunque todavía hay muy pocos productos en el mercado.[cita requerida]
Algunos gigantes del mundo informático como IBM, Hewlett-Packard (HP), NEC e Intel están invirtiendo millones de dólares al año en el tema. Los gobiernos del llamado Primer Mundo también se han tomado el tema muy en serio, con el claro liderazgo del gobierno estadounidense, que dedica cientos de millones de dólares a su National Nanotechnology Initiative.
En España, los científicos hablan de “nanopresupuestos”. Pero el interés crece, ya que ha habido algunos congresos sobre el tema: en Sevilla, en la Fundación San Telmo, sobre oportunidades de inversión, y en Madrid, con una reunión entre responsables de centros de nanotecnología de Francia, Alemania y Reino Unido en la Universidad Autónoma de Madrid.
Las industrias tradicionales podrán beneficiarse de la nanotecnología para mejorar su competitividad en sectores habituales, como textil, alimentación, calzado, automoción, construcción y salud. Lo que se pretende es que las empresas pertenecientes a sectores tradicionales incorporen y apliquen la nanotecnología en sus procesos con el fin de contribuir a la sostenibilidad del empleo. Actualmente la cifra en uso cotidiano es del 0,2 %.


== Ensamblaje interdisciplinario ==
La característica fundamental de nanotecnología es que constituye un ensamblaje interdisciplinar de varios campos de las ciencias naturales que están altamente especializados. Por tanto, los físicos juegan un importante rol no solo en la construcción del microscopio usado para investigar tales fenómenos, sino también sobre todas las leyes de la mecánica cuántica. Alcanzar la estructura del material deseado y las configuraciones de ciertos átomos hacen jugar a la química un papel importante. En medicina, el desarrollo específico dirigido a nanopartículas promete ayuda al tratamiento de ciertas enfermedades. Aquí, la ciencia ha alcanzado un punto en el que las fronteras que separan las diferentes disciplinas han empezado a diluirse, y es precisamente por esa razón por la que la nanotecnología también se refiere a ser una tecnología convergente.
Una posible lista de ciencias involucradas sería la siguiente:

Química (Moleculares y computacional)
Bioquímica
Biología molecular
Física
Electrónica
Informática
Matemáticas
Medicina
Nanoingenieria


== Nanotecnología avanzada ==
La nanotecnología avanzada, a veces también llamada fabricación molecular, es un término dado al concepto de ingeniería de nanosistemas (máquinas a escala nanométrica) operando a escala molecular. Se basa en que los productos manufacturados se realizan a partir de átomos. Las propiedades de estos productos dependen de cómo estén esos átomos dispuestos. Así por ejemplo, si reubicamos los átomos del grafito (compuesto por carbono, principalmente) de la mina del lápiz podemos hacer diamantes (carbono puro cristalizado). Si reubicamos los átomos de la arena (compuesta básicamente por sílice) y agregamos algunos elementos extras se hacen los chips de un ordenador.
A partir de los incontables ejemplos encontrados en la biología se sabe que miles de millones de años de retroalimentación evolucionada puede producir máquinas biológicas sofisticadas y estocásticamente optimizadas. Se tiene la esperanza que los desarrollos en nanotecnología harán posible su construcción a través de algunos significados más cortos, quizás usando principios biomiméticos. Sin embargo, K. Eric Drexler y otros investigadores han propuesto que la nanotecnología avanzada, aunque quizá inicialmente implementada a través de principios miméticos, finalmente podría estar basada en los principios de la ingeniería mecánica.
Determinar un conjunto de caminos a seguir para el desarrollo de la nanotecnología molecular es un objetivo para el proyecto sobre el mapa de la tecnología liderado por Instituto Memorial Battelle (el jefe de varios laboratorios nacionales de EE. UU.) y del Foresigth Institute. Ese mapa debería estar completado a finales de 2006.


== Futuras aplicaciones ==
Según un informe de un grupo de investigadores de la Universidad de Toronto, en Canadá, las quince aplicaciones más prometedoras de la nanotecnología son:[50]​

Alimentos transgénicos.
Almacenamiento, producción y conversión de energía.
Armamento y sistemas de defensa.
Cambios térmicos moleculares (Nanotermología).
Construcción.
Control de desnutrición en lugares pobres.
Cosmética.
Diagnóstico y cribaje de enfermedades.
Detección y control de plagas.
Informática.
Monitorización de la salud.
Procesamiento de alimentos.
Producción agrícola.
Resolución de la contaminación atmosférica.
Sistemas de administración de fármacos.
Tratamiento y remediación de aguas.
Energías renovables: Actualmente, la demanda es cubierta principalmente por centrales que emplean energías no renovables (combustibles fósiles, materiales radioactivos). No obstante, el aumento del empleo en energías renovables es cada vez mayor haciendo que las infraestructuras actuales resulten insuficientes y caras, por lo que se hace necesaria la introducción de la nanotecnología en este ámbito. Se cree que en un futuro esta podría llegar a cambiar las matrices energéticas existentes. Una de las soluciones que se expone es la sustitución de las baterías del talón de Aquiles, cuya capacidad de almacenamiento es insuficiente, por baterías de flujo. Este tipo de baterías estarían basadas en la utilización de líquidos que contienen una red de partículas fluctuantes a nanoescala y podrían llegar a ser mucho más baratas.


== Aplicaciones actuales con nanotecnología ==
Textil. 
Desarrollo de tejidos inteligentes: capaces de repeler manchas, ser autolimpiables, anti olores o poseer nanochips para cambiar de color y temperatura.
Agricultura. 
Diseño de productos para mejorar plaguicidas, herbicidas y fertilizantes. La principal finalidad es el mejoramiento de suelos. Además, podemos incluir en esta categoría los nano sensores para la detección de agua, nitrógeno, agroquímicos, etc.
Cosmética. 
Desarrollo de cremas anti-arrugas o cremas solares con nanopartículas.
Ganadería. 
Desarrollo de nanopartículas con el fin de administrar vacunas o fármacos para los animales, así como destinados a detectar microorganismos, enfermedades y sustancias tóxicas.
Alimentos.  
Dispositivos (nanosensores y nanochips) que funcionen principalmente como nariz y lengua electrónica, es decir, para analizar aspectos relacionados con el olfato y el gusto. Son utilizados también para detectar la frescura y vida útil de un alimento, patógenos, aditivos, fármacos, metales pesados, toxinas, contaminantes… por otro lado, otro aspecto muy desarrollado es la creación de nanoenvases, como se explicará en el siguiente apartado. Estos poseen propiedades funcionales, nutritivas, saludables y organoeléctricas (descripciones de las características físicas que tiene la materia según las pueden percibir los sentidos, como sabor, textura, olor, color o temperatura).


=== Nanotecnología aplicada al envasado de alimentos ===
La conservación de los alimentos es una idea que viene desde los inicios de la historia humana. A partir de la edad prehistórica, la necesidad de mejorar la preservación del alimento mediante diferentes técnicas ha sido un característica del comportamiento humano. Fermentación, salinización, secado al sol, rostización, curado, irradiación, carbonación y la adición de preservantes químicos y físicos, se han desarrollado desde el inicio de la humanidad. Todos estos métodos tienen la misma idea central. Evidencia arqueológica soporta la idea que las técnicas de preservación fueron desarrolladas en las civilizaciones griega, romana y egipcia. Sin embargo, los diversos métodos presentan el desafío de mantener las condiciones originales por periodos de tiempo prolongados.
Los métodos de envasado de alimentos tienen como objetivo asegurar la calidad de los alimentos para que permanezcan con sus propiedades de manera intacta. Los principales envases tienen como objetivo entregar protección física con el propósito de prevenir la contaminación de los alimentos con otros alimentos o con microorganismos. Los materiales de envasado están confeccionados preferentemente de materiales biodegradables, con el propósito de reducir la contaminación medioambiental. Esta idea se ha llevado a cabo gracias a la introducción de la nanotecnología. 
Una de las aplicaciones de la nanotecnología en el campo de envases para alimentación es la aplicación de materiales aditivados con nanoarcillas, que mejoren las propiedades mecánicas, térmicas, barrera a los gases, entre otras; de los materiales de envasado. En el caso de mejora de la barrera a los gases, las nanoarcillas crean un recorrido tortuoso para la difusión de las moléculas gaseosas, lo cual permite conseguir una barrera similar con espesores inferiores, reduciendo así los costos asociados a los materiales.
Los procesos de incorporación de las nanopartículas se pueden realizar mediante extrusión o por recubrimiento, y los parámetros a controlar en el proceso de aditivación de los materiales son: la dispersión nanopartículas, la interacción de las nanopartículas con la matriz, las agregaciones que puedan tener lugar entre las nanopartículas y la cantidad de nanopartículas incorporada.
Los nanosensores ayudan a detectar cualquier cambio en el color de los alimentos y ayuda a la detección de gases dentro del producto. Estos sensores son usualmente sensibles a gases como el hidrógeno, sulfuro de hidrógeno, óxido de nitrógeno, dióxido de sulfuro y amonio. Los nanosensores son dispositivos que procesan datos capaces de detectar cambios a nivel de luz, calor, humedad, gases y señales del tipo eléctricas y químicas.[51]​
Las nanoemulsiones son utilizadas para producir alimentos para aderezo de ensaladas, aceites saborizantes, endulzantes y otros- Ayudan en la liberación de diferentes sabores con la estimulación que tienen relación con calor, pH, ondas de ultrasonidos, etc. Las nanoemulsiones pueden retener los sabores eficientemente y prevenir la oxidación y las reacciones enzimáticas. Las nanoemulsiones son creadas principalmente a través del compromiso de alta energía con homogeneización de alta presión, métodos de ultrasonido, chorros coaxiales líquidos de alta velocidad y métodos con dispositivos de alta velocidad. De forma similar, los métodos de baja energía, compromete emulsificación de membranas, emulsificación espontánea, desplazamiento de solventes, punto de inversión de emulsiones y mediante puntos de inversión de fases. Las nanoemulsiones son creadas por dispersión de la fase líquida en una fase acuosa continua. Los componentes que son utilizados para la creación de nanoemulsiones son del tipo lipofílicos.[51]​


=== Nanotecnología aplicada a la administración de fármacos ===
Dentro de las posibilidades de administración de fármacos, ha surgido la posibilidad de utilizar la nanotecnología como un sistema de liberación del principio activo. En general los vehículos utilizados para administrar un fármaco, deben ser de baja toxicidad, con propiedades óptimas para el transporte y liberación y vida media larga. Ejemplos de nanosistemas son: micelas, liposomas, dentrímeros, nanopartículas, nanotubos y bioconjugados.[52]​
Las nanopartículas son partículas sólidas coloidales con un tamaño de 1 nm a 1000 nm que son utilizadas como agentes de administración de fármacos. Con esto se logra un aumento en la velocidad de disolución y el límite de saturación de la solubilidad.[53]​ Existe además un tipo especial llamadas nanopartículas lipídicas sólidas (SLN). Estas nanopartículas protegen al principio activo contra la degradación química, además de generar una mayor flexibilidad en la modulación de la liberación del fármaco.[54]​
Los liposomas son moléculas amfifílicas, como los fosfolípidos, que forman vesículas de membranas en bicapas que pueden llevar a vesículas. Los liposomas son estructuras esféricas formadas por una o más capas que contienen en su interior una fase acuosa. Los liposomas se han utilizado para mejorar el efecto terapéutico de fármacos muy potentes. Se considera que este sistema de distribución reduce la toxicidad.[55]​
Los bioconjugados o conjugados poliméricos actúan como transportadores y como componentes biológicos (péptidos, proteínas, nucleótidos) que actúan como ligandos para efectos terapéuticos específicos o dianas. Un ejemplo de bioconjugados con los productos obtenidos de la adición de polietilenglicol (PEG) a fármacos o proteínas terapéuticas.[56]​
Los dendrones o dendrímeros son nanomateriales que pueden incorporar bloques poliméricos sintéticos o componentes naturales. Su estructura factorial jerárquica presenta numerosos sitios de conjugación para cargos o motivos diana.[56]​ 
Las nanopartículas inorgánicas son nanopartículas construidas a partir de materiales inorgánicos. Los materiales más comunes son puntos cuánticos junto con oro, plata, óxido de hierro o nanopartículas mesoporosas. Las propiedades características de cada material son el tamaño, la carga, la química de la superficie y la estructura.[56]​ 
Uno de los primeros fármacos en nanomedicina que mostró ser seguro para la FDA fue obtenido por las encapsulaciones de doxorrubicina dentro de los liposomas. Esta nanoformulación mejoró las características farmacocinéticas y de distribución de doxorrubicina, lo que lleva a la prolongación de la vida media y generar un proceso de acumulación en el tejido tumoral.[57]​
En los últimos años se han desarrollado dispositivos implantables de distribución de fármacos. La principal función de esta nueva tecnología es la administración controlada de fármaco durante varias semanas a meses, de acuerdo las necesidades terapéuticas de un paciente individual. Terapias a largo plazo pueden ayudar a mejorar el cumplimiento y la adherencia de los pacientes a los tratamientos farmacológico. Los dispositivos implantables utilizan una estrategia on demand de los agentes terapéuticos y algunas tecnologías ayudarían a controlar la liberación de manera remota, mediante radiofrecuencia, energía de ultrasonido y de campos magnéticos, se podrían activar y controlar las administraciones. A pesar del gran número de estudios reportados acerca de los dispositivos médico auto-regulados y de los esfuerzos tecnológicos, no se ha logrado probar los beneficios de este tipo de tecnologías.


=== Nanotecnología aplicada a la terapia del cáncer ===
Uno de los aspectos más desafiantes en las terapias que existen contra el cáncer, es la especificidad de los tratamientos. Esto podría conducir a reducir los efectos tóxicos que se generan luego de administrar las terapias anticancerígenas. Además de esta posibilidad, podría mejorarse la solubilidad y biodisponibilidad de fármacos que son pobremente solubles. Debido a estas necesidades, han surgido algunas investigaciones que utilizan nanotransportadores (liposomas, micelas poliméricas y nanoparticulas poliméricas) para la preparación de nuevas formulaciones que mejoran la biodisponibilidad de estos tratamientos y mejoran la distribución del fármaco anticancerígeno en el sitio del tumor. Dentro de los factores que se consideran del tipo fisicoquímicos, se encuentra el potencial Z, el tamaño de partícula, la carga catiónica de la superficie y la solubilidad.[58]​


=== Nanotecnología aplicada a la terapia del VIH/sida ===
Los de distribución de fármacos aplicados a distribución sistémica de fármacos antivirales podría tener ventajas similares a los ejemplos exitosos en la terapia contra el cáncer. Los sistemas de liberación controlada podría aumentar la vida media de los fármacos, manteniendo concentraciones plasmáticas en niveles terapéuticos por periodos de tiempo más prolongados que tengan finalmente impactos en la eficacia de la terapia farmacológica. Adicionalmente se podría obtener un mejor perfil de seguridad que lleve una mejor adherencia de los pacientes. De manera específica, la distribución dirigida de fármacos antivirales frente a células CD4+ y macrófagos, tanto como la distribución a órganos de difícil acceso como el cerebro, que podrían asegurar la mantención de las concentraciones a través de la generación de reservas latentes. De forma conjunta a la mejora de la terapia farmacológica, ha nacido la idea de lograr realizar terapia génica a través de la nanotecnología. Al parecer es una promisoria la terapia génica, en la cual un gen es insertado dentro de una célula para llevar a un interferencia de los procesos de infección o replicación. Existe evidencia que indica que el silenciamiento de genes podría ser una potencial herramienta para atacar los genes de interés. Se ha descrito también que podría ser posible generar vacunas que sean eficaces y seguras en contra del VIH/sida. Es posible utilizar antígenos encapsulados en su centro desde los cuales las células presentadoras de antígenos pueden procesar, presentar y cross-presentar antígenos a las células CD4+ y CD8+, respectivamente, o absorber antígenos en su superficie, permitiendo a las células B generar una respuesta humoral. Por otro lado, la inmunoterapia para VIH/sida basada en agentes virales y administración de células dendríticas autólogas generadas ex-vivo.[59]​


=== Nanotecnología aplicada a la terapia del Alzheimer ===
Los métodos de tratamientos mediante nanotecnología han resultado con interesantes resultados en la terapia de la enfermedad de Alzheimer. Los fármacos usualmente disponibles para el tratamiento de la enfermedad de Alzheimer, incluyen fármacos que son inhibidores de la enzima acetilcolinesterasa, que poseen una pobre solubilidad y baja biodisponibilidad. Adicionalmente, estos fármacos poseen una incapacidad de atravesar la barrera hemato-encefálica, por lo que el mejoramiento en la distribución de estos fármacos en el sitio de acción, es desafiante a nivel de tecnológico. Las nanotecnologías incluidas son las nanopartículas poliméricas, las nanopartículas sólido-lípido, transportadores de nanoestructuras lípidas, microemulsión, nanoemulsión y cristales líquidos. Las características fisicoquímicas especiales de los fármacos disponibles para el tratamiento del Alzheimer llevan a falla terapéutica en muchos casos. Estas limitaciones se han superado, en parte, debido al desarrollo de la administración intranasal, lo cual favorece una alternativa no invasiva de la distribución del fármaco a nivel del sistema nervioso central, a través del paso por la barrera hemato-encefálica.


== Nanotecnología del ADN ==
Las aplicaciones de la nanotecnología en la biología celular tienen como foco desafiante la molécula de ácido desoxirribonucleico (ADN). Se han desarrollado elementos estructurales con una cierta lógica molecular para llevar a cabo acciones terapéuticas en un determinado tipo celular o tejido, llevando a una mayor especificidad y disminuyendo los efectos indeseables de las terapias convencionales. Además las nanoestructuras de ADN pueden ser utilizadas como una unión programable de fármacos, ligandos diana y otras modificaciones o sistemas como bicapas lipídicas. Por otro lado, se han desarrollado sondas de imagen con buena sensibilidad y especificidad, que se consideran mecanismos de amplificación basados en ADN y que pueden ser programados para interactuar específicamente con las secuencias de ácido ribonucleico (ARN) a nivel intracelular. Otra aplicación es la generación de estructuras de ADN que entregan un control preciso a la organización espacial intracelular, proporcionando una base para desarrollar sistemas de cuantificación a nivel subcelular.[60]​ Las nanoestructuras de ADN como vehículos de liberación de fármacos se ha desarrollado de manera importante en los últimos años. Para tal efecto, los oligodesoxinucleotidos CpG (ODNs) pueden disparar una respuesta inmune innata activando los receptores tipo Toll del tipo TLR9. Dichos ODNs se han convertido en un interesante cargo terapéutico debido a que puede ser integrado directamente dentro de la nanoestructura del ADN a través de hibridación. Se han desarrollado moléculas de ADN en forma de Y con motivos CpG que pueden desencadenar una respuesta inmune aumentando la eficiencia de captación de macrófagos. Otros hallazgos han llevado a la creación de complejos de vacunas sintéticas por ensamblaje de nanoestructuras de ADN tetraedricas (TDNs) que fueron modificadas con estreptavidina y ODNs CpG. En ese caso la estreptavidina sirve como un antígeno modelo que lleva a que el constructo genere anticuerpos IgG anti-estreptavidina.[60]​


== Nanotecnología por países ==


=== Argentina ===


==== Desarrollo conceptuales ====
Según la Fundación Argentina de Nanotecnología (FAN), “Las propiedades de la materia cambian cuando se pasa de una escala macroscópica, a la nanoscópica… En la nanoescala las propiedades intensivas (color, punto de fusión, densidad, conductividad eléctrica y térmica, etc) cambian sorprendentemente, no dependen de la cantidad de materia. Por ejemplo las plata, el cual en las distintas escalas adquiere distintos colores.”[61]​
En cambio, las nanociencias según la Escuela de Nanociencias y Nanotecnologías[62]​ de la Argentina, a diferencia de las nanotecnologías, abordan el estudio y explicación de los aspectos fundamentales y tecnológicos de las propiedades y procesos físicos, químicos y/o biológicos que emergen en sistemas y materiales a la nanoescala; Además de las distintas técnicas, cálculos y herramientas para la fabricación y control de los nanosistemas.


==== Historia de la Nanotecnología en la Argentina. ====
Desde principios de los años 2000, esta tecnología ha experimentado un fuerte crecimiento en todo el mundo, a partir de la fabricación de un gran número de productos beneficiados con sus aportes. En ese contexto, nuestro país ha desarrollado un ecosistema de grupos de investigación, empresas y otros actores públicos y privados que han trabajado y trabajan en esa misma dirección.[63]​
En marzo de 2004 se realiza en la entonces Secretaría de Ciencia, Tecnología e innovación Productiva (SECyT), y actualmente Ministerio de Ciencia, Tecnología e Innovación) el primer taller nacional sobre las nanociencias y nanotecnologías.
Es en 2005 donde el Estado anunció la creación de la Fundación Argentina de Nanotecnología (FAN) que hoy en día sigue activa y es un pilar importantísimo en el desarrollo y producción de la Nanotecnología en Argentina.
Considerada una tecnología de propósito general por su capacidad de ofrecer innovaciones a industrias muy disímiles entre sí como la medicina, los alimentos y la electrónica, la nanotecnología se ha convertido en un campo de relevancia en el desarrollo científico y tecnológico de los países y la Argentina no es la excepción. En la actualidad, el país cuenta con 335 grupos en 91 institutos de ciencia y tecnología que desarrollan líneas de investigación en el tema y, a su vez, según el relevamiento realizado, existen 73 empresas nacionales que comercializan productos o procesos con sus aportes o están en proceso de hacerlo.
El abanico de opciones es realmente muy amplio, en Argentina por ejemplo, existen empresas que fabrican implantes dentales con bio nanomateriales, barbijos con nanopartículas de plata y cobre, alimentos saludables enriquecidos con nanomateriales orgánicos biodegradables o insumos sustentables para la producción agrícola.  A esos actores que constituyen parte del ecosistema, se suman otros para potenciarlos; entre ellos están las unidades de vinculación tecnológica, las incubadoras, las universidades y los organismos públicos que también juegan un rol clave en su desarrollo.  
Geográficamente, la distribución de las instituciones que participan en el desarrollo de la nanotecnología en la Argentina se concentra en las provincias del centro y específicamente en las grandes ciudades como Capital Federal, Córdoba, Río Cuarto, Santa Fe, Rosario, Mendoza, La Plata, Mar del Plata y Bahía Blanca. Si bien estos son los lugares principales, también existen institutos con sus grupos de investigación y en algunos casos empresas en las provincias del norte y sur del país, fundamentalmente en Bariloche y San Miguel de Tucumán, entre otras ciudades.[63]​


==== Herramientas, aplicaciones y desarrollos de la nanotecnología en la Argentina. ====
Los microscopios convencionales ópticos, como los que podemos encontrar en los laboratorios de instituciones de educación primarios y secundarios, quedan obsoletos. Actualmente se cuenta con herramientas muy útiles, los microscopios de alta resolución, como el microscopio electrónico de barrido (SEM) de la Universidad de Buenos Aires (UBA), el cual nos permite visualizar los sistemas nanométricos, como por ejemplo nanopartículas de Cu20 (dióxido de cobre) utilizadas en el sector agrónomo como fungicida.
Argentina actualmente cuenta con un incremento de instrumentos y aplicaciones de la nanotecnología, donde el 60 % de la I+D es realizada por grupos de investigación en institutos y centros que se encuentran en organismos de ciencia y tecnología o en Universidades mayoritariamente públicas y algunas privadas.[64]​
Ya en 2011, el Laboratorio de Microscopía Electrónica y Análisis por Rayos X (LAMARX) adquirió una microsonda por un valor de 1,8 millones de dólares, la cual se encuentra en la Facultad de Matemática, Astronomía, Física y Computación (FAMAF), perteneciente a  la Universidad Nacional de Córdoba (UNC).[65]​
Actualmente, se cuenta además entre otros, la Nanofab[66]​, un laboratorio de asesoramiento, incubación y servicios de equipamiento público que cuenta con la participación de más de 25 instituciones.
Las aplicaciones de la nanotecnología y los nanomateriales abarcan todo tipo de sectores industriales. En la Argentina algunas de estas son:
Medio ambiente: Según la FAN “Nanotek S.A.[67]​ plantea la utilización de nanopartículas de hierro cerovalentes en napas subterráneas para la absorción de arsénico, sustancia que afecta a una gran parte del territorio nacional (16 provincias, 435 000 km2 y 2,5 millones de habitantes) e implica un desembolso de 14 millones de dólares para el presupuesto del área de salud pública”.
Biomedicina: La pandemia generada por el Covid-19 (SARS-CoV-2) conllevo a la creación y mejoras de los barbijos, nuevamente empleando tecnologías desarrolladas por Nanotek S.A. los cuales indican que estos barbijos: “Poseen nanopartículas de plata que liberan iones positivos, capaces de alterar los procesos biológicos de los microorganismos.”[68]​
Energía: Existen 22 grupos en la Argentina en dirección a producir nuevos materiales con mayor eficiencia para su utilización en el sector energético,, por ejemplo en los componentes de los molinos eólicos (mejorar su resistencia y disminuir su peso) y paneles solares (semiconductores capaces de captar mayor energía solar).[69]​


== Consideraciones legales y éticas ==
Por su parte, en el ámbito legislativo la Comisión Europea proporciona una posible definición de los nanomateriales en función de su tamaño[70]​[71]​(sin tener en cuenta el riesgo que puedan suponer). Sin embargo, es realmente complicado trazar la línea para su identificación una vez incorporados a los productos finales. Por otro lado, la producción e importación de este tipo de materiales dependen de los compuestos químicos que los formen, ya que todos ellos deben estar recogidos en el REACH. Además, se exigen técnicas de etiquetado y envasado rigurosas de estos nanomateriales (especialmente si contienen sustancias peligrosas, en cuyo caso se debe notificar a la CLP); así como la provisión de un protocolo de actuación para garantizar un uso seguro de los mismos. Pese a todo, las implicaciones legislativas son tremendamente amplias al tratarse de una disciplina que tantos ámbitos científicos abarca, y quedan pendientes cuestiones como[72]​el derecho sanitario, la regulación del mercado o la protección de datos.
En cuanto a las consideraciones éticas, estas se llevan discutiendo desde el año 2003, en la reunión celebrada en diciembre por parte de la COMEST(un cuerpo administrativo de la UNESCO) en Río de Janeiro. Tres años después, en la reunión celebrada en Dakar, se elaboró un escrito más detallado al respecto, que son las conocidas “Recomendaciones de la COMEST sobre políticas en materia de nanotecnología y ética” [73]​. En este documento se habla, entre otras cosas, sobre:

 La dificultad de identificar la toxicidad de los nanomateriales y de los posibles daños a largo plazo que estos pudieran causar, ya sea a los individuos o al medio ambiente.
Otro aspecto muy interesante es la privacidad y confidencialidad, ya que estas tecnologías podrían suponer la implantación de dispositivos de vigilancia nunca vistos; por lo que definir bajo qué términos se aceptaría esto es algo que también queda en el aire.
 En otro apartado también se alude a cómo la línea entre tecnología y ciencia cada vez se ve más desdibujada, y a la posibilidad de que la propiedad intelectual pudiera contribuir a la “nanobrecha” entre países desarrollados y aquellos que están en vías de ello.
 En líneas generales, se alude a la necesidad de una formación ética al respecto, especialmente en el ámbito científico y tecnológico. También se propone la acción inversa, es decir, que los especialistas en ciencias sociales amplíen sus bases de conocimientos científicos; resultando en un efecto más de la pluri-afección de la nanotecnología.
Se hace especial hincapié en la exigencia de fomentar el debate participativo, ya que, al ser una cuestión interdisciplinar, expertos de todas las áreas deben sentarse a debatir cuestiones como los riesgos que entrañan, los potenciales beneficios de las mismas o los contextos de aplicación más favorables.
Sin embargo, pese a todo el debate y la aparente fragilidad de los mecanismos legislativos y éticos, hoy en día existen cientos de productos que incorporan este tipo de tecnologías en el mercado, especialmente medicamentos y cosméticos. Esta situación se ve reflejada de estupenda manera en el artículo “La ética y el desarrollo de la Nanotecnología” [74]​, en el que Hugh Lacey alude a que el contexto del desarrollo de la nanotecnología es realmente similar al de los productos transgénicos en su momento, es decir, guiado principalmente por el beneficio económico (y cuanto más inmediato, mejor). En cambio, el debate ético sobre cuestiones como los riesgos que estas tecnologías podrían entrañar o los potenciales beneficiarios queda en segundo plano, porque implicaría retrasar el avance científico y la posibilidad de quedarse atrás tecnológicamente.


== Véase también ==
Nanofibra
Nanoalimentos
Nanomedicina
Minatec


== Referencias ==


== Bibliografía ==
Acosta, Antonio J. (2016). La nanotecnología: explorando un cosmos en miniatura. Barcelona: RBA Coleccionables. ISBN 867-73-362-7271-4


== Enlaces externos ==
 Wikcionario  tiene definiciones y otra información sobre nanotecnología.
"Laboratorio Nacional de Nanotecnología (México)", El Laboratorio Nacional de Nanotecnología representa una avanzada plataforma tecnológica para el impulso de la Nanociencia y la Nanotecnología en México.
"Nanospain - Red Española de Nanotecnología", Sitio web sobre la Red Española de Nanotecnología coordinada por el Consejo Superior de Investigaciones Científicas y la Fundación Phantoms.
Centro de Investigación en Nanomateriales y Nanotecnología (CINN)
Artículo sobre el tema en el No. 6 de la Revista Iberoamericana de Ciencia, Tecnología, Sociedad e Innovación
Riesgos sanitarios de la nanotecnología resumen de un dictamen del CCRSERI de la Comisión Europea (2006)
Promesas y Peligros de la Nanotecnología
Medicina nanológica - Aplicaciones médicas de las nanotecnologías Informe del Grupo ETC
Libro publicado por la Oficina de Seguridad y Calidad Alimentaria de la FAO/ONU The FAO/WHO Expert Meeting on the Application of Nanotechnologies in the Food and Agriculture Sectors: Potential Food Safety Implications Meeting Report - Rome 2010
Qué es la Nanotecnología ?
El término genética (del griego antiguo: γενετικός, guennetikós, ‘genetivo’, y este de γένεσις, génesis, ‘origen’;[1]​[2]​[3]​ acuñado en 1905 por William Bateson) alude al área de estudio de la biología que busca comprender y explicar cómo se transmite la herencia biológica de generación en generación mediante el ADN. Se trata de una de las funciones fundamentales de la biología moderna, y abarca en su interior un gran número de disciplinas propias e interdisciplinarias que se relacionan directamente con la bioquímica, la medicina y la biología celular.
El principal objeto de estudio de la genética son los genes, formados por segmentos de ADN y ARN, tras la transcripción de ARN mensajero, ARN ribosómico y ARN de transferencia, los cuales se sintetizan a partir de ADN. El ADN controla la estructura y el funcionamiento de cada célula, tiene la capacidad de crear copias exactas de sí mismo tras un proceso llamado replicación.


== Primeros estudios genéticos ==

Gregor Johann Mendel (20 de julio de 1822[4]​-6 de enero de 1884) fue un monje agustino católico y naturalista nacido en Heinzendorf, Austria (actual Hynčice, distrito Nový Jičín, República Checa) que descubrió, por medio de la experimentación de mezclas de diferentes variedades de guisantes, chícharos o arvejas (Pisum sativum), las llamadas Leyes de Mendel que dieron origen a la herencia genética. 
En 1941 Edward Lawrie Tatum y George Wells Beadle demostraron que los genes ARN mensajero codifican proteínas; luego en 1953 James D. Watson y Francis Crick determinaron que la estructura del ADN es una doble hélice en direcciones antiparalelas, polimerizadas en dirección 5' a 3', para el año 1977 Frederick Sanger, Walter Gilbert, y Allan Maxam secuencian ADN completo del genoma del bacteriófago y en 1990 se funda el Proyecto Genoma Humano.


== La ciencia de la genética ==
Aunque la genética juega un papel muy significativo en la apariencia y el comportamiento de los organismos, es la combinación de la genética, replicación, transcripción y procesamiento (maduración del ARN) con las experiencias del organismo la cual determina el resultado final.
Los genes corresponden a regiones del ADN o ARN, dos moléculas compuestas de una cadena de cuatro tipos diferentes de bases nitrogenadas (adenina, timina, citosina y guanina en ADN), en las cuales tras la transcripción (síntesis de ARN) se cambia la timina por uracilo —la secuencia de estos nucleótidos es la información genética que heredan los organismos. El ADN existe naturalmente en forma bicatenaria, es decir, en dos cadenas en que los nucleótidos de una cadena complementan los de la otra.
La secuencia de nucleótidos de un gen es traducida por las células para producir una cadena de aminoácidos, creando proteínas —el orden de los aminoácidos en una proteína corresponde con el orden de los nucleótidos del gen. Esto recibe el nombre de código genético. Los aminoácidos de una proteína determinan cómo se pliega en una forma tridimensional y responsable del funcionamiento de la proteína. Las proteínas ejecutan casi todas las funciones que las células necesitan para vivir.
El genoma es la totalidad de la información genética que posee un organismo en particular. Por lo general, al hablar de genoma en los seres eucarióticos se refiere solo al ADN contenido en el núcleo, organizado en cromosomas, pero también la mitocondria contiene genes y es llamada genoma mitocondrial.


=== Subdivisiones de la genética ===
La genética se subdivide en varias ramas, como:

Citogenética: El eje central de esta disciplina es el estudio del cromosoma y su dinámica, así como el estudio del ciclo celular y su repercusión en la herencia. Está muy vinculada a la biología de la reproducción y a la biología celular.
Clásica o Mendeliana: Se basa en las leyes de Mendel para predecir la herencia de ciertos caracteres o enfermedades. La genética clásica también analiza como el fenómeno de la recombinación o el ligamiento alteran los resultados esperados según las leyes de Mendel.
Cuantitativa: Analiza el impacto de múltiples genes sobre el fenotipo, muy especialmente cuando estos tienen efectos de pequeña escala.
Filogenia: Es la genética que estudia el parentesco entre los distintos taxones de seres vivos.
Genética clínica: Aplica la genética para diagnosticar patologías de origen genético.
Genética preventiva: Hace uso de la genética para mostrar las distintas predisposiciones que se pueden tener a diversos factores.
Genética de poblaciones: Se preocupa del comportamiento de los genes en una población y de cómo esto determina la evolución de los organismos.
Genética del desarrollo: Estudia cómo los genes son regulados para formar un organismo completo a partir de una célula inicial.
Genética molecular: Estudia el ADN, su composición y la manera en que se duplica. Así mismo, estudia la función de los genes desde el punto de vista molecular: Como transmiten su información hasta llegar a sintetizar proteínas.
Mutagénesis: Estudia el origen y las repercusiones de las mutaciones en los diferentes niveles del material genético.


=== Ingeniería genética ===

La ingeniería genética es la especialidad que utiliza tecnología de la manipulación y trasferencia del ADN de unos organismos a otros, permitiendo controlar algunas de sus propiedades genéticas. Mediante la ingeniería genética se pueden potenciar y eliminar cualidades de organismos en el laboratorio (véase Organismo genéticamente modificado). Por ejemplo, se pueden corregir defectos genéticos (terapia génica), fabricar antibióticos en las glándulas mamarias de vacas de granja o clonar animales como la oveja Dolly.
Algunas de las formas de controlar esto es mediante transfección (lisar células y usar material genético libre), conjugación (plásmidos) y transducción (uso de fagos o virus), entre otras formas. Además se puede ver la manera de regular esta expresión genética en los organismos.
Respecto a la terapia génica, antes mencionada, hay que decir que todavía no se ha conseguido llevar a cabo un tratamiento, con éxito, en humanos para curar alguna enfermedad. Todas las investigaciones se encuentran en la fase experimental. Debido a que aún no se ha descubierto la forma de que la terapia funcione (tal vez, aplicando distintos métodos para introducir el ADN), cada vez son menos los fondos dedicados a este tipo de investigaciones. Por otro lado, aunque este es un campo que puede generar muchos beneficios económicos, este tipo de terapias son muy costosas, por lo que, en cuanto se consiga mejorar la técnica y  disminuir su coste, es de suponer que las inversiones subirán.


== Genética muscular ==
Investigaciones actuales afirman que los marcadores metabólicos entre los distintos tipos de genética muscular pueden diferenciarse en un 7-18%. La diferencia principal se encuentra en la reacción del cuerpo ante la ingesta de carbohidratos y los niveles de las hormonas sexuales como la testosterona. 
La genética muscular es un área de la ciencia con potenciales herramientas para mejorar los resultados en el deporte. Determinar la predisposición genética de un individuo: ectomorfo, mesomorfo o endomorfo, es una estrategia utilizada por los profesionales del deporte para incrementar el rendimiento. Se han diferencias en la concentración de creatina en los distintos tipos somatotipos corporales así como diferencias en las concentraciones de distintos marcadores metabólicos.[5]​[6]​


== Cronología de descubrimientos genéticos notables ==


== Adaptaciones genéticas ==
Los cambios genéticos pueden dotar a las especies de rasgos complejos que les permita expandirse y ocupar nuevos nichos. Estos cambios son claves para la especiación y diversificación. Por ejemplo, para adaptarse a la vida en las alturas de los árboles, diferentes especies de ranas han adquirido evolutivamente rasgos complejos para escalar y planear.[9]​


== Véase también ==


== Referencias ==


== Bibliografía ==
GRIFFITHS, A.J.F., S. R. WESSLER, R.C. LEWONTIN & S. B. CARROLL (2008). Genética. MGraw-Hill Interamericana. Novena edición.
KLUG, W.S. & CUMMINGS, M.R. (1998). Conceptos de Genética. 5.ª Edición. Prentice Hall. España.
BENITO-JIMÉNEZ, C. (1997). 360 Problemas de Genética. Resueltos paso a paso. 1.ª Edición. Editorial Síntesis. España.
MENSUA, J.L. (2002). Genética: Problemas y ejercicios resueltos. Prentice.


== Bibliografía adicional ==
Alberts, Bruce; Bray, Dennis; Hopkin, Karen; Johnson, Alexander; Lewis, Julian; Raff, Martin; Roberts, Keith; Walter, Peter (2013). Essential Cell Biology, 4th Edition (en inglés). Garland Science. ISBN 978-1-317-80627-1. 
Griffiths, Anthony J.F.; Miller, Jeffrey H.; Suzuki, David T.; Lewontin, Richard C.; Gelbart, eds. (2000). An Introduction to Genetic Analysis (en inglés) (7th edición). New York: W. H. Freeman. ISBN 978-0-7167-3520-5. 
Hartl D, Jones E (2005). Genetics: Analysis of Genes and Genomes (en inglés) (6th edición). Jones & Bartlett. ISBN 978-0-7637-1511-3. 
King, Robert C; Mulligan, Pamela K; Stansfield, William D (2013). A Dictionary of Genetics (en inglés) (8th edición). New York: Oxford University Press. ISBN 978-0-19-976644-4. 
Lodish H, Berk A, Zipursky LS, Matsudaira P, Baltimore D, Darnell J (2000). Molecular Cell Biology (en inglés) (4th edición). New York: Scientific American Books. ISBN 978-0-7167-3136-8. 


== Enlaces externos ==
 Wikcionario  tiene definiciones y otra información sobre genética.
 Wikiversidad alberga proyectos de aprendizaje sobre Genética.
 Wikinoticias tiene noticias relacionadas con Genética.
 Wikimedia Commons alberga una categoría multimedia sobre Genética.
Sociedad española de genética.
Sociedad de Genética de Chile.
Centro de Genética Humana, Facultad de Medicina CAS-UDD.
Asociación Española de Genética Humana.
Instituto de Genética Humana.
Grado de genética de la Universidad Autónoma de Barcelona.
La genética al alcance de todos.
Citología y Genética. Revista científica.
Genética de poblaciones y gráficos de distancias genéticas.
Centro de Regulación Genómica.
Leyendo el libro de la vida: Museo Virtual Interactivo sobre la Genética y el ADN.
Curso genética de la UAB. Plataforma Web 2.0 para la docencia universitaria
Genética Médica News.
Noticias de actualidad sobre genética
La tecnología de la información (TI o IT, information technology) es la aplicación de ordenadores y equipos de telecomunicación para almacenar, recuperar, transmitir y manipular datos, con frecuencia utilizado en el de los negocios u otras empresas. El término se utiliza como sinónimo para los computadores y las redes de computadoras, pero también abarca otras tecnologías de distribución de información, tales como la televisión y los teléfonos. Múltiples industrias están asociadas con las tecnologías de la información: hardware y software de computadoras, electrónica, semiconductores, internet, equipos de telecomunicación, el comercio electrónico y los servicios computacionales.[1]​
Frecuentemente, los términos TI y TIC suelen usarse indistintamente: mientras que TI se refiere a tecnologías de la información, TIC implica, además, las destinadas a la comunicación. De esta forma, TIC es un término más amplio, que engloba las TI.[2]​ «Las TI abarcan el dominio completo de la información, que incluye al hardware, al software, a los periféricos y a las redes. Un elemento cae dentro de la categoría de las TI cuando se usa con el propósito de almacenar, proteger, recuperar y procesar datos electrónicamente».[3]​
Los seres humanos han estado almacenando, recuperando, manipulando y comunicando información desde que los sumerios en Mesopotamia desarrollaron la escritura, cerca del año 3000 a. C., pero el término tecnología de la información, en su significado moderno, hizo su aparición en 1958, en un artículo publicado en la revista Harvard Business Review. Sus autores, Harold J. Leavitt y Thomas L. Whisler, comentaron que «la nueva tecnología no tiene aún un nombre establecido. Deberíamos llamarla tecnología de la información (TI)». Su definición consistía en tres categorías: técnicas de procesamiento, la aplicación de métodos estadísticos y matemáticos para la toma de decisión y la simulación del pensamiento de orden superior a través de programas computacionales.[4]​
Basándose en la tecnología de almacenamiento y procesamiento empleada, es posible distinguir cuatro eras del desarrollo de la TI: pre-mecánica (3000 a. C.-1450 d. C.), mecánica (1450-1840), electromecánica (1840-1940) y electrónica (1940 al presente).[5]​


== Historia de la informática ==

La informática puede definirse como la ciencia que se encarga del estudio de la obtención de información por medios automáticos. Para entender mejor esta definición, hace falta conocer lo que se entiende por información, datos y medios automáticos. Los datos son el conjunto de elementos que, a través de indicaciones, deben darse a una máquina para que los procese y ofrezca un resultado. La información es el conjunto de datos y los resultados que entrega la máquina. Un medio automático es una máquina que es capaz, por ella sola, de elaborar o procesar una cierta información sobre la base de unos ciertos datos de entrada que nos condicionarán los resultados del procesamiento de esta.[6]​
Han sido utilizados dispositivos para asistir a la computación durante miles de años, iniciando probablemente con el palo tallado. El mecanismo de Anticitera, que data cerca del comienzo del primer siglo a. C., es considerado generalmente como la computadora análoga más antigua descubierta, y el más antiguo mecanismo de engranaje. Dispositivos de engranaje comparables no surgieron en Europa hasta el siglo XVI, y no fue hasta 1645 cuando se inventó la primera calculadora mecánica capaz de realizar las cuatro operaciones aritméticas básicas.
Las computadoras electrónicas, usando tanto relés como válvulas, comenzaron a aparecer a comienzos de la década de 1940. La electromecánica Zuse Z3, terminada en 1941, fue la primera computadora programable del mundo, y, según los estándares modernos, una de las primeras máquinas que podrían ser consideradas de cómputo completa. Colossus, desarrollada durante la Segunda Guerra Mundial para descifrar mensajes alemanes, fue la primera computadora electrónica digital. Aunque era programable, no era de uso general, habiendo sido diseñada para realizar una única tarea. Carecía además de la capacidad de almacenar su programa en una memoria; su programación se realizaba usando enchufes e interruptores para alterar su cableado interno. La primera computadora de programas almacenados electrónica digital reconocible fue la Máquina Experimental de Pequeña Escala de Mánchester (SSEM por su nombre en inglés: Manchester Small-Scale Experimental Machine), que ejecutó su primer programa el 21 de junio de 1948. 

El desarrollo de los transistores a finales de la década de 1940 en los Laboratorios Bell permitió una nueva generación de computadoras diseñadas con un consumo de energía reducido considerablemente. La primera computadora de programa almacenado disponible comercialmente, la Ferranti Mark I, contenía 4050 válvulas y tenía un consumo energético de 25 kilowatts. En comparación, la primera computadora transistorizada, desarrollada en la Universidad de Mánchester y operacional en noviembre de 1953, consumía solo 150 watts en su versión final.
La tecnología de la información comenzó a desarrollarse con fuerza en la década de 1960, junto con la aparición y el desarrollo de los primeros sistemas de información.
IBM lanzó el primer disco duro en 1956, como componente del sistema informático 305 RAMAC. En la actualidad, la mayoría de los datos digitales se almacenan magnéticamente en discos duros u ópticamente en soportes como el CD-ROM. Antes de 2002, la mayor parte de la información se almacenaba en dispositivos analógicos, pero ese año la capacidad digital superó a la de los dispositivos analógicos por primera vez. En 2007, casi el 94 % de los datos almacenados en todo el mundo se almacenan digitalmente: El 52 % en discos duros, el 28 % en dispositivos ópticos y el 11 % en cinta magnética digital. Se calcula que la capacidad mundial de almacenamiento de los dispositivos electrónicos ha pasado de menos de 3 exabytes en 1986 a 295 exabytes en 2007, duplicándose aproximadamente cada 3 años.


== Desarrollo ==

Una entrada es el proceso por el cual un ordenador recibe datos.[3]​ Ya que estos son digitales, cualquier entrada recibida debe ser digitalizada. Para poder enviar datos a un ordenador se requiere de hardware, los periféricos de entrada.[7]​ Estos son algunos de los más habituales:[8]​

Teclado: transforma la pulsación de una tecla en datos entendibles por el ordenador.
Ratón: facilita la interacción en un entorno gráfico.
Micrófono: se conecta a la tarjeta de sonido y digitaliza datos en formatos de sonido como WAV o MP3.
Cámara web: consiste en una cámara digital conectada al ordenador.
Escáner: digitaliza imágenes y documentos.
En el procesamiento electrónico, los datos de entrada son aquellos que la computadora va a procesar. Los datos de salida son obtenidos a partir del procesamiento de los datos de entrada.[8]​


== Desarrollo ==
Se recurre a las tecnologías de la información, basadas y utilizando racionalmente los logros modernos en el campo de la tecnología informática y otras tecnologías avanzadas, las últimas herramientas de comunicación, software y experiencia práctica, para resolver problemas sobre la organización efectiva del proceso de información para reducir el costo del tiempo, mano de obra, energía y recursos materiales en todos los ámbitos de la vida humana y la sociedad moderna. Las tecnologías de la información interactúan y, a menudo, forman parte de los servicios, la gestión, la producción industrial y los procesos sociales.[9]​


== Almacenamiento de datos ==

Las primeras computadoras electrónicas, como la Colossus, hacían uso de cintas perforadas, una larga tira de papel en donde los datos son representados por una serie de agujeros, una tecnología ahora obsoleta. El almacenamiento electrónico de datos usado por las computadoras modernas data de la Segunda Guerra Mundial, cuando una forma de memoria de línea de retardo fue desarrollada para eliminar el desorden de las señales de radar; la primera aplicación práctica de esto fue la línea de retardo de mercurio. El primer dispositivo de almacenamiento digital de acceso aleatorio fue el Tubo Williams, basado en un tubo de rayos catódicos estándar, pero la información almacenada en ella y en la memoria de línea de retardo era volátil, por lo que debía ser continuamente refrescada, y por lo tanto se perdía una vez que se desconectaba de la energía. La primera forma de almacenamiento computacional no volátil fue la memoria de tambor, inventada en 1932 y usada en la Ferranti Mark I, la primera computadora de uso general disponible comercialmente.
IBM introdujo el primer disco duro en 1956, como un componente de su sistema computacional 305 RAMAC. La mayoría de los datos digitales al día de hoy son almacenados magnéticamente en discos duros, u ópticamente en medios como los CD-ROMs. Hasta 2002, la mayoría de la información era almacenada en dispositivos analógicos, pero ese año la capacidad de almacenamiento digital superó al analógico por primera vez. En 2007 cerca del 94 % de los datos almacenados mundialmente eran digitales: 52 % en discos duros, 28 % en medios ópticos y 11 % en cintas magnéticas digitales. Se ha estimado que la capacidad mundial de almacenamiento de información en dispositivos electrónicos creció de menos de 3 exabytes en 1986 a 295 exabytes en 2007, doblándose aproximadamente cada tres años.


=== Bases de datos ===
Los sistemas de administración de bases de datos surgieron en la década de 1960 para abordar el problema de almacenar y recuperar grandes cantidades de datos de manera precisa y rápida. Uno de los primeros sistemas fue el Information Management System de IBM, el cual sigue siendo ampliamente implementado más de 40 años después. El IMS almacena datos jerárquicamente, pero en la década de 1970, Ted Codd propuso como alternativa los modelos de almacenamiento relacionales basándose en la teoría de conjuntos y en la lógica de predicados y en conceptos familiares como lo son las tablas, filas y columnas. El primer sistema de gestión de bases de datos relacionales (RDBMS del inglés: relational database management system) comercial disponible fue el de Oracle en 1980.
Todos los sistemas de administración de bases de datos consisten en un número de componentes que juntos permiten que los datos que ellos almacenan sean accedidos simultáneamente por varios usuarios mientras mantienen su integridad. Una característica de todas las bases de datos es que la estructura de los datos que contienen es definido y almacenado de manera separada de los datos mismos, en el llamado esquema de la base de datos.
El lenguaje de marcas extensible o XML, siglas en inglés de eXtensible Markup Language, se ha vuelto un formato para la representación de datos popular en los últimos años. Aunque los datos XML pueden ser almacenados en sistemas de archivos normales, son comúnmente usados en bases de datos relacionales para aprovechar su «aplicación robusta verificada durante años por esfuerzos tanto teóricos como prácticos». Como una evolución del Estándar de Lenguaje de Marcado Generalizado o SGML, las estructuras basadas en texto XML ofrecen la ventaja de poder ser leídas por máquinas como por humanos.


== Base de conocimiento ==
Una Base de conocimiento (o knowledge base en inglés; KB, kb oro Δ) es un tipo especial de base de datos para la gestión del conocimiento. Provee los medios para la recolección, organización y recuperación computarizada de conocimiento.
Las bases de conocimiento se han clasificado en dos grandes tipos:

Bases de conocimiento legibles por máquinas, diseñadas para almacenar conocimiento en una forma legible por el ordenador, usualmente para obtener razonamiento deductivo automático aplicado a ellas. Contienen una serie de datos, usualmente en la forma de reglas que describen el conocimiento de manera lógicamente consistente. Operadores lógicos como AND (conjunción), OR (disyunción), condición lógica y negación son utilizada para aumentarla desde el conocimiento atómico. Por lo tanto la deducción clásica puede ser utilizada para razonar sobre el conocimiento en la base de conocimiento. Este tipo de bases de conocimiento son utilizadas por la web semántica.[10]​
Bases de conocimiento legibles por humanos están diseñadas para permitir a las personas acceder al conocimiento que ellas contienen, principalmente para propósitos de aprendizaje. Estas son comúnmente usadas para obtener y conducir conocimiento explícito de las organizaciones, incluyen artículos, libro blanco, manuales de usuario y otros. El principal beneficio que proveen las bases de conocimiento es proporcionar medios de descubrir soluciones a problemas ya resueltos, los cuales podrían ser aplicados como base a otros problemas dentro o fuera del mismo área de conocimiento.
Lo más importante aspecto de una base de conocimiento es la calidad de la información que ésta contiene. Las mejores bases de conocimiento tienen artículos cuidadosamente redactados que se mantienen al día, un excelente sistema de recuperación de información (motor de búsqueda), y un delicado formato de contenido y estructura de clasificación. Una base de conocimiento puede usar una ontología para especificar la estructura (tipo de entidades y relaciones) y su esquema de clasificación. Una ontología, junto con un grupo de instancias de sus clases constituyen una base de conocimiento.[11]​


== Recuperación de datos ==
El modelo relacional introdujo un lenguaje de programación independiente llamado Structured Query Language, basado en el álgebra relacional. El término «dato» e «información» no son sinónimos. Cualquier cosa almacenada es un dato, pero solo se transforma en información cuando es organizada y presentada de forma significativa. La mayoría de los datos digitales a nivel mundial están desestructurados y almacenados en una variedad de diferentes formatos físicos, incluso aquellos pertenecientes a una misma organización. Los almacenes de datos comenzaron a ser desarrollados en la década de 1980 para integrar estos diversos depósitos de datos. Por lo general contienen datos extraídos de variadas fuentes, incluidas fuentes externas como Internet, y organizadas de tal manera que sirva a los Sistemas de Soporte a Decisiones (DSS por sus siglas en inglés Decision Support System).


== Transmisión de datos ==
La transmisión de datos contempla tres etapas: transmisión, propagación y recepción. Puede ser ampliamente categorizada como broadcasting, en donde la información es transmitida unidireccional y descendentemente, o como telecomunicación, con canales bidireccionales tanto ascendentes como descendentes. XML ha sido empleado cada vez más como medio de intercambio de información desde comienzos de la década de 2000, particularmente para interacciones orientadas a la máquina como aquellas involucradas en protocolos web como SOAP, describiendo «datos en tránsito en vez de datos en reposo». Uno de los retos de su uso es convertir datos de una base de datos relacional en estructuras como la Document Object Model o DOM.


== Manipulación de datos ==

Hilbert y López identificaron un ritmo exponencial de cambio tecnológico (una especie de Ley de Moore): la capacidad per cápita de las máquinas de uso específico para procesar información se duplicó aproximadamente cada 14 meses entre 1986 y 2007; la capacidad per cápita de las computadoras de uso general se duplicó cada 18 meses durante las mismas dos décadas; la capacidad mundial de telecomunicaciones per cápita se duplicó cada 34 meses; la capacidad de almacenaje global per cápita necesitó aproximadamente 40 meses para duplicarse (cada tres años); y la información difundida per cápita se duplicó cada 12.3 años.[12]​ Enormes cantidades de datos son almacenados cada día a nivel mundial, pero a menos que pueda ser analizada y presentada de manera efectiva se cataloga en lo que se han llamado tumbas de datos: «archivos de datos que rara vez son visitados». Para abarcar ese problema, el campo de la minería de datos («el proceso de descubrir patrones interesantes y conocimiento desde grandes cantidades de datos») emergió a finales de la década de 1980.[13]​[14]​


=== Sistema de apoyo a la toma de decisiones ===
El concepto de sistema de apoyo a las decisiones (DSS por sus siglas en inglés Decision support system) es muy amplio, porque hay muchos enfoques para la toma de decisiones y debido a la extensa gama de ámbitos en los que se toman. Estos sistemas de apoyo son del tipo OLAP o de minería de datos , que proporcionan información y apoyo para tomar una decisión.
Un DSS puede adoptar muchas formas diferentes. En general, podemos decir que un DSS es un sistema informático utilizado para servir de apoyo, más que automatizar, el proceso de toma de decisiones. La decisión es una elección entre alternativas basadas en estimaciones de los valores de estas alternativas. El apoyo a una decisión significa ayudar a las personas que trabajan solas o en grupo a reunir inteligencia, generar alternativas y tomar decisiones. Apoyar el proceso de toma de decisión implica el apoyo a la estimación, la evaluación y / o la comparación de alternativas. En la práctica, las referencias a DSS suelen ser referencias a aplicaciones informáticas que realizan una función de apoyo.


== Perspectivas ==


=== Perspectiva académica ===
En un contexto académico, la Association for Computing Machinery define las TI como:

 
.


=== Perspectiva comercial y laboral ===
En un contexto de negocios, la Information Technology Association of America ha definido TI como «el estudio, diseño, desarrollo, aplicación, implementación, soporte o mantenimiento de sistemas computacionales de información». Las responsabilidades de este trabajo en el área incluyen administración de redes, desarrollo de software e instalación, y la planificación y administración del ciclo de vida de las tecnologías de una organización, en donde el hardware y software son mantenidos, actualizados y reemplazados.
Las empresas del campo de la tecnología de la información a menudo se discuten como grupo como el «sector tecnológico» o la «industria tecnológica».  Estos títulos pueden ser engañosos en ocasiones y no deben confundirse con «empresas de tecnología»; que son generalmente corporaciones con fines de lucro a gran escala que venden software y tecnología de consumo. También vale la pena señalar que, desde una perspectiva comercial, los departamentos de tecnología de la información son un «centro de costos» la mayor parte del tiempo. Un centro de costos es un departamento o personal que incurre en gastos, o «costos», dentro de una empresa en lugar de generar ganancias o flujos de ingresos. Las empresas modernas dependen en gran medida de la tecnología para sus operaciones diarias, por lo que los gastos delegados para cubrir la tecnología que facilita los negocios de una manera más eficiente generalmente se consideran «solo el costo de hacer negocios». Los departamentos de TI reciben fondos por parte de la alta dirección y deben intentar lograr los entregables deseados sin salirse de ese presupuesto. El gobierno y el sector privado pueden tener diferentes mecanismos de financiación, pero los principios son más o menos los mismos. Esta es una razón que a menudo se pasa por alto para el rápido interés en la automatización y la inteligencia artificial, pero la presión constante para hacer más con menos está abriendo la puerta para que la automatización tome el control de al menos algunas operaciones menores en las grandes empresas.
Muchas empresas ahora tienen departamentos de TI para administrar las computadoras, las redes y otras áreas técnicas de sus negocios. Las empresas también han buscado integrar la TI con los resultados comerciales y la toma de decisiones a través de un departamento de operaciones comerciales o BizOps. El valor de negocio de las tecnologías de información recae en la automatización de procesos de negocio, provisión de información para la toma de decisiones, conectando los negocios con sus clientes y la provisión de herramientas de productividad para incrementar la eficiencia.


=== Perspectiva ética ===
El campo de la ética de la información fue establecida por el matemático Norbert Wiener en la década de 1940. Algunos de los problemas éticos asociados con el uso de las tecnologías de la información incluyen:

Violación de derechos de autor por aquellos que descargan archivos sin el permiso de los titulares de los derechos de autor.
Empleadores monitorizando los correos electrónicos de sus empleados y otros usos de Internet.
Spam o correo electrónico no deseado.
Hackers accediendo a bases de datos en línea.
Sitios web instalando cookies o programas espía para monitorizar la actividad de un usuario en línea.


== Potencial y crecimiento tecnológico ==
Gilbert y López señalan el crecimiento exponencial del progreso tecnológico (una especie de ley de Moore ) como una duplicación de la densidad de potencia per cápita de todas las máquinas de procesamiento de información cada 14 meses entre 1986 y 2007; el potencial mundial de telecomunicaciones per cápita se duplica cada 34 meses; la cantidad de información ingresada en el mundo per cápita se duplica cada 40 meses (es decir, cada tres años), y la transmisión de información per cápita tiende a duplicarse aproximadamente cada 12.3 años.[15]​


== Véase también ==
Informática
Ciencias de la computación
Procesamiento de datos
Tecnologías de la información y la comunicación
Gestión de la información
Sociedad del conocimiento
World Information Technology and Services Alliance (WITSA)


== Referencias ==


== Bibliografía ==
Alavudeen, A.; Venkateshwaran, N. (2010), Computer Integrated Manufacturing, PHI Learning, ISBN 978-81-203-3345-1.
Chaudhuri, P. Pal (2004), Computer Organization and Design, PHI Learning, ISBN 978-81-203-1254-8.
Han, Jiawei; Kamber, Micheline; Pei, Jian (2011), Data Mining: Concepts and Techniques (3rd ed.), Morgan Kaufmann, ISBN 978-0-12-381479-1.
Lavington, Simon (1980), Early British Computers, Manchester University Press, ISBN 978-0-7190-0810-8.
Lavington, Simon (1998), A History of Manchester Computers (2nd ed.), The British Computer Society, ISBN 978-1-902505-01-5.
Pardede, Eric (2009), Open and Novel Issues in XML Database Applications, Information Science Reference, ISBN 978-1-60566-308-1.
Ralston, Anthony; Hemmendinger, David; Reilly, Edwin D., eds. (2000), Encyclopedia of Computer Science (4th ed.), Nature Publishing Group, ISBN 978-1-56159-248-7.
van der Aalst, Wil M. P. (2011), Process Mining: Discovery, Conformance and Enhancement of Business Processes, Springer, ISBN 978-3-642-19344-6.
Ward, Patricia; Dafoulas, George S. (2006), Database Management Systems, Cengage Learning EMEA, ISBN 978-1-84480-452-8.
Weik, Martin (2000), Computer Science and Communications Dictionary, 2, Springer, ISBN 978-0-7923-8425-0.
Wright, Michael T. (2012), "The Front Dial of the Antikythera Mechanism", in Koetsier, Teun; Ceccarelli, Marco (eds.), Explorations in the History of Machines and Mechanisms: Proceedings of HMM2012, Springer, pp. 279–292, ISBN 978-94-007-4131-7.


=== Bibliografía adicional ===
Allen, T.; Morton, M. S. Morton, eds. (1994), Information Technology and the Corporation of the 1990s, Oxford University Press .
Gitta, Cosmas and South, David (2011). Southern Innovator Magazine Issue 1: Mobile Phones and Information Technology: United Nations Office for South-South Cooperation. ISSN 2222-9280
Gleick, James (2011).The Information: A History, a Theory, a Flood. New York: Pantheon Books.
Price, Wilson T. (1981), Introduction to Computer Data Processing, Holt-Saunders International Editions, ISBN 978-4-8337-0012-2 .
Shelly, Gary, Cashman, Thomas, Vermaat, Misty, and Walker, Tim. (1999). Discovering Computers 2000: Concepts for a Connected World. Cambridge, Massachusetts: Course Technology.
Webster, Frank, and Robins, Kevin. (1986). Information Technology – A Luddite Analysis. Norwood, NJ: Ablex.


== Enlaces externos ==

 Wikiversidad alberga proyectos de aprendizaje sobre Tecnología de la información.

 Wikimedia Commons alberga una categoría multimedia sobre Tecnología de la información.

 Wikiquote alberga frases célebres de o sobre Tecnología de la información.
La robótica es la disciplina que se ocupa del diseño, operación, manufacturación, estudio y aplicación de autómatas o robots. Combina áreas como la ingeniería mecánica, eléctrica, electrónica, biomédica y las ciencias de la computación para crear herramientas que puedan realizar tareas de manera eficiente, rápida y en ambientes inaccesibles para los humanos.[1]​[2]​ 
La robótica combina diversas disciplinas como la informática, la inteligencia artificial, la ingeniería de control y la física.[3]​ Otras áreas importantes en robótica son el álgebra, los autómatas programables, la animatrónica y las máquinas de estados, y se usa también como ayuda para la enseñanza.[4]​
El término robot se popularizó con el éxito de la obra R.U.R. (Robots Universales Rossum), escrita por Karel Čapek en 1920. En la traducción al inglés de dicha obra la palabra checa robota, que significa trabajos forzados o trabajador, fue traducida al inglés como robot.[5]​
Los avances de la robótica han demostrado que hay aparatos robotizados que pueden moverse e interactuar con su entorno basándose en la enorme disponibilidad de sensores precisos y de motores de alto rendimiento, y el desarrollo de complejos algoritmos que permiten cartografiar, localizar, planificar desplazamientos y orientarse mediante coordenadas.[6]​


== Historia de la robótica ==
La robótica va unida a la construcción de «artefactos» que trataban de materializar el deseo humano de crear seres a su semejanza y que al mismo tiempo lo descargasen de trabajos tediosos o peligrosos. El ingeniero español Leonardo Torres Quevedo (que construyó el primer mando a distancia para su automóvil mediante telegrafía, el ajedrecista automático, el primer transbordador aéreo y otros muchos ingenios), acuñó el término «automática» en relación con la teoría de la automatización de tareas tradicionalmente asociadas.[cita requerida] 
El término robótica es acuñado por Isaac Asimov, definiendo a la ciencia que estudia a los robots. Asimov creó también las tres leyes de la robótica. En la ciencia ficción, se ha imaginado a los robots visitando nuevos mundos, haciéndose con el poder o, simplemente, aliviando de las labores caseras. Los robots se utilizan ampliamente en la fabricación, ensamblaje, empaque y embalaje, minería, transporte, exploración espacial, cirugía,[7]​ armamento, investigación de laboratorio, seguridad y la producción en masa de consumidor y bienes industriales.[8]​


== Clasificación de los robots ==


=== Según su cronología ===
La que a continuación se presenta es la clasificación más común:

Primera generación: Robots manipuladores y simples. Son sistemas mecánicos multifuncionales con un sencillo sistema de control, bien manual, de secuencia fija o de secuencia variable.
Segunda generación: Robots de aprendizaje. Repiten una secuencia de movimientos que ha sido ejecutada previamente por un operador humano. El modo de hacerlo es a través de un dispositivo mecánico. El operador realiza los movimientos requeridos mientras el robot le sigue y los memoriza.
Tercera generación: Robots con control sensorizado. El controlador es un ordenador que ejecuta las órdenes de un programa y las envía al manipulador o robot para que realice los movimientos necesarios.


=== Según su estructura ===

La estructura es definida por el tipo de configuración general del robot, puede ser metamórfica. El concepto de metamorfismo, de reciente aparición, se ha introducido para incrementar la flexibilidad funcional de un robot a través del cambio de su configuración por el propio robot. El metamorfismo admite diversos niveles, desde los más elementales (cambio de herramienta o de efecto terminal), hasta los más complejos como el cambio o alteración de algunos de sus elementos o subsistemas estructurales. Los dispositivos y mecanismos que pueden agruparse bajo la denominación genérica del robot, tal como se ha indicado, son muy diversos y es por tanto difícil establecer una clasificación coherente de los mismos que resista un análisis crítico y riguroso. La subdivisión de los robots, con base en su arquitectura, se hace en los siguientes grupos: poliarticulados, móviles, androides, zoomórficos e híbridos. 

Poliarticulados:[12]​ En este grupo se encuentran los robots de muy diversa forma y configuración, cuya característica común es la de ser básicamente sedentarios (aunque excepcionalmente pueden ser guiados para efectuar desplazamientos limitados) y estar estructurados para mover sus elementos terminales en un determinado espacio de trabajo según uno o más sistemas de coordenadas, y con un número limitado de grados de libertad. En este grupo se encuentran los robots manipuladores, los robots industriales y los robots cartesianos, que se emplean cuando es preciso abarcar una zona de trabajo relativamente amplia o alargada, actuar sobre objetos con un plano de simetría vertical o reducir el espacio ocupado en el suelo.
Móviles: Son robots con gran capacidad de desplazamiento, basados en carros o plataformas y dotados de un sistema locomotor de tipo rodante. Siguen su camino por telemando o guiándose por la información recibida de su entorno a través de sus sensores. Estos robots aseguran el transporte de piezas de un punto a otro de una cadena de fabricación. Guiados mediante pistas materializadas a través de la radiación electromagnética de circuitos empotrados en el suelo, o a través de bandas detectadas fotoeléctricamente, pueden incluso llegar a sortear obstáculos y están dotados de un nivel relativamente elevado de inteligencia.
Androides: Son los tipos de robots que intentan reproducir total o parcialmente la forma y el comportamiento cinemático del ser humano. Actualmente, los androides son todavía dispositivos muy poco evolucionados y sin utilidad práctica, y destinados, fundamentalmente, al estudio y experimentación. Uno de los aspectos más complejos de estos robots, y sobre el que se centra la mayoría de los trabajos, es el de la locomoción bípeda. En este caso, el principal problema es controlar dinámica y coordinadamente en el tiempo real el proceso y mantener simultáneamente el equilibrio del robot. Vulgarmente se los suele llamar «marionetas» cuando se les ven los cables que permiten ver cómo realiza sus procesos.
Zoomórficos: Los robots zoomórficos, que considerados en sentido no restrictivo podrían incluir también a los androides, constituyen una clase caracterizada principalmente por sus sistemas de locomoción que imitan a los diversos seres vivos.  A pesar de la disparidad morfológica de sus posibles sistemas de locomoción es conveniente agrupar a los robots zoomórficos en dos categorías principales: caminadores y no caminadores. El grupo de los robots zoomórficos no caminadores está muy poco evolucionado. Los experimentos efectuados en Japón basados en segmentos cilíndricos biselados acoplados axialmente entre sí y dotados de un movimiento relativo de rotación. Los robots zoomórficos caminadores multípedos son muy numerosos y están siendo objeto de experimentos en diversos laboratorios con vistas al desarrollo posterior de verdaderos vehículos terrenos, pilotados o autónomos, capaces de evolucionar en superficies muy accidentadas. Las aplicaciones de estos robots serán interesantes en el campo de la exploración espacial y en el estudio de los volcanes.
Híbridos: Estos robots corresponden a aquellos de difícil clasificación, cuya estructura se sitúa en combinación con alguna de las anteriores ya expuestas, bien sea por conjunción o por yuxtaposición. Por ejemplo, un dispositivo segmentado articulado y con ruedas es, al mismo tiempo, uno de los atributos de los robots móviles y de los robots zoomórficos.


== Consideraciones legales y éticas ==
En la sociedad actual, la robótica ha avanzado significativamente, integrándose en diversos aspectos de la sociedad, desde la industria hasta la atención médica pasando por la investigación ciéntifica. Esta integración plantea importantes consideraciones legales y éticas que deben ser abordadas para garantizar un desarrollo y uso responsable y seguro de la robótica.
Atendiendo a esas consideraciones, organismos como la Unión Europea, entre otros, han desarrollado diversos marcos legislativos para regular esta tecnología y garantizar un uso adecuado de la misma en la industria y la sociedad.


=== Consideraciones legales ===
Son necesarias leyes específicas que regulen la fabricación, operación y uso de robots, especialmente en áreas críticas como la cirugía robótica o los vehículos autónomos. Hay diversos intentos de atajar el problema, por ejemplo, en Europa se están estudiando normas de derecho civil en robótica,[13]​ y en Estados Unidos existen diversas regulaciones hechas por la FAA[14]​ o la NHTSA[15]​, entre otras agencias.


=== Consideraciones éticas ===
Las consideraciones legales y éticas en la robótica son fundamentales para una integración exitosa en la sociedad. Requieren un enfoque multidisciplinar para desarrollar un marco que se enfoque en lograr una innovación responsable y el respeto por los derechos humanos.

Impacto en el empleo: La automatización y la robótica tienen el potencial de desplazar a los trabajadores humanos en ciertas industrias[16]​. Esto plantea cuestiones éticas sobre el impacto en el empleo y la necesidad de estrategias para la reubicación o reorientación profesional de la fuerza laboral[17]​[18]​[19]​.
Autonomía y consentimiento: A medida que los robots se vuelven más autónomos, surge la cuestión de hasta qué punto deben tomar decisiones independientes, con especial atención en contextos críticos, como la atención médica, la administración de justicia[20]​ o el uso de armamento.


== Véase también ==


== Referencias ==


== Bibliografía ==
McGaughey, Ewan (16 de octubre de 2019). Will robots automate your job away? Full employment, basic income, and economic democracy. S2CID 243172487. SSRN 3044448. doi:10.31228/osf.io/udbj8. 
Autor, David H. (1 de agosto de 2015). «Why Are There Still So Many Jobs? The History and Future of Workplace Automation». Journal of Economic Perspectives 29 (3): 3-30. doi:10.1257/jep.29.3.3. hdl:1721.1/109476. 


== Enlaces externos ==
 Wikcionario  tiene definiciones y otra información sobre robótica.
 Wikimedia Commons alberga una categoría multimedia sobre Robótica.
 Wikilibros alberga un libro o manual sobre Robótica.
 Wikiversidad alberga proyectos de aprendizaje sobre Robótica.
Robotics and Automation Society, IEEE
Robotics Portal.
Harvard Graduate School of Design, Design Robotics Group.
Robotics Academy of Iran.
The Robotics Institute at Carnegie Mellon University.
Design and Manufacture of Robotics Control Systems.
Biologically Inspired Robotics Lab, Case Western Reserve University.
Foro de robótica en español
uso de robots en logística e influencia de los Robots en el mundo de la logística
Robots de la vida real que te harán pensar que el futuro es ahora
SpeedFolding. Crean un robot doblador de ropa que puede doblar 40 prendas en una hora
La Revolución Industrial o Primera Revolución Industrial es el proceso de transformación económica, social y tecnológica que se inició en la segunda mitad del siglo XVIII en el Reino de Gran Bretaña, que se extendió unas décadas después a gran parte de Europa occidental y América Anglosajona y que concluyó entre 1820 y 1840; y que sucedió a la revolución comercial. Durante este periodo se vivió el mayor conjunto de transformaciones económicas, tecnológicas y sociales de la historia de la humanidad desde el Neolítico,[1]​ que vio el paso desde una economía rural basada fundamentalmente en la agricultura y el comercio a una economía de carácter urbano, industrializada y mecanizada.[2]​
La Revolución Industrial marca un punto de inflexión en la historia, modificando e influenciando todos los aspectos de la vida cotidiana de una u otra manera. La producción tanto agrícola como de la naciente industria se multiplicó a la vez que disminuía el tiempo de producción. A partir de 1800 la riqueza y la renta per cápita se multiplicó como no lo había hecho nunca en la historia,[3]​ pues hasta entonces el PIB per cápita se había mantenido prácticamente estancado durante siglos.[4]​ En palabras del premio Nobel Robert Lucas:

 

A partir de este momento se inició una transición que acabaría con siglos de una mano de obra basada en el trabajo manual y el uso de la tracción animal, siendo estos sustituidos por maquinaria para la fabricación industrial y para el transporte de mercancías y pasajeros. Esta transición se inició hacia finales del siglo XVIII en la industria textil, así como en lo relacionado con la extracción y utilización de carbón. La expansión del comercio fue posible gracias al desarrollo de las comunicaciones, con la construcción de vías férreas, canales y carreteras. El paso de una economía fundamentalmente agrícola a una economía industrial influyó sobremanera en la población, que experimentó un rápido crecimiento sobre todo en el ámbito urbano. La introducción de la máquina de vapor de James Watt (patentada en 1769) en las distintas industrias fue el paso definitivo en el éxito de esta revolución, pues su uso significó un aumento espectacular de la capacidad de producción. Más tarde, el desarrollo de los barcos y ferrocarriles a vapor, así como el desarrollo en la segunda mitad del siglo XIX del motor de combustión interna y la energía eléctrica, supusieron un progreso tecnológico sin precedentes.[6]​[7]​
Como consecuencia del desarrollo industrial nacieron nuevos grupos o clases sociales encabezadas por el proletariado —los trabajadores industriales y campesinos pobres— y la burguesía, dueña de los medios de producción y poseedora de la mayor parte de la renta y el capital. Esta nueva división social dio pie al desarrollo de problemas sociales y laborales, protestas populares y nuevas ideologías que propugnaban y demandaban una mejora de las condiciones de vida de las clases más desfavorecidas, por la vía del sindicalismo, el socialismo, el anarquismo, o el comunismo.[8]​
Aún sigue habiendo discusión entre historiadores y economistas sobre las fechas de los grandes cambios provocados por la Revolución Industrial. El comienzo más aceptado de lo que podríamos llamar Primera Revolución Industrial, se podría situar a finales del siglo XVIII, mientras su conclusión se podría situar a mediados del siglo XIX, con un período de transición ubicado entre 1840 y 1870. Por su parte, lo que podríamos llamar Segunda Revolución Industrial, partiría desde mediados del siglo XIX a principios del siglo XX, destacando como fecha más aceptada de finalización a 1914, año del comienzo de la Primera Guerra Mundial. El historiador marxista Eric Hobsbawm, considerado pensador clave de la historia del siglo XX[9]​ sostenía que el comienzo de la Revolución Industrial debía situarse en la década de 1780, pero que sus efectos no se sentirían claramente hasta 1830 o 1840.[10]​ En cambio, el historiador económico inglés Thomas Southcliffe Ashton declaraba por su parte que la Revolución Industrial tuvo sus inicios entre 1760 y 1830.[11]​
El término «Revolución Industrial» es también materia de discusión. Algunos historiadores del siglo XX, como John Clapham y Nicholas Crafts, argumentan que el proceso de cambio económico y social fue muy gradual, por lo que el término «revolución» resultaría inapropiado. Asimismo, es cuestionado el mote de «industrial», ya que el proceso englobó también cambios agrarios, sociales, energéticos, y demográficos.[12]​ Estas cuestiones siguen siendo tema de debate entre historiadores y economistas.[13]​


== Antecedentes y causas ==

Los inicios de la industrialización europea hay que buscarlos en la Edad Moderna. A partir del siglo XVI se vislumbra un avance en el comercio, métodos financieros, banca y un cierto progreso técnico en la navegación, impresión o relojería. Sin embargo, estos avances siempre se veían lastrados por epidemias, constantes y largas guerras y hambrunas que no permitían la dispersión de los nuevos conocimientos ni un gran crecimiento demográfico. Según el historiador Angus Maddison, Europa Occidental experimentó un crecimiento demográfico prácticamente nulo entre 1500 y 1800.
El Renacimiento marcó otro punto de inflexión con la aparición de las primeras sociedades capitalistas en Holanda y el norte de Italia. Es a partir de mediados del siglo XVIII cuando Europa comenzó a distanciarse del resto del mundo y a asentar las bases de la futura sociedad industrial debido al desarrollo, aún primitivo, de la industria pesada y la minería.[14]​[15]​ La alianza de los comerciantes con los agricultores hizo aumentar la productividad, lo que a su vez provocó una explosión demográfica, acentuada a partir del XIX. La Revolución Industrial se caracterizó por la transición de una economía agrícola y manual a una comercial e industrial[16]​ cuya ideología se basaba en el racionalismo la razón y la innovación científica.[17]​
Otro de los principales desencadenantes de la Revolución nace de la necesidad.[18]​ Aunque en algunos lugares de Europa como Gran Bretaña ya existía una base industrial, las Guerras Napoleónicas consolidaron la industria europea. Debido a la guerra, que se extendía por la mayor parte de Europa, las importaciones de muchos productos y materias primas se suspendieron. Esto obligó a los gobiernos a presionar a sus industrias y a la nación en general para producir más y mejor que antes, desarrollándose industrias antes inexistentes.
La industrialización tuvo lugar en diferentes oleadas en los distintos países. Las primeras áreas industriales aparecieron en Gran Bretaña a finales del siglo XVIII, extendiéndose a Bélgica y Francia a principios del siglo XIX y a Alemania y a Estados Unidos a mediados de siglo, a Japón a partir de 1868 y a Rusia, Italia y España a finales de siglo. Entre las razones se encontraron algunas tan dispares como la notable ausencia de grandes guerras entre 1815 y 1914, la aceptación de la economía de mercado y el consecuente nacimiento del capitalismo, la ruptura con el pasado, un cierto equilibrio monetario y la ausencia de inflación.


=== Otras interpretaciones ===

Otras interpretaciones sugieren que este nuevo cambio de mentalidad y la posterior evolución del sistema económico fue por causas morales y religiosas. La Reforma protestante de Martín Lutero y Juan Calvino trajo consigo un cambio de mentalidad en el trato y visión respecto del trabajo. Según Max Weber el protestantismo considera al trabajo y al esfuerzo como un bien y un valor fundamental, al contrario que la ética católica que lo considera un castigo a raíz del pecado original.[19]​ Esto explicaría en parte las diferencias a la hora de desarrollarse de las distintas naciones europeas, teniendo como pioneros a países protestantes como Gran Bretaña, Alemania u Países Bajos y como países atrasados a España, Portugal e Italia, todos ellos católicos.[20]​ Esta interpretación sigue siendo muy discutida.


== Gran Bretaña ==

La Revolución Industrial se originó en Inglaterra a causa de diversos factores, cuya elucidación es uno de los temas historiográficos más trascendentes.
Como factores técnicos, era uno de los países con mayor disponibilidad de las materias primas esenciales, sobre todo el carbón mineral, indispensable para alimentar la máquina de vapor que fue el gran motor de la Revolución Industrial temprana, así como para utilizar coque en los altos hornos de la siderurgia,[21]​ sector principal desde mediados del siglo XIX. Su ventaja frente a la madera, el combustible tradicional, no es tanto su poder calorífico como la mera posibilidad en la continuidad de suministro (la madera, a pesar de ser fuente renovable, está limitada por la deforestación; mientras que el carbón, combustible fósil y por tanto no renovable, solo lo está por el agotamiento de las reservas, cuya extensión se amplía con el precio y las posibilidades técnicas de extracción). La fundición con coque permite una mayor oferta de hierro, mejoras en la calidad y reducción de costos de este material.[21]​[22]​[23]​[nota 1]​
Como factores ideológicos, políticos y sociales, la sociedad inglesa poseía una tendencia hacia un menor absolutismo e instituciones más inclusivas. Comenzando por la Carta Magna de 1215, que limitaba el poder del rey,[24]​[25]​[26]​ había atravesado la llamada crisis del siglo XVII de una manera particular: mientras la Europa meridional y oriental se refeudalizaba y establecía monarquías absolutas, la guerra civil inglesa (1642-1651) y la posterior revolución gloriosa (1688) determinaron el establecimiento de una monarquía parlamentaria basada en la división de poderes, la libertad individual y un nivel de seguridad jurídica (con el Common Law)[27]​[28]​ que proporcionaba suficientes garantías para el empresario privado; muchos de ellos surgidos de entre activas minorías de disidentes religiosos que en otras naciones no se hubieran consentido (autores como Max Weber vinculan explícitamente La ética protestante y el espíritu del capitalismo). Síntoma importante fue el espectacular desarrollo del sistema de patentes industriales.[29]​
Algunos autores también mencionan los enclosures (cercamientos) como un factor que contribuyó a la industrialización, como una incipiente «privatización» de los recursos.[24]​[30]​ También, la creciente liberalización, y la reducción de las restricciones impuestas por los gremios a la instalación de industrias y el cambio tecnológico.[31]​[32]​[33]​
Como factor geoestratégico, durante el siglo XVIII Inglaterra (que tras las firmas del Acta de Unión con Escocia en 1707 y del Acta de Unión con Irlanda en 1800, después de la derrota de la rebelión irlandesa de 1798, consiguieron la unión con Escocia e Irlanda, formando el Reino Unido de Gran Bretaña e Irlanda) construyó una flota naval que la convirtió (desde el tratado de Utrecht, 1714, y de forma indiscutible desde la batalla de Trafalgar, 1805) en una verdadera talasocracia dueña de los mares y de un extensísimo imperio colonial. A pesar de la pérdida de las Trece Colonias, emancipadas en la guerra de Independencia de Estados Unidos (1776-1781), controlaba, entre otros, los territorios del subcontinente Indio, fuente importante de materias primas para su industria, destacadamente el algodón que alimentaba la industria textil, así como mercado cautivo para los productos de la metrópolis. La canción patriótica Rule Britannia (1740) explícitamente indicaba: rule the waves (gobierna las olas).


=== Revolución demográfica ===

Durante la Revolución Industrial se vivió un incremento espectacular de la población, debido fundamentalmente a la caída de la tasa de mortalidad provocada por la mejora de las condiciones higiénicas, sanitarias y alimenticias que se plasmó en gran medida en la reducción de la mortandad infantil. En este periodo nacen las primeras vacunaciones y se mejoran los sistemas de alcantarillado y de depuración de aguas residuales. Una alimentación más abundante y regular, no sometida a las fluctuaciones de las cosechas, bajó la incidencia de las epidemias e hizo posible la casi desaparición de la mortalidad catastrófica, sobre todo la infantil.
La población de Inglaterra y Gales, que había permanecido constante alrededor de 6 millones desde 1700 a 1740, se incrementó bruscamente a partir de esta fecha y alcanzó 8,3 millones en 1801, para doblarse en cincuenta años y llegar a los 16,8 millones en 1850 y en 1901 casi se había doblado de nuevo con 30,5 millones.[34]​ En Europa, la población pasó de 100 millones en 1700 hasta alcanzar 400 millones en 1900.[35]​ La Revolución Industrial fue así el primer periodo histórico durante el que hubo simultáneamente un incremento de la población y un incremento de la renta per cápita.[36]​ El aumento de la población fue un estímulo para el crecimiento industrial, ya que proporcionó a la vez mano de obra abundante para las nuevas industrias y de otro lado supuso un incremento de la demanda interna para los nuevos productos.
El aumento de la población urbana en ciudades con trazado medieval supuso el hacinamiento, la insalubridad y la aparición de las primeras patologías sociales (alcoholismo, prostitución y delincuencia).[37]​


=== El nacimiento del factory system: la industria textil ===

Entre finales del siglo XVII y principios del siglo XVIII el gobierno británico aprobó una serie de leyes con el fin de proteger a la industria de la lana británica de la creciente cantidad de tela de algodón que se importaba desde India Oriental.
También empezó a darse una mayor demanda de tejidos gruesos, los cuales eran fabricados por la industria británica en la localidad de Lancashire, donde destacaba la producción de pana, fabricada a partir de fibras entrecruzadas de lino y algodón. El lino era utilizado para dotar de más resistencia al tejido, cuyo material principal, el algodón, no tenía una resistencia suficiente, aunque esta mezcla resultante no era tan suave como los tejidos 100% algodón y era más difícil de coser.[38]​
Hasta el nacimiento de la industria textil, los tejidos y el hilado en general se realizaba en los hogares, en la mayor parte de los casos para consumo propio. Este método productivo, basado en que la producción estaba dispersa y se desarrollaba en los domicilios de los trabajadores, es a menudo denominado en inglés como sistema Putting-out (Putting-out system) en contraposición al posterior sistema industrial o factory system.[39]​ Solo en ocasiones puntuales los trabajos se realizaban en el taller de un maestro tejedor. Bajo el sistema putting-out los trabajadores, antes de fabricar su producto, pactaban contratos con comerciantes y vendedores, quienes les suministraban a menudo las materias primas necesarias. Fuera de temporada, por lo general, las esposas de los agricultores hacían los hilados mientras que los hombres producían los tejidos. Utilizando la máquina de hilar o rueca, en cualquier momento entre cuatro y ocho hilanderas podían echar una mano al tejedor.[38]​[40]​[41]​
Uno de los grandes inventos de la industria textil fue la lanzadera volante, patentada en 1733 por John Kay,[42]​ que permitió una cierta automatización del proceso de tejido. Posteriores mejoras, destacando las de 1747, permitieron duplicar la capacidad de producción de los tejedores, lo que también agravó el desequilibrio que existía entre el hilado y el tejido. Este invento empezó a ser ampliamente utilizado en todo Lancashire en la década de 1760, cuando Robert Kay, hijo de John Kay, inventó la caja ascendente (drop box).[43]​
Lewis Paul patentó en Birmingham, con la ayuda de John Wyatt, la máquina de hilar mediante rodillos y el sistema flyer-and-bobbin, que conseguían un espesor más uniforme en el proceso de elaboración de la lana. Paul y Wyatt abrieron una fábrica en Birmingham que utilizaba una nueva máquina de laminado impulsada por un burro. En 1743 se abrió una fábrica en Northampton que empleaba cinco máquinas como la de Paul con cincuenta husos cada una. Estuvo en funcionamiento hasta 1764. Una fábrica similar fue construida por Daniel Bourn en Leominster, pero un incendio la destruyó. Tanto Paul como Bourn habían patentado el cardador de lana en 1748. El uso de dos conjuntos de rodillos que giraban a diferentes velocidades fue utilizado posteriormente en la primera fábrica de hilados de algodón. La invención de Lewis fue posteriormente mejorada por Richard Arkwright con su Water frame (1769) y por Samuel Crompton con su Spinning mule (1779).[42]​

En 1764 en el pueblo de Stanhill, Lancashire, James Hargreaves inventó la hiladora Jenny, que patentó en 1770. Fue la primera máquina que empleaba varios husos de una manera eficaz. La hiladora Jenny trabajaba de una manera similar a la rueca. Era una máquina simple, construida con madera y que solo costaba alrededor de 6 libras (un modelo de 40 husos) en 1792. Era utilizada principalmente en los hogares o por pequeños artesanos. La hiladora Jenny producía un hilo ligeramente torcido solo adecuado para la trama, que se torcía.[45]​
La máquina de hilar (Water frame) inventada por Richard Arkwright, fue patentada por este junto con dos socios en 1769. El diseño se basaba en parte en una máquina de hilado construida por Thomas High, quien fue contratado por Arkwright.[46]​
En 1786, Edmund Cartwright inventó el primer telar mecánico.[47]​ En 1793, Eli Whitney inventó la desmotadora de algodón, lo que le permitió a Gran Bretaña importar grandes cantidades de algodón para su industria textil, a bajo costo, desde el sur de Estados Unidos.[48]​


== El comercio internacional ==


=== Economía industrial ===

Sin embargo, y a pesar de todos los factores anteriores, la Revolución Industrial no hubiese podido prosperar sin el concurso y el desarrollo de los transportes, que llevarán las mercancías producidas en la fábrica hasta los mercados donde se consumían.
Estos nuevos transportes se hacen necesarios no solo en el comercio interior, sino también en el comercio internacional, ya que en esta época se crean los grandes mercados nacionales e internacionales. El comercio internacional se liberaliza, sobre todo tras el Tratado de Utrecht (1713) que liberaliza las relaciones comerciales de Inglaterra, y otros países europeos, con la América española. Se termina con las compañías privilegiadas y con el proteccionismo económico; y se aboga por una política imperialista y la eliminación de los privilegios gremiales. Además, se desamortizan las tierras eclesiásticas, señoriales y comunales, para poner en el mercado nuevas tierras y crear un nuevo concepto de propiedad. La Revolución Industrial generó también un ensanchamiento de los mercados extranjeros y una nueva división internacional del trabajo (DIT). Los nuevos mercados se conquistaron mediante el abaratamiento de los productos hechos con la máquina, por los nuevos sistemas de transporte y la apertura de vías de comunicación, así como también, mediante una política expansionista.
El Reino Unido fue el primero que llevó a cabo toda una serie de transformaciones que la colocaron a la cabeza de todos los países del mundo. Los cambios en la agricultura, en la población, en los transportes, en la tecnología y en las industrias, favorecieron un desarrollo industrial. La industria textil algodonera fue el sector líder de la industrialización y la base de la acumulación de capital que abrirá paso, en una segunda fase, a la siderurgia y al ferrocarril.
A mediados del siglo XVIII, la industria británica tenía sólidas bases y con una doble expansión: las industrias de bienes de producción y de bienes de consumo. Incluso se estimuló el crecimiento de la minería del carbón y de la siderurgia con la construcción del ferrocarril. Así, en Gran Bretaña se desarrolló de pleno el capitalismo industrial, lo que explica su supremacía industrial hasta 1870 aproximadamente, como también financiera y comercial desde mediados de siglo XVIII hasta la Primera Guerra Mundial (1914). En el resto de Europa y en otras regiones como América del Norte o Japón, la industrialización fue muy posterior y siguió pautas diferentes a la británica.
Unos países tuvieron la industrialización entre 1850 y 1914: Francia, Alemania y Bélgica. En 1850 apenas existía la fábrica moderna en Europa continental, solo en Bélgica hay un proceso de revolución seguido al del Reino Unido. En la segunda mitad del siglo XIX, se fortalece en Turingia y Sajonia la industrialización de Alemania.
Otros países siguieron un modelo de industrialización diferente y muy tardía: Italia, Imperio austrohúngaro, España o Rusia. La industrialización de éstos se inició tímidamente en las últimas décadas del siglo XIX, para terminar mucho después de 1914.


== Transportes ==


=== El ferrocarril ===

El ferrocarril, nacido en el siglo XVIII, es uno de los grandes protagonistas de la Revolución Industrial.
En sus comienzos se empleaba la fuerza animal como medio de locomoción, los raíles eran de madera y su empleo se limitaba a las minas para el transporte de carbón.[nota 2]​ En un libro publicado en 1797, Carz aseguraba haber sido el primero que pensó en sustituir la madera por hierro.[49]​ La primera concesión del Parlamento de Inglaterra para la construcción de un ferrocarril —movido por caballos— se remonta a 1801; se trataba de una línea entre Wandsworth y Croydon con unos 13 kilómetros de longitud y con un coste de 60 000 libras. La gran revolución del ferrocarril comenzó en 1814, cuando George Stephenson utilizó la máquina de vapor como medio de locomoción. Su invento fue un éxito y comenzó a usarse de inmediato en las minas, pudiendo transportar ocho vagones de 30 toneladas a una velocidad de 7 km/h. Estos resultados eran suficientes para expandir el uso de la máquina a otros servicios. Fue en 1821 cuando el Parlamento autorizó la construcción de la primera línea de ferrocarril con tracción de vapor entre Stockton y Darlington. La línea fue inaugurada en 1825 con una máquina maniobrada por el propio Stephenson tirando de 34 vagones a una velocidad de entre 10 y 12 millas por hora —16–19 km/h— ;[50]​ El periódico The Times describió esta hazaña de la siguiente manera:

 

En los 5 años posteriores el Parlamento autorizó la construcción de 23 nuevas líneas de ferrocarril entre las que se encontraba la célebre línea entre Mánchester y Liverpool, siendo sus constructores los primeros en ofrecer en el ferrocarril el servicio de transporte de pasajeros. En aquel momento se desconfiaba de la seguridad que podían ofrecer las locomotoras, pero la acogida fue muy buena, mejorando en un 10% los beneficios derivados de este servicio, aunque los ingresos por el transporte de algodón, tejidos, carbón y ganado aún seguían siendo mayoritarios. Este éxito también fue tratado por George Porter, quien en su libro El progreso de la nación dice :

 

Fue en esta ocasión el propio Stephenson el que ganó la puja en esta línea convirtiéndose su Cohete en el encargado de remolcar un tren de 12 toneladas a 22 km/h.[52]​ El primer correo por ferrocarril se envió el 11 de noviembre de 1830.[51]​ Los tiempos de llegada se redujeron considerablemente, llegando el correo entre Londres y Mánchester en aproximadamente 18 horas. En Inglaterra, siguiendo la consigna laissez faire, el Estado no intervenía en la construcción o subvención del ferrocarril sino que se limitaba a otorgar las licencias y permisos de construcción y explotación;[52]​ de esta manera se gastaron enormes fortunas con el objetivo de obtener los distintos permisos; por ejemplo el Great Western costó en gastos preliminares 89 000 libras y otros como el London and Birmingham 62 000.[53]​

Los ferrocarriles eran al principio de vía estrecha y solo admitían velocidades comprendidas entre los 15 y los 20 kilómetros por hora, pero en 1840 se habían ensanchado las vías y se podían conseguir unas velocidades de casi 40 km/h.

El primer país continental en seguir el ejemplo inglés fue Bélgica con dos líneas Bruselas-Malinas y Malinas-Amberes en 1835. El primer año transportaron 70 000 pasajeros. El coste fue bajísimo y el billete Bruselas-Amberes costaba solo un franco.[54]​ El invento entró en Francia con algo de retraso, pues mientras jóvenes, ingenieros y adeptos al saintsimonismo reclamaban su construcción, tropezaban con el rechazo y la desconfianza de muchos, además de la carencia de hierro. El gobierno francés, que veía el potencial del aparato, ordenó un estudio para un plan nacional de los ferrocarriles. El estudio quedó finalizado en 1837 y los capitalistas, impacientes, presionaban al gobierno para la ejecución del proyecto con el fin de especular con las obras y los terrenos. El plan consistía en siete líneas con centro en París, que unirían el Atlántico, el Mediterráneo y el Rin. Al contrario que en Inglaterra y Bélgica, el estado se hizo cargo, al menos en parte, de su construcción y explotación, aportando 150 000 francos por kilómetro de vía y construyendo las infraestructuras necesarias.[54]​ Mientras, las compañías privadas aportaron 100 000 francos para edificios y material.[55]​ Tras 40 años de administración y explotación privada, el sistema pasaría al Estado. Socialistas románticos y conservadores se oponían al proyecto, los primeros reclamaban que el sistema fuera del estado desde el primer día y los segundos lo consideraban demasiado caro.[55]​ Finalmente el plan fue aprobado, pero algunos acuerdos se revisaron y en la práctica la construcción y explotación corrió a cuenta casi exclusiva del sector privado.[55]​ En 1857 la red estaba consolidada siendo propiedad de 6 grandes compañías. Debido a la obligación de ceder la propiedad al Estado a los 40 años de explotación se descuidó sobremanera su cuidado y mantenimiento por lo que el gobierno francés se vio en la obligación de ampliar el plazo en 99 años más, comprometiéndose incluso a pagar las obligaciones a su vencimiento.[55]​
En Alemania la primera línea se construyó en 1835 con una extensión de siete kilómetros entre Núremberg y Fürth, pero fue en 1839 cuando se construyó la primera línea de importancia entre Dresde y Leipzig, promovida por el profesor de economía política List, uno de los principales promotores de la línea Núremberg-Fürth. Pronto se vio al ferrocarril como una poderosa arma política; en el momento de la aparición del ferrocarril, Alemania se encontraba dividida en más de 300 pequeños estados y ciudades autónomas. Desde la construcción de la línea Dresde-Leipzig todas las ciudades alemanas quisieron unirse con su vecina lo que además de un gran impulso económico hizo un gran servicio para el triunfo del Zollverein.[56]​ Al contrario que en el resto de países, en Alemania fue la administración la encargada de vigilar o administrar todos los ferrocarriles.[57]​ En 1850 el Zollverein ya poseía 5800 kilómetros casi el doble que toda Francia. Hannover, Bremen, Hamburgo, Berlín, Fráncfort formaban una gran línea que transcurría sobre los principales focos industriales y unía Alemania con Suiza a través de Basilea y a Austria a través de Moravia y Silesia.

A partir de la década de 1820 el ferrocarril y el vapor saltaron a los Estados Unidos y pronto conquistaron a la opinión pública. Stevens realizó en Hoboken una primera prueba que causó un gran interés entre los hombre de negocios de Pensilvania, quienes compraron una locomotora a Inglaterra.[58]​ Al igual que en Gran Bretaña, la acumulación de capital hizo posible solo un año después el comienzo de la construcción de una primera línea entre Washington y Winchester. En 1830 una locomotora llamada Best Friend explotó cuando marchaba por la línea Charleston-Hambourg debido a que el maquinista se había sentado sobre la válvula de escape por las molestias que sentía debido al silbido del vapor al salir. Pero lejos de echarse atrás, el país progresó a un ritmo frenético y a mediados de 1830 ya producía sus propias locomotoras en la fundición de West Point[59]​ asegurando una industria nacional sólida. Desde entonces Estados Unidos colocó raíles a través de su vasto territorio a una velocidad mucho mayor que Europa. Si en 1830 poseía tan solo 65 kilómetros de trazado —contra 316 europeos, 276 de ellos en Gran Bretaña—, 10 años después ya superaba a Europa con 4509 kilómetros contra 3543 europeos.[58]​ En 1850 las vías férreas ya sumaban 14 400 kilómetros. Uno de los problemas que planteaban los ferrocarriles era el ancho de vía,[nota 3]​ que variaba en anchura en los distintos países, lo que obligaba a numerosos transbordos para deleite de los hosteleros. Pero problemas aparte el tiempo de viaje no hizo sino disminuir; así, en apenas unos años no se tardaban más de 20 horas en viajar de Boston a Nueva York en ferrocarril cuando antes se tardaban unas 80.[58]​

En Italia los augurios de d´Azeglio de que los ferrocarriles coserían la bota no pasaron de simples promesas, pues hasta 1845 solo se encontraban pequeñas líneas aisladas como la línea Milán-Monza, Padua-Venecia, Liorna-Pisa o la línea de Campania que Fernando de Nápoles construyó para su recreo y uso privado.[60]​ En Hungría solo existía una pequeña vía alrededor de Budapest y en Rusia el zarismo tuvo que imponer la construcción de la línea Moscú-San Petersburgo debido a los numerosos detractores.[60]​ En España, el gran tirón y entusiasmo que de manera muy temprana había producido el invento se apaga en la guerra civil de 1833, que paraliza todas las obras de construcción ante la desconfianza de los capitalistas.[60]​ Hubo que esperar hasta 1843 cuando se concedió a Juan Manuel Roca y Miguel Biada la construcción y explotación del ferrocarril Barcelona-Mataró, que estuvo construido en solo cinco años bajo la dirección del ingeniero inglés Locke, su inauguración fue el 28 de octubre de 1848, un trayecto de 28 km y 600 m que se completaba en 35 minutos.[nota 4]​ En 1851 realizó su primer viaje el segundo ferrocarril español que cubría la línea Madrid-Aranjuez, cuya concesión había sido otorgada en 1844 con prolongación hasta Cádiz. En 1850 se inició la construcción de la primera locomotora española, finalizada en 1852.[60]​
Excepciones aparte, en el periodo entre 1820 y 1840, Gran Bretaña conservaba un adelanto manifiesto sobre el resto del mundo.[60]​ Era la única que poseía una buena red de transporte entre sus principales ciudades. Trabajó con verdadero frenesí entre 1840 y 1847 a pesar de la rivalidad latente entre la oposición, los grupos financieros, los Turnpike trusts y la población, cuyo medio de subsistencia continuaban siendo las carreteras. Similar situación se dio en Bélgica, que en 1843 tenía incluso más kilómetros que Francia y una opinión pública muy favorable al ferrocarril.[60]​
No fueron pocos los que vieron en el ferrocarril un gran peligro, incluso mortal. Desde el siglo XVIII, cuando se pusieron en marcha en Inglaterra hubo voces, incluso procedentes de la Real Academia de Ciencias británica, que sugerían que a unas velocidades superiores a los 40 km/h los pasajeros se asfixiarían, se volverían ciegos y el ganado enloquecería. Se temía también la destrucción de las tierras de cultivo o que la gente y mercancías salieran despedidas del aparato por sus "endiabladas" velocidades.[61]​

Pasada la primera mitad de siglo, el medio siglo siguiente entre 1851 y 1901, conocido con el nombre de Railway Age vive el apogeo y reinado definitivo del ferrocarril. Pero la tracción mecánica sobre raíles es sobre todo, obra de Occidente. En 1860 Europa y EE. UU. se reparten más o menos 198 000 en igualdad mientras que el resto del mundo no cuenta con más de 15 000 kilómetros, la mayoría ubicados en colonias europeas.[62]​ En 1910 ya se han construido más de un millón de kilómetros de los que 380 000 están en EE. UU. y 330 000 en Europa.[62]​ Su construcción necesitó de un esfuerzo enorme, movilizando grandes cantidades de capital, trabajadores y estimulando la industria metalúrgica y la construcción de gigantescos talleres de trabajo, además de dar su máximo esplendor a la máquina de vapor.[62]​
Además de los vagones y locomotoras, también evolucionaron los raíles sobre los que circulaban. El raíl de acero sustituye al de hierro y a la madera de las traviesas se le empezó a inyectar cloruro de zinc para evitar que se pudriera. El ferrocarril también necesitó de una gran infraestructura que fue necesario desarrollar, como túneles, que se excavaban a costa del sufrimiento obrero a altísimas temperaturas con el uso de perforadoras de aire comprimido y el revestimiento de las galerías con fundición, en sustitución de la madera; La ventilación se lograba con sopladoras. Hay que destacar algunos éxitos entre los que se encuentran el túnel que atraviesa el Mont Cenis, construido a lo largo de 15 años y con una extensión de 13 600 m a 1300 metros de altura.[63]​ Otros como el San Gotardo de más de 15 000 metros se terminaron en menos de 10 años usando la perforadora automática siendo las condiciones de trabajo nefastas: los obreros llegaron a trabajar a una temperatura de 86 grados.[63]​ Fuera de Europa los estadounidenses construyeron un túnel bajo el río Hudson. Escandinavia queda unida a Alemania a través del ferry-boats entre Rügen y Malmoe.
Mientras que en la primera mitad de siglo la locomotora apenas había ganado en velocidad sin sobrepasar nunca los 40 km/h, hace progresos decisivos a partir de la idea del ingeniero inglés Crampton de colocar las ruedas motrices detrás de la caldera (y no debajo), ruedas que están acopladas, transfiriéndose el movimiento de rotación. En 1850 la velocidad media que se situaba en 27 km/h se eleva en 1880 a 74 km/h en Inglaterra y a 59 km/h en Estados Unidos.[64]​ En 1890 el Empire-State-Express rebasó por primera vez en la historia los 100 km/h entre Nueva York y Búfalo.[64]​ Para cruzar Francia de un extremo en ferrocarril solo se precisaban 14 horas. En esta segunda parte del siglo el coste del billete disminuyó entre un 50 y un 70 %.[65]​
Las prestaciones de la locomotora aumentaron sin cesar. El freno de mano se sustituyó por un nuevo freno hidráulico de aire comprimido.[64]​ Los vagones de pasajeros fueron dotados de alumbrado de gas a base de aceite de esquisto o iluminación eléctrica a finales de siglo, siendo la línea Londres-Brighton la primera en incorporarla.[64]​ La máquina de vapor, el corazón de la máquina, también procura calefacción en los vagones. El llamado Boggie o bastidor de varios ejes permitió al convoy dar curvas mucho más acentuadas disminuyendo los riesgos, pues se adaptaba a la curvatura de la vía.[64]​ También se crearon los llamados palace-cars en las líneas más largas para las familias ricas en las que disfrutaban de todo tipo de comodidades y sin tener que mezclarse con el resto de pasajeros.[64]​ En 1880 se instaló en la línea del Pacífico un vagón imprenta en el que se editaba un periódico diario con las noticias recibidas telegráficamente en las estaciones.[64]​

Exceptuando Gran Bretaña, Bélgica y algunas partes de España y Alemania, las vías férreas no dibujaban redes en ninguna parte antes de 1860.[66]​ En Francia por fin se realizó un esfuerzo serio a partir del Segundo Imperio y en los albores de la Tercera República. En esta segunda mitad de siglo se empezaba a vislumbrar la columna vertebral de ferrocarriles europeos.[66]​ Sus límites se extendían desde el norte de Francia hasta la Alta Silesia de este a oeste y de Alemania al norte de Italia de norte a sur; en el centro, Suiza reparte el tráfico por el continente. En cambio la mayor parte de Italia, la península ibérica y los países del este quedaban fuera.[66]​ En Estados Unidos se siguen consiguiendo grandes logros. En 1869 se finalizó el primer transcontinental que conectó el país de este a oeste. La construcción fue dirigida por el implacable general Grenville M. Dodge como si se tratará de una campaña militar. Usó como mano de obra a los soldados desmovilizados, inmigrantes irlandeses y hasta chinos en California.[66]​ Pero este triunfo no se logró con facilidad; indios, el relieve irregular y sobre todo la competencia entre Union Pacific y Central Pacific dificultaron sobremanera la situación. Pero el entusiasmo predomina y en 1893 ya había en funcionamiento otras 5 líneas transcontinentales, usándose como medio de colonización en el oeste americano o en la Columbia británica como medio de presión para conseguir su adhesión a la Unión.[66]​
Aunque tardío, se presenta el esfuerzo ruso, logrado gracias a los préstamos de Occidente.[66]​ En primer lugar se construyó el transcaspiano al que a partir de 1905 complementó el transaraliano. En Siberia las dificultades eran mayúsculas: hielo, infiltraciones de agua, ríos inmensos, débil densidad humana, distancias enormes, sin olvidar el irregular relieve. Pero las viejas rutas y caminos ya no eran suficientes y el ferrocarril más largo del mundo se empezó en 1891 y alcanzó su destino, Vladivostok, gracias a un acuerdo con China, en 1902.[66]​
Así pues, el ferrocarril no solo sirvió para revolucionar el mundo del transporte tanto material como humano sino que fue empleado como un excelente instrumento de unión.[67]​ Sirvió bien en la reconciliación y la anexión de nuevos territorios a Estados Unidos y el Imperio alemán sabía lo mucho que le debía al ferrocarril como para dejarlo en manos privadas. En Italia facilitó la hegemonía de la Casa de Saboya. No ocurrió igual en Francia o en Gran Bretaña, donde se encontraban mayoritariamente en manos privadas, aunque en Inglaterra prestaron un servicio inigualable, encumbrando al naciente Imperio británico a la hegemonía mundial. Hacia 1850 el ferrocarril había conducido a entre 400 y 500 millones de viajeros y entre 200 y 300 millones de toneladas de mercancías desde su nacimiento. Cinco décadas después, solo en 1905 transportó a entre 4000 y 5000 millones de viajeros.[67]​


=== El barco de vapor ===

Antes del siglo XIX la larga tradición naval europea se había sustentado sobre el control de los vientos como medio de propulsión y la seguridad más que por la velocidad en el mar. A principios de siglo no se empleaban menos de dos o tres semanas en cruzar el Atlántico de este a oeste, necesitándose entre 30 y 40 días de oeste a este. Con la formación de los imperios coloniales europeos se hizo necesario desarrollar una tecnología que asegurase el viaje sobre las aguas; en el siglo XVIII se generalizó el uso del sextante, mapas con las notaciones de los vientos y el cronómetro. La invención de la nueva embarcación partió de los trabajos de Jouffroy d´Abbens sobre el Sena y los de Fulton con su máquina Clermont.[68]​ Fue en Estados Unidos donde tuvieron lugar las primeras pruebas del navío de ruedas sobre el río Hudson. En 1815 ya circulaban un centenar de estos navíos de ruedas que obtenían su energía de la leña, material barato y abundante. El Savannah consiguió cruzar en 29 días el Atlántico Norte en 1819 y la Sphink, que llevó a Francia las noticias de la toma de Argel, desarrollaba una velocidad de 6 nudos. Pero los problemas eran numerosos: las paletas utilizadas provocaban un gran desperdicio de energía, existía el riesgo de incendio o explosión a bordo, su velocidad era aún menor a la desarrollado por los veleros y el poder militar aún se oponía a su utilización como navío de guerra.[69]​
Pero a pesar de las dificultades los avances prosiguieron y en 1838, con una combinación de vapor y velas, los navíos Sirius y Great Western cruzaron el Atlántico entre Liverpool y Nueva York en 16 y 13 días respectivamente. Los grandes avances llegaron entre 1840 y 1860 con la invención de la hélice, basándose los primeros modelos en el tornillo de Arquímedes, el condensador de superficie y la máquina Compound, que logró ahorrar grandes cantidades de combustible y la introducción de calderas cilíndricas que posibilitaron la producción de vapor a alta presión.[68]​
Lo que sí es indudable es la supremacía del velero sobre el vapor durante la mayor parte del siglo; la seguridad y prestigio de la que aún gozaba, sobre todo en Estados Unidos, donde también tenía lugar la mayoría de los avances del barco de vapor era indiscutible. En 1850 el barco de vapor había transportado ya 750 000 toneladas, aunque el vapor aún estaba muy lejos de ganar la partida.[69]​


=== Carreteras y canales ===

El esfuerzo en la construcción y mejora de carreteras (o caminos) comenzó en muchas partes de Europa antes de la Revolución Industrial. Desde el fin de las guerras napoleónicas a principios del siglo XVIII y en ausencia de otros medios de comunicación más eficaces, las carreteras fueron extensamente mejoradas. A principios del siglo XIX el país más adelantado en esta materia era Francia con una red de 33 000 kilómetros de gran calidad que se extendían hasta Alemania, Suiza e Italia. Los Países Bajos, el Reino de Prusia o Suiza también habían vivido una gran mejora en las comunicaciones. En el otro extremo se encontraban lugares como Sicilia, que no empezó su construcción hasta bien entrado el XIX, la Rusia zarista, que no tendría su primera calzada entre Moscú y San Petersburgo —sus principales ciudades— hasta 1834 o España, que cuenta antes de la mitad del siglo XIX con solo 6000 kilómetros de vías, siendo además estrechas y llenas de irregularidades y deficiencias. En Gran Bretaña el rápido desarrollo de ferrocarriles y canales quita importancia a su construcción, pero aun así se suceden las ampliaciones y modernizaciones de la maltrecha red británica contando en 1850 con más de 50 000 kilómetros de trazado, 18 000 más que veinte años atrás.[70]​
La técnica en la construcción de estas vías de comunicación también mejora. En cada país se construyen de manera distinta, pero los problemas clásicos derivados de estas construcciones como filtraciones de agua, mantenimiento o infraestructura se solucionan en las décadas de 1820 y 1830 a partir de las mejoras introducidas por Mac Adam o Telford.[71]​ El uso de la diligencia y los servicios públicos de transporte se desarrollan y generalizan con unas velocidades que oscilan entre los 10 y 15 km/h, usándose en el transporte de pasajeros, mercancías y correo.[72]​ No es hasta principios del siglo XX cuando gracias al motor de explosión y el desarrollo del automóvil se da un uso masivo a estos trazados.
Los primeros canales empezaron a ser construidos en Gran Bretaña en el siglo XVIII con el objeto de comunicar los centros industriales del norte británico con los puertos marítimos del sur y Londres. Los canales fueron la primera tecnología que permitió un fácil y relativamente rápido transporte de mercancías por todo el país, pudiéndose transportar varias docenas de veces más de tonelaje por viaje que con un transporte terrestre. A esto se unía el relieve del país, completamente llano, lo que permitía que los canales fueran construidos rápidamente y a un bajo precio. A principios de la década de 1820, ya existía una red nacional consolidada. El ejemplo inglés fue copiado en Francia que con un relieve similar al británico pudo desarrollar su propio sistema, que a mediados del siglo XIX contaba con 8500 kilómetros de vías. En Alemania gracias a sus grandes ríos como el Rín y el Elba, la navegación se vio muy favorecida, así como el comercio que vivió un gran desarrollo. En otros países como España la construcción de canales no pasó de un proyecto por el difícil relieve y la falta de capitales. Fuera del continente, los estadounidenses con su ímpetu emprendedor y sus numerosos lagos y grandes ríos consiguieron desarrollar con velocidad su propio sistema, que al igual que el ferrocarril, ayudó en la colonización y explotación de las vastas tierras del país. A principios de 1835 EE. UU. ya contaba con 7000 kilómetros de canales que allanaron el camino a la introducción del barco de vapor en el país con una rapidez incluso mayor a la siempre innovadora Gran Bretaña.[73]​
El uso de los canales en Gran Bretaña empezó a decaer a partir de 1840, cuando el ferrocarril se impuso en el transporte de mercancías y pasajeros.[74]​ El irregular y más tardío desarrollo a gran escala del ferrocarril en el resto de países, con la siempre notable excepción de los Estados Unidos, alargó en ocasiones el uso pleno de los canales hasta los albores del siglo XX. Hoy en día la red de canales británicos y la infraestructura ligada a esta es una de las características más perdurables y destacables de la Revolución Industrial en el país.


== Consecuencias ==

La existencia de controles fronterizos más intensos evitaron la propagación de enfermedades y disminuyó la propagación de epidemias como las ocurridas en tiempos anteriores. La revolución agrícola británica hizo además más eficiente la producción de alimentos con una menor aportación del factor trabajo, alentando a la población que no podía encontrar trabajos agrícolas a buscar empleos relacionados con la industria y, por ende, originando un movimiento migratorio desde el campo a las ciudades así como un nuevo desarrollo en las fábricas. La expansión colonial del siglo XVII acompañada del desarrollo del comercio internacional, la creación de mercados financieros y la acumulación de capital son considerados factores influyentes, como también lo fue la revolución científica del siglo XVII. Se puede decir que se produjo en Inglaterra por su desarrollo económico.
La presencia de un mayor mercado doméstico debería también ser considerada como un catalizador de la Revolución Industrial, explicando particularmente por qué ocurrió en el Reino Unido.
La invención de la máquina de vapor fue una de las más importantes innovaciones de la Revolución Industrial. Hizo posible mejoramientos en el trabajo del metal basado en el uso de coque en vez de carbón vegetal. En el siglo XVIII la industria textil aprovechó el poder del agua para el funcionamiento de algunas máquinas. Estas industrias se convirtieron en el modelo de organización del trabajo humano en las fábricas.
Además de la innovación de la maquinaria, la cadena de montaje (fordismo) contribuyó mucho en la eficiencia de las fábricas.

Revolución agrícola: aumento progresivo de la producción gracias a la inversión de los propietarios en nuevas técnicas y sistemas de cultivo, además de la mejora del uso de fertilizantes.
El desarrollo del capital comercial: Las máquinas se aplicaron a los transportes y a la comunicación iniciando una enorme transformación. Ahora las relaciones entre patronos y trabajadores son únicamente laborales y con el fin de obtener beneficios.
Cambios demográfico-sociales: la modernización de la agricultura permitió un crecimiento demográfico debido a la mejora de la alimentación. También hubo adelantos en la medicina y en la higiene, de ahí que creciera la población. También hubo una migración del campo a la ciudad porque la ocupación en labores agrícolas disminuyó mientras crecía la demanda de trabajo en las ciudades.


== Etapas de la Revolución Industrial ==
La Revolución Industrial estuvo dividida en dos etapas: la primera del año 1750 hasta 1840, y la segunda de 1880 hasta 1914. Todos estos cambios trajeron consigo consecuencias tales como:

Demográficas: Traspaso de la población del campo a la ciudad (éxodo rural) — Migraciones internacionales — Crecimiento sostenido de la población — Grandes diferencias entre los pueblos — Independencia económica
Económicas: Producción en serie — Desarrollo del capitalismo — Aparición de las grandes empresas (Sistema fabril) — Intercambios desiguales
Sociales: Nace el proletariado — Nace la Cuestión social
Ambientales: Deterioro del ambiente y degradación del paisaje — Explotación irracional de la tierra y de materias primas.

A mediados del siglo XIX, en Inglaterra se realizaron una serie de transformaciones que hoy conocemos como Revolución Industrial dentro de las cuales las más relevantes fueron:

La aplicación de la ciencia y tecnología permitió el invento de máquinas que mejoraban los procesos productivos.
La despersonalización de las relaciones de trabajo: se pasa desde el taller familiar a la fábrica.
El uso de nuevas fuentes energéticas, principalmente el carbón.
La revolución en el transporte: ferrocarriles y barco de vapor.
El surgimiento del proletariado urbano.
La industrialización que se originó en Inglaterra y luego se extendió por toda Europa no solo tuvo un gran impacto económico, sino que además generó enormes transformaciones sociales.
Proletariado urbano. Como consecuencia de la revolución agrícola y demográfica, se produjo un éxodo masivo de campesinos hacia las ciudades; el antiguo agricultor se convirtió en obrero industrial. La ciudad industrial aumentó su población como consecuencia del crecimiento natural de sus habitantes y por el arribo de este nuevo contingente humano. La carencia de habitaciones fue el primer problema que sufrió esta población socialmente marginada; debía vivir en espacios reducidos sin comodidades mínimas y carentes de higiene. A ello se sumaban jornadas de trabajo, que llegaban a más de catorce horas diarias, en las que participaban hombres, mujeres y niños con salarios miserables, y carentes de protección legal frente a la arbitrariedad de los dueños de las fábricas o centros de producción. Este conjunto de males que afectaba al proletariado urbano se llamó la Cuestión social, haciendo alusión a las insuficiencias materiales y espirituales que les afectaban.
Burguesía industrial. Como contraste al proletariado industrial, se fortaleció el poder económico y social de los grandes empresarios, afianzando de este modo el sistema económico capitalista, caracterizado por la propiedad privada de los medios de producción y la regulación de los precios por el mercado, de acuerdo con la oferta y la demanda.
En este escenario, la burguesía desplaza definitivamente a la aristocracia terrateniente y su situación de privilegio social se basó fundamentalmente en la fortuna y no en el origen o la sangre. Avalados por una doctrina que defendía la libertad económica, los empresarios obtenían grandes riquezas, no solo vendiendo y compitiendo, sino que además pagando bajos salarios por la fuerza de trabajo aportada por los obreros.
Las propuestas para solucionar el problema social. Frente a la situación de pobreza y precariedad de los obreros, surgieron críticas y fórmulas para tratar de darles solución; por ejemplo, los socialistas utópicos, que aspiraban a crear una sociedad ideal, justa y libre de todo tipo de problemas sociales (para algunos, el comunismo). Otra propuesta fue el socialismo científico de Karl Marx, que proponía la revolución proletaria y la abolición de la propiedad privada (marxismo); también la Iglesia católica, a través del papa León XIII, dio a conocer la Encíclica Rerum Novarum (1891), primera encíclica social de la historia, la cual condenaba los abusos y exigía a los estados la obligación de proteger a lo más débiles. A continuación, un fragmento de dicha encíclica: 

 
 Estos elementos fueron decisivos para el surgimiento de los movimientos reivindicativos de los derechos de los trabajadores. Durante el siglo XX en medio de los procesos de democratización, el movimiento obrero lograba que se reconocieran los derechos de los trabajadores y su integración a la participación social. Otros ejemplos de tendencias que buscaron soluciones fueron los nacionalismos, así como también los fascismos en los cuales se consideraban a los obreros y trabajadores como una parte fundamental en el desarrollo productivo de la nación, por lo que debían ser protegidos por el Estado.


== Principios fundamentales de la industria ==
Uno de los principios fundamentales de la industria moderna es que nunca considera a los procesos de producción como definitivos o acabados. Su base técnico-científica es revolucionaria, generando así el problema de la obsolescencia tecnológica en períodos cada vez más breves. Desde esta perspectiva puede afirmarse que todas las formas de producción anteriores a la industria moderna (artesanía y manufactura) fueron esencialmente conservadoras, al trasmitirse los conocimientos de generación en generación sin apenas cambios. Sin embargo, esta característica de obsolescencia e innovación no se circunscribe a la ciencia y la tecnología, sino debe ampliarse a toda la estructura económica de las sociedades modernas. En este contexto la innovación es, por definición, negación, destrucción, cambio, la transformación es la esencia permanente de la modernidad.
El desarrollo de nuevas tecnologías, como ciencias aplicadas, en un receptivo clima social, es el momento y el sitio para una revolución industrial de innovaciones en cadena, como un proceso acumulativo de tecnología, que crea bienes y servicios, mejorando el nivel y la calidad de vida. Son básicos un capitalismo incipiente, un sistema educativo y espíritu emprendedor. La no adecuación o correspondencia entre unos y otros crea desequilibrios o injusticias. Parece ser que este desequilibrio en los procesos de industrialización, siempre socialmente muy inestables, es en la práctica inevitable, pero mensurable para poder construir modelos mejorados.[cita requerida]


== Impacto y consecuencias de la Revolución Industrial ==
Despegue económico y técnico de Occidente: aparición y extensión del industrialismo o capitalismo industrial.[75]​
Transformaciones sociales (Revolución burguesa): complejidad creciente de las sociedades abiertas de clases.
Crecimiento de la población (aumento de la esperanza de vida y baja de la mortalidad infantil gracias al progreso económico y tecnológico)
Transformación de sociedades rurales en sociedades urbanas.
Crecimiento de la burguesía y los sectores medios.[76]​


== Véase también ==


== Bibliografía ==
Crouzet, Maurice (1969). Historia general de las civilizaciones: El siglo XIX, Tomo VI. Ediciones destino. ISBN 84-233-0126-5. 
Hounshell, David A. (1984). From the American System to Mass Production, 1800-1932: The Development of Manufacturing Technology in the United States. Baltimore, Maryland: Johns Hopkins University Press. ISBN 978-0-8018-2975-8. 
McNeil, Ian (1996). An Encyclopedia of the History of Technology. 
Navarro, Pérez, Salvat, M.C, Francesc, Alicia (2004). El siglo XIX en Europa y Norteamérica. Salvat. ISBN 84-345-6256-1. 
Sigmann, Jean, 1848, las revoluciones románticas y democráticas de Europa, Madrid, Siglo XXI, 1985.
Escudero, Antonio (2000). «La Revolución Industrial». Aula-Historia Social (5): 16-38. ISSN 1139-1405. 
Cameron, Rondo; Neal, Larry (2014). Historia económica mundial: desde el Paleolítico hasta el presente (Cuarta edición). ISBN 978-84-206-8852-7. OCLC 991922048. 
Zamagni, Vera (2016). Una historia económica : Europa de la Edad Media a la crisis del euro. ISBN 978-84-16771-12-7. OCLC 958931704. 
Escudero, Antonio (2009). La revolución industrial una nueva era. Grupo Anaya. ISBN 978-84-667-8675-1. OCLC 733662545. 
Spielvogel, Jackson J. (2019). Historia universal contemporánea. ISBN 978-607-526-830-9. OCLC 1161953244. 


== Notas ==


== Referencias ==


== Enlaces externos ==
 Wikimedia Commons alberga una categoría multimedia sobre Revolución Industrial.
Internet Modern History Sourcebook: La Revolución industrial Archivado el 31 de agosto de 2009 en Wayback Machine. (en inglés).
Trabajadores industriales en la Revolución (en inglés).
"The Day the World Took Off". University of Cambridge. Documento video en seis partes (en inglés).
La Revolución Industrial. BBC History Home Page (en inglés).
La Segunda Guerra Mundial (también escrito II Guerra Mundial)[1]​ fue un conflicto militar global que se desarrolló entre 1939 y 1945. En ella se vieron implicadas la mayor parte de las naciones del mundo —incluidas todas las grandes potencias, así como prácticamente todas las naciones europeas— agrupadas en dos alianzas militares enfrentadas: los Aliados, por un lado, y las Potencias del Eje, por otro. Fue la mayor contienda bélica en la historia de la humanidad, con más de cien millones de militares movilizados y un estado de guerra total en que los grandes contendientes destinaron toda su capacidad económica, militar y científica al servicio del esfuerzo bélico, borrando la distinción entre recursos civiles y militares. Marcada por hechos de enorme repercusión que incluyeron la muerte masiva de civiles (el Holocausto, los bombardeos masivos sobre ciudades y el uso, por primera vez en un conflicto bélico, de armas nucleares), la Segunda Guerra Mundial fue la más mortífera de la historia, con un resultado de entre 50 y 70 millones de víctimas, el 2,5 % de la población mundial.[2]​
El comienzo del conflicto se suele situar en el 1 de septiembre de 1939, con la invasión alemana de Polonia, cuando Hitler se decidió a la incorporación de una de sus reivindicaciones expansionistas más delicadas: El Corredor Polaco, que implicaba la invasión de la mitad occidental de Polonia; la mitad oriental, junto con Estonia, Letonia y Lituania fue ocupada por la Unión Soviética, mientras que Finlandia logró mantener su independencia de los soviéticos (guerra de Invierno). El Reino Unido y Francia le declararon la guerra a Alemania, que esperaban como una repetición de la guerra de trincheras («guerra de mentira») para la que habían tomado toda clase de precauciones (línea Maginot) que demostraron ser del todo inútiles. Las maniobras espectaculares de la blitzkrieg («guerra relámpago») proporcionaron en pocos meses a Alemania el control de Noruega, Dinamarca, Países Bajos, Bélgica y la propia Francia, mientras que el ejército británico escapaba in extremis desde las playas de Dunkerque durante la batalla de Francia. La mayor parte del continente europeo estaba ocupado por el ejército alemán o por sus aliados, entre los que destacaba la Italia fascista, cuya aportación militar no fue muy significativa (batalla de los Alpes, guerra greco-italiana).
La batalla de Inglaterra, la primera completamente aérea de la historia, mantuvo durante el periodo siguiente la presión sobre el nuevo gobierno de Winston Churchill, decidido a la resistencia («sangre, sudor y lágrimas») y que finalmente venció, entre otras cosas gracias a una innovación tecnológica (el radar) y al decisivo apoyo estadounidense, que negoció en varias entrevistas con Franklin D. Roosevelt (Carta del Atlántico, 14 de agosto de 1941).
En 1941, la necesidad estratégica de ocupar los campos petrolíferos del Cáucaso impulsó a Alemania a invadir la Unión Soviética (operación Barbarroja), inicialmente exitosa, pero que se estancó en la batalla de Moscú y los sitios de Leningrado y Stalingrado. Al mismo tiempo, Japón, en su campaña de expansión por Asia y en venganza por el embargo económico que el gobierno estadounidense les había impuesto, atacó Pearl Harbor el 7 de diciembre de 1941; la agresión precipitó la entrada de Estados Unidos en la guerra. Pocos meses después, la batalla de Midway (en julio de 1942) marcaría un punto de inflexión en la guerra del Pacífico ante el debilitamiento de la capacidad de combate japonesa frente a los estadounidenses. En el norte de África, los británicos frenaron el avance de los Afrika Korps alemanes desde Libia hacia Egipto en la batalla de El Alamein (1942), después de la invasión italiana al canal de Suez (1940).
El periodo final de la guerra se caracterizó por las complejas operaciones necesarias para los desembarcos aliados en Europa (Sicilia, en julio de 1943; Anzio, en enero de 1944; Normandía, en junio de 1944) y por el hundimiento del frente oriental, en el que se libraron las operaciones con tanques más encarnizadas de la historia (batalla de Kursk, especialmente en Prójorovka, julio de 1943), mientras en el frente occidental los alemanes experimentaban armas tecnológicamente muy desarrolladas (misiles V-1 y V-2) y soportaban bombardeos destructivos sobre sus ciudades a una escala nunca antes vista (bombardeo de Dresde, en febrero de 1945) y la destrucción total de su capital (batalla de Berlín, entre abril y mayo de 1945).
En el frente del Pacífico, los estadounidenses tuvieron que desalojar isla a isla a los japoneses, tanto en el sur del Pacífico (Guadalcanal, en agosto de 1942) como en Filipinas (Manila, en febrero de 1945); tras librar las mayores batallas navales de la historia (batalla del Mar del Coral, en mayo de 1942; batalla de Midway, en junio de 1942; batalla del Golfo de Leyte, en octubre de 1944), alcanzaron tierras niponas (Iwo Jima, en febrero de 1945 y Okinawa, en abril de 1945). En agosto de 1945, el presidente de Estados Unidos, Harry S. Truman ordenó bombardear con las recién inventadas armas nucleares las ciudades de Hiroshima y Nagasaki. La devastación causada por el ataque, que a la larga se cobraría la vida de 250 000 personas, precipitó la capitulación de Japón.
A diferencia de la Primera Guerra Mundial, la rendición (tanto la japonesa como la alemana) se produjo por derrota incondicional, sin pasar por ningún tipo de negociación. Las conversaciones decisivas fueron las que plantearon la división de Europa en zonas de influencia entre los aliados, y que se negociaron en sucesivas cumbres (conferencia de Teherán, el 1 de diciembre de 1943; conferencia de Yalta, en febrero de 1945; y conferencia de Potsdam, en julio de 1945).
La Segunda Guerra Mundial alteró las relaciones políticas y la estructura social del mundo. Tras la conflagración, se fundó la Organización de las Naciones Unidas con el fin de fomentar la cooperación internacional y de prevenir potenciales conflictos. La Unión Soviética y Estados Unidos se erigieron como superpotencias rivales, estableciéndose el escenario para la Guerra Fría, que se prolongó durante los siguientes cuarenta y seis años. Al mismo tiempo, la influencia de las grandes potencias europeas entró en decadencia, materializada en el inicio de la descolonización de Asia y África. La mayoría de los países cuyas industrias habían sido perjudicadas abordaron la recuperación económica con la ayuda financiera del país americano (plan Marshall), mientras que la integración política emergía como un esfuerzo para establecer las relaciones de posguerra.


== Cronología ==

En general se considera que la guerra comenzó en Europa el 1 de septiembre de 1939[3]​[4]​ con la invasión alemana de Polonia, que provocó la declaración de guerra de Reino Unido y Francia a Alemania dos días después, seguida por la invasión soviética de Polonia el 17 de septiembre de 1939. Las fechas de inicio de las hostilidades en la zona del océano Pacífico son varias y anteriores en el tiempo: La segunda guerra chino-japonesa que comenzó el 7 de julio de 1937[5]​[6]​ o incluso la invasión japonesa de Manchuria a partir del 19 de septiembre de 1931.[7]​[8]​
Otros coinciden con el historiador británico A. J. P. Taylor, que sostenía que la guerra chino-japonesa y la guerra en Europa y sus colonias ocurrieron simultáneamente y ambas se desataron en 1941. Otra fecha de inicio a veces usada para la Segunda Guerra Mundial es la invasión italiana de Etiopía desde el 3 de octubre de 1935.[9]​ El también historiador Antony Beevor opina que la conflagración comenzó con la batalla de Jaljin Gol entre Japón y las fuerzas de Mongolia y la Unión de Repúblicas Socialistas Soviéticas (URSS), de mayo a septiembre de 1939.[10]​ En este artículo se seguirá la datación convencional.
La fecha exacta del fin de la guerra tampoco tiene un consenso universal. Generalmente se ha aceptado que el conflicto terminó con el armisticio japonés del 14 de agosto de 1945, en lugar de la rendición formal de Japón, que se produjo el 2 de septiembre y que puso final definitivo a las hostilidades en Asia. En 1951 se firmó un tratado de paz con Japón.[11]​ Décadas después, en 1990, un tratado sobre el futuro de Alemania permitió la reunificación del país y resolvió muchos de los problemas de la posguerra en Europa.[12]​ Japón y la URSS no firmaron nunca un tratado de paz formal.[13]​


== Antecedentes ==

Las causas bélicas del estallido de la Segunda Guerra Mundial son, en Occidente, la invasión de Polonia por las tropas alemanas; y en Oriente, la invasión japonesa de China, las colonias británicas y neerlandesas y posteriormente el ataque a Pearl Harbor.
La Segunda Guerra Mundial estalló después de que estas acciones agresivas recibieran como respuesta una declaración de guerra, la resistencia armada o ambas, por parte de los países agredidos y aquellos con los que mantenían tratados. En un primer momento, los países aliados estaban formados tan solo por Polonia, Reino Unido y Francia, mientras que las fuerzas del Eje las constituían únicamente Alemania e Italia en una alianza llamada el Pacto de Acero. A medida que la guerra progresó, los países que iban entrando en ella (por ser atacados o tener tratados con los países agredidos) se alinearon en uno de los dos bandos, dependiendo de cada situación. Ese fue el caso de los Estados Unidos y la URSS, atacados respectivamente por Japón y Alemania. Algunos países, como Hungría o Italia, cambiaron sus alianzas en las fases finales de la guerra.


=== En Europa ===

El Tratado de Versalles, establecía la compensación que Alemania debía pagar a los vencedores de la Primera Guerra Mundial. El Reino Unido obtuvo la mayor parte de las colonias alemanas en África y Oceanía (aunque algunas fueron a parar a manos de Japón y Australia). Francia, en cuyo suelo se libraron la mayor parte de los combates del frente occidental, recibió como pago una gran indemnización económica y la recuperación de Alsacia y Lorena, que habían sido anexionadas a Alemania por Otto von Bismarck tras la Guerra Franco-prusiana en 1870.
En el Imperio ruso, la Dinastía Románov había sido derrocada y reemplazada por un gobierno provisional que a su vez fue derrocado por los bolcheviques de Lenin y Trotski. Después de firmar el Tratado de Brest-Litovsk, los bolcheviques tuvieron que hacer frente a una guerra civil, que vencieron, creando la URSS en 1922. Sin embargo, ésta había perdido mucho territorio por haberse retirado prematuramente de la guerra. Estonia, Letonia, Lituania y Polonia resurgieron como naciones a partir de una mezcla de territorios soviéticos y alemanes tras el Tratado de Versalles.
En Europa Central, aparecieron nuevos estados tras el desmembramiento del Imperio Austrohúngaro: Austria, Hungría, Checoslovaquia y Yugoslavia. Además, el extinto Imperio tuvo que ceder territorios a la nueva Polonia, a Rumanía y a Italia.
En Alemania, el Tratado de Versalles tuvo amplio rechazo popular: Bajo su cobertura legal se había desmembrado el país, la economía alemana se veía sometida a pagos y servidumbres a los Aliados considerados abusivos, y el Estado carecía de fuerzas de defensa frente a amenazas externas, sobre todo por parte de la URSS, que ya se había mostrado dispuesta a expandir su ideario político por la fuerza. Esta situación percibida de indefensión y represalias abusivas, combinada con el hecho de que nunca se llegó a combatir en territorio alemán, hizo surgir la teoría de la Dolchstoßlegende (puñalada por la espalda), la idea de que en realidad la guerra se podía haber ganado si grupos extranjeros no hubieran conspirado contra el país, lo que hacía aún más injusto el ser tratados como perdedores. Surgió así un gran rencor a nivel social contra los Aliados, sus tratados, y cualquier idea que pudiera surgir de ellos.
La desmovilización forzosa del ejército hasta la fuerza máxima de cien mil hombres permitida por el tratado (un tamaño casi testimonial respecto al anterior) dejó en la calle a una cantidad enorme de militares de carrera que se vieron obligados a encontrar un nuevo medio de subsistencia en un país vencido, con una economía en pleno declive, y tensión social. Todo eso favoreció la creación y organización de los Freikorps, así como otros grupos paramilitares. La lucha de los Freikorps y sus aliados contra los movimientos revolucionarios alemanes como la Liga Espartaquista (a veces con la complicidad o incluso el apoyo de las autoridades) hizo que tanto ellos como los segmentos de población que les apoyaban se fueran inclinando cada vez más hacia un ideario reaccionario y autoritario, del que surgiría el nazismo como gran aglutinador a finales de los años 20 e inicios de los 30. Hasta entonces, había sido un partido en auge, pero siempre minoritario; un intento prematuro de hacerse con el poder por la fuerza (el Putsch de Múnich) acabó con varios muertos, el partido ilegalizado y Hitler en la cárcel. Durante ese periodo de encarcelamiento Hitler escribió el Mein Kampf (Mi lucha), el libro en el que sintetizó su ideario político para Alemania.

El caldo de cultivo existente a nivel social, combinado con la Gran Depresión de inicios de los 30, hizo que la débil República de Weimar no fuera capaz de mantener el orden interno; los continuos disturbios y conflictos en las calles incrementaron la exigencia de orden y seguridad por parte de sectores de la población cada vez más amplios. Sobre esa ola de descontento y rencor, el Partido Nazi, liderado por Adolf Hitler se presentó como el elemento necesario para devolver la paz, la fuerza y el progreso a la nación. Los ideólogos del partido establecieron las controvertidas teorías que encauzarían el descontento y justificarán su ideario: La remilitarización era imprescindible para librarse del yugo opresor de las antiguas potencias aliadas; la inestabilidad del país era ocasionada por movimientos sociales de obediencia extranjera (comunistas) o grupos de presión no alemanes (judíos), culpables además de haber apuñalado por la espalda a la Gran Alemania en 1918; además, Alemania tiene derecho a recuperar los territorios que fueron suyos, así como asegurarse el necesario espacio vital (Lebensraum) para asegurar su crecimiento y prosperidad. Todas estas ideas quedaron plasmadas en el Mein Kampf.
Partiendo de la sensación de afrenta originada por el Pacto de Versalles, los nazis potenciaron, alimentaron y extendieron la necesidad de reparación en la sociedad alemana, mezclando los problemas reales con las necesidades de su propio programa político, presentando el militarismo y la adherencia a la disciplina fascista como las únicas vías capaces de reconducir la situación. Así se justificó la represión brutal de cualquiera que no pensara del mismo modo o fuera percibido como un enemigo del Estado. Y el clima existente a causa del Pacto hizo que aparte de la sociedad no le preocupase lo más mínimo el incumplimiento de cualquier tipo de tratado internacional. Hasta 1932, el NSDAP fue incrementando su cuota electoral en las elecciones federales, manteniendo un estilo político igual de bronco y agresivo que el que practicaba en la calle.

En noviembre de 1932 tienen lugar las octavas elecciones federales alemanas, en las que el NSDAP logra un 33.1 % de votos (aunque bajó algo más de un 4 %). Al ser la lista más votada y ante la imposibilidad de lograr una opción de consenso entre las demás fuerzas políticas, el presidente Hindenburg nombra canciller a Hitler y le ordena formar gobierno.
El 27 de febrero de 1933, un incendio arrasa el Reichstag, la sede del parlamento alemán. A raíz de este suceso, Hitler declara el estado de excepción. Pronto surge desde el partido nazi la acusación de que los comunistas son los instigadores de la quema, y Hitler logra que un Hindenburg ya muy mermado de salud firme el Decreto del Incendio del Reichstag, aboliendo tanto al partido comunista como a cualquier organización afín a ese partido.
Con sus principales enemigos políticos ilegalizados, Hitler procedió a convocar las novenas elecciones federales alemanas el 5 de marzo de 1933. Esta vez logra un 43.9 % de votos y pasa a gobernar, en coalición con el DNVP, en mayoría absoluta. Una vez conseguido el poder político, para lograr el apoyo de la cúpula del ejército (Reichswehr), ordenó asesinar a los dirigentes de las SA, en la llamada noche de los cuchillos largos, la noche del 30 de junio al 1 de julio de 1934.

Hitler restauró en Alemania el servicio militar generalizado que había sido prohibido por el Tratado de Versalles, remilitarizó la Renania en 1936 y puso en práctica una política extranjera agresiva, el pangermanismo, inspirada en la búsqueda del Lebensraum, destinada a reagrupar en el seno de un mismo estado a la población germana de Europa central, comenzando por Austria (Anschluss) en marzo de 1938.
El principal objetivo declarado de la política exterior alemana de la época inmediatamente anterior a la guerra era, por una parte, la recuperación de esos territorios, así como del Corredor polaco y la Ciudad libre de Dánzig, en los antiguos territorios de Prusia perdidos por Alemania después de 1918. Esas reclamaciones territoriales constantes constituían elementos importantes de inestabilidad internacional, pues Berlín reivindicaba abiertamente su restitución, de forma cada vez más agresiva, con la intención de reconstruir la Gran Alemania Großdeutschland.
El apoyo al levantamiento militar del general Francisco Franco en España por parte de Italia y Alemania con tropas y armamento desafió abiertamente al acuerdo de no-intervención en el conflicto civil (guerra civil española) de las naciones extranjeras. Hitler había firmado ya el Pacto de Acero con Mussolini, el único de los dirigentes europeos con un ideario similar. El apoyo a las fuerzas franquistas fue un intento de establecer un Estado fascista controlando el acceso al Mediterráneo con vistas a una futura guerra europea, algo que solo funcionó a medias.

El oeste de Checoslovaquia (la región conocida como los Sudetes) era el hogar de una gran cantidad de población de ascendencia germana, cuyos derechos, según el gobierno alemán, estaban siendo infringidos. La anexión de los Sudetes fue aceptada en los Acuerdos de Múnich en septiembre de 1938 tras una conferencia tripartita entre Alemania, Francia y Gran Bretaña, donde el francés Édouard Daladier y el primer ministro británico Neville Chamberlain, siguiendo una Política de apaciguamiento, confiaron en que sería la última reivindicación de la Alemania nazi. Hitler había transmitido personalmente esa idea a Chamberlain, tras entregarle un conjunto de informes con supuestas atrocidades cometidas contra habitantes alemanes en los Sudetes. La postura inglesa y francesa se debía en gran parte a la reticencia de sus poblaciones a verse envueltos de nuevo en una guerra a escala mundial, así como al convencimiento (sobre todo por parte de ciertos sectores de la sociedad inglesa) de que realmente el Tratado de Versalles había sido excesivo.
Sin embargo, en marzo de 1939 los ejércitos de Alemania entraron en Praga tomando el control de los territorios checos restantes. Al día siguiente, Hitler, desde el Castillo de Praga, proclamó el establecimiento del Protectorado de Bohemia y Moravia, a la vez que propició la aparición del Estado títere de Eslovaquia. También se apoderó del territorio de Memel, perteneciente a Lituania.

El fracaso del apaciguamiento demostró a las potencias occidentales que no era posible confiar en los tratados que pudieran firmarse con Hitler, así como que sus aspiraciones expansionistas no podían seguir siendo toleradas. Polonia rechaza ceder Dánzig a Alemania y firma con Francia un acuerdo de mutua defensa el 19 de mayo de 1939 y en agosto también lo suscribió con Gran Bretaña.
Por su parte, Alemania y la URSS firmaron el 23 de agosto del mismo año el Pacto Ribbentrop-Mólotov, que incluía un protocolo secreto por el que ambas potencias se dividían Europa central en esferas de influencia, incluyendo la ocupación militar. El tratado establecía el comercio e intercambio de petróleo y comida de la URSS a Alemania, reduciendo así el efecto de un futuro bloqueo por parte de Gran Bretaña como el que casi había ahogado a Alemania en la Primera Guerra Mundial. Hitler pasó entonces a centrarse en la preparación del futuro conflicto con los Aliados cuando, como pretendía, invadiera Polonia con el fin de incorporarla a Alemania. La ratificación del tratado de defensa entre Polonia y el Reino Unido no alteró sus planes.

Benito Mussolini se había convertido en líder indiscutido de Italia durante ese mismo período de entreguerras. Expulsado del Partido Socialista Italiano por apoyar la participación de Italia en la Primera Guerra Mundial, en 1919 fundó los Fasci italiani di combattimento, grupo militar integrado por excombatientes, que reprimían a los movimientos denominados obreros y al partido socialista; era por tanto análogo a los Freikorps alemanes tanto en ideario como en actuación. El fascismo creado por Mussolini defendía un régimen militarista, autoritario, nacionalista, que centralizara el poder en una persona y un movimiento (Partido Nacional Fascista en el caso italiano) y contrario a las instituciones democráticas. Los fascistas tomaron como emblema el fascio, antiguo símbolo de poder entre los romanos, consistente en un haz de varas con un hacha en el centro.
En estos años los movimientos obrero y campesino se manifestaron de manera más radical al tomar las fábricas y las tierras bajo su control, en un intento por imitar la Revolución Rusa. Los industriales y terratenientes, asustados por esta amenaza a sus intereses, apoyaron económicamente a los Fasci di combattimento. En septiembre de 1922 los camisas negras, como también eran conocidos los fascistas, organizaron una marcha sobre Roma, para presionar al gobierno por la incapacidad de resolver la situación económica. En respuesta, Víctor Manuel III nombró a Mussolini primer ministro. Este empezó a autodenominarse Duce ('Caudillo'), y estableció un gobierno totalitario. Creó el Gran Consejo Fascista que controló el Parlamento. Persiguió a los sindicatos, al Partido Socialista, a la prensa contraria a su gobierno, y a la Iglesia. Suprimió las libertades individuales y el derecho de huelga. Controló los medios de comunicación y solo permitió propaganda que exaltara el nacionalismo y el fascismo. También introdujo el militarismo en el sistema educativo italiano.
Del mismo modo que Hitler en Alemania, Mussolini defendía el derecho de Italia a la expansión territorial, de grado o por fuerza. Mussolini comenzó una gran campaña expansionista conocida como el colonialismo italiano. Estableció colonias en Somalia, Eritrea y Libia, y conquistó por la fuerza Abisinia y Albania, ignorando las protestas de la Sociedad de Naciones.


=== En Asia ===

A pesar de ser nominalmente una democracia parlamentaria, el Ejército y la Marina de Japón eran dirigidos por los ministros de Guerra y Marina (que debían ser obligatoriamente generales o almirantes retirados o activos), los cuales no estaban sujetos a la autoridad del primer ministro, sino directamente a la del Emperador. De las 29 personas que recibieron el cargo de primer ministro durante el periodo 1885-1945, 15 eran almirantes o generales retirados o activos (durante el período 1932-45 fueron 8 de 11).
Esta anómala situación, combinada con el paso de un ejército permanente a otro reclutado (lo que obligaba a dar instrucción militar a todos los jóvenes del país), favoreció la progresiva militarización de la sociedad japonesa; el ejército y la marina, escasamente controlados por el poder civil, definían sus propios objetivos y se peleaban por los recursos presupuestarios disponibles, pero ambos coincidían en su desprecio a la clase política. Se formaron grupos de opinión enfrentados dentro de las fuerzas armadas que llevaban una «política paralela» a la del gobierno. Japón, un conjunto de islas con gran cantidad de población pero falto de recursos naturales, entró en el siglo XX con el firme propósito de imitar el sistema económico de las potencias occidentales, incluyendo el colonialismo, como forma de mantener su propio desarrollo, y volvió sus ojos hacia el continente asiático.
En 1894 Japón, que ya hacía tiempo que se disputaba la península de Corea con el Imperio Chino, inició la Primera Guerra Sino-japonesa con un ataque sin previo aviso. Para sorpresa de todos, el pequeño Imperio de Japón aplastó a las fuerzas del mastodóntico Imperio Chino, forzando un tratado de paz que le supuso la concesión de Taiwán, de las Islas Pescadores y de Liao-dong. La Rusia Imperial intentó limitar el dominio local de la emergente potencia: Subvencionó el pago de las deudas de guerra chinas con Japón y, apoyada por Alemania y Francia, humilló a Tokio e impuso la restitución de Liao-dong a China.

Rusia y Japón se vieron desde ese momento implicadas en la lucha por la influencia en la parte noroeste de China. Rusia obtuvo la concesión para la construcción del ferrocarril Transmanchuriano, y aumentó su presencia militar en el sector con la creación de una base naval en Port Arthur, en la parte sur de la península de Liao-dong. La política rusa se encaminaba a desarrollar su influencia sobre toda Manchuria y Corea. Japón se inquietó e intentó en un principio negociar una repartición de áreas de influencia en Manchuria, aunque sin éxito. De modo que en 1904 la Marina Imperial Japonesa atacó y destruyó (de nuevo sin previa declaración de guerra) la flota rusa estacionada en Port Arthur. Japón estaba bien preparado, dominaba los mares de la zona en conflicto y sus bases estaban cerca de la zona. Por el contrario, Rusia estaba minada por tensiones internas, dirigida en el este por un mando incompetente e incapaz de asegurar un enlace eficaz con el oeste, ya que el Transiberiano era su única vía terrestre, por lo que no pudo plantar cara. La guerra ruso-japonesa terminó en 1905 con un armisticio que humilló a Rusia y dejó Liao-dong en manos de Japón, junto con la mitad meridional de la isla Sajalín y la preeminencia absoluta sobre Corea. En 1914, Japón declaró la guerra a Alemania, consiguiendo al final de la Primera Guerra Mundial las posesiones alemanas del Océano Pacífico septentrional.
En la década de los 30 la posición política de los militares en Japón era cada vez más dominante. El poder político estaba controlado por los grupos de presión dentro del Ejército y la Armada, hasta el punto de que ocurrieron varios golpes de estado y atentados por parte de cadetes y oficiales jóvenes del Ejército y la Marina contra ministros y altos cargos que estorbaban los intereses de las camarillas militares. Estas acciones llegaron a costar la vida incluso de un primer ministro en 1932, lo que supuso el final a todos los efectos de cualquier intento de controlar al ejército desde el gobierno: La clase política era consciente de que simplemente emitir en público una opinión desfavorable hacia las fuerzas armadas significaba arriesgarse a morir a manos de un ultranacionalista en un arranque de patriotismo.

En 1931, usando como casus belli unos supuestos incidentes transfronterizos, Japón invadió Manchuria, que convirtió en 1932 en Manchukuo, estado independiente bajo protectorado japonés, junto con Jehol. Las críticas internacionales por esta acción llevaron a Japón a retirarse de la Sociedad de Naciones al año siguiente. En 1937, necesitado de recursos naturales y aprovechando la debilidad china provocada por la guerra civil entre comunistas y republicanos, Japón inició la Segunda Guerra Sino-japonesa, y ocupó la parte noreste de ese país. Los Estados Unidos de América y Gran Bretaña reaccionaron en apoyo del Kuomintang concediéndole créditos, ayuda militar encubierta, pilotos y aeroplanos, y también levantando embargos cada vez mayores contra Japón de materias primas y petróleo (su comercio exterior llegó a caer en un 75 %, mientras que las importaciones de petróleo lo hicieron en un 89 %).


== Transcurso de la guerra ==


=== Inicio de la guerra en Asia (julio de 1937-septiembre de 1939) ===

 

La Segunda Guerra Sino-japonesa comenzó en 1937, tras el Incidente del Puente de Marco Polo, cuando Japón atacó en profundidad a China desde Manchukuo.[15]​ Pekín, es atacada el 25 de junio, siendo finalmente tomada el día 8 de agosto junto a Tianjin. Los japoneses terminaron de ocupar el norte rápidamente, pero fueron detenidos finalmente en la batalla de Shanghái. Después de combatir alrededor de la ciudad durante más de tres meses, Shanghái finalmente cayó ante los japoneses en noviembre de 1937. La capital china, Nankín, cayó poco después. Como resultado, el Gobierno nacionalista chino trasladó su sede a Chongqing durante el resto de la guerra. Las fuerzas japonesas cometieron brutales atrocidades contra los civiles y los prisioneros de guerra en la masacre de Nankín, matando unos 300 000 civiles en un mes. Ni Japón ni China declararon oficialmente la guerra por razones similares: Japón deseaba evitar la intervención de potencias extranjeras, sobre todo el Reino Unido y los Estados Unidos, que era su primer proveedor de acero y hubiera debido imponer un embargo en virtud de las Leyes de Neutralidad vigentes en dicho país; mientras que China temía que la declaración le granjeara la enemistad de las potencias occidentales en la zona.
Las tensiones entre Japón y la Unión Soviética, países cuya enemistad se remonta a la guerra ruso-japonesa y a la Intervención japonesa en Siberia, aumentan considerablemente tras el inicio de la guerra total en China. Entre julio y agosto de 1938 tiene lugar la Batalla del Lago Jasán, en territorio soviético, finalizada con un alto al fuego entre la URSS y Japón. Más importante fue la Batalla de Jaljin Gol entre mayo y septiembre de 1939 que concluye con una aplastante victoria de los soviéticos y sus aliados de la República Popular de Mongolia sobre nipones y manchúes finalizando así la guerra no declarada entre el Imperio Japonés y la URSS.[16]​
El Imperio japonés establece una serie de gobiernos títere en China. En diciembre de 1937, se instaura el Gobierno provisional de la República de China con capital en Pekín. Al año siguiente se crea el Gobierno Reformado de la República de China con capital en Nankín.[17]​ En 1939 se crea Mengjiang, un estado colaboracionista mongol situado en la región de la Mongolia Interior, el territorio de mayoría étnica mongola de China. Los tres gobiernos se fusionan en 1940 dando lugar a un único estado, de nombre oficial República de China y con capital en Nankín. Estaría gobernado por Wang Jingwei, exmiembro del Kuomintang y principal rival de Chiang durante el ascenso al poder de este último.


=== Inicio de la guerra en Europa (septiembre de 1939-mayo de 1940) ===

 

El 1 de septiembre de 1939, Alemania invadió Polonia, usando el pretexto de un ataque polaco simulado en un puesto fronterizo alemán. La llanura polaca ofrecía una ventaja para el desplazamiento de los blindados alemanes, aunque los bosques y las carreteras mal construidas eran problemas que hacían más arduo el avance. Alemania avanzó usando la blitzkrieg («guerra relámpago»). El Reino Unido y Francia le dieron dos días a Alemania para retirarse de Polonia. Una vez que pasó la fecha límite, el 3 de septiembre, el Reino Unido, Australia, y Nueva Zelanda le declararon la guerra a Alemania, seguidos rápidamente por Francia, Sudáfrica y Canadá.
Los franceses se movilizaron lentamente y después solo hicieron una ofensiva de «demostración» en el Sarre, que pronto abandonaron, mientras que los británicos no pudieron hacer ninguna acción directa en apoyo de los polacos en el tiempo disponible (véase Traición occidental). Mientras, el 8 de septiembre, los alemanes alcanzaban Varsovia, tras haber penetrado a través de las defensas polacas, y comenzaron el asedio de Varsovia (8-28 septiembre). Durante este tiempo (9-22 de septiembre), hubo un contraataque polaco y la mayor batalla de la campaña conocido como batalla de Bzura.
El 17 de septiembre, la Unión Soviética, siguiendo su protocolo secreto del Pacto Ribbentrop-Mólotov, invadió Polonia desde el este, convirtiendo las defensas polacas en un caos mediante la apertura de un segundo frente. La defensa polaca no aguantaría la lucha en dos frentes a la vez. Un día más tarde, tanto el presidente polaco como el comandante en jefe huyeron a Rumanía. El 1 de octubre, después de un mes de asedio de Varsovia, las fuerzas hostiles entraron en la ciudad. Las últimas unidades polacas se rindieron el 6 de octubre. Polonia, sin embargo, nunca se rindió oficialmente a los alemanes. Algunas tropas polacas se fueron a países vecinos. Como consecuencia de la Campaña de septiembre, la Polonia ocupada consiguió crear un poderoso movimiento de resistencia y contribuyó con fuerzas militares significativas al esfuerzo aliado durante el resto de la Segunda Guerra Mundial.

Tras la conquista de Polonia, Alemania se tomó una pausa para reagruparse durante el invierno de 1939-1940, mientras británicos y franceses se mantenían a la defensiva. Los periodistas llamaron a este período la «guerra de broma» o Sitzkrieg (drôle de guerre, en francés), debido a que casi no existieron combates. Durante este período, la Unión Soviética atacó Finlandia el 30 de noviembre, con lo que comenzó la Guerra de Invierno. A pesar de superar a las tropas finesas en número de 4 a 1, el Ejército Rojo encontró que su ataque se volvía muy difícil, lo cual resultó muy embarazoso y la fuerte defensa finlandesa evitó una invasión completa. Finalmente, los soviéticos acabaron por imponerse y el tratado de paz vio cómo Finlandia cedía áreas estratégicamente importantes en la frontera cerca de Leningrado, así como en la Carelia. Esto sentó un precedente de flaqueza en el ejército Rojo, el cual los alemanes se tomarían en serio para la futura invasión.

Alemania invadió Dinamarca y Noruega el 9 de abril de 1940, en la Operación Weserübung, en parte para contrarrestar la amenaza de una inminente invasión Aliada de Noruega. Dinamarca no resistió, pero Noruega luchó. La defensa noruega fue socavada desde el interior por la colaboración de Vidkun Quisling, cuyo nombre es hoy en día sinónimo de «traidor». Tropas del Reino Unido, cuya propia invasión estaba preparada, desembarcaron en el norte de Noruega. A últimos de junio, los Aliados habían sido derrotados y se retiraban, Alemania controlaba la mayor parte de Noruega, y las Fuerzas Armadas de Noruega se habían rendido, mientras que la Familia real noruega escapaba a Londres. Alemania usó Noruega como base para ataques navales y aéreos contra los convoyes árticos que se dirigían a la Unión Soviética con armas y suministros. Los partisanos noruegos continuarían la lucha contra la ocupación alemana durante toda la guerra.


=== Frente occidental (mayo-septiembre de 1940) ===

 

Los alemanes acabaron la «guerra de broma» el 10 de mayo de 1940, cuando invadieron Luxemburgo, Bélgica, los Países Bajos y Francia. Los Países Bajos fueron arrollados rápidamente y la ciudad neerlandesa de Róterdam fue destruida en un bombardeo aéreo. La Fuerza Expedicionaria Británica (BEF) y el Ejército Francés, avanzaron hacia el norte de Bélgica y planeaban hacer una guerra móvil en el norte, mientras mantenían un frente continuo y estático a lo largo de la línea Maginot más al sur. Los planes Aliados fueron desbaratados inmediatamente por el más clásico e importante ejemplo en la historia de la Blitzkrieg.
En la primera fase de la invasión, Fall Gelb, el Panzergruppe von Kleist de la Wehrmacht, se precipitó a través de las Ardenas, una región con espesos bosques que los Aliados habían pensado que sería impenetrable para un ejército mecanizado moderno. Los alemanes rompieron la línea francesa en Sedán, sostenida por reservistas más que por tropas de primera línea, para luego girar hacia el oeste a través del norte de Francia hacia el Canal de la Mancha, dividiendo en dos a los Aliados.
La BEF y las fuerzas Francesas, rodeadas en el norte, fueron evacuadas desde Dunkerque en la Operación Dinamo. La operación fue una de las evacuaciones más grandes de la historia militar, cuando 338 000 soldados británicos, franceses y belgas fueron evacuados a través del Canal de la Mancha en barcos de guerra y civiles. La ofensiva pudo haber sido más satisfactoria para los alemanes de no haber sido parada por Hitler para que sus tropas cogieran aliento, cosa que en particular a Guderian no gustó nada.

El 10 de junio, Italia se unió a la guerra, atacando a Francia por el sur. Las fuerzas alemanas continuaron entonces la conquista de Francia con el llamado plan rojo o Fall Rot. Francia firmó un armisticio con Alemania el 22 de junio de 1940, que condujo a la ocupación directa alemana de París y de dos tercios de Francia, y al establecimiento de un gobierno títere alemán con sede en el sudeste de Francia conocido como la Francia de Vichy.
Alemania había empezado los preparativos en el verano de 1940 para invadir el Reino Unido en la Operación León Marino. Muchos de los suministros y de las armas pesadas del ejército británico se habían perdido en Dunkerque. Los alemanes no tenían ninguna esperanza de batir a la Marina Real británica, pero pensaron que tendrían una oportunidad de éxito si podían alcanzar la superioridad aérea. Para hacerlo, tenían que suprimir primero a la Royal Air Force (RAF). Entonces se inició un combate aéreo a finales del verano de 1940 entre alemanes y británicos que llegó a conocerse como la batalla de Inglaterra. La Luftwaffe (Fuerza Aérea de Alemania) tomó como objetivo inicialmente a los aeródromos y estaciones de radar del RAF Fighter Command (Mando de Cazas de la RAF).

Pero tras no tener los resultados esperados e impulsado por el contraataque inglés lanzado a Berlín, Hitler desvió los bombardeos directamente a las ciudades inglesas. Así se pudo ver en la operación Blitz, donde los nazis bombardearon por más de cinco meses las ciudades más importantes de Inglaterra, pero más potentemente en su capital Londres. Las urbes de Liverpool, Coventry, Bristol, Southampton, Birmingham, Swindon, Plymouth, Cardiff, Mánchester y Sheffield también fueron fuertemente bombardeadas. Pese a todos los fuertes ataques de Alemania, Inglaterra resistió firmemente y al final, la Luftwaffe fue rechazada por los Hurricanes y los Spitfires, mientras la Marina Real británica mantenía el control del canal de la Mancha. El Blitz provocó alrededor de 43 000 muertes, y destruyó más de un millón de viviendas, pero fracasó en alcanzar los objetivos estratégicos de sacar a Inglaterra de la guerra o dejarla incapaz de resistir una invasión. Así, los planes de invasión alemanes fueron pospuestos indefinidamente.
Después de la caída de Francia en 1940, el Reino Unido estaba sin recursos económicos. Franklin Delano Roosevelt persuadió al Congreso de los Estados Unidos, para que aprobase la Ley de Préstamo y Arriendo el 11 de marzo de 1941, que proveyó al Reino Unido y a otros 37 países con 50 000 millones de dólares en equipo militar y otros suministros. El Reino Unido y la Commonwealth recibieron 34,4 mil millones de dólares. Canadá realizó un programa similar que envió 4,7 mil millones de dólares en suministros al Reino Unido.


=== El Mediterráneo (abril de 1940-mayo de 1943) ===

 

El control del sur de Europa, el mar Mediterráneo y de África del Norte era importante debido a que el Imperio británico dependía del tráfico marítimo a través del canal de Suez. Si el canal caía en las manos del Eje o si la Marina Real británica perdía el control del Mediterráneo, entonces el transporte entre el Reino Unido, la India, y Australia tendría que efectuarse alrededor del cabo de Buena Esperanza, un incremento de miles de millas.

Así, tras la rendición francesa, los británicos atacaron a la Armada Francesa anclada en el norte de África en julio de 1940, por temor a que pudiese caer en manos alemanas, incrementando así su potencial naval y dificultando la posición británica. Esto contribuyó a un distanciamiento en las relaciones anglo-francesas durante los años siguientes. Con la flota francesa destruida, la Marina Real combatió contra la flota italiana por la supremacía en el Mediterráneo desde sus fuertes bases en Gibraltar, Malta y Alejandría (Egipto). En África, las tropas italianas invadieron y capturaron la Somalilandia Británica en agosto.
Italia invadió Grecia el 28 de octubre de 1940, desde Albania, entonces ocupada por Italia, pero fue rechazada rápidamente. A mediados de diciembre, el ejército griego avanzó incluso hacia el sur de Albania, apresando así en la campaña a 530 000 soldados italianos. Mientras tanto, en cumplimiento de la garantía británica dada a Grecia, la Marina Real atacó a la flota italiana el 11 de noviembre de 1940. Aviones torpederos que habían partido desde los portaaviones británicos atacaron a la flota italiana en Tarento, un puerto del sur. Un acorazado fue hundido y se pusieron temporalmente fuera de servicio otros buques. El éxito de los torpedos aéreos en Tarento, fue visto con mucho interés por el jefe naval japonés, Isoroku Yamamoto, que estaba ponderando los medios para neutralizar a la Flota del Pacífico de los Estados Unidos. La Grecia continental, cuyas mejores tropas se habían desgastado en contra de Italia en Albania, cayó finalmente ante una invasión alemana desde el nordeste, que atravesó Bulgaria.
Las tropas italianas pasaron a Egipto desde Libia para atacar las bases británicas en septiembre de 1940, comenzando así la Campaña en África del Norte. El objetivo era la captura del canal de Suez. Las fuerzas británicas, indias, y australianas contraatacaron en la Operación Compass, que terminó en 1941. Entonces, numerosas fuerzas australianas y de Nueva Zelanda (ANZAC) fueron transferidas a Grecia para defenderla del ataque alemán. Las fuerzas alemanas (conocidas más tarde como el Afrika Korps) bajo el mando del general Erwin Rommel desembarcaron en Libia en febrero de 1941 para renovar el asalto contra Egipto.

Alemania también invadió Creta, operación importante por el uso a gran escala de las tropas paracaidistas alemanas. Creta estaba defendida por unos once mil griegos y veintiocho mil tropas del ANZAC, que habían escapado hacía poco de Grecia sin su artillería y sus vehículos. Los alemanes atacaron los tres aeropuertos principales de la isla en Maleme, Rétino y Candía. Después de un día de lucha, no se había alcanzado ninguno de los objetivos y los alemanes habían sufrido bajas devastadoras. Los planes alemanes estaban en desorden y el comandante alemán, el general Kurt Student, estaba contemplando el suicidio. Durante el día siguiente, gracias a la mala comunicación y del fallo de los comandantes aliados en comprender la situación, el aeropuerto de Maleme en el oeste de Creta cayó en poder de los alemanes. La pérdida de Maleme hizo que los alemanes pudiesen enviar refuerzos pesados transportados en avión con los que arrollar a las fuerzas aliadas en la isla. Sin embargo, en vista de las fuertes bajas sufridas por los paracaidistas, Hitler prohibió realizar más operaciones aerotransportadas.
En el norte de África, las fuerzas de Rommel avanzaron rápidamente hacia el este, poniendo sitio al vital puerto de Tobruk. Fueron derrotados dos intentos aliados por liberar Tobruk, pero una ofensiva mayor a fines de año (Operación Crusader) rechazó a las fuerzas de Rommel después de intensos combates.
La guerra entre las armadas aliada e italiana cambió decisivamente a favor de los aliados el 28 de marzo de 1941, cuando los barcos del almirante Andrew Browne Cunningham encontraron a la flota principal italiana al sur del Cabo Matapán, en el extremo sur de la Grecia continental. Con un coste de un par de aviones derribados, los Aliados hundieron cinco cruceros italianos y tres destructores, y dañaron al moderno acorazado Vittorio Veneto. La Marina italiana fue anulada como fuerza de combate y se vio facilitada la tarea aliada de transportar tropas a través del Mediterráneo hacia Grecia.

El 6 de abril de 1941, fuerzas alemanas, italianas, húngaras y búlgaras invadieron Yugoslavia, provocando la rendición del ejército yugoslavo el 17 de abril y la creación de un estado títere en Croacia y Serbia. También el 6 de abril, Alemania invadió Grecia desde Bulgaria. El ejército griego que defendía la línea Metaxas, fue superado en número y en capacidad de maniobra por el rápido avance alemán a través de Yugoslavia y colapsó. Atenas cayó el 27 de abril, aunque el Reino Unido consiguió evacuar unos cincuenta mil soldados, especialmente a Creta.
La resistencia comenzó en Yugoslavia a mediados de 1941, centrada en dos movimientos: Los partisanos comunistas, AVNOJ, liderados por Tito, y el grupo realista Chetniks, liderado por Draza Mihailovic. Los dos grupos paramilitares cooperaron brevemente en 1941, pero se enfrentaron pronto, cuando los chetniks asumieron un papel más ambivalente, poniéndose frecuentemente del lado de las fuerzas de ocupación, y en contra de los comunistas.
En abril-mayo de 1941, hubo una corta guerra en Irak que resultó en una renovación de la ocupación británica. En junio, fuerzas Aliadas invadieron Siria y el Líbano, y capturaron Damasco el 17 de junio. Más tarde, en agosto, tropas del Reino Unido y del Ejército Rojo ocuparon el neutral Irán, asegurando su petróleo y una línea de suministro por el sur para la Unión Soviética.
Al comienzo de 1942, las fuerzas Aliadas en el norte de África fueron debilitadas al mandar destacamentos al Lejano Oriente. Rommel una vez más recapturó Bengasi. Entonces derrotó a los Aliados en la batalla de Gazala y conquistó Tobruk, haciendo miles de prisioneros y apoderándose de grandes cantidades de suministros, antes de continuar más profundamente dentro de Egipto.
En junio de 1942 se registró la Batalla de Mediados de Junio, en que los aliados se enfrentaron a las fuerzas aéreas y navales de Italia y Alemania durante el desarrollo de dos operaciones de abastecimiento de la isla de Malta conducidas por la Royal Navy británica (que comprendía también unidades australianas y polacas), llamadas en código Harpoon y Vigorous. Tales operaciones – ejerciéndose en una zona del Mediterráneo muy amplia – estuvieron definidas basándose en las rutas: De Alejandría de Egipto la Vigorous y de Gibraltar la Harpoon, convergentes ambas sobre Malta en un arco temporal de cinco días.

La Primera Batalla de El Alamein tuvo lugar en julio de 1942. Las fuerzas Aliadas se habían retirado al último punto defendible antes de Alejandría y el canal de Suez. El Afrika Korps, sin embargo, había agotado sus suministros y los defensores pararon su empuje. La Segunda Batalla de El Alamein ocurrió entre el 23 de octubre y el 3 de noviembre. El teniente general Bernard Montgomery estaba al mando de las fuerzas Aliadas conocidas como el 8.º Ejército. Los Aliados iniciaron entonces su ofensiva y, a pesar de una dura resistencia inicial de los italianos y alemanes, triunfaron al final. Después de la derrota alemana en El Alamein, las fuerzas del Eje efectuaron con éxito una retirada estratégica hacia Túnez.
La Operación Torch fue efectuada por los Estados Unidos, Gran Bretaña y las fuerzas de la Francia libre el 8 de noviembre de 1942, para ganar el control del Norte de África por medio de desembarcos simultáneos en Casablanca, Orán y Argelia, seguidos unos pocos días después por un desembarco en Bône, la puerta de entrada a Túnez. Las fuerzas locales de la Francia de Vichy opusieron una resistencia mínima antes de someterse a la autoridad de la Francia libre del general Henri Giraud. Como represalia, Hitler invadió y ocupó la Francia de Vichy, mientras Mussolini ocupó Córcega y la costa azul francesa hasta el Ródano. Las fuerzas alemanas e italianas, que habían ocupado Túnez, fueron cogidas en un movimiento de pinza por los avances aliados, desde Argelia en el oeste y desde Libia en el este. La victoria táctica de Rommel contra las fuerzas inexpertas de los estadounidenses en la batalla del paso de Kasserine, solo pospuso un tiempo la futura rendición de las fuerzas del Eje en el norte de África en mayo de 1943.
En 1943, el Eje casi tuvo éxito en la supresión de la resistencia partisana yugoslava. Desde enero a abril, se forzó a las guerrillas a huir hacia el este, en condiciones invernales sobre el duro terreno de Bosnia. Sufrieron graves pérdidas, y cruzaron el río Neretva (batalla del Neretva), asegurando su puesto de mando y su hospital. Continuaron hacia el este, incapacitando las fuerzas chetniks del área, y cayeron en un embolsamiento alemán casi fatal en el valle del Sutjeska a últimos de mayo (batalla del Sutjeska).


=== África subsahariana (julio de 1940-septiembre de 1943) ===

Italia había ganado el control de Eritrea y de la Somalía Italiana durante la Repartición de África, y había tomado Etiopía antes del comienzo de la Segunda Guerra Mundial durante la Invasión de Etiopía (1935-36). Estas tres colonias fueron reorganizadas en el dominio del África Oriental Italiana.
A principios de 1940, las fuerzas coloniales italianas consistían en ochenta mil soldados italianos y doscientos mil soldados nativos, mientras que las fuerzas británicas en toda la Somalilandia Británica, Kenia y Sudán solamente totalizaban unos diecisiete mil.[21]​ Los italianos primero se desplegaron para la toma de la Somalilandia Francesa (hoy en día conocida como Yibuti). Este ataque fue cancelado debido al colapso del Ejército francés y la formación del Gobierno colaboracionista de la Francia de Vichy. En julio, las ciudades en la frontera con Sudán, Kassala y Gallabat fueron ocupadas por una fuerza italiana de cincuenta mil hombres,[22]​ y en agosto de 1940, el ejército colonial italiano atacó y tomó la Somalilandia Británica utilizando una fuerza de veinticinco mil hombres. Esto le dio a Italia el control de casi todo el Cuerno de África.
En septiembre de 1940, las fuerzas aliadas fallaron, durante la batalla de Dakar, en la captura de la capital de Senegal, luchando contra las tropas de la Francia de Vichy que la defendían; el África Occidental Francesa permaneció en manos de Vichy hasta los desembarcos de la Operación Torch en el norte de África en noviembre de 1942. Aunque en noviembre los Aliados tuvieron éxito en la batalla de Gabón, consolidando su control sobre el África Ecuatorial Francesa para las fuerzas de la Francia libre.

También en noviembre de 1940, los británicos empezaron una contraofensiva desde el Sudán con solamente siete mil soldados, atacando Gallabat ocupada por los italianos, pero fueron incapaces de tomarla.[23]​ Sin embargo, en enero de 1941, el ejército italiano retiró sus fuerzas desde las ciudades fronterizas del Sudán a un terreno más defendible al este de Kassala.[24]​ Con refuerzos adicionales provenientes del ejército de la India Británica y de Sudáfrica, la campaña empezó a hacer progresos. La Somalilandia Británica fue reconquistada en marzo, y Adís Abeba, capital de Etiopía, fue capturada el 6 de abril. El emperador Haile Selassie I volvió a la ciudad el 5 de mayo. Sin embargo, una fuerza de italianos continuó luchando una guerra de guerrillas en Etiopía, hasta la rendición italiana de septiembre de 1943.
Madagascar, como colonia francesa que era, estaba considerada territorio enemigo por los británicos desde la creación del régimen colaboracionista de Vichy. Era también la tierra sugerida a la que los judíos europeos deberían ser deportados, en una propuesta antisemita conocida como el «Plan Madagascar». Mientras los británicos controlasen Egipto y el Canal de Suez, estos planes alemanes eran imposibles, y finalmente fueron archivados en favor de una campaña de genocidio, que se llamó la Solución final. Con la entrada de los japoneses en la guerra en diciembre de 1941, y la rendición de Singapur en febrero de 1942, los Aliados llegaron a preocuparse cada vez más de que Madagascar pudiese caer en manos del Eje. Por lo tanto, realizaron una invasión, conocida como la Operación Ironclad en mayo de 1942. La lucha contra los defensores franceses de Vichy duró hasta noviembre, porque los franceses estaban respaldados por varios submarinos japoneses. En diciembre, la Somalilandia Francesa también fue conquistada por los británicos.
Después de los desembarcos de la Operación Torch, el resto de los territorios de Vichy en África quedaron bajo el control de los Aliados. Con el control del sur del continente seguro, aparte de la insurgencia italiana en Etiopía, los Aliados volvieron su atención a otros teatros de la guerra.


=== Frente oriental (abril de 1941-enero de 1942) ===

 

La batalla de Grecia (Operación Marita) y la invasión de Yugoslavia retrasaron la invasión alemana seis semanas críticas, como posteriormente se puso de manifiesto. Tres grupos de ejércitos alemanes, junto con otras unidades militares del Eje, que sumaban unos 3,5 millones de hombres, se lanzaron a la invasión de la Unión Soviética el 22 de junio de 1941. El Grupo de Ejércitos Norte estaba desplegado en Prusia Oriental y estaba compuesto por los ejércitos de infantería 18.º y 16.º y un ejército Panzer, el 4.º al mando de los generales Busch, Von Küchler y Hoepner, todos bajo las órdenes del mariscal Ritter Von Leeb, apoyados por la 1.ª Flota aérea del general Koller totalizando cuatrocientos cincuenta mil combatientes del Eje. Sus objetivos principales eran asegurar los estados bálticos y tomar Leningrado. Oponiéndose al Grupo de Ejércitos Norte estaban tres Ejércitos soviéticos compuestos por cuatrocientos cincuenta mil hombres en un principio, pero con las nuevas movilizaciones se aumentó el número a seiscientos mil al mando del mariscal Voroshilov. Los alemanes lanzaron sus 600 tanques contra el punto de contacto de los dos Ejércitos soviéticos en ese sector. El objetivo del 4.º Ejército Panzer era cruzar los ríos Niemen y Dvina, que eran los dos mayores obstáculos en la ruta hacia Leningrado. En el primer día, los tanques cruzaron el río Niemen y penetraron 80 kilómetros. Cerca de Rasienai, los Panzers fueron contraatacados por 300 tanques soviéticos. Los alemanes tardaron 4 días en rodear y destruir a los tanques soviéticos. Los Panzers cruzaron después el río Dvina cerca de Dvinsk.

Los alemanes estaban ahora a una distancia suficiente como para atacar Leningrado; sin embargo, Hitler ordenó a los Panzers mantener su posición mientras los Ejércitos de infantería los alcanzaban. Las órdenes de mantener la posición durarían cerca de una semana, y dieron tiempo suficiente a los soviéticos para que fortaleciesen sus defensas alrededor de Leningrado. Los soviéticos recibieron apoyo de la flota soviética del Báltico, hasta que los Stukas alemanes lograron hundir a los acorazados Marat y Revolución de Octubre. Después de que Hitler dio la orden de ataque, el 4.º Ejército Panzer trató de perforar la plaza desde el 10 de agosto hasta el 8 de septiembre. Voroshilov movilizó a toda la población civil para evitar que la ciudad cayera, lo que consiguió con enormes pérdidas que oscilan entre medio millón y un millón y medio de bajas solamente en el bando soviético.
El Grupo de Ejércitos Centro estaba desplegado en Polonia y comprendía a los ejércitos 9.º, al mando del general Strauss, 4.º, al mando del general Von Kluge, al 2.º, comandado por el general Von Weichs, y dos ejércitos Panzer, el 2.º y el 3.º, bajo las órdenes de los generales Guderian y Hoth respectivamente, todos a su vez dirigidos por el mariscal Fedor von Bock. Su objetivo principal era la captura de Moscú. Oponiéndose al Grupo de Ejércitos del Centro estaban cuatro Ejércitos soviéticos con 3500 tanques, bajo el mando del mariscal Timoshenko. Los soviéticos ocupaban un saliente que se introducía en terreno alemán con su centro en Bialystok. Más allá de Bialystok estaba Minsk, un nudo de ferrocarriles clave, que guardaba la principal carretera a Moscú. El 3.º Ejército Panzer penetró a través de la unión de los dos Ejércitos soviéticos desde Prusia y cruzó el río Niemen, y el 2.º Ejército Panzer cruzó el río Bug desde el sur para lo cual se emplearon 80 tanques capaces de caminar bajo el agua. Mientras atacaban los panzers, los ejércitos de infantería golpeaban en el saliente y rodeaban a las tropas soviéticas en Bialystok. El objetivo de los ejércitos panzer era encontrarse en Minsk e impedir una retirada soviética. El 27 de junio, tras cinco días de operaciones, los ejércitos Panzer II y III se encontraron en Minsk habiendo avanzado 350 kilómetros en territorio soviético. En la enorme bolsa entre Minsk y la frontera polaca quedaron rodeadas 32 divisiones de infantería soviéticas y ocho divisiones de tanques, totalizando cuatrocientos mil soldados soviéticos con más de 3500 tanques (tres veces más que los atacantes) y dos mil cañones que en la batalla de Bialystok-Minsk fueron atacados y cercados en un triángulo que inicialmente tenía unos 300 km de lado.

La batalla de cerco duró 14 días, del 27 de junio al 10 de julio, y al desplomarse la resistencia fueron capturados 323 898 soldados soviéticos, aunque consiguieron escapar unos doscientos cincuenta mil más, capturaron o destruyeron 3332 tanques y 1909 cañones (más del total de tanques enviados a la lucha por Francia); el aniquilamiento de esa cantidad de material blindado dio confianza al mando alemán, ya que los tanques disponibles de Alemania para la invasión de Rusia eran solamente 2434, y se creyó que se había logrado acabar con la mayoría de los blindados soviéticos. En realidad era falso, pues el Ejército Rojo tenía una imponente masa de veinte mil máquinas en 1941, aunque se debe matizar que el 92 % de esos carros eran viejos tanques de los años 30 de los que en la primera semana se averió casi el 50 % de ellos debido a problemas mecánicos: El 90 % de los T-35 se averiaron sin luchar, solo un 5 % eran T-34s y un 3 % KV-1s. En ese mismo tiempo la Luftwaffe había organizado 2800 aviones en tres flotas comandados por Loehr, Kesselring y Keller. En los primeros días de lucha, numerosas escuadrillas de tres bombarderos se internaron en territorio soviético volando casi a ras de suelo, sin cruzar ciudades, para atacar los principales aeródromos en un radio de 300 km. En esos dos primeros días de lucha se reportaron 2700 aviones derribados o destruidos en sus bases, pero tras ocupar los aeródromos por tierra se comprobó que fueron destruidos 2700 aparatos, de los cuales unos 1800 en el primer día.
El Grupo de Ejércitos Sur estaba desplegado al sur de Polonia y en Rumanía y estaba compuesto por los ejércitos 6.º, 11.º, y 17.º, y un Ejército Panzer, el 1.º, junto con dos Ejércitos rumanos y varias divisiones italianas, croatas, eslovacas y húngaras. Su objetivo era capturar los campos petrolíferos del Cáucaso. En el sur, los comandantes soviéticos habían reaccionado rápidamente al ataque alemán y sus fuerzas de tanques superaban con mucho a las alemanas. Oponiéndose a los alemanes en el sur había tres ejércitos soviéticos. Los alemanes atacaron en los puntos de contacto de los tres ejércitos soviéticos, pero el 1.º Ejército Panzer golpeó justo a través del Ejército soviético con el objetivo de capturar Brody. El 26 de junio, cinco cuerpos de ejército mecanizado soviéticos con unos mil tanques montaron un contraataque masivo contra el 1.er Ejército Panzer. La batalla de Lutsk-Brody-Rovno fue una de las más feroces de la invasión y duró varios días. Al final de ella los alemanes resultaron vencedores, pero los soviéticos infligieron duras pérdidas al 1.er Ejército Panzer. Con el fracaso de la ofensiva soviética, se habían acabado las últimas fuerzas substanciales de tanques soviéticos.

El 3 de julio, apenas terminada la batalla de Bialystock-Minsk Hitler dio su consentimiento a los panzers para que relanzasen su empuje hacia el este, después que los ejércitos de infantería los hubiesen alcanzado. Fedor von Bock lanzó la vanguardia de sus nueve divisiones blindadas y sus siete motorizadas, seguidas por treinta y cinco divisiones de infantería hacia el frente. A las orillas del río Beresina los alemanes se enfrentaron a un nuevo tipo de tanque soviético desconocido hasta entonces. Era el T-34, con 45 milímetros de blindaje, coraza frontal inclinada, y cañón de 76,2 mm de diámetro, eficaz a 1500 m. Los efectivos de la 18.ª División Blindada de Guderian se enfrentaron a él, pasando serias dificultades antes de descubrir que tenía mala visibilidad por detrás y una comunicación por radio muy deficiente (los carros no solían tener radio y se hacía por señas entre ellos). Iguales dificultades pasaron al repeler al tanque pesado KV-1, mejor blindado que el T-34. Después de la sorpresa se destruyeron varias unidades soviéticas encabezadas por el VIII Cuerpo de Ejército, en la que militaba el hijo de Stalin Yákov Dzhugashvili, que fue hecho prisionero. A pesar de todo, Stalin se negó a hacer un trato con los nazis para el intercambio de su hijo.
El siguiente objetivo del Grupo de Ejércitos Centro sería la ciudad de Smolensk que dominaba la carretera a Moscú. Frente a los alemanes estaban las fortificaciones no concluidas de la Línea Stalin, apoyadas sobre el río Dniéper, y al perforarla consiguieron capturar Perekop. El 6 de julio, los soviéticos lanzaron un ataque con 700 tanques contra el 3.º Ejército Panzer. Los alemanes tenían una abrumadora superioridad aérea en calidad; los soviéticos poseían la flota aérea más numerosa de todas las naciones, pero sus cazas J-15 y sus bombarderos que eran relativamente lentos y de los más diversos modelos, no podían competir contra los Messerschmitt 109 ni contra los Junkers Ju 87 (Stukas) más rápidos. El 2.º Ejército Panzer cruzó el Dniéper y se acercó a Smolensk desde el sur, mientras que el 3.er Ejército Panzer, después de derrotar el contraataque soviético, se aproximó a Smolensk desde el norte. Tres Ejércitos soviéticos quedaron embolsados. El 26 de julio, los Panzers cerraron la trampa y entonces comenzó la eliminación de la bolsa, cogiendo trescientos diez mil prisioneros soviéticos, 3205 tanques y 3210 cañones, de un total de tres mil seiscientos tanques, tres mil quinientos cañones y cuatrocientos sesenta mil combatientes soviéticos. Hitler ahora, se vio en un dilema: Sus generales querían continuar con el empuje hacia Moscú, pero el problema para continuar con la ofensiva del sector central era que, en el sur, los ejércitos comandados por Gerd von Rundstedt se encontraban atascados a la entrada de Kiev, donde el mariscal Budionni tenía cinco ejércitos con más de setecientos mil hombres, parapetados en poderosas defensas, y otro ejército soviético se encontraba en la región de Gómel con más de cien mil hombres; este conjunto de tropas preocupaba a Hitler, ya que las líneas de abastecimiento de los ejércitos de Von Bock se encontraban demasiado extendidas. Tanques del Grupo de Ejércitos Centro fueron desviados en apoyo de los Grupos de Ejércitos Norte y Sur. Los generales de Hitler se opusieron vehementemente a esta medida, ya que Moscú se encontraba solo a 350 kilómetros del Grupo de Ejércitos Centro y el grueso del Ejército Rojo estaba desplegado en ese sector y solamente un ataque allí tenía esperanzas de acabar la guerra rápidamente. Pero Hitler fue inflexible y los tanques del Grupo de Ejércitos Centro se fueron a reforzar al 4.º Ejército Panzer en el norte, atravesando las defensas soviéticas el 8 de agosto, llegando al final de agosto a solo 50 km de Leningrado. Mientras tanto los finlandeses habían atacado hacia el sudeste, a ambos lados del lago Ládoga, alcanzando la antigua frontera soviética.
En el sur, a mediados de julio, más allá de los Pantanos de Pinsk, los alemanes se habían quedado a solo unos kilómetros de Kiev. El 1.er Ejército Panzer entonces fue hacia el Sur, mientras que el 17.º Ejército alemán, que estaba en el flanco sur del 1.er Ejército Panzer, golpeó hacia el este y entre los dos atraparon tres ejércitos soviéticos cerca de Uman. Cuando los alemanes eliminaron la bolsa, los tanques giraron hacia el norte y cruzaron el Dniéper; mientras tanto el 2.º Ejército Panzer, que había sido desviado del Grupo de Ejércitos Centro por orden de Hitler, había cruzado el río Desná con el 2.º Ejército en su flanco derecho. Los dos ejércitos Panzer atraparon ahora cuatro ejércitos soviéticos y parte de otros dos. El embolsamiento de las fuerzas soviéticas en Kiev fue conseguido el 16 de septiembre. Los rodeados soviéticos no abandonaron fácilmente, siguió una batalla salvaje (véase Batalla de Kiev) que duró diez días, después de la cual los alemanes declararon que habían capturado seiscientos mil soldados soviéticos. Hitler la llamó la batalla más grande de la historia. Después de Kiev, los alemanes no estaban superados en número por el Ejército Rojo, y los soviéticos no tenían más reservas próximas. A Stalin le quedaban ochocientos mil hombres para defender Moscú.

En el norte, el 25 de agosto, el Grupo de Ejércitos Norte capturó Chúdovo, en la línea principal de ferrocarril entre Moscú y Leningrado. Cinco días más tarde tomaron el importante nudo ferroviario de Mga, y el 8 de septiembre, la 20.º División Motorizada ocupó Shlisselburg, en la esquina sureste del lago Ládoga, a treinta y siete kilómetros al este de la ciudad, completando de esta manera el cerco de la ciudad.[26]​
Los enormes cañones de la Flota del Báltico frenaron en seco la primera ofensiva alemana en 1941 a tan solo siete kilómetros de Leningrado, sus poderosos cañones eran capaces de lanzar por los aires los tanques alemanes, tan solo una de estas baterías navales fue capaz de destruir treinta y cinco tanques alemanes, doce posiciones de artillería, un batallón de infantería y un tren militar alemán cargado de soldados y municiones.[27]​ Entonces el mariscal de campo Wilhelm von Leed Comandante del Grupo de Ejércitos Norte, decidió que fuera la Luftwaffe quien despejara el camino a Leningrado hundiendo los barcos de la Flota del Báltico, la primera víctima fue el viejo Acorazado Marat (antiguo Petropavlovsk), hundido en aguas someras tras el impacto directo de dos bombas de 1000 kg. Sin embargo, tres de sus torretas principales estaban intactas junto al resto del casco y los soviéticos lo pusieron en servicio, por lo cual, el Marat continuó como batería estacionaria durante el resto del cerco.[28]​[29]​
La poderosa demostración de fuego de la Flota Soviética y el traslado de la mayor parte de la Luftwaffe y de las unidades blindadas del Grupo de Ejércitos Norte para apoyar la gran ofensiva alemana contra Moscú (véase Operación Tifón) impidió a la Wehrmacht ocupar rápidamente Leningrado, por lo que el Alto Mando Alemán ordenó al Grupo de Ejércitos Norte, atrincherarse y dejar morir de hambre a la población y a la guarnición de la ciudad.[30]​ El 6 de septiembre de 1941, Adolf Hitler, emitió la directiva del Führer n.º 35 ordenaba que tres cuerpos motorizados y el VIII Cuerpo aéreo se pusieran bajo el control del Grupo de Ejércitos Centro para participar en la ofensiva sobre Moscú. Con sus dos divisiones Panzer y sus dos divisiones motorizadas restantes, el Grupo de Ejércitos Norte fue incapaz de hacer progresos en los ataques terrestres. En su lugar comenzaron a bombardear la ciudad con artillería pesada y ataques de la Luftwaffe. El día 12, las bombas alemanas destruyeron el principal almacén de alimentos de la ciudad, hecho que marcaría el comienzo de dos años de hambruna y sufrimiento.[31]​
La Batalla de Moscú (Operación Tifón) comenzó el 2 de octubre. Frente al Grupo de Ejércitos Centro estaba una serie de elaboradas líneas de defensa. Los alemanes sobrepasaron fácilmente la primera línea de defensa cuando el 2.º Ejército Panzer, volviendo desde el sur, tomó Orel que estaba 110 kilómetros detrás de la primera línea soviética de defensa. Entonces los alemanes avanzaron y en el vasto embolsamiento capturaron a 663 000 soldados soviéticos. Los soviéticos solo tenían ahora noventa mil hombres y mil quinientos tanques para la defensa de Moscú.

Casi desde el principio de la Operación Tifón el clima había ido empeorando, haciendo más lento el avance alemán hacia Moscú, hasta llegar a ser de 3 kilómetros diarios. El 31 de octubre, el Alto Mando del Ejército alemán ordenó un alto en la Operación Tifón para que los ejércitos pudiesen reorganizarse. La pausa dio tiempo a los soviéticos para organizar nuevos ejércitos y traer tropas desde el este, cuando el Pacto de Neutralidad firmado por soviéticos y japoneses en abril de 1941, le aseguraba a Stalin que ya no sería amenazado por los japoneses por más tiempo.
El 15 de noviembre, los alemanes reiniciaron una vez más el ataque a Moscú. Frente a los alemanes esperaban seis ejércitos soviéticos. Los alemanes intentaron que los 3.º y 4.º ejércitos Panzer cruzaran el Canal de Moscú y rodearan Moscú desde el nordeste. El 2.º Ejército Panzer atacaría Tula y después se acercaría a Moscú desde el sur y el 4.º Ejército atacaría en el centro. Pero el 22 de noviembre, las tropas siberianas soviéticas atacaron el 2.º Ejército Panzer en el sur, e infligieron una sorprendente derrota a los alemanes. El 4.º Ejército Panzer tuvo éxito en cruzar el Canal de Moscú y el 2 de diciembre había penetrado hasta siuarse a 25 kilómetros del Kremlin. Pero empezaron las primeras tormentas del invierno y, por falta de previsión, la Wehrmacht no estaba equipada para la guerra de invierno y las congelaciones y enfermedades causaron más bajas que el propio combate; los muertos y heridos ya habían alcanzado un número de 155 000 en tres semanas. Las divisiones estaban a mitad de potencia y el frío causaba grandes problemas a los cañones y al resto de equipo. Los ataques soviéticos solían realizarse muy temprano, dado que las armas alemanas no funcionaban bien a tan bajas temperaturas, mientras que las de los soviéticos sí. Las condiciones climatológicas hacían que la Luftwaffe quedase en tierra. Las tropas soviéticas recién reclutadas cerca de Moscú, eran de cerca de 500 000 hombres, y el general Zhúkov lanzó un contraataque masivo el 5 de diciembre que hizo retroceder a los alemanes cerca de 325 kilómetros, aunque no consiguió una brecha definitiva. La invasión de la Unión Soviética había costado a los alemanes hasta la fecha unos 250 000 muertos y 500 000 heridos, así como gran parte de sus tanques.


=== El Pacífico (abril de 1941-junio de 1943) ===

 

Hitler ocultó a los japoneses su plan de invadir la Unión Soviética. La URSS, temiendo una guerra en dos frentes, decidió hacer la paz con Japón. El 13 de abril de 1941, la URSS y Japón firmaron el Pacto de Neutralidad, permitiendo que los japoneses concentrasen su atención en la inminente guerra en Asia y el Pacífico.
En el verano de 1941, los Estados Unidos, el Reino Unido y los Países Bajos comenzaron un embargo de petróleo contra el Japón, amenazando con impedir su capacidad para librar una guerra importante tanto en el mar como en el aire. Sin embargo, las fuerzas japonesas continuaron avanzando hacia el interior de China. Durante los meses de verano, Japón trató de sondear las posibilidades de lograr que los Estados Unidos levantasen el embargo de petróleo contra el Imperio de Japón.[15]​ La respuesta estadounidense fijaba como condición sine qua non la retirada de las tropas japonesas en China. Rechazando estas condiciones, Japón planeó un ataque a Pearl Harbor para mermar gravemente a la Flota del Pacífico de los Estados Unidos, y después apoderarse de los campos de petróleo de las Indias Orientales Neerlandesas.[15]​
El primer ministro, príncipe Fumimaro Konoe, era muy reticente a iniciar una guerra contra los Estados Unidos y los países de la Commonwealth. Sin embargo, el emperador Hirohito se inclinó finalmente por las tesis del sector más belicista, como el propio Konoe admitiría ante su jefe de gabinete, Kenji Tomita.[33]​ Ante su aislamiento en el Gobierno y la falta de apoyo del emperador, Konoe se vio forzado a dimitir el 16 de octubre de 1941. Para reemplazarlo, Hirohito eligió, de acuerdo con la recomendación del Señor del Sello Privado, Koichi Kido, al hasta entonces ministro de la Guerra, general Hideki Tōjō, una de las figuras más destacadas del sector belicista, encargándole la organización del ataque contra la flota estadounidense en el Pacífico. El 1 de diciembre, en una Conferencia Imperial celebrada en Tokio, Hirohito dio su aprobación oficial al comienzo de la guerra.[15]​

El 7 de diciembre, Japón lanzó ataques por sorpresa, prácticamente simultáneos, contra Pearl Harbor, Tailandia y los territorios británicos de Malaya y Hong Kong. Una flota de portaaviones japoneses lanzó un ataque aéreo por sorpresa sobre Pearl Harbor. El ataque destruyó la mayor parte de los aviones estadounidenses de la isla y dejó fuera de combate a la principal flota de batalla estadounidense (tres acorazados fueron hundidos, y cinco más gravemente dañados, aunque solo se perdieron definitivamente el USS Arizona y el USS Oklahoma, los otros seis acorazados fueron reparados y pudieron regresar al servicio activo). Sin embargo, los cuatro portaaviones estadounidenses (que eran el principal objetivo del ataque japonés) estaban fuera, en alta mar. En Pearl Harbor, el muelle principal, las instalaciones de suministro y de reparación fueron reparadas rápidamente. Más aún, las instalaciones para el almacenaje de combustible de la base, cuya destrucción habría dejado gravemente mermada a la flota del Pacífico, fueron dejadas intactas. El ataque unió a la opinión pública estadounidense pidiendo venganza contra el Japón. Al día siguiente, el 8 de diciembre, los Estados Unidos declararon la guerra al Japón.
A la vez que atacaban Hawái, los japoneses atacaron la isla de Wake, un territorio estadounidense en el Pacífico Central. El intento de desembarco inicial, fue rechazado por la guarnición de Marines, y una resistencia muy dura continuó hasta el 23 de diciembre. Los japoneses enviaron un gran número de refuerzos, y la guarnición se rindió cuando estuvo claro que no estaba viniendo ninguna fuerza de auxilio estadounidense.
Japón también invadió las Filipinas, un protectorado de los Estados Unidos, el 8 de diciembre. Las fuerzas estadounidenses y filipinas, bajo el mando del general Douglas MacArthur, fueron forzadas a retirarse a la península de Bataán. Una fiera resistencia continuó hasta abril, comprando un tiempo precioso para los Aliados. Después de su rendición, los supervivientes fueron conducidos a la Marcha de la Muerte de Bataán. La resistencia Aliada continuó por un mes más en la isla fortaleza de Corregidor, hasta que también se rindieron. El general MacArthur, al que se le había ordenado retirarse a Australia, prometió: Volveré.
Un desastre golpeó a los británicos el 10 de diciembre, cuando perdieron 2 barcos de guerra importantes, el HMS Prince of Wales y el HMS Repulse. Ambos buques fueron atacados por 85 bombarderos y torpederos japoneses con base en Saigón, en la Indochina francesa, y 840 marineros británicos perecieron. Winston Churchill dijo acerca del suceso: En toda la guerra, nunca recibí un golpe más directo.
Alemania declaró la guerra a los Estados Unidos el 11 de diciembre, aunque no estaba obligada a hacerlo bajo el acuerdo del Pacto Tripartito. Hitler esperaba que Japón apoyaría a Alemania atacando a la Unión Soviética. Japón no lo hizo porque había firmado un tratado de no agresión, prefiriendo concentrarse en expandir su imperio en China, Sudeste de Asia, y el Pacífico. Más que abrir un segundo frente sobre la URSS, el efecto de la declaración de guerra alemana fue el de borrar cualquier oposición significativa dentro de los Estados Unidos, para unirse a la lucha en el Teatro Europeo.

Los Aliados Cuatro Grandes (Reino Unido, los Estados Unidos, la Unión Soviética y China[34]​) fueron creados oficialmente a través de la Declaración de las Naciones Unidas el 1 de enero de 1942. Poco después se formó el Comando estadounidense-británico-neerlandés-australiano, en inglés (ABDACOM), para unificar las fuerzas Aliadas en el Sureste de Asia. Fue el primer mando supremo Aliado de la guerra.
Las fuerzas navales ABDACOM casi fueron destruidas en la batalla del Mar de Java, la batalla naval más grande de la guerra hasta ese momento, desde el 28 de febrero hasta el 1 de marzo. El mando conjunto se acabó poco después, para reemplazarse por tres mandos supremos Aliados en el Sudeste de Asia y en el Pacífico.
En abril, la incursión Doolittle, la primera incursión aérea Aliada sobre Tokio, levantó la moral en los Estados Unidos e hizo que Japón gastase recursos en la defensa de la tierra madre, pero causó poco daño real.
A principios de mayo, los japoneses empezaron a realizar la Operación Mo, un plan para conquistar Port Moresby, en Nueva Guinea. El primer paso fue abortado por las marinas de los Estados Unidos y de Australia en la batalla del Mar del Coral. Esta fue la primera batalla que se luchó entre portaaviones, y la primera batalla donde las flotas enemigas nunca tuvieron contacto visual directo entre ellas. El portaaviones estadounidense Lexington fue hundido y el Yorktown gravemente dañado, mientras que los japoneses perdieron el portaaviones ligero Shōhō y el gran portaaviones Shōkaku sufrió daño moderado. El Zuikaku perdió la mitad de su complemento aéreo, y junto con el Shōkaku, fue incapaz de participar en la consiguiente batalla en Midway. La batalla fue una victoria táctica para los japoneses, ya que infligieron más pérdidas sobre la flota estadounidense que las sufridas por ellos, pero fue una victoria estratégica estadounidense, ya que el ataque japonés sobre Port Moresby fue rechazado.
En los seis meses siguientes a Pearl Harbor, los japoneses habían conseguido casi todos sus objetivos navales. Su flota de 11 acorazados, 10 portaaviones, 18 cruceros pesados y 20 ligeros, permanecía relativamente intacta. Habían hundido o dañado de manera importante todos los acorazados de Estados Unidos en el Pacífico. Las flotas británica y neerlandesa del Lejano Oriente habían sido destruidas, y la Real Armada Australiana, había sido rechazada hacia sus puertos de origen.[35]​ Su anillo de conquistas se cimentaba en un perímetro defensivo de su elección, que se extendía desde el Pacífico Central hasta Nueva Guinea y Birmania.
La única fuerza estratégica aliada de importancia, que permanecía oponiéndose a todo esto, era la base naval de Pearl Harbor, incluyendo los tres portaaviones de la Flota del Pacífico de los Estados Unidos. Ambos bandos veían como algo inevitable una batalla decisiva entre portaaviones, y los japoneses confiaban en que si mantenían una ventaja numérica de 10:3 en portaaviones pesados, obtendrían la victoria.[36]​ También tenían un avión excelente basado en los portaaviones, el Zero. Los japoneses enviaron una flota hacia la Isla de Midway, una isla periférica de las Islas Hawái, con el objetivo de atraer lo que quedaba de la flota estadounidense a una batalla decisiva. El 5 de junio, bombarderos estadounidenses basados en portaaviones avistaron la fuerza japonesa y hundieron 4 de sus mejores portaaviones durante la batalla de Midway, a un coste de un solo portaaviones, el Yorktown. Esta fue una victoria muy importante para los Estados Unidos, y marcó el punto de inflexión en la guerra del Pacífico. La capacidad estadounidense en la construcción de barcos y aviones superaba ampliamente a la japonesa, y la flota japonesa nunca disfrutaría otra vez de tal superioridad numérica.
En julio, los japoneses intentaron un ataque por tierra sobre Port Moresby, a lo largo del sendero Kokoda, un sendero de tierra, en fila india, a través de la jungla y las montañas. Un batallón australiano, que estaba esperando el regreso de las unidades regulares desde el norte de África y la llegada del ejército estadounidense, superado en número y mal equipado y entrenado, libró una lucha en retirada contra una fuerza japonesa de 5000 hombres.

El 7 de agosto, los Marines estadounidenses comenzaron la batalla de Guadalcanal. Durante los seis meses siguientes, las fuerzas estadounidenses lucharon contra las fuerzas japonesas por el control de la isla. Mientras tanto, se libraron muchos encuentros navales en las aguas cercanas, incluyendo la batalla de la isla de Savo, la batalla del Cabo Esperance, la batalla naval de Guadalcanal, y la batalla de Tassafaronga.
A finales de agosto y principios de septiembre, mientras se combatía en el sendero Kokoda y en Guadalcanal, fue derrotado un ataque de los marines japoneses por fuerzas australianas en la costa sur de Nueva Guinea, en la batalla de la Bahía de Milne. Esta fue la primera derrota de las fuerzas de tierra japonesas en la guerra del Pacífico.
El 22 de enero, después de una dura batalla en Gona y Buna, las fuerzas australianas y estadounidenses recuperaron las cabezas de playa japonesas más importantes en el este de Nueva Guinea.
Las autoridades estadounidenses declararon segura a Guadalcanal el 9 de febrero. Las fuerzas de Estados Unidos, Nueva Zelanda, Australia, y de las Islas del Pacífico, empezaron una larga campaña para recuperar las partes ocupadas de las Islas Salomón, Nueva Guinea, y las Indias Orientales Neerlandesas, sufriendo algunas de las resistencias más duras de toda la guerra. El resto de las Islas Salomón fueron recuperadas en 1943.


=== China y el Sureste de Asia (septiembre de 1941-marzo de 1944) ===

En 1940, la guerra había llegado a un punto muerto con ambos bandos consiguiendo solamente ganancias mínimas. Los Estados Unidos dieron un importante apoyo financiero a China, y crearon a los Flying Tigers ('Tigres Voladores'), una unidad aérea, para impulsar las fuerzas aéreas Chinas.
Las fuerzas Japonesas invadieron partes del norte de la Indo-China Francesa el 22 de septiembre. Las relaciones Japonesas con occidente se habían deteriorado rápidamente en los últimos años, y los Estados Unidos, que habían rechazado el Tratado de comercio entre Japón y los Estados Unidos de 1911, colocaron un embargo a las exportaciones a Japón de material de guerra y otras materias.
Menos de 24 horas después del ataque sobre Pearl Harbor, Japón invadió Hong Kong. Las Filipinas y las colonias británicas de Malasia, Borneo, y Birmania siguieron poco después, con la intención Japonesa de apoderarse de los campos petrolíferos de las Indias Orientales Neerlandesas. A pesar de la fiera resistencia de las fuerzas filipinas, australianas, neozelandesas, británicas, canadienses, indias y estadounidenses, todos estos territorios capitularon ante los japoneses en cuestión de meses. Singapur cayó ante los japoneses el 15 de febrero. Aproximadamente 80 000 hombres de la Commonwealth Británica (junto con otros 50 000 que cayeron en Malasia), fueron a los campos de prisioneros japoneses, siendo la rendición más grande de un ejército conducido por los británicos hasta la fecha. Churchill consideraba la derrota británica en Singapur como una de las derrotas británicas más humillantes de toda la historia.

Japón lanzó una ofensiva importante en China después del ataque sobre Pearl Harbor. El objetivo de la ofensiva era el capturar la ciudad de Changsha, estratégicamente importante. Anteriormente los japoneses habían tratado de capturar la ciudad en dos ocasiones, fallando en ambas. Para el ataque, los japoneses reunieron 120 000 soldados en 4 divisiones. Los chinos respondieron con 300 000 hombres, y pronto el ejército japonés estaba rodeado, teniendo que retirarse.
El Ejército Nacionalista Chino del Kuomintang, bajo el mando de Chiang Kai-shek, y el Ejército Chino Comunista, bajo el mando de Mao Zedong, ambos se oponían a la ocupación japonesa de China, pero nunca se aliaron realmente contra los japoneses. El conflicto entre las fuerzas nacionalistas y comunistas, emergió mucho antes de la guerra; y continuó después y, hasta cierto punto, incluso durante la guerra, aunque de forma menos abierta.
Los Japoneses habían capturado gran parte de Birmania, cortando la Carretera de Birmania por la que los Aliados Occidentales habían estado suministrando a los Chinos Nacionalistas. Esta pérdida forzó a los Aliados a crear y sostener un gran puente aéreo desde la India, conocido como volar «The Hump» (la joroba). Bajo el mando del general estadounidense Joseph Stilwell, las fuerzas Chinas en la India fueron reentrenadas y reequipadas, mientras que se hicieron preparativos para construir la Carretera de Ledo, desde la India para reemplazar la Carretera de Birmania. Este esfuerzo se iba a convertir en una tarea de ingeniería enorme.


=== La batalla del Atlántico (enero de 1942-febrero de 1943) ===

 

En el Atlántico Norte, los submarinos alemanes (U-Boot) intentaron cortar las líneas de suministro al Reino Unido hundiendo barcos mercantes.[37]​ En los primeros cuatro meses de guerra hundieron más de 110 barcos. Además de los barcos de suministro, los sumergibles atacaban ocasionalmente barcos de guerra británicos. Un submarino hundió al portaaviones británico HMS Courageous, mientras que el U-47 del legendario comandante Günther Prien consiguió hundir al acorazado HMS Royal Oaken su puerto base de Scapa Flow. Además de los submarinos, los corsarios de superficie también suponían una amenaza para la navegación aliada.
En el Atlántico Sur, el Acorazado de bolsillo Admiral Graf Spee hundió nueve buques de la Marina mercante británica. Fue localizado más allá de la costa sur de Sudamérica, y después combatió con los cruceros HMS Ajax, HMS Exeter, y HMNZS Achilles en la batalla del Río de la Plata, y fue forzado a entrar en el puerto de Montevideo. Antes que volver a afrontar una nueva batalla, el capitán Hans Langsdorff se hizo a la mar y hundió su buque justo fuera del puerto.
El 24 de mayo de 1941, el acorazado alemán Bismarck partió de su puerto, amenazando con dirigirse hacia el Atlántico. Hundió al HMS Hood, uno de los mejores cruceros de batalla de la Marina Real británica. Siguió entonces una caza masiva, en la que el acorazado alemán fue hundido después de una persecución de 2700 kilómetros, durante la cual los británicos emplearon 8 acorazados y cruceros de batalla, 2 portaaviones, 11 cruceros, 21 destructores, y 6 submarinos. Los aviones torpederos Fairey Swordfish del portaaviones HMS Ark Royal alcanzaron al Bismarck, provocando el bloqueo de su timón y permitiendo que los escuadrones perseguidores de la Marina Real Británica lo alcanzasen y hundiesen.
En el verano de 1941, la Unión Soviética entró en la guerra al lado de los Aliados. Aunque su ejército era muy numeroso, había perdido mucho de su equipo y de su base industrial en las primeras semanas que siguieron a la invasión alemana. Los Aliados Occidentales intentaron remediarlo enviando los Convoyes Árticos, que viajaban desde el Reino Unido y los Estados Unidos hasta los puertos del norte de la Unión Soviética (Arjánguelsk y Múrmansk). La traicionera ruta alrededor del Cabo Norte de Noruega, fue lugar de muchas batallas, donde los alemanes trataban continuamente de destruir los convoyes usando sumergibles, bombarderos con base en la costa noruega, ocupada por Alemania, y barcos de superficie.
Tras la entrada de los Estados Unidos en guerra, en diciembre de 1941, los submarinos alemanes hundieron barcos mercantes a lo largo de la Costa Este de los Estados Unidos, el Mar de las Antillas y el Golfo de México. Tuvieron un éxito inicial tan grande que llegó a ser conocido entre las tripulaciones de los sumergibles alemanes como los Segundos buenos tiempos. La institución de los apagones costeros y el sistema de convoyes llevaron a una disminución de los ataques y los submarinos volvieron a su anterior práctica de esperar a los convoyes aliados a mitad de su recorrido en el océano Atlántico.

El 9 de mayo de 1942, el destructor HMS Bulldog capturó al sumergible alemán U 110 y recobró, completa e intacta, una máquina Enigma, un ingenio de cifrado. La máquina se llevó a Bletchley Park, Inglaterra, donde se utilizó para descifrar el código concreto utilizado por los submarinos alemanes. Desde entonces los Aliados disfrutaron de ventaja, ya que podían interceptar y comprender algunas de las comunicaciones por radio alemanas, dirigiendo sus fuerzas navales al lugar donde podían ser más efectivas.
En diciembre de 1943, tuvo lugar la última batalla importante entre la Marina Real Británica y la Armada Alemana. En la batalla de Cabo Norte, el último crucero de batalla alemán, el Scharnhorst, fue hundido por el HMS Duke of York, HMS Belfast y varios destructores.
El momento en el que dio un vuelco la batalla del Atlántico fue a principios de 1943, cuando los Aliados refinaron sus tácticas navales, haciendo un uso efectivo de su nueva tecnología para contrarrestar los ataques de los sumergibles. Los Aliados producían barcos más rápidamente de lo que los submarinos lograban hundirlos, merced a la introducción de la producción en serie, y perdían además menos barcos adoptando el sistema de convoyes, que ya se había ensayado con éxito en la Primera Guerra Mundial. El desarrollo y mejora de la guerra antisubmarina rebajó la esperanza de vida de una tripulación de submarino alemán a meses. Los submarinos del tipo XXI, o elektroboote, con enormes mejoras con relación a los tipos clásicos, aparecieron cuando la guerra ya daba sus últimas bocanadas, demasiado tarde como para afectar su resultado, aunque sirvieron como referente a los vencedores Aliados para desarrollar nuevas clases de submarinos.


=== Frente oriental (enero de 1942-febrero de 1943) ===

 

El 6 de enero de 1942, Stalin, confiado después de su victoria en Moscú, ordenó una contraofensiva general. Inicialmente los ataques tuvieron éxito cuando los embolsamientos soviéticos se cerraron alrededor de Demiansk (bolsa de Demyansk) y Viazma (bolsa de Viazma), y se hicieron amenazadores ataques hacia Smolensko y Briansk. Pero a pesar de estos éxitos, la ofensiva soviética pronto perdió fuerza. En marzo, los alemanes habían recobrado y estabilizado su línea, y asegurado el corredor de la bolsa de Viazma. Solamente en la bolsa de Demjansk existía alguna perspectiva seria de una gran victoria soviética, ya que allí una gran parte del 16.º Ejército Alemán había sido rodeado. Hitler ordenó que no hubiese ninguna retirada y los 92 000 hombres atrapados en la bolsa tuvieron que defender el terreno en el que estaban, mientras recibían los suministros desde el aire. Aguantaron durante diez semanas, hasta abril, cuando se abrió un corredor terrestre hacia el oeste. De esta manera, las fuerzas alemanas retuvieron Demiansk, hasta que se les permitió retirarse en febrero de 1943.
Con la primavera, ambos bandos decidieron reiniciar la ofensiva. Mientras que el Alto Mando Alemán decidió estabilizar el frente en Járkov, los soviéticos sin saberlo, decidieron atacar en el mismo sector para mantener la presión en el sur. Los soviéticos habían atacado en el sector de Járkov en enero, y habían establecido un saliente en la orilla oeste del río Donets.
El 12 de mayo, los soviéticos comenzaron su ofensiva con ataques concéntricos a cada lado de Járkov (Segunda batalla de Járkov) y, en ambos lados, atravesaron las líneas alemanas, quedando la ciudad seriamente amenazada. Como respuesta, los generales alemanes aceleraron sus planes para su propia ofensiva, que se lanzó cinco días más tarde.
El 6.º Ejército Alemán atacó el saliente desde el sur y rodeó completamente a todo el ejército soviético que estaba asaltando Járkov. En los últimos días de mayo, los alemanes destrozaron las fuerzas que se encontraban dentro de la bolsa. De las tropas soviéticas enbolsadas, 70 000 soldados fueron muertos, 200 000 capturados y solo 22 000 consiguieron escapar. Los alemanes no se percataron de la magnitud de la victoria conseguida y, aunque no lo sabían, a principios de junio las extensas estepas del Cáucaso estaban virtualmente sin defensa.

Tardíamente, Hitler se había dado cuenta de que no contaba con tantas fuerzas como para llevar a cabo una ofensiva en todos los sectores del Frente Oriental. No obstante, pensó que si sus ejércitos lograban apoderarse del petróleo y de las tierras fértiles del sur de Rusia, obtendrían los medios para poder continuar la guerra, privando a su vez al Ejército Rojo de su vital fuente de combustible y cereales. En abril, Hitler confirmó sus planes para la campaña principal en Rusia, de nombre en código Operación Azul. Los objetivos de la Operación Azul serían la destrucción del frente sur del Ejército Rojo, la consolidación del control en Ucrania, al oeste del río Volga, y la captura de los campos petrolíferos del Cáucaso. Los alemanes reforzaron al Grupo de Ejército Sur, transfiriendo divisiones de otros sectores y obteniendo divisiones de los aliados del Eje. A finales de junio, Hitler tenía 74 divisiones listas para la ofensiva, aunque solo 54 de ellas eran alemanas.
El plan alemán era un ataque de tres puntas en el sur de Rusia:

El 4.º Ejército Panzer (transferido desde el Grupo de Ejércitos Norte) y el 2.º Ejército apoyados por el 2.º Ejército Húngaro atacarían desde Kursk hacia Vorónezh, después de lo cual continuarían atacando y anclando su ala izquierda alrededor del río Volga.
El 6.º Ejército atacaría desde Járkov y se movería en paralelo con el 4.º Ejército Panzer para alcanzar el Volga.
El 1.er Ejército Panzer golpearía hacia el bajo río Don, flanqueado a su derecha por el 17.º Ejército.
Se esperaba que estos movimientos diesen como resultado una serie de grandes bolsas de tropas soviéticas como en la Operación Barbarroja. Aunque los oficiales de la inteligencia soviética no sabían de donde vendría la principal ofensiva alemana de 1942, Stalin estaba convencido de que el principal objetivo alemán sería Moscú de nuevo, y un 50 % de todas las tropas del Ejército Rojo fueron desplegadas en esta región. Solo un 10 % de las tropas soviéticas estaban desplegadas en el sur de Rusia.

El 28 de junio de 1942, comenzó la Operación Azul. En todos frentes los soviéticos retrocedieron cuando los alemanes atravesaron sus defensas. El 5 de julio, elementos adelantados del 4.º Ejército Panzer alcanzaron el río Don cerca de Vorónezh y quedaron enzarzados en una amarga batalla para capturar la ciudad. Los soviéticos mantuvieron ocupado al 4.º Ejército Panzer, ganando un tiempo vital para reforzar sus defensas. De esta manera, por vez primera en la guerra, los soviéticos no estaban luchando para aguantar sin esperanza posiciones expuestas, sino para permitir una retirada organizada. Cuando la pinzas alemanas se cerraron, solamente encontraron rezagados y guardias de cobertura.
Enfadado con los retrasos, Hitler reorganizó al Grupo de Ejércitos Sur en dos Grupos de Ejércitos más pequeños: A y B. El Grupo de Ejércitos A incluía al 17.º Ejército, al 1.º Ejército Panzer y al 4.º Ejército Panzer. El Grupo de Ejércitos B incluía al 2.º Ejército, al 6.º Ejército, al 8.º Ejército Italiano, al 2.º Ejército Húngaro, y a los 3.º y 4.º Ejércitos Rumanos. El grueso de las fuerzas acorazadas ahora estaba concentrado en el Grupo de Ejércitos A, al que se le ordenó avanzar hacia los campo petrolíferos del Cáucaso, mientras que al Grupo de Ejércitos B se le ordenó capturar Stalingrado y defenderlo de cualquier contraataque soviético. La transferencia del 4.º Ejército Panzer lejos del 6.º Ejército ayudó al 1.er Ejército Panzer a cruzar la región baja del río Don, pero redujo el avance del 6.º Ejército a una marcha, dando más tiempo a los soviéticos a consolidar sus posiciones en Stalingrado.
El 23 de julio, el 6.º Ejército Alemán había tomado Rostov del Don, pero los soviéticos lucharon con una hábil acción de cobertura que enzarzó a los alemanes en una dura lucha urbana para tomar la ciudad. Esto también permitió que las principales formaciones soviéticas escapasen de un embolsamiento. Con el cruce del río Don asegurado en el sur y con el avance del 6.º Ejército yendo muy despacio, Hitler envió al 4.º Ejército Panzer para reunirse otra vez con el 6.º Ejército. A finales de julio, el 6.º Ejército reemprendió su ofensiva y el 10 de agosto limpió la orilla occidental del Don, pero los soviéticos aguantaron en algunas zonas, retrasando la marcha del 6.º Ejército hacia el este. En contraste, el Grupo de ejército A, después de cruzar el Don el 25 de julio, se había extendido en un amplio frente. El 17.º Ejército Alemán giró hacia el oeste, hacia el Mar Negro, mientras que el 1.er Ejército Panzer atacó hacia el sur y al este, barriendo un terreno abandonado en su mayor parte por los soviéticos en retirada. El 9 de agosto, el 1.er Ejército Panzer alcanzó las estribaciones de las montañas del Cáucaso, habiendo avanzando más de 450 kilómetros.
Después de limpiar de tropas soviéticas la orilla oeste del Don, el 6.º Ejército Alemán cruzó el río el 21 de agosto y empezó a avanzar hacia Stalingrado. La Luftwaffe bombardeó la ciudad matando 40 000 personas, convirtiendo gran parte de la ciudad en ruinas. El 6.º Ejército avanzó entonces sobre Stalingrado desde el norte, mientras que el 4.º Ejército Panzer avanzó desde el sur. Entre estos ejércitos y en el área desde el Don al Volga, se había creado un saliente. Dos ejércitos soviéticos defendían el saliente y, el 29 de agosto, el 4.º Ejército Panzer lanzó un gran ataque a través del saliente hacia Stalingrado. Se le ordenó al 6.º Ejército que hiciese lo mismo, pero los soviéticos montaron fuertes ataques contra el 6.º Ejército desde el norte que lo inmovilizaron durante tres días vitales, que hicieron posible que las fuerzas soviéticas escapasen al embolsamiento, y se retirasen hacia Stalingrado. Los soviéticos, que en este momento ya se habían dado cuenta de que el plan alemán era apoderarse de los campos petrolíferos, empezaron a enviar un gran número de tropas desde el sector de Moscú para reforzar a sus tropas en el sur. Zhúkov asumió el mando del frente de Stalingrado y a principios de septiembre lanzó una serie de ataques desde el norte que retrasaron aún más el intento del 6.º Ejército de tomar la ciudad. A mediados de septiembre, el 6.º Ejército, después de neutralizar los contraataques soviéticos, reasumió otra vez la captura de la ciudad. El 13 de septiembre, los alemanes avanzaron a través de los suburbios del sur y para el 23 de septiembre de 1942, el principal complejo de fábricas estaba rodeado y la artillería alemana alcanzaba los muelles del río, a través de los cuales, los soviéticos evacuaban a los heridos y traían refuerzos. La lucha callejera feroz, el conflicto cuerpo a cuerpo de la clase más salvaje, se adueñaban ahora de Stalingrado. El agotamiento y las privaciones quitaban gradualmente las fuerzas a los hombres de ambos bandos, ya que una de las batallas más sangrientas de la Segunda Guerra Mundial acababa de comenzar.

El 6.º Ejército, al mando del general Friedrich Paulus, no había sido equipado para luchar en un ambiente urbano, y le pidió a Hitler poder retirarse para reorganizar sus fuerzas, pero este, que había llegado a obsesionarse con la toma de Stalingrado, rehusó contemplar una retirada. El general Paulus, desesperado, usando sus últimas reservas lanzó otro ataque a principios de noviembre, ya que en este momento los alemanes habían conseguido capturar el 90 % de la ciudad. Los soviéticos, sin embargo, habían estado acumulando fuerzas frescas en los flancos de Stalingrado, que estaban en este momento severamente bajas de hombres por parte del Eje, ya que el grueso de las fuerzas alemanas estaba concentrado en la captura de la ciudad, y las tropas de los Socios del Eje se habían dejado guardando los flancos. El 19 de noviembre de 1942, los soviéticos lanzaron la Operación Urano, con ataques simultáneos que rompieron los débiles flancos enemigos, custodiados por tropas rumanas e italianas, y se encontraron en la ciudad de Kalach cuatro días más tarde, embolsando al 6.º Ejército en Stalingrado.

Los generales pidieron permiso para intentar romper el cerco, lo cual fue rechazado por Hitler, que ordenó al 6.º Ejército permanecer en Stalingrado, y les prometió que serían enviados suministros desde el aire hasta que fuesen rescatados. La palabra de Göring se vio duramente puesta en entredicho, pues de las 500 toneladas diarias de suministros prometidos, para apoyar a los soldados alemanes asediados, no llegaron a Stalingrado ni la décima parte. 
Al mismo tiempo, los soviéticos lanzaron la Operación Marte en un saliente cerca de Moscú. Su objetivo era el inmovilizar al Grupo de Ejércitos Centro e impedir que pudiese reforzar a las fuerzas del Grupo de Ejércitos B en Stalingrado.
Mientras tanto, el avance del Grupo de Ejércitos A en el Cáucaso se había detenido cuando los soviéticos destruyeron las instalaciones petrolíferas, y se requeriría un año de trabajo para volverlas a hacer operativas, y los campos petrolíferos que quedaban, estaban al sur de las montañas del Cáucaso. Todo agosto y septiembre, las tropas de montaña alemanas sondearon para intentar encontrar un medio de pasar las montañas, pero para octubre, con el comienzo del invierno, no estaban más cerca de conseguir su objetivo. Con las tropas alemanas rodeadas en Stalingrado, el Grupo de Ejércitos A comenzó a replegarse.
En diciembre, el mariscal de campo Erich von Manstein, formó rápidamente una fuerza de socorro alemana compuesta con unidades del Grupo de Ejército A para liberar al aislado 6.º Ejército. Incapaz de obtener refuerzos del Grupo de Ejércitos Centro, la fuerza de socorro solo consiguió penetrar 50 kilómetros antes de ser forzada a retroceder por los soviéticos. Para final del año, el 6.º Ejército estaba en una situación desesperada, cuando la Luftwaffe solamente fue capaz de suministrar un sexto de los suministros que Hermann Goering había prometido.
En enero de 1943, se lleva a cabo la Operación «Iskra» Chispa, planeada por el Alto Mando soviético con el objetivo prioritario de romper el sitio de Leningrado. La planificación de la operación comenzó poco después del fracaso de la ofensiva de Siniávino (19 de agosto-10 de octubre de 1942).[39]​ La realización de la operación se encomendó al Frente de Leningrado y al Frente del Vóljov del Ejército Rojo[nota 2]​con el apoyo de la Flota del Báltico y de la Flotilla del Ládoga, del 12 al 30 de enero de 1943, con el objetivo de crear una conexión terrestre con Leningrado. Las fuerzas de ambos frentes se unieron el 18 de enero y el 22 de enero la línea del frente se había estabilizado. La operación abrió con éxito un corredor terrestre de entre ocho a diez kilómetros de ancho hasta la ciudad. Inmediatamente después de la operación, se construyó un ferrocarril a través del corredor que permitió que llegaran muchos más suministros a la ciudad que por el Camino de la Vida a través de la superficie congelada del lago Ládoga, reduciendo significativamente la posibilidad de captura de la ciudad y cualquier vínculo entre las tropas de Alemania y de Finlandia.[41]​ 
Poco antes de rendirse al Ejército Rojo el 2 de febrero de 1943, Friedrich Paulus fue ascendido a mariscal de campo. De esta manera, Hitler le indicaba a Paulus que se suicidase, porque ningún Mariscal de Campo alemán había rendido jamás sus tropas o había sido cogido prisionero. De los 300 000 hombres del 6.º Ejército, solo sobrevivieron 91 000 para ser cogidos como prisioneros, incluyendo 22 generales, pero solo unos 5000 hombres volverían a Alemania después de la guerra. Ésta llegó a ser la batalla más grande, y más costosa en vidas humanas, de la historia. En ambos lados murieron o fueron heridos alrededor de dos millones de personas, incluyendo civiles, siendo las bajas del Eje de aproximadamente unas 850 000.
El 10 de febrero de 1943, el Cuartel General del Mando Supremo (Stavka) lanzó la operación Estrella Polar, menos de dos semanas después de que la operación chispa, levantara parcialmente el sitio de Leningrado. El objetivo de esta nueva ofensiva era derrotar de manera decisiva al Grupo de Ejércitos Norte, levantando el asedio por completo, pero solo logró ganancias muy modestas a costa de un gran número de bajas.[42]​ El Ejército Rojo realizó otros intentos en 1943 para renovar su ofensiva y levantar el sitio por completo, pero solo lograron avances limitados en cada uno de ellos. El estrecho corredor a través del cual, discurría el Camino de la Victoria, permaneció dentro del alcance de la artillería alemana. Al mismo tiempo la artillería alemana de largo alcance continuó bombardeando la ciudad de forma intermitente. El Ejército Rojo no levantó completamente el asedio hasta un año después, el 27 de enero de 1944.[43]​ La ofensiva terminó un mes después, el 1 de marzo, cuando la Stavka ordenó a las tropas del Frente de Leningrado realizar una operación de seguimiento a través del río Narva, mientras que el Segundo Frente Báltico debía defender el territorio ganado en persecución del XVI Cuerpo de Ejército alemán.[44]​


=== Frente occidental (septiembre de 1940-junio de 1944) ===

 

Aparte de Italia, Europa Occidental vio muy poca lucha desde septiembre de 1940 a junio de 1944. Fuerzas británicas y canadienses lanzaron un pequeño ataque en el pequeño puerto pesquero de la Francia ocupada en Dieppe, el 19 de agosto de 1942, cuyo objetivo era sondear y ganar información para una invasión de Europa que sucedería más tarde en la guerra. La batalla de Dieppe fue un desastre total, pero proporcionó información crítica acerca de las tácticas anfibias que serían utilizadas más tarde en la Operación Torch y la Operación Overlord.[45]​
En diciembre de 1941, siguiendo al ataque japonés en Pearl Harbor, que llevó a los Estados Unidos a la guerra, Churchill y Roosevelt se encontraron en la Conferencia Arcadia. Acordaron que la derrota de Alemania tenía prioridad sobre la derrota del Japón. Para aliviar la presión alemana sobre la Unión Soviética, los Estados Unidos propusieron una invasión de Francia cruzando el canal en 1942. Los británicos se opusieron a esto, sugiriendo en vez de ello una pequeña invasión de Noruega o desembarcos en el África del Norte Francesa. La Declaración de las Naciones Unidas fue emitida, y los Aliados Occidentales invadieron primero el norte de África.[46]​

Con la entrada de los Estados Unidos en la contienda, la guerra aérea se volvió a favor de los Aliados a últimos de 1942. Las Fuerzas Aéreas del Ejército de los Estados Unidos comenzaron a llevar a cabo los primeros bombardeos diurnos sobre Alemania, lo que permitió apuntar de manera mucho más precisa, pero expuso a los bombarderos a un mayor peligro que en el bombardeo nocturno. Mientras tanto, los británicos y los canadienses tomaron como objetivos las ciudades alemanas y las industrias de guerra para el bombardeo nocturno. Este esfuerzo fue orquestado por el Primer Mariscal del Aire Harris, que llegó a ser conocido como Bombardero Harris. Los ataques en masa, que podían llegar a tener entre quinientos a mil bombarderos pesados[cita requerida], fueron realizados contra aeropuertos, centros industriales, bases de submarinos, centros de ferrocarril, depósitos de combustible y, en los últimos estados de la guerra, los lugares de lanzamiento para armas tales como el misil V-1 o el cohete V2. Aparte de instalaciones industriales y militares, las ciudades alemanas sufrieron duros bombardeos que se saldaron con cientos e incluso miles de civiles muertos.
Los aliados también empezaron misiones de sabotaje contra Alemania, tales como la Operación Antropoide, en la que Reinhard Heydrich, el arquitecto de la Solución final, fue asesinado en mayo de 1942 por agentes de la resistencia checa que habían volado desde el Reino Unido.[47]​ Hitler ordenó graves represalias contra los ocupantes del cercano pueblo checoslovaco de Lídice. Todo el tiempo, los Aliados continuaron construyendo e incrementando sus fuerzas en el Reino Unido para una eventual invasión de Europa Occidental que fue planeada para finales de primavera, o para principios del verano de 1944.


=== El Mediterráneo (mayo de 1943-marzo de 1945) ===

 

La rendición de las fuerzas del Eje en Túnez el 13 de mayo de 1943, dejó como resultado 250 000 prisioneros. La Guerra del Norte de África, resultó un desastre para Italia, y cuando los Aliados invadieron Sicilia el 10 de julio en la Operación Husky, capturando la isla en poco menos de un mes, el régimen de Benito Mussolini se colapsó. El 25 de julio, fue destituido de su cargo por Víctor Manuel III, el rey de Italia, y arrestado con el consentimiento del Gran Consejo Fascista. Un nuevo gobierno, dirigido por Pietro Badoglio, tomó el poder y declaró ostensiblemente que Italia permanecería en la guerra. Badoglio ya había empezado a tener negociaciones secretas de paz con los Aliados.
Los Aliados invadieron la Italia continental el 3 de septiembre de 1943. Italia se rindió a los Aliados el 8 de septiembre, como había sido acordado en las negociaciones. La familia real y el gobierno de Badoglio escaparon hacia el sur, dejando al Ejército Italiano sin órdenes, mientras que los alemanes continuaron la lucha, forzando a los Aliados a una parada completa en el invierno de 1943-1944 en la Línea Gustav al sur de Roma.

En el norte, Mussolini, fue liberado por orden de Hitler, por un grupo de paracaidistas de las SS de Alemania bajo el mando de Otto Skorzeny el 12 de septiembre de 1943. Con el apoyo nazi, creó lo que era de hecho un gobierno títere, la República Social Italiana o República de Saló, llamada así por la nueva capital en Saló en el lago de Garda. En estos momentos, los grupos clandestinos de oposición a Mussolini y a la ocupación alemana se habían armado y habían comenzado una guerra de guerrillas para desestabilizar su poder. A este movimiento subversivo se le conoce como Resistencia italiana.
A mediados de 1943 se produjo la quinta y final ofensiva del Sutjeska de los alemanes contra los partisanos yugoslavos.
Siguiendo la rendición Italiana, las tropas alemanas tomaron la defensa de la península itálica y establecieron la Línea Gustav en los montes Apeninos del sur, al sur de Roma. Los Aliados fueron incapaces de romper esta línea, y así intentaron rodearla con un desembarco anfibio en Anzio el 22 de enero de 1944. El desembarco, llamado Operación Shingle, fue rodeado rápidamente por los alemanes y parado en seco, haciendo que Churchill comentase: En vez de lanzar un gato salvaje a la costa, todo lo que tenemos es una ballena varada.
Incapaz de flanquear la Línea Gustav, los Aliados intentaron de nuevo, romperla mediante asaltos frontales. El 15 de febrero, el monasterio de Montecassino, fundado en el 524 por San Benito fue destruido por bombarderos estadounidenses B-17 y B-26. Paracaidistas de élite alemanes se lanzaron inmediatamente sobre las ruinas para defenderlas. Desde el 12 de enero hasta el 18 de mayo, fue asaltado cuatro veces por las tropas Aliadas, con el resultado de unas pérdidas de 54 000 bajas aliadas y de 20 000 soldados alemanes.
Después de unos meses, se rompió la línea Gustav y los Aliados avanzaron hacia el norte. El 4 de junio, Roma fue liberada, y el ejército Aliado alcanzó Florencia en agosto. Fue entonces detenido en la Línea Gótica en los Apeninos toscanos durante el invierno.


=== Frente oriental (febrero de 1943-enero de 1945) ===

 

Después de la rendición del 6.º Ejército Alemán en Stalingrado el 2 de febrero de 1943, el Ejército Rojo lanzó ocho ofensivas durante el invierno. Muchas estaban concentradas a lo largo de la cuenca del Don cerca de Stalingrado. Estos ataques resultaron en ganancias iniciales, hasta que las fuerzas alemanas fueron capaces de tomar ventaja de la sobre extensión y debilitada condición del Ejército Rojo, y lanzar un contraataque para recapturar la ciudad de Járkov y áreas circundantes. Esta sería la última victoria estratégica importante de los alemanes en la Segunda Guerra Mundial.

Las lluvias de primavera impidieron las operaciones en la Unión Soviética, pero ambos lados usaron este tiempo para prepararse para la inevitable batalla que llegaría en el verano. La fecha del comienzo de la ofensiva se había movido repetidamente, debido a que retrasos en su preparación habían forzado a los alemanes a posponer el ataque. El 4 de julio, la Wehrmacht, después de reunir la concentración de poder de fuego más grande de toda la Segunda Guerra Mundial, lanzó su ofensiva contra la Unión Soviética en el saliente de Kursk. Los soviéticos conocían sus intenciones, y se apresuraron a defender el saliente con un sistema enorme de defensas en el terreno. Los alemanes atacaron a la vez desde el norte y el sur del saliente y esperaban encontrarse en el medio, cortar el saliente y atrapar a 60 divisiones soviéticas. La ofensiva alemana en el sector Norte fue abortada cuando consiguieron realizar muy pocos progresos a través de las defensas soviéticas, pero en el sector Sur hubo verdadero peligro de producirse una penetración alemana. Los soviéticos trajeron entonces sus reservas para contener el empuje alemán en el sector Sur, y la consiguiente batalla de Kursk, llegó a ser la batalla de tanques más grande de la guerra, cerca de la ciudad de Prójorovka. Los alemanes ya no tenían reservas de consideración, habiendo agotado sus fuerzas acorazadas y no pudieron parar la contraofensiva soviética que los lanzó de vuelta a sus posiciones de partida.
Los soviéticos capturaron Járkov después de su victoria en Kursk, y con la amenaza de las lluvias del otoño, Hitler estuvo de acuerdo en una retirada general a la línea del Dniéper en agosto. A fines de septiembre, los alemanes encontraron la línea del Dniéper imposible de sostener cuando crecieron las cabezas de puente soviéticas. Ciudades importantes del Dniéper empezaron a caer, siendo la primera Zaporozhye, seguida por Dnepropetrovsk. A principios de noviembre los soviéticos penetraron a través de sus cabezas de puente a ambos lados de Kiev y recapturaron la capital ucraniana. El 1.er Frente Ucraniano atacó en Korosten en Nochebuena, y el avance soviético continuó a lo largo de la línea del ferrocarril hasta que se alcanzó la frontera polaco-soviética de 1939.

El 26 de enero de 1944, después de la exitosa Ofensiva de Leningrado-Nóvgorod, Iósif Stalin declaró que el Sitio de Leningrado había sido levantado y que las fuerzas alemanas fueron expulsadas del óblast de Leningrado.[49]​ Poco después, Nóvgorod también fue liberada y en febrero el avance soviético se detuvo en la frontera con Estonia, después de haber hecho retroceder 100 kilómetros el frente y liberar por completo la región de Leningrado.«De pronto, Leningrado emergió de la oscuridad ante nuestros ojos», escribió la poetisa Olga Bergholz. «Hasta las últimas grietas en los muros, la ciudad nos fue reveladaː bombardeada, acribillada y marcada con sus ventanas de madera contrachapada. Y vimos que a pesar de tantos golpes crueles, Leningrado conservaba su orgullosa belleza. Bajo las luces azuladas, rosadas, verdes y blancas, la ciudad nos pareció tan austera y conmovedora que no nos cansábamos de contemplarla».[50]​Para marzo los soviéticos golpearon en Rumanía desde Ucrania. Las fuerzas soviéticas rodearon al 1.er Ejército Panzer, al norte del río Nistru. Los alemanes escaparon de la bolsa en abril, salvando a la mayoría de sus hombres pero perdiendo su equipo pesado. Durante abril, el Ejército Rojo lanzó una serie de ataques cerca de la ciudad de Iași, Rumanía, con el objetivo de capturar el sector, estratégicamente importante, que esperaban usar de trampolín para lanzarse hacia Rumanía para una ofensiva de verano. Cuando lanzaron el ataque a través del bosque de Târgu Frumos los soviéticos fueron rechazados por los alemanes y las fuerzas rumanas, al defender con éxito las fuerzas del Eje el sector a través del mes de abril.
Cuando las tropas soviéticas se acercaron a Hungría, las tropas alemanas ocuparon Hungría el 20 de marzo. Hitler pensó que el líder húngaro, el almirante Miklós Horthy ya no podía considerarse un aliado fiable. Otro de los aliados del Eje, Finlandia, había buscado una paz separada con Stalin en febrero de 1944, pero no aceptaron los términos iniciales que se les ofrecieron. El 9 de junio, la Unión Soviética comenzó la Ofensiva de Víborg-Petrozavodsk en el Istmo de Karelia que, después de tres meses, forzó a Finlandia a aceptar un armisticio.

Antes que los soviéticos pudiesen comenzar su ofensiva de verano hacia Bielorrusia, tenían que limpiar la península de Crimea de fuerzas del Eje. Restos del 17.º Ejército alemán del Grupo de Ejércitos Sur y algunas fuerzas rumanas, habían sido aisladas y dejadas atrás en la península cuando los alemanes se habían retirado de Ucrania. A principios de mayo, el 3.er Frente Ucraniano del Ejército Rojo atacó a los alemanes y la consiguiente batalla fue una victoria completa para las fuerzas soviéticas, fracasando un chapucero esfuerzo de evacuación a través del Mar Negro por parte de los alemanes (véase ofensiva de Crimea).
Con Crimea limpia, la largamente esperada ofensiva soviética de verano, de nombre en código, Operación Bagratión, comenzó el 22 de junio de 1944, con 2,5 millones de hombres y 6000 tanques. Su objetivo era limpiar Bielorrusia de tropas alemanas, y aplastar al Grupo de Ejército Centro Alemán que estaba defendiendo ese sector. La ofensiva se organizó para coincidir con los desembarcos Aliados en Normandía, pero retrasos hicieron que la ofensiva tuviese que ser pospuesta por algunas semanas. La subsiguiente batalla resultó en la destrucción del Grupo de Ejército Centro Alemán, y en unas 800 000 bajas alemanas, la derrota más grande de la Wehrmacht durante la guerra. Los soviéticos continuaron imparables adelante, alcanzando los alrededores de Varsovia el 31 de julio.
La proximidad del Ejército Rojo, hizo que los polacos de Varsovia pensasen que serían liberados pronto. El 1 de agosto, se rebelaron como parte de la más amplia Operación Tempest. Casi 40 000 luchadores de la resistencia polaca tomaron el control de la ciudad. Los soviéticos, sin embargo, no avanzaron más. La única ayuda que recibieron los polacos fue fuego de artillería, cuando unidades del ejército alemán, que se movían dentro de la ciudad para acallar la revuelta, recibieron disparos de artillería soviética. La resistencia acabó el 2 de octubre. Después unidades alemanas destruyeron la mayor parte de lo que había quedado de la ciudad.

Después de la destrucción del Grupo de Ejército Centro Alemán, los soviéticos atacaron a las fuerzas alemanas en el sur a mediados de julio de 1944, y en el plazo de un mes habían limpiado Ucrania de la presencia alemana, infligiéndoles graves pérdidas a los alemanes. Una vez que Ucrania fue limpiada, las tropas soviéticas golpearon en Rumanía. El 2.º y 3.er Frentes Ucranianos del Ejército Rojo, se enzarzaron con el Heeresgruppe Südukraine alemán, que estaba constituido por formaciones alemanas y rumanas, en un operación para ocupar Rumanía y destruir las formaciones Alemanas en el sector. El resultado de la batalla de Rumanía fue una victoria completa para el Ejército Rojo, y significó el paso de Rumanía desde el campo del Eje hacia el campo Aliado. Bulgaria se rindió al Ejército Rojo en septiembre. Siguiendo a los alemanes en retirada desde Rumanía, los soviéticos entraron en Hungría en octubre de 1944 pero el 6.º Ejército Alemán rodeó y destruyó tres cuerpos del Grupo Pliyev del Mariscal Rodión Malinovski cerca de Debrecen, en Hungría. Los soviéticos habían esperado con su rápido asalto la captura de Budapest, pero fueron rechazados y Hungría permanecería como aliada de Alemania hasta el fin de la guerra en Europa. Esta batalla sería la última victoria alemana en el Frente Oriental.
Los soviéticos se recobraron de su derrota en Debrecen, y las columnas adelantadas del Ejército Rojo colaboraron con los Partisanos yugoslavos en la liberaron Belgrado a últimos de noviembre y alcanzaron Budapest el 29 de diciembre de 1944, rodeando la ciudad y atrapando unas 188 000 tropas del Eje, incluyendo muchas Waffen-SS alemanas. Los alemanes aguantaron hasta el 13 de febrero de 1945, y el asedio se convirtió en uno de los más sangrientos de la guerra. Mientras tanto el 1.er, 2.º y 3.er Frentes del Báltico del Ejército Rojo entablaron combate con los restos del Grupo de Ejército Centro y del Grupo de Ejércitos Norte para capturar la región báltica de manos alemanas en octubre de 1944. El resultado de la consiguiente serie de batallas fue la pérdida permanente de contacto entre los Grupos de Ejército Norte y Centro, y la creación de la bolsa de Curlandia en Letonia, donde los ejércitos alemanes 16.º y 18.º fueron atrapados, con un total de unos 250 000 hombres, y allí permanecerían hasta el final de la guerra.


=== El Pacífico (junio de 1943-julio de 1945) ===

 

El 30 de junio, los Aliados lanzaron la Operación Cartwheel, una operación de gran estrategia para el Pacífico Sur y Suroeste, encaminada a aislar la base Japonesa más importante, Rabaul, antes de proceder a la campaña de «saltar de isla en isla» hacia Japón. Había tres objetivos principales: Volver a capturar Tulagi y las Islas Santa Cruz; volver a conquistar la costa norte de Nueva Guinea, y las Islas Salomón centrales; y la toma de Rabaul y bases cercanas.
Para septiembre, las fuerzas australianas y estadounidenses en Nueva Guinea habían capturado las bases más importantes Japonesas en Salamaua y Lae. Poco después se lanzaron sobre la Península Huon, la cadena montañosa Finisterre, Bougainville, y las campañas de Nueva Bretaña.
En noviembre, los marines de Estados Unidos vencieron en la batalla de Tarawa. Este fue el primer asalto anfibio con una oposición muy fuerte en el teatro del Pacífico. La gran cantidad de bajas que sufrieron los Marines, desató una tormenta de protestas en los Estados Unidos, donde no se podía comprender que se sufriesen pérdidas tan grandes por una diminuta y aparentemente sin importancia isla. Los Aliados adoptaron una política de puentear algunas islas fuertes Japonesas y dejarlas «pudrirse en el árbol», rotos sus suministros y tropas de refresco.
El avance aliado continuó en el Pacífico con la captura de las Islas Marshall antes de finales de febrero. Unos 42 000 soldados del Ejército y Marines de los Estados Unidos desembarcaron en el atolón Kwajalein el 31 de enero. Se produjo una batalla muy dura, y la isla fue conquistada el 6 de febrero. Después los Marines de Estados Unidos volvieron a derrotar a los Japoneses en la batalla de Eniwetok.

El objetivo estratégico de los Estados Unidos era el conseguir bases aéreas para poder bombardear Japón con sus nuevos B29, en las Islas Marianas, especialmente Saipán, Tinian y Guam. El 11 de junio, la Armada de los Estados Unidos bombardeó Saipán, defendido por 32 000 tropas japonesas; La batalla de Saipán comenzó el día 15, cuando 77 000 marines desembarcaron, consiguiendo asegurar la isla el 9 de julio. Los Japoneses emplearon toda su menguante fuerza naval en la batalla del Mar de Filipinas, pero sufrieron graves pérdidas en barcos y aviones. Después de la batalla, la fuerza de portaaviones Japonesa ya no era efectiva militarmente. Con la captura de Saipán, Japón estaba al fin al alcance de los bombarderos B-29.
Guam fue invadida el 21 de julio y conquistada el 10 de agosto, pero los japoneses lucharon fanáticamente. Las operaciones de limpieza continuaron mucho tiempo después de que la batalla de Guam hubiese acabado oficialmente. La isla de Tinian fue invadida el 24 de julio y fue tomada el 1 de agosto. Esta operación vio el uso por vez primera del napalm en una guerra.[52]​
Las tropas del general MacArthur liberaron las Filipinas, desembarcando en la isla de Leyte el 20 de octubre. Los Japoneses se habían preparado, dispuestos a una defensa a toda costa, y usaron los últimos restos de sus fuerzas navales en un intento fallido para destruir la fuerza de invasión en la batalla del Golfo de Leyte, desde el 23 de octubre hasta el 26 de octubre de 1944, la batalla naval más grande de la historia del mundo moderno. Esta fue la primera batalla en la que los Japoneses emplearon ataques kamikaze. El acorazado Japonés Musashi, uno de los dos acorazados más grandes jamás construidos, fue hundido por 19 torpedos estadounidenses y 17 bombas.
A lo largo de 1944, los submarinos y aviones de los Aliados atacaron la Armada Imperial Japonesa, y privaron a la industria japonesa de las materias primas, por cuya obtención Japón había ido a la guerra. El principal objetivo era el petróleo, y Japón estaba casi seco a finales de 1944. En 1944, los submarinos hundieron unos dos millones de toneladas de carga,[53]​ mientras que los Japoneses solamente fueron capaces de reemplazar menos de un millón de toneladas.[54]​ El 6.º Ejército de los Estados Unidos desembarcó en Luzón, la principal isla de las Filipinas. Manila fue reconquistada en marzo.

Los Estados Unidos capturaron Iwo Jima en febrero. La isla era psicológicamente importante porque era un territorio tradicional Japonés, administrado por la prefectura de Tokio. Estaba fuertemente defendido con muchos túneles, trincheras y fuertes bajo tierra, pero finalmente fue conquistado por los Marines, después de que hubiesen capturado el Monte Suribachi, un punto clave de la defensa. Iwo Jima probó ser de un valor incalculable debido a sus dos campos de aviación que fueron usados para los aterrizajes de emergencia de los B29, y porque estaba bastante cerca de Japón como para proveer escolta de cazas a los bombarderos, y así alcanzar las islas de origen japonesas.[55]​
Con la consiguiente captura de Okinawa (desde abril hasta junio), los Estados Unidos trajeron a la tierra natal de los Japoneses, dentro de un radio de acción más cómodo, para sus ataques navales y aéreos. Los japoneses defendieron la isla con tropas terrestres, kamikazes, y con la misión suicida del acorazado Yamato, que fue hundido por los bombarderos en picado estadounidenses. Junto con docenas de otras ciudades Japonesas, Tokio fue bombardeado con bombas incendiarias, y murieron cerca de 90 000 personas en el ataque inicial. Las condiciones de vida hacinadas alrededor de los centros de producción y las construcciones residenciales de madera contribuyeron a las cifras tan grandes de pérdidas humanas. Además, los puertos y las mayores áreas de tránsito marítimo de Japón fueron saturadas con minas colocadas desde el aire, en la Operación Starvation, que desorganizó totalmente la logística de la nación isla.
La última ofensiva importante en el área del Pacífico Sudoeste fue la Campaña de Borneo de mediados de 1945, cuyo objetivo era aislar más aún, a las fuerzas japonesas que quedaban en el Sureste de Asia, y asegurar la liberación de los prisioneros de guerra aliados.


=== China y el Sureste de Asia (marzo de 1944-junio de 1945) ===

En abril de 1944, los japoneses comenzaron la Operación Ichigo, para asegurar la ruta férrea entre Peking y Nankín, y para limpiar el sur de China de campos de aviación estadounidenses bajo el mando del general Chennault.[56]​ La operación tuvo éxito, ya que abrió un corredor continuo entre Peking e Indochina, y forzó la recolocación de los campos de aviación más tierra adentro.Sin embargo, falló en la destrucción del ejército de Chiang Kai-shek, y los estadounidenses pronto adquirieron las Marianas, desde las que podían bombardear las islas de origen japonesas.

Mientras los estadounidenses continuaban sin pausa la construcción de la carretera de Ledo desde la India hasta China, en marzo de 1944, los japoneses empezaron su propia ofensiva hacia la India. Esta «Delhi Chalo» ('Marcha hacia Delhi') fue iniciada por Netaji Subhas Chandra Bose,[57]​ el comandante del Ejército Nacional Indio (una fuerza compuesta de prisioneros de guerra del Ejército Indio Británico, que habían sido capturados por los japoneses y que habían decidido unirse a la guerra en un intento para librar a la India de sus gobernantes coloniales, y desde ahí obtener la independencia).[58]​ Los japoneses intentaron destruir a las principales fuerzas indias y británicas en Kohima e Imphal, resultando en algunos de los combates más feroces de la guerra. Mientras que las tropas aliadas que estaban cercadas eran reforzadas y suministradas por aviones de transporte hasta que tropas frescas consiguieron romper el asedio, los japoneses, debido en parte a las lluvias torrenciales, agotaron sus suministros y empezaron a pasar hambre. Las fuerzas supervivientes se retiraron finalmente perdiendo 85 000 hombres, una de las derrotas más grandes del Japón durante la guerra.
Durante el monzón desde agosto hasta noviembre de 1944, los japoneses fueron perseguidos hasta el río Chindwin en Birmania. Con el comienzo de la estación seca a principios de 1945, las fuerzas estadounidenses y chinas finalmente completaban la carretera de Ledo, aunque demasiado tarde como para tener ningún efecto decisivo. El 14.º Ejército Británico, compuesto de unidades indias, británicas y africanas, lanzó una ofensiva en Birmania central. Las fuerzas Japonesas fueron derrotadas decisivamente, y los aliados los persiguieron hacia el sur, conquistando Rangún el 2 de mayo (véase Operación Drácula).


=== Frente occidental (junio de 1944-abril de 1945) ===

 

En la primavera de 1944, se habían completado las preparaciones aliadas para la invasión de Francia. Se habían reunido unas 120 divisiones con unos dos millones de hombres, de los cuales 1,3 millones eran estadounidenses, 600 000 eran británicos y el resto unidades canadienses, franceses libres y polacos. La invasión se emplazó para el 5 de junio pero debido al mal tiempo se pospuso para el 6 de junio de 1944.[60]​ Entre el 85 y el 90 por ciento de todas las tropas alemanas estaba desplegado en el Frente Oriental, y solo unos 400 000 alemanes en dos ejércitos, el 7.º Ejército alemán y el recién creado 5.º Ejército Panzer eran todo lo que Alemania podía reservar para defenderse contra la invasión aliada. Los alemanes habían construido también una serie de fortificaciones elaboradas a lo largo de la costa, llamadas el Muro del Atlántico para detener la invasión, pero en muchos sitios el Muro estaba incompleto o destruido a causa de los bombardeos aliados, cuya superioridad en aviación era apabullante. Las fuerzas aliadas, bajo el mando supremo de Dwight D. Eisenhower, habían lanzado una elaborada campaña de engaños, para convencer a los alemanes que los desembarcos ocurrirían en el área de Calais, lo que causó que los alemanes desplegaran gran parte de sus fuerzas en ese sector. Solamente 50 000 alemanes estaban desplegados en el sector de Normandía el día de la invasión.
La invasión comenzó cuando se lanzaron 17 000 paracaidistas en Normandía para servir como una fuerza de distracción e impedir que los alemanes atacasen las playas. Al apuntar el día, una flota naval inmensa apoyada por aviones bombardeó las defensas alemanas en las playas, pero debido al mar que estaba muy agitado, muchos barcos fallaron su blanco. Se desembarcó en cinco puntos conocidos en clave como Utah, Omaha, Gold, Juno y Sword. Los estadounidenses en particular, sufrieron fuertes pérdidas en la playa de Omaha debido a que las fortificaciones alemanas estaban intactas. Sin embargo, al final del primer día, se habían cumplido muchos de los objetivos aliados, incluso habiendo sido muy optimista el objetivo británico de capturar Caen. Los alemanes no lanzaron ningún contraataque significativo sobre las playas, salvo una contraofensiva de los panzer que separó Juno y Sword, ya que Hitler creía que los desembarcos eran una distracción. Solamente tres días más tarde, el Alto Mando alemán se dio cuenta de que Normandía era el lugar de la verdadera invasión, pero para entonces, los Aliados habían consolidado sus cabezas de playa.
Relato de un testigo del desembarco en Omaha, Cornelius Ryan, famoso tras la guerra por su libro «Normandía»: 

 

El terreno «bocage» de Normandía, donde los estadounidenses habían desembarcado, era ideal para la guerra defensiva. No obstante, los estadounidenses progresaron de forma constante y capturaron el puerto de aguas profundas de Cherburgo el 26 de junio, uno de los objetivos primarios de la invasión. Sin embargo, los alemanes habían minado el puerto y destruido muchas de las instalaciones antes de rendirlo, y haría falta otro mes antes de que el puerto pudiese ser habilitado para un uso limitado. Los británicos lanzaron otro ataque el 13 de junio para capturar Caen, pero fueron rechazados debido a que los alemanes habían reforzado la ciudad con un gran número de tropas en la ciudad para retenerla. La ciudad permanecería todavía en manos alemanas durante otras 6 semanas.

El 23 de julio, en la Operación Cobra, las fuerzas mecanizadas estadounidenses consiguieron forzar la salida por el lado oeste de la cabeza de playa de Normandía gracias a su superioridad numérica, al poder de fuego aliado y a tácticas mejoradas. Cuando Hitler supo de la salida estadounidense, ordenó a sus fuerzas en Normandía que lanzasen una contraofensiva inmediata. Sin embargo, las fuerzas alemanas que se movían en campo abierto, eran un objetivo fácil para la aviación aliada, ya que al principio habían escapado de los ataques aéreos aliados, debido solamente a sus posiciones defensivas bien camufladas.
Los estadounidenses colocaron fuertes formaciones en sus flancos para que neutralizaran los ataques, y empezaron entonces a rodear al 7.º Ejército alemán y a grandes partes del 5.º Ejército Panzer en la bolsa de Falaise. Fueron capturados unos 50 000 alemanes, pero 100 000 consiguieron escapar de la bolsa, aunque sin sus tanques ni armamento pesado. Todavía peor para los alemanes, fue que los británicos y canadienses que habían estado bloqueados en su sector, ahora hicieron una brecha en las líneas alemanas. Se había desvanecido cualquier esperanza que tuviesen los alemanes de contener el avance aliado en Francia, formando una nueva línea defensiva. Los aliados se precipitaron por toda Francia, avanzando 1000 km en dos semanas.[61]​ Las fuerzas alemanas se retiraron hacia el norte de Francia, Países Bajos y Bélgica. Las fuerzas aliadas estacionadas en Italia invadieron la Riviera francesa el 15 de agosto de 1944, y enlazaron con las fuerzas de Normandía. La resistencia francesa clandestina en París, se levantó contra los alemanes el 19 de agosto, y una división acorazada francesa bajo el mando del general Philippe Leclerc, presionando a la vanguardia desde Normandía, recibió la rendición de las fuerzas alemanas de la ciudad, y liberó a la ciudad el 25 de agosto.
Los alemanes lanzaron la bomba volante V-1, el primer misil de crucero del mundo, para atacar blancos en el sur de Inglaterra y en Bélgica. Más tarde, emplearían el cohete V2, un misil balístico guiado de combustible líquido. Ninguna de estas armas era muy precisa y podían solamente ser apuntadas hacia blancos grandes, como las ciudades. Tuvieron muy poco impacto militar, pero su intención era más bien la desmoralización de los civiles.

Los problemas logísticos eran una constante en el avance aliado hacia el este, ya que las líneas de suministro todavía venían desde las playas de Normandía. Los paracaidistas aliados y las fuerzas acorazadas intentaron un avance para ganar la guerra, a través de los Países Bajos y el Rin con la Operación Market Garden en septiembre, pero fueron rechazados. Una victoria decisiva lograda por el 1.er Ejército canadiense en la batalla del Escalda, aseguró la entrada al puerto de Amberes, con lo cual se pudo usar para recibir suministros a últimos de noviembre de 1944. Mientras tanto, los estadounidenses lanzaron un ataque a través del bosque de Hurtgen en septiembre; los alemanes, a pesar de tener menor número de hombres, fueron capaces de rechazar a los estadounidenses durante cinco meses, usando el difícil terreno y buenas posiciones defensivas. En octubre, los estadounidenses capturaron, Aquisgrán, la primera ciudad importante alemana en ser ocupada.
Hitler había estado planeando desde mediados de septiembre una contraofensiva importante contra los aliados. El objetivo del ataque sería la captura de Amberes. La captura o destrucción de Amberes no solo cortaría los suministros a los ejércitos aliados, también dividiría a las fuerzas aliadas en dos, desmoralizando la alianza y forzando a sus líderes a negociar. Para el ataque, Hitler concentró lo mejor de lo que le quedaba de sus fuerzas, en el Oeste. El 5.º Ejército Panzer, el reconstruido 7.º Ejército y el recién creado 6.º Ejército Panzer, en total, 240 000 hombres en 28 divisiones, 1 200 tanques y cañones de asalto. La ofensiva empezó el 16 de diciembre de 1944, con una barrera artillera disparada por 900 cañones alemanes. Una hora más tarde, los tres ejércitos alemanes golpearon la línea estadounidense del frente. Hitler lanzó su golpe hacia Amberes a través de las Ardenas, en el sur de Bélgica, una región llena de colinas y en algunos lugares llena de espesos bosques, y el lugar de su victoria en 1940.

El ataque del 6.º Ejército Panzer tuvo un progreso lento, pero una de sus puntas de lanza consiguió penetrar en las líneas estadounidenses y lanzarse con rapidez hacia el río Mosa. En el Sur, el 5.º Ejército Panzer penetró a través de la inexperta infantería estadounidense. El avance alemán fue retrasado en Saint-Vith, población que las fuerzas estadounidenses defendieron durante varios días. En el vital nudo de carreteras de Bastogne, los alemanes sitiaron la ciudad, defendida por la 101.ª División Aerotransportada, pero no consiguieron tomarla. Algunas unidades alemanas sobrepasaron Bastogne, pero el avance principal fue bloqueado. La ofensiva alemana tuvo un gran impacto en los comandantes aliados, ya que no creían que los alemanes aún tuvieran capacidad para organizar una ofensiva a gran escala. Muchas de las tropas alemanas que atacaban eran veteranos del Frente Oriental, y sabían como combatir en invierno. Un cielo denso y cubierto había impedido el uso de sus aviones de reconocimiento y de ataque a tierra a los estadounidenses. Sin embargo, los aliados estaban empezando a recuperarse de su impacto inicial y el 1.er Ejército y el 9.º Ejército se reagruparon para bloquear cualquier intento de avance de los alemanes hacia el Norte. El 3.º Ejército de Patton hizo un giro rápido de 90 grados y golpeó el flanco sur alemán. El 26 de diciembre, el 3.º Ejército había liberado Bastogne. El clima en estos momentos había mejorado, permitiendo liberar todo el poder aéreo aliado, hasta detener el ataque terrestre alemán en Dinant. En un intento para mantener el impulso de la ofensiva los alemanes lanzaron un ataque aéreo masivo contra los campos de aviación aliados en los Países Bajos el 1 de enero de 1945. Los alemanes destruyeron 465 aviones pero perdieron 277 de sus propios aviones. Mientras que los aliados recuperaron sus pérdidas en cuestión de días, la Luftwaffe no, por lo que ya no fue capaz de lanzar más ataques aéreos importantes.[62]​ Las fuerzas aliadas del norte y el sur se encontraron en Houffalize, y a finales de enero habían empujado a los alemanes a sus posiciones de partida. Se habían desperdiciado meses de la producción de guerra del Reich, en un momento en el que las fuerzas alemanas del Frente Oriental necesitaban esos recursos desesperadamente, ya que el Ejército Rojo se estaba preparando para su masiva ofensiva contra Alemania.


=== Frente oriental (enero de 1945-abril de 1945) ===

 

Con los Balcanes y la mayor parte de Hungría limpias de tropas alemanas a últimos de diciembre de 1944, los soviéticos comenzaron un redespliegue masivo de sus fuerzas hacia Polonia para su inminente ofensiva de invierno. Los preparativos soviéticas todavía estaban en marcha, cuando Churchill le pidió a Stalin que lanzase su ofensiva tan pronto como fuera posible para aliviar la presión alemana en el Oeste. Stalin accedió y la ofensiva fue dispuesta para el 12 de enero de 1945. Los ejércitos de Kónev atacaron a los alemanes en el sur de Polonia y se expandieron desde su cabeza de puente en el río Vístula cerca de Sandomierz. El 14 de enero, los ejércitos de Rokossovsky atacaron desde el río Narew al norte de Varsovia. Los ejércitos de Zhúkov, situados en el centro, atacaron desde sus cabezas de puente cerca de Varsovia. La ofensiva combinada soviética rompió las defensas que cubrían Prusia Oriental, dejando el frente Alemán en un completo caos.[cita requerida]
Zhúkov tomó Varsovia el 17 de enero y, ya el 19 de enero, sus tanques habían llegado a Łódź. Ese mismo día, las fuerzas de Kónev alcanzaron la frontera alemana anterior a la guerra. Al final de la primera semana de la ofensiva, los soviéticos habían penetrado 160 kilómetros en profundidad, en un frente que tenía 650 kilómetros de ancho. La apisonadora soviética se paró finalmente en el río Óder al final de enero, a solo 60 kilómetros de Berlín.

Los soviéticos habían esperado capturar Berlín para mediados de febrero, pero resultó una previsión demasiado optimista. La resistencia alemana que casi se había colapsado en la fase inicial del ataque, se había endurecido tremendamente. Las líneas soviéticas de suministro estaban sobreextendidas y la disciplina entre las tropas soviéticas en el momento que fueron lanzadas sobre suelo alemán se colapsó. El deshielo de primavera, la falta de apoyo aéreo, y el miedo a ser rodeados a través de ataques de flanco desde Prusia Oriental, Pomerania y Silesia, condujo a un alto general de la ofensiva soviética. El recién creado Grupo de Ejércitos Vístula, bajo el mando de Heinrich Himmler, intentó un contraataque en el flanco expuesto del Ejército Rojo pero había fallado para el 24 de febrero. Esto hizo que Zhúkov tuviese claro que el flanco tenía que ser asegurado antes que pudiese montarse cualquier ataque sobre Berlín. Los soviéticos reorganizaron entonces sus fuerzas y golpearon hacia el norte, limpiando Pomerania, y después atacaron hacia el sur y limpiaron Silesia de tropas alemanas. En el sur, tres intentos alemanes de liberar la asediada guarnición de Budapest fallaron, y la ciudad cayó ante los soviéticos el 13 de febrero. Los alemanes contraatacaron otra vez; Hitler insistía en la tarea imposible de recuperar el río Danubio. El 16 de marzo, el ataque había fallado, y el Ejército Rojo contraatacó ese mismo día. El 30 de marzo, entraron en Austria y capturaron Viena el 13 de abril.
Hitler creía que el objetivo principal para la inminente ofensiva Soviética sería en el sur cerca de Praga, y no Berlín, y había enviado las últimas reservas alemanas a defender en ese sector. El principal objetivo del Ejército Rojo era realmente Berlín y para el 16 de abril estaba listo para comenzar su asalto final sobre Berlín. Las fuerzas de Zhúkov golpearon por el centro y cruzaron el río Óder pero quedaron detenidas debido a la desesperada resistencia alemana en las Alturas Seelow. Después de tres días de lucha muy dura y de 33 000 soldados soviéticos muertos,[64]​ se penetraron las últimas defensas de Berlín. Kónev cruzó el río Óder desde el sur y se encontró que podía atacar Berlín pero Stalin le ordenó que guardase los flancos de las fuerzas de Zhúkov y que no atacase Berlín. Las fuerzas de Rokossovski cruzaron el Óder por el norte y enlazaron con las fuerzas del Mariscal de Campo Bernard Montgomery en el norte de Alemania mientras que las fuerzas de Zhúkov y Kónev capturaban Berlín.

Para el 24 de abril, grupos del ejército soviéticos habían rodeado al 9.º Ejército Alemán y aparte del 4.º Ejército Panzer. Estas eran las principales fuerzas que supuestamente tenían que defender Berlín, pero Hitler había dado órdenes a estas fuerzas que aguantasen donde estaban y que no retrocediesen. Así que las principales fuerzas alemanas que supuestamente debían defender Berlín, estaban atrapadas al sureste de la ciudad. Berlín fue rodeada más o menos en este momento, y como esfuerzo de resistencia final, Hitler llamó a los civiles, incluyendo a los adolescentes y ancianos, a que luchasen en la milicia Volkssturm, contra el Ejército Rojo que se estaba aproximando. Estas fuerzas marginales fueron aumentadas con los vapuleados restos alemanes que habían luchado contra los soviéticos en las Alturas Seelow. Hitler le ordenó al cercado 9.º Ejército, que rompiese el cerco y que enlazase con el 12.º Ejército del general Walther Wenck y que liberase Berlín. Una tarea imposible, las unidades supervivientes del 9.º Ejército fueron conducidas hacia los bosques que rodeaban Berlín, cerca del pueblo de Halbe, donde estuvieron envueltos en una lucha particularmente dura, tratando de romper las líneas soviéticas y de alcanzar al 12.º Ejército. Una minoría consiguió unirse al 12.º Ejército y dirigirse peleando hacia el oeste, para rendirse a los estadounidenses. Mientras tanto, la durísima lucha urbana continuaba en Berlín. Los alemanes habían almacenado una gran cantidad de panzerfausts, y consiguieron destruir una gran cantidad de tanques soviéticos en las calles llenas de escombros de Berlín. Sin embargo, los soviéticos emplearon las lecciones que habían aprendido en la lucha urbana en Stalingrado, y fueron avanzando lentamente hacia el centro de la ciudad. Las fuerzas alemanas en la ciudad resistieron tenazmente, en particular la unidad SS Nordland, que estaba compuesta de voluntarios SS extranjeros, porque estaban muy motivados ideológicamente y creían que no vivirían si eran capturados. La lucha fue casa por casa y cuerpo a cuerpo. Los soviéticos tuvieron 360 000 bajas; los alemanes 450 000 bajas incluyendo civiles, y además 170 000 capturados. Hitler y su personal se trasladaron al búnker de la Cancillería, donde se suicidó el 30 de abril de 1945, junto a Eva Braun, con la que había contraído matrimonio unas horas antes.


=== La Guerra acaba en Europa ===

 

Roosevelt, Churchill, y Stalin llegaron a acuerdos para la Europa de posguerra en la Conferencia de Yalta en febrero de 1945. Su encuentro llegó a muchas resoluciones importantes, tales como la formación de las Naciones Unidas, elecciones democráticas en Polonia, las fronteras de Polonia se movieron hacia el oeste a expensas de Alemania, los nacionales soviéticos serían repatriados, y se acordó que la Unión Soviética atacaría a Japón a los tres meses de la rendición de Alemania.
Los Aliados reasumieron su avance hacia el interior de Alemania a finales de enero. El obstáculo final para los Aliados era el Río Rin, que fue cruzado a finales de marzo de 1945, ayudados por la captura fortuita del Puente de Ludendorff en Remagen. Una vez que los Aliados hubieron cruzado el Rin, los británicos se dirigieron en abanico hacia el nordeste en dirección a Hamburgo, cruzando el río Elba y moviéndose hacia Dinamarca y el mar Báltico.

El 9.º Ejército de los Estados Unidos se dirigió al sur para formar la pinza norte del embolsamiento del Ruhr, mientras que el 1.er Ejército fue hacia el norte como la pinza sur del embolsamiento. Estos ejércitos estaban comandados por el general Omar Bradley, que tenía bajos su mando a 1 300 000 hombres. El 4 de abril, el cerco estaba completado, y el Grupo de Ejército Alemán B, que incluía al 5.º Ejército Panzer, al 7.º Ejército y al 15.º Ejército comandados por el Mariscal de Campo Walther Model, estaban atrapados en la Bolsa del Ruhr. Se cogió a unos 300 000 soldados alemanes como prisioneros de guerra. El 1.er y 9.º ejércitos de los Estados Unidos giraron entonces hacia el este. Pararon su avance en el río Elba, donde se encontraron con las tropas soviéticas a mediados de abril.
Los avances Aliados hacia el norte de la Península Italiana, en el invierno de 1944-45, habían sido lentos debido al terreno montañoso y al redespliegue de tropas en Francia. Pero para el 9 de abril, el 15.º Grupo de Ejército Britoestadounidense, penetró a través de la Línea Gótica y atacó el valle del Po, cercando gradualmente las principales fuerzas alemanas. Milán se conquistó a finales de abril. El 5.º Ejército de Estados Unidos continuó su avance hacia el oeste y enlazó con unidades francesas, mientras que los británicos entraron en Trieste, y se encontraron con los partisanos yugoslavos. Unos pocos días antes de la rendición de las tropas alemanas en Italia, partisanos italianos capturaron a Mussolini, que trataba de escapar a Suiza. Fue ejecutado, junto con su amante Clara Petacci. Se llevaron sus cuerpos a Milán, donde fueron colgados boca abajo, para escarnio público.

Después de la muerte de Hitler, Karl Dönitz se convirtió en el jefe del gobierno alemán pero su poderío se desintegraba rápidamente. Las fuerzas alemanas en Berlín entregaron la ciudad a las tropas soviéticas el 2 de mayo de 1945. Las fuerzas alemanas en Italia se rindieron el 2 de mayo de 1945, en el cuartel general del general Alexander, y las fuerzas alemanas en el Norte de Alemania, Dinamarca y los Países Bajos se rindieron el 4 de mayo. El Alto Mando Alemán bajo el generaloberst Alfred Jodl rindieron incondicionalmente todo el resto de fuerzas alemanas el 7 de mayo en Reims, Francia. Los Aliados occidentales celebraron el «Día de la Victoria en Europa» el 8 de mayo. La Unión Soviética celebró el «Día de la Victoria» el 9 de mayo. Algunos restos del Grupo de Ejército Centro Alemán continuaron resistiendo hasta el 11 de mayo o el 12 de mayo (véase batalla de Praga).[66]​


=== La Guerra acaba en Asia ===

 

La última conferencia aliada de la Segunda Guerra Mundial se celebró en la ciudad de Potsdam, cercana a Berlín, desde el 17 de julio hasta el 2 de agosto. Durante la Conferencia de Potsdam se alcanzaron acuerdos entre los Aliados sobre la política a llevar en la Alemania ocupada. También se lanzó un ultimátum a Japón pidiendo su rendición incondicional.
El presidente de los Estados Unidos Harry Truman decidió usar la nueva arma atómica para acelerar el final de la guerra. La batalla de Okinawa había mostrado que una invasión en las islas de origen japonesas (planeada para noviembre) significaría un gran número de bajas estadounidenses. La estimación oficial que fue dada por la Secretaría de Guerra era de 1,4 millones de bajas aliadas, aunque algunos historiadores discuten si esto habría sido el caso o no. La invasión habría significado la muerte de millones de soldados japoneses y civiles, que estaban siendo entrenados como milicia.
El 6 de agosto de 1945, un B-29 Superfortress, el Enola Gay, lanzó una bomba atómica apodada Little Boy sobre Hiroshima, destruyendo la ciudad. El 9 de agosto, un B-29 llamado Bockscar lanzó la segunda bomba atómica, apodada Fat Man, sobre la ciudad portuaria de Nagasaki.[68]​

El 8 de agosto, dos días después de que se hubiese lanzado la bomba atómica sobre Hiroshima, la Unión Soviética, habiendo abolido su pacto de no agresión con Japón en abril, atacó a los japoneses en Manchukuo y Mengjiang, cumpliendo su promesa hecha en Yalta de atacar a los Japoneses tres meses después de que hubiese acabado la guerra en Europa. En menos de dos semanas, el ejército japonés en Manchuria, que consistía en aproximadamente un millón de hombres, había sido destruido por los soviéticos.[69]​[70]​ El Ejército Rojo, ayudado por tropas de la República Popular de Mongolia, se movió hacia Corea del Norte el 18 de agosto. Corea fue seguidamente dividida en el paralelo 38 en las zonas soviética y estadounidense.[71]​[72]​
[73]​
El uso estadounidenses de las armas atómicas contra Japón y la invasión soviética del Manchukuo, hicieron que Hirohito se apresurase a puentear al gobierno existente e interviniese para finalizar la guerra. En su alocución radiofónica a la nación, el Emperador no mencionó la entrada de la Unión Soviética en la guerra, pero en su «reescritura a los soldados y marineros» del 17 de agosto, ordenándoles el alto el fuego y entregar las armas, acentuó la relación entre la entrada de los soviéticos en la guerra y su decisión de rendirse, omitiendo cualquier mención a las bombas atómicas.
Los japoneses se rindieron el 14 de agosto de 1945, o el Día de la Victoria sobre Japón, firmando el Acta de Rendición de Japón el 2 de septiembre. Las tropas japonesas en China se rindieron formalmente el 9 de septiembre de 1945.


== Medios militares de los beligerantes ==


=== Armas ===
El uso generalizado de carros de combate es una primera ilustración de la tendencia a la motorización. Mientras que el Ejército francés escogió la dispersión de los blindados, al servicio de la infantería, los alemanes adoptaron una táctica basada en la agrupación de blindados y salieron victoriosos de la batalla de Francia. La concepción del carro de combate en sí mismo tiende a dos conceptos diferentes: La potencia y la maniobrabilidad.
El progreso de los carros de combate va acompañado del progreso del armamento antitanque: El uso de la carga hueca permite atravesar los blindajes aunque estos sean muy espesos. Tubos lanzacohetes como la bazuca permiten al soldado poseer contra los tanques la potencia de un artillero.[77]​

Paralelamente a la utilización de tanques se asiste a un aumento intensivo de la utilización de transportes motorizados de tropas, dejando de lado a los caballos, todavía muy presentes tanto del lado alemán como del lado francés durante la batalla de Francia o en el frente Este, principalmente por razones de logística. La división blindada estadounidense fue, por el contrario, totalmente motorizada.
Los inmensos progresos de la aviación realizados entre las dos guerras van a dar a los aviones de guerra un lugar preponderante. El mejoramiento de las estructuras del avión permiten a los cazabombarderos como el Stuka realizar bombardeos en picada y de este modo permitir los bombardeos a objetivos terrestres. Los bombarderos pesados como el Boeing B-17 Flying Fortress estadounidense, que tenían un radio de acción que alcanzó 5 000 kilómetros hacia el final de la guerra, fueron utilizados en campañas masivas de bombardeos de más de mil aviones, poniendo en práctica el concepto de bombardeo estratégico. Para contrarrestar a los bombarderos, los beligerantes hicieron uso de sus caza y de cañones de defensa contra aviones(DCA). La eficacia de los (DCA) obligó a organizar las operaciones de bombardeo nocturnas. A los aviones de caza se les encomendó asegurar el espacio aéreo sobre el campo de batalla o sobre un frente dado.[78]​
Por mar, después de la Primera Guerra Mundial, se privilegió la construcción de navíos de línea. Los cruceros de batalla, más rápidos que los acorazados estaban menos protegidos. Los primeros acorazados rápidos no aparecieron hasta el final de los años 1930. Pero esos navíos constituían un objetivo ideal para la aviación embarcada en los portaaviones, sobre todo los bombardeos en picada y los aviones de torpedo. A pesar de una fuerte defensa aérea, disponiendo a veces de un tiro radar, el acorazado era todavía vulnerable. Los portaaviones, que podían disponer de 50-60 aparatos, tuvieron un papel cada vez más determinante. Los portaaviones se convirtieron en una pieza central, que los estadounidenses llamaron «Task force», y los otros navíos fueron comúnmente utilizados de escoltas.[79]​
Al final de la Segunda Guerra Mundial, nuevas armas hicieron aparición en el campo de batalla, como el avión sin piloto V1 lanzado por primera vez por los alemanes sobre Inglaterra en la noche del 13 al 14 de junio de 1944, o el V2 lanzado por primera vez sobre Londres el 8 de septiembre de 1944.[79]​ Contrariamente a los temores de los aliados, los alemanes no tenían un proyecto de bomba atómica.[80]​ Los estadounidenses, por el contrario, dispusieron a partir de diciembre de 1941 gigantescos recursos en el proyecto Manhattan, que concluyó el 16 de julio de 1945, después de la rendición de la Alemania Nazi, con la primera explosión nuclear en el desierto de Nuevo México y a los bombardeos atómicos de Hiroshima y Nagasaki el 6 y 9 de agosto de 1945.


=== Estadísticas ===


== Repercusiones fuera de los países beligerantes ==


=== Participación de América Latina ===

A pesar de tratarse de un país neutral, en los primeros años de la guerra, un grupo de aviadores argentinos se alistaron como voluntarios en la Royal Air Force británica, dando lugar al 164.º Escuadrón de la RAF de voluntarios, el cual combatió en el norte de Francia y Bélgica. Se presentaron 776 argentinos como voluntarios en las fuerzas aéreas de Gran Bretaña, Canadá, Sudáfrica[84]​ En total, se estima que de 4000[85]​ a 5000[86]​ argentinos combatieron durante la Segunda Guerra Mundial como voluntarios de los aliados.
En diciembre de 1941 tras el ataque a Pearl Harbor, Cuba fue el único país independiente antillano que le declaró la guerra a las Potencias del Eje. En el país fueron arrestados varios agentes alemanes y se convirtió en el principal proveedor de azúcar a los aliados. Alemania hundió cinco buques mercantes cubanos, con un saldo de 82 muertos. Por su parte los cazasubmarinos cubanos hundieron al submarino alemán U-176. El siguiente país de América en declararle la guerra a las potencias del Eje es Honduras, curiosamente ese mismo día uno de sus barcos fue capturado en Shanghái por la armada imperial Japonesa y rebautizado como el Ekkai Maru.[87]​ Por consecuencias de estos, Honduras rompe relaciones con Japón y expulsa al cónsul de Alemania de su país.[88]​ Sus primeras acciones iniciaron en 1942 con el patrullaje aéreo, y contribuyo a la guerra enviando materias primas. 
También como consecuencia del ataque a Pearl Harbor, Venezuela rompe relaciones con las potencias del Eje en diciembre de 1941. A raíz de ello, el 16 de febrero de 1942, los tanqueros venezolanos Monagas y Tía Juana son torpedeados y hundidos por submarinos del Tercer Reich en aguas del golfo de Venezuela, tras lo cual, el gobierno del presidente Isaías Medina Angarita, aunque sin declarar la guerra, pasa a cooperar con el esfuerzo aliado de manera más estrecha, autorizando incluso el uso temporal de bases militares venezolanas por el Ejército y la Armada de los Estados Unidos, así como garantizando el suministro de combustible a dichas fuerzas.

En mayo de ese mismo año, Alemania hundió dos navíos petroleros mexicanos (el Potrero del Llano y el Faja de Oro); con este hecho se da inicio a la única participación de México en una Guerra Mundial. Ante la descortesía de los países del Eje de no contestar a la nota de protesta enviada por la cancillería de ese país, el Congreso mexicano le declaró la guerra el 22 de mayo de 1942, siendo el tercer y último país norteamericano en entrar en la guerra. Desde fines de junio a principios de septiembre los submarinos alemanes hundirían cuatro barcos más: Túxpam, Oaxaca, Las Choapas y Amatlán. De esta forma, la aviación mexicana conformada por el Escuadrón 201 participó en la guerra del Pacífico y otros tantos mexicanos se enlistaron en ejércitos de países aliados que combatían en suelo europeo.
Si bien varios países sudamericanos le declararon la guerra a las potencias del Eje, solo Brasil envió una fuerza expedicionaria (FEB) a combatir. Entre julio y agosto de 1942, submarinos alemanes hundieron 18 barcos brasileños y hasta el final de la guerra se llegó a 36 buques hundidos y alrededor de 1 100 muertos. Aunque el Gobierno de Brasil se mostraba reacio a entrar en el conflicto, la indignación pública empujó a Brasil a declarar la guerra a Alemania en noviembre de 1942, y a enviar una División completa de casi 30 000 hombres al frente de Italia donde participaron en la rotura de la Línea Gótica y en la ofensiva aliada final en aquel frente.

El país también participado con el suministro de bases en su Noreste con la Marina de Brasil proporcionando escolta para los convoyes que se dirigen al sur del continente americano y al norte de África, en total escoltaron los convoyes de 3.164 barcos y, junto a la Fuerza Aérea Brasileña, la vigilancia y guerra submarina hundiendo algunos submarinos alemanes y el italiano Arquimede.[89]​ La Fuerza Aérea Brasileña contribuido con un escuadrón de combate y otro de observación en Itália, completando misiones de ataque a tierra, escolta y observación.
Colombia declaró la guerra en 1943, porque un submarino alemán hundió uno de sus barcos, la goleta Resolute, que unos días antes había transportado soldados británicos a la isla de San Andrés. A raíz de esto, el Gobierno colombiano decidió hacer patrullajes para evitar más hundimientos. El 29 de marzo de 1944 el ARC Cabimas transportaba gasóleo en la ruta Cartagena-Panamá escoltado por el ARC Caldas, que detectó la presencia del submarino alemán U-154, hundiéndolo en el acto.[90]​[91]​
El resto de los países sudamericanos como Perú, Ecuador, Uruguay, Paraguay, Venezuela, Chile y Argentina, solo rompieron relaciones diplomáticas con los países del Eje entre 1942 y 1944. La mayor parte de los cuales declararon, finalmente, la guerra al Eje recién en febrero de 1945. Salvo Argentina, que le declaró la guerra a Alemania y a Japón el 27 de marzo de 1945, y Chile, que hizo lo propio con Japón el 12 de abril de ese año, siendo el último país en emitir una declaración de guerra.
Los países centroamericanos lo hicieron bien al lado de México, o bien al lado de Brasil; excepto Costa Rica, que declaró la guerra a Japón el 8 de diciembre de 1941, al mismo tiempo que los Estados Unidos.


=== Participación española en la guerra ===

El 23 de octubre de 1940 se celebró la llamada «entrevista de Hendaya», en la que Francisco Franco se reunió con Adolf Hitler en presencia de sus ministros de Asuntos Exteriores, Ramón Serrano Suñer y Joachim von Ribbentrop, para tratar la posible entrada de España en la guerra en el bando alemán. Tras ella, Franco cambió la declaración de «neutralidad» por la de «no beligerancia», para mostrar de esta forma el apoyo de España al Eje Roma-Berlín. En junio de 1941 se autorizó el reclutamiento de voluntarios para luchar contra el comunismo, dando origen a la División Azul, la cual combatió en el Ejército alemán durante la invasión de la Unión Soviética.
Franco, que había recibido el apoyo británico y estadounidense, lo seguía compensando con las explotaciones mineras británicas, como Riotinto, a la vez que permitía el paso de refugiados judíos o militares (principalmente pilotos) hacia Portugal. La intención era quedar bien con cualquiera que ganara la guerra. Esta posición se apreció especialmente desde que Franco pretendió suavizar la posición de su régimen con las destituciones del ministro germanófilo Ramón Serrano Suñer en 1942, y la repatriación de los voluntarios de la División Azul en 1943, después de la Conferencia de Casablanca.
Respecto a la guerra, Franco dijo:[cita requerida] 

 

Luchando contra el comunismo o en contra del fascismo, había españoles en casi todos los ejércitos:

En el Ejército alemán:
Los voluntarios españoles fueron encuadrados en la 250 Infanterie-Division, más conocida como la División Azul integrada en la Wehrmacht, lucharon como voluntarios contra la Unión Soviética en el frente oriental, operando únicamente al norte de la Unión Soviética en el frente de Leningrado hasta 1943.
En 1943, Franco ordenó la repatriación de los voluntarios que formaban la División Azul. Sin embargo, algunos de ellos rechazaron volver y fueron reagrupados en otras unidades alemanas. También hubo voluntarios españoles en otras unidades alemanas, principalmente en las Waffen-SS, y otros voluntarios que atravesaron la frontera española furtivamente por Lourdes (Francia). Las nuevas unidades fueron llamadas colectivamente la Legión Azul. Estos lucharon en Letonia, en Yugoslavia contra los partisanos de Tito, en Francia contra la resistencia.
En el Ejército Rojo de la Unión Soviética:
La Unión Soviética recibió a muchos ex líderes españoles comunistas y niños evacuados de familias republicanas. Cuando Alemania invadió la Unión Soviética en 1941, muchos, como el general comunista Enrique Líster o Rubén Ruiz Ibárruri el hijo de la Pasionaria que murió en combate en la batalla de Stalingrado, se unieron al Ejército Rojo. Fueron, al menos, 700 españoles los que se alistaron voluntarios en el Ejército Rojo para combatir a los nazis y otros 700 actuaron como partisanos detrás de las líneas alemanas.[92]​ Cerca de 300 voluntarios españoles perdieron la vida o desaparecieron en combate.[93]​
En el Ejército francés y la resistencia:
El otro país que más exiliados españoles recibió fue Francia, debido a que cientos de miles de republicanos españoles huyeron al otro lado de la frontera tras la derrota en la Guerra Civil. Cuando estalló la guerra, muchos antiguos combatientes republicanos españoles se presentaron voluntarios en el Ejército regular francés. Tras la derrota francesa de 1940 y cuando Francia estaba ocupada por las fuerzas del Eje, algunos se incorporaron a la resistencia.
Algunos de los primeros tanques que entraron en París, tras su liberación en 1944, pertenecían a la 9.ª Compañía; conocida popularmente como La Nueve; de la 2.ª División Blindada, del Regimiento de Marcha del Chad, de la División Leclerc. Esta División estaba encuadrada en el III Ejército estadounidense, liderado por el general George Patton.
Ejército británico:
El Ejército británico, como no aceptaba extranjeros, creó una compañía española llamada: Spanish Company Number One, que incluso luchó en la batalla de Normandía (aunque no desembarcó el día D).


== Genocidio ==

La guerra y la dominación del continente europeo permitieron al régimen nazi de llevar al extremo su ideología racista. Según las palabras de Goebbels: La guerra nos ofrece toda clase de posibilidades que la paz nos rechazaba.[94]​
Dentro de esas posibilidades mencionadas aparece un plan de destrucción étnica teniendo como objetivo los pueblos de la Europa del este. El mismo día de la entrada en guerra, septiembre de 1939, Hitler autoriza la exterminación de discapacitados mentales y otras personas en situación de enfermedad, la Aktion T4 conduce a la muerte por gas de más de 150 000 discapacitados.
A partir de 1939, los judíos son concentrados a la fuerza en guetos miserables, deliberadamente superpoblados y gestionados con falta de comida. Durante su exterminación sistemática, que se designa con el nombre de Shoah, es antes de todo puesta en marcha por la Wehrmacht y por los Einsatzgruppen en territorios polacos y soviéticos. En la URSS y en una parte de Polonia, la «Shoah por balas» da paso en 1942 al empleo metódico de «camiones de gas».


== Consecuencias históricas ==

Además de los horrores propios de toda guerra, la Segunda Guerra Mundial introdujo formas de sufrimiento no achacables a la propia escala de la misma:

Deportaciones masivas a campos de concentración y de trabajo forzado, organizados en Europa por Alemania (contra judíos, homosexuales, eslavos, discapacitados, gitanos, Testigos de Jehová, comunistas, españoles republicanos, sacerdotes católicos y ministros de otras religiones, etc.), que se convertirían en campos de exterminio donde tendría lugar el Holocausto; también en Estados Unidos y otros países de América, internando a sus ciudadanos de ascendencia japonesa.
Masacres masivas de población y de prisioneros enemigos perpetrada por las fuerzas japonesas, principalmente en China, y las alemanas, en Rusia. Tras la guerra, malos tratos a prisioneros de guerra, sobre todo por parte de la Unión Soviética.
Violaciones masivas de mujeres por parte de tropas soviéticas y japonesas.
Experimentos científicos usando prisioneros realizados por médicos nazis y japoneses, que solían acabar con la muerte del individuo.
Bombardeo aéreo masivo de civiles y lanzamiento de cohetes V-1 y V-2 iniciado por el Eje en Varsovia, Londres, Coventry y otras ciudades, que fue continuado por los aliados a una escala mucho mayor (Tokio, Berlín, Dresde y Hamburgo entre otras). Además, por primera y única vez, la bomba atómica fue utilizada en una guerra: dos bombas arrojadas por Estados Unidos explotaron con tres días de intervalo, en Hiroshima y Nagasaki.
Durísimos años de postguerra para la población civil.
Como consecuencia de los cambios territoriales, millones de personas se vieron desplazadas y desarraigadas de sus lugares de origen.
En el ámbito intelectual y artístico, queda de forma oprimente y, a veces, obsesiva, la pregunta de cómo fue posible la guerra y cómo fueron posibles las circunstancias históricas que llevaron a ella. En muchos casos esta cuestión se ve agravada por el saber de que intelectuales y artistas colaboraron con los totalitarismos y el clima bélico o, al menos, no se opusieron decididamente a ello.
Guerra después de la guerra: Combates en Indochina entre franceses y movimientos separatistas creados tras el vacío de poder que ocasionó la guerra, guerra civil en Grecia y Turquía, etc.
La Segunda Guerra Mundial contribuyó a que emergieran dos superpotencias que buscaban repartirse el mundo: Estados Unidos y la URSS. La Sociedad de Naciones, a la que se responsabilizó de contribuir a desatar la guerra, fue reemplazada por la ONU. La carta de las Naciones Unidas se firmó en San Francisco el 26 de junio de 1945.
En los Juicios de Núremberg y Tokio, parte de la jerarquía nazi y del Tenno nipón fue juzgada y condenada por crímenes contra la humanidad. La investigación científica y técnica, en su conjunto, se benefició de un fuerte impulso en particular: el dominio del átomo tras el Proyecto Manhattan. También contribuyó a la creación del helicóptero, los aviones de reacción y la creación del ICBM.
Los soviéticos, que se aliaron con EE. UU. y los aliados solo por conveniencia contra el enemigo común, Alemania, se convirtieron en enemigos por sus ideales contrarios, y así comenzó una era de guerra fría a nivel mundial, concentrándose en Europa.
En Alemania tras la firma del armisticio por parte del Eje, el Plan Marshall contribuyó a la reconstrucción de Alemania. Si bien los alemanes perdieron la guerra, sus adelantos en tecnología punta en cadenas de industrias, fabricación de componentes para cohetes, misiles y diversos tipos de armas ayudaron a los Aliados del Oeste y sirvieron para el llamado «milagro alemán».
Sin embargo se presentó la expulsión de alemanes en Europa central (Prusia, Checoslovaquia, Polonia y países bálticos) donde había asentamientos alemanes desde varios siglos atrás. Los alemanes de los Sudetes, que pedían su incorporación a Alemania, habían desencadenado el desmantelamiento de Checoslovaquia, acordado en los Acuerdos de Múnich de 1938.
Tras la toma de esos territorios por el ejército soviético, numerosos alemanes fueron expulsados o dejaron su tierra para ir a Alemania o Austria, en condiciones generalmente dramáticas.
Los Estados Unidos tomaron la iniciativa de una actitud «positiva». Impusieron la democracia (particularmente al Japón), a través de una depuración y de un control del Estado y la educación.
Las pérdidas de vidas humanas para Estados Unidos fueron, en comparación con el resto de los Aliados, muy inferiores en número porque en su territorio no se desarrolló la guerra y las pérdidas solo fueron militares.
En este contexto, la actitud francesa, país liberado tras la batalla de Normandía, según la historiografía francesa, estuvo marcada por la afirmación original de una voluntad de independencia, sobre todo debido a la personalidad de Charles de Gaulle, quien hizo jugar a Francia un papel en la ocupación de Alemania al lado de los vencedores y, por otra parte, desarrolló la investigación nuclear para afirmar su independencia de Estados Unidos. La liberación se acompaña de una depuración de personas sospechosas de ser colaboradores (gran parte de ellos ejecutados sin juicio previo) y la destrucción de ciudades como El Havre. Se forma un gobierno de unión, entre comunistas y gaullistas de una parte y representantes de la resistencia y radicales, de centro-izquierda.
Los otros aliados, si se exceptúa el Reino Unido, jugaron un rol menor o fueron descartados de las negociaciones referentes a la puesta en práctica de las dos zonas de influencia que siguieron a los acuerdos de Yalta y de Potsdam. Esta situación, que porta en sí misma los gérmenes de la Guerra Fría, llegaría a durar hasta 1991.
El Reino Unido salió considerablemente debilitado de la guerra que consagró el fin de su poderío colonial. Por consiguiente, las islas británicas conocieron una crisis sin precedentes que requirió la reconstrucción y reestructuración de su economía.
Se estima que alrededor de seis millones de judíos, junto con otros grupos étnicos, fueron asesinados por los nazis, principalmente mediante la deportación a campos de concentración, algunos tan conocidos como Auschwitz, Treblinka y Majdanek. La expresión hebrea Shoah (catástrofe) —también conocida como «Holocausto»— designa la exterminación en masa de los judíos perpetrada durante esta sangrienta guerra.
Al final del conflicto la Organización de las Naciones Unidas (ONU) reemplazó a la Sociedad de Naciones (SDN), fundada en 1919, y se otorgó a sí misma la misión de resolver los conflictos, en general bélicos, de carácter internacional.


=== Consecuencias territoriales en el mundo ===

La Unión Soviética se anexionó Estonia, Letonia, Lituania, el este de Polonia y partes de Finlandia y Rumanía. Polonia recibió territorios de Alemania (Pomerania, Silesia y la mitad de Prusia Oriental). Austria recuperó su independencia en 1955.
Alemania quedó dividida en cuatro zonas de influencia: Estados Unidos, Francia y Reino Unido unificaron sus respectivas zonas en la República Federal Alemana y la URSS hizo lo mismo con su zona que se convirtió en la República Democrática Alemana, hasta 1990, cuando los Länder que la conformaban se incorporaron a la República Federal de Alemania, dando lugar a la reunificación alemana y a la creación de la actual Alemania.
La guerra dejó al descubierto la debilidad de los países europeos y los movimientos de independencia de las colonias se generalizaron con el apoyo de las dos superpotencias. Los ejércitos de las potencias coloniales no tenían ya capacidad para controlar dichos movimientos, por lo que a lo largo de la segunda mitad del siglo XX se produjo la llamada descolonización.
El mundo quedó dividido en dos bloques:

El bloque capitalista: Liderado por los Estados Unidos y con influencia en Europa Occidental.
El bloque comunista: Liderado por la URSS y con influencia en Europa del Este.


== Véase también ==


== Notas ==


== Referencias ==


== Bibliografía ==
Churchill, Winston S. La Segunda Guerra Mundial. Barcelona: Planeta, 2004.
Artola, Ricardo. La II Guerra Mundial. De Varsovia a Berlín. Madrid: Alianza, 1995.
Dear, I.C.B. The Oxford Companion to World War II. Oxford: Oxford University Press, 1995.
La guerra que había que ganar. Williamson Murray & Allan R. Millett. Crítica, 2002.
Leguineche, Manuel. Los años de la infamia. Crónica de la II Guerra Mundial. Temas de Hoy, 1999.
Michel, Henri. La Segunda Guerra Mundial. Akal.
World War II. H.P. Willmott, Robin Cross & Charles Messenger, Dorling Kindersly, 2005.
Historia de la Segunda Guerra Mundial. Basil H. Liddell Hart, Caralt, 2001.
Enciclopedia del arte de la guerra. Antonio Martínez Teixidó & José Romero & José Luis Calvo. Barcelona: Planeta, 2001.
The Great Crusade. A New Complete History of the Second World War. H.P. Willmott, Plimlico, 1992.
Un mundo en armas. La Segunda Guerra Mundial: una visión de conjunto. Gerhard L. Weinberg, Grijalbo, 1995.
The Times Atlas of the Second World War. John Keegan, Times Books, 1989.
Hillgruber, Andreas. La Segunda Guerra Mundial. Objetivos de guerra y estrategia de las grandes potencias. Alianza, 1995.
Geheime Kommandosache. Recopilatorio de hechos de la Segunda Guerra Mundial (en alemán), 1952
Jordan, David y Andrew Wiest. Atlas de la II Guerra Mundial. Libsa, 2005.
La Segunda Guerra Mundial Raymond Cartier. Planeta, 1968.
Beevor, Antony (1998). Stalingrad. Nueva York: Viking Press. ISBN 978-0-670-87095-0. 
——— (2012). The Second World War. Londres: Weidenfeld & Nicolson. ISBN 978-0-297-84497-6. 
Ben-Horin, Eliahu (1943). The Middle East: Crossroads of History. New York: W.W. Norton. 
Canfora, Luciano (2006) [2004]. Democracy in Europe: A History. Oxford & Malden MA: Blackwell Publishing. ISBN 978-1-4051-1131-7. 
Förster, Stig; Gessler, Myriam (2005). «The Ultimate Horror: Reflections on Total War and Genocide». In Roger Chickering, Stig Förster and Bernd Greiner, eds., A World at Total War: Global Conflict and the Politics of Destruction, 1937–1945 (pp. 53–68). Cambridge: Cambridge University Press. ISBN 978-0-521-83432-2. 
Masaya, Shiraishi (1990). Japanese Relations with Vietnam, 1951–1987. Ithaca, NY: SEAP Publications. ISBN 978-0-87727-122-2. 
Prins, Gwyn (2002). The Heart of War: On Power, Conflict and Obligation in the Twenty-First Century. London & New York: Routledge. ISBN 978-0-415-36960-2. 
Taylor, A.J.P. (1961). The Origins of the Second World War. London: Hamish Hamilton. 
——— (1979). How Wars Begin. London: Hamish Hamilton. ISBN 978-0-241-10017-2. 
Weinberg, Gerhard L. (2005). A World at Arms: A Global History of World War II (2nd edición). Cambridge: Cambridge University Press. ISBN 978-0-521-85316-3. 
Aspectos concretos del conflicto
Beevor, Antony. Stalingrado, Berlín. La caída: 1945 y la batalla de Creta. Crítica, 2002.
Beevor, Antony. Berlín, La caída: 1945. Planeta, 2005.
Beevor, Antony. El día D. La batalla de Normadía. Editorial Crítica, 2009.
Auschwitz, Los nazis y la «solución final», Laurence Rees, Planeta, 2005
Varsovia, 1944. La heroica lucha de una ciudad atrapada entre la Wehrmacht y el Ejército Rojo. Norman Davies. Planeta, 2005.
La batalla del Atlántico. Andrew Williams. Crítica, 2004.
Hitler, una biografía, Joachim Fest. Planeta, 2005.
El Alamein, Jon Latimer. Planeta, 2005.
Dresde. El bombardeo más controvertido de la Segunda Guerra Mundial. Frederick Taylor. Temas de Hoy, 2005.
Historia secreta de las SS, Robin Lumsden. Planeta, 2005.
Los secretos del día D, la historia desconocida del desembarco de Normandía, Larry Collins. Planeta, 2005.
Un ejército al amanecer. La guerra en el norte de África, 1942-43. Rick Atkinson. Crítica, 2004.
Las conversaciones privadas de Hitler. Planeta, 2005.
When Titans Clashed. How the Red Army Stopped Hitler. David M. Glantz & Jonathan House, University Press of Kansas, 1995.
Recordad Pearl Harbor. Manuel Leguineche. Temas de Hoy, 2001.
Hirohito and the Making of Modern Japan. Herbert P. Bix, HarperCollins Publishers, 2000.
T-34/76 Medium Tank 1941-1945. Steven Zaloga, Petter Sarson Osprey Military 1998.
El Carro Medio T-34/85. Steven Zaloga, Jim Kinnear, Peter Sarson, Osprey Military 1999.
El Carro Medio Panzer III. Bryan Perrett, Mike Badrocke, Osprey Military 1999.
Victorias frustradas. Erich Von Manstein. Altaya 2008.


== Enlaces externos ==
 Wikimedia Commons alberga una galería multimedia sobre Segunda Guerra Mundial.
Relaciones de los Estados Miembros de Naciones Unidas con España (en inglés)
La Edad Media o el Medievo[1]​ es el período histórico de la civilización occidental comprendido entre los siglos v y xv. Convencionalmente, su inicio se sitúa en el año 476 con la caída del Imperio romano de Occidente y su fin en 1492 con el descubrimiento de América,[2]​ o en 1453 con la caída de Constantinopla, fecha que tiene la singularidad de coincidir con la invención de la imprenta —publicación de la Biblia de Gutenberg— y con el fin de la guerra de los Cien Años. Con esto dicho, considerando la caída del Imperio romano de Occidente hasta el descubrimiento de América, la Edad Media abarcó un periodo de 1016 años.
Al día de hoy, los historiadores del período prefieren matizar esta ruptura entre Edad Antigua y Edad Media de manera que entre los siglos iii y viii se suele hablar de Antigüedad Tardía, que habría sido una gran etapa de transición en todos los ámbitos: en lo económico, para la sustitución del modo de producción esclavista por el modo de producción feudal; en lo social, para la desaparición del concepto de ciudadanía romana y la definición de los estamentos medievales, en lo político para la descomposición de las estructuras centralizadas del Imperio romano que dio paso a una dispersión del poder; y en lo ideológico y cultural para la absorción y sustitución de la cultura clásica por las teocéntricas culturas cristiana o islámica (cada una en su espacio).[3]​
Suele dividirse en dos grandes períodos: Temprana o Alta Edad Media (ss. v-x, sin una clara diferenciación con la Antigüedad Tardía); y Baja Edad Media (ss. xi-xv), que a su vez puede dividirse en un periodo de plenitud, la Plena Edad Media (ss. xi-xiii), y los dos últimos siglos que presenciaron la crisis del siglo xiv.
Aunque hay algunos ejemplos de utilización previa,[Nota 1]​ el concepto de Edad Media nació como la segunda edad de la división tradicional del tiempo histórico debida a Cristóbal Cellarius (Historia Medii Aevi a temporibus Constantini Magni ad Constaninopolim a Turcis captam deducta, Jena, 1688)[4]​ quien la consideraba un tiempo intermedio, sin apenas valor por sí mismo, entre la Edad Antigua identificada con el arte y la cultura de la civilización grecorromana de la Antigüedad clásica y la renovación cultural de la Edad Moderna —en la que él se sitúa— que comienza con el Renacimiento y el Humanismo. La popularización de este esquema ha perpetuado un preconcepto erróneo: el de considerar a la Edad Media como una época oscura, sumida en el retroceso intelectual y cultural, y un aletargamiento social y económico secular (que a su vez se asocia con el feudalismo en sus rasgos más oscurantistas, tal como se definió por los revolucionarios que combatieron el Antiguo Régimen). Sería un periodo dominado por el aislamiento, la ignorancia, la teocracia, la superstición y el miedo milenarista alimentado por la inseguridad endémica, la violencia y la brutalidad de guerras e invasiones constantes y epidemias apocalípticas.[Nota 2]​
Sin embargo, en este largo período de mil años hubo todo tipo de hechos y procesos muy diferentes entre sí, diferenciados temporal y geográficamente, respondiendo tanto a influencias mutuas con otras civilizaciones y espacios como a dinámicas internas. Muchos de ellos tuvieron una gran proyección hacia el futuro, entre otros los que sentaron las bases del desarrollo de la posterior expansión europea, y el desarrollo de los agentes sociales que desarrollaron una sociedad estamental de base predominantemente rural pero que presenció el nacimiento de una incipiente vida urbana y una burguesía que con el tiempo desarrollarán el capitalismo.[5]​ Lejos de ser una época inmovilista, la Edad Media, que había comenzado con migraciones de pueblos enteros, y continuado con grandes procesos repobladores (Repoblación en la península ibérica, Ostsiedlung en Europa Oriental) vio cómo en sus últimos siglos los antiguos caminos (muchos de ellos vías romanas decaídas) se reparaban y modernizaban con airosos puentes, y se llenaban de toda clase de viajeros (guerreros, peregrinos, mercaderes, estudiantes, goliardos, etc.) encarnando la metáfora espiritual de la vida como un viaje (homo viator).[6]​
También surgieron en la Edad Media formas políticas nuevas, que van desde el califato islámico a los poderes universales de la cristiandad latina (Pontificado e Imperio) o el Imperio bizantino y los reinos eslavos integrados en la cristiandad oriental (aculturación y evangelización de Cirilo y Metodio); y en menor escala, todo tipo de ciudades estado, desde las pequeñas ciudades episcopales alemanas hasta repúblicas que mantuvieron imperios marítimos como Venecia; dejando en la mitad de la escala a la que tuvo mayor proyección futura: las monarquías feudales, que transformadas en monarquías autoritarias prefiguran el estado moderno.
De hecho, todos los conceptos asociados a lo que se ha venido en llamar modernidad aparecen en la Edad Media, en sus aspectos intelectuales con la misma crisis de la escolástica.[7]​ Ninguno de ellos sería entendible sin el propio feudalismo, se entienda este como modo de producción (basado en las relaciones sociales de producción en torno a la tierra del feudo) o como sistema político (basado en las relaciones personales de poder en torno a la institución del vasallaje), según las distintas interpretaciones historiográficas.[Nota 3]​
El choque de civilizaciones entre cristianismo e islamismo, manifestado en la ruptura de la unidad del Mediterráneo (hito fundamental de la época, según Henri Pirenne, en su clásico Mahoma y Carlomagno[8]​), la Reconquista española y las Cruzadas; tuvo también su parte de fértil intercambio cultural (escuela de Traductores de Toledo, Escuela Médica Salernitana) que amplió los horizontes intelectuales de Europa, hasta entonces limitada a los restos de la cultura clásica salvados por el monacato altomedieval y adaptados al cristianismo.

 

Esa misma Europa Occidental produjo una impresionante sucesión de estilos artísticos (prerrománico, románico y gótico), que en las zonas fronterizas se mestizaron también con el arte islámico (mudéjar, arte andalusí, arte árabe-normando) o con el arte bizantino.

La ciencia medieval no respondía a una metodología moderna, pero tampoco lo había hecho la de los autores clásicos, que se ocuparon de la naturaleza desde su propia perspectiva; y en ambas edades sin conexión con el mundo de las técnicas, que estaba relegado al trabajo manual de artesanos y campesinos, responsables de un lento pero constante progreso en las herramientas y procesos productivos. La diferenciación entre oficios viles y mecánicos y profesiones liberales vinculadas al estudio intelectual convivió con una teórica puesta en valor espiritual del trabajo en el entorno de los monasterios benedictinos, cuestión que no pasó de ser un ejercicio piadoso, sobrepasado por la mucho más trascendente valoración de la pobreza, determinada por la estructura económica y social y que se expresó en el pensamiento económico medieval.

Medievalismo es tanto la cualidad o carácter de medieval,[10]​ como el interés por la época y los temas medievales y su estudio; y medievalista el especialista en estas materias.[Nota 4]​ El descrédito de la Edad Media fue una constante durante la Edad Moderna, en la que Humanismo, Renacimiento, Racionalismo, Clasicismo e Ilustración se afirman como reacciones contra ella, o más bien contra lo que entienden que significaba, o contra los rasgos de su propio presente que intentan descalificar como pervivencias medievales. No obstante desde fines del siglo XVI se producen interesantes recopilaciones de fuentes documentales medievales que buscan un método crítico para la ciencia histórica. El Romanticismo y el Nacionalismo del siglo XIX revalorizaron la Edad Media como parte de su programa estético y como reacción antiacadémica (poesía y drama románticos, novela histórica, nacionalismo musical, ópera), además de como única posibilidad de encontrar base histórica a las emergentes naciones (pintura de historia, arquitectura historicista, sobre todo el neogótico —labor restauradora y recreadora de Eugène Viollet-le-Duc— y el neomudéjar). Los abusos románticos de la ambientación medieval (exotismo), produjeron ya a mediados del siglo XIX la reacción del realismo.[12]​ Otro tipo de abusos son los que dan lugar a una abundante literatura pseudohistórica que llega hasta el presente, y que ha encontrado la fórmula del éxito mediático entremezclando temas esotéricos sacados de partes más o menos oscuras de la Edad Media (Archivo Secreto Vaticano, templarios, rosacruces, masones y el mismísimo Santo Grial).[Nota 5]​ Algunos de ellos se vincularon al nazismo, como el alemán Otto Rahn. Por otro lado, hay abundancia de otros tipos de producciones artísticas de ficción de diversa calidad y orientación inspiradas en la Edad Media (literatura, cine, cómic). También se han desarrollado en el siglo XX otros movimientos medievalistas: un medievalismo historiográfico serio, centrado en la renovación metodológica (fundamentalmente por la incorporación de la perspectiva económica y social aportada por el materialismo histórico y la Escuela de los Annales) y un medievalismo popular (espectáculos medievales, más o menos genuinos, como actualización del pasado en el que la comunidad se identifica, lo que se ha venido en llamar memoria histórica).


== Es impropio hablar de Edad Media en otras civilizaciones ==

Las grandes migraciones de la época de las invasiones significaron paradójicamente un cierre al contacto de Occidente con el resto del mundo. Muy pocas noticias tenían los europeos del milenio medieval (tanto los de la cristiandad latina como los de la cristiandad oriental) de que, aparte de la civilización islámica, que ejerció de puente pero también de obstáculo entre Europa y el resto del Viejo Mundo,[8]​ se desarrollaban otras civilizaciones. Incluso un vasto reino cristiano como el de Etiopía, al quedar aislado, se convirtió en el imaginario cultural en el mítico reino del Preste Juan, apenas distinguible de las islas atlánticas de San Brandán y del resto de las maravillas dibujadas en los bestiarios y los escasos, rudimentarios e imaginativos mapas. El desarrollo marcadamente autónomo de China, la más desarrollada civilización de la época (aunque volcada hacia su propio interior y ensimismada en sus ciclos dinásticos: Sui, Tang, Song, Yuan y Ming), y la escasez de contactos con ella (el viaje de Marco Polo, o la mucho más importante expedición de Zheng He), que destacan justamente por lo inusuales y por su ausencia de continuidad, no permiten denominar a los siglos V al XV de su historia como historia medieval, aunque a veces se haga, incluso en publicaciones especializadas, más o menos impropiamente.[13]​
La historia de Japón (que durante este periodo estaba en formación como civilización, adaptando las influencias chinas a la cultura autóctona y expandiéndose desde las islas meridionales a las septentrionales), a pesar de su mayor lejanía y aislamiento, suele ser paradójicamente más asociada al término medieval; aunque tal denominación es acotada por la historiografía, significativamente, a un periodo medieval que se localiza entre los años 1000 y 1868, para adecuarse al denominado feudalismo japonés anterior a la era Meiji (véase también shogunato, han y castillo japonés).[14]​
La historia de la India o la del África negra a partir del siglo VII contaron con una mayor o menor influencia musulmana, pero se atuvieron a dinámicas propias bien diferentes (Sultanato de Delhi, Sultanato de Bahmani, Imperio Vijayanagara —en la India—, Imperio de Malí, Imperio Songhay —en África negra—). Incluso llegó a producirse una destacada intervención sahariana en el mundo mediterráneo occidental: el Imperio almorávide.
De un modo todavía más claro, la historia de América (que atravesaba sus periodos clásico y postclásico) no tuvo ningún tipo de contacto con el Viejo Mundo, más allá de la llegada de la denominada Colonización vikinga en América que se limitó a una reducida y efímera presencia en Groenlandia y la enigmática Vinland, o las posibles posteriores expediciones de balleneros vascos en parecidas zonas del Atlántico Norte, aunque este hecho ha de entenderse en el contexto del gran desarrollo de la navegación de los últimos siglos de la Baja Edad Media, ya encaminada a la Era de los Descubrimientos.
Lo que sí ocurrió, y puede considerarse como una constante del periodo medieval, fue la periódica repetición de puntuales interferencias centroasiáticas en Europa y el Próximo Oriente en forma de invasiones de pueblos del Asia Central, destacadamente los turcos (köktürks, jázaros, otomanos) y los mongoles (unificados por Gengis Kan) y cuya Horda de Oro estuvo presente en Europa Oriental y conformó la personalidad de los Estados cristianos que se crearon, a veces vasallos y a veces resistentes, en las estepas rusas y ucranianas. Incluso en una rara ocasión, la primitiva diplomacia de los reinos europeos bajomedievales vio la posibilidad de utilizar a los segundos como contrapeso a los primeros: la frustrada embajada de Ruy González de Clavijo a la corte de Tamerlán en Samarcanda, en el contexto del asedio mongol de Damasco, un momento muy delicado (1401-1406) en el que también intervino como diplomático Ibn Jaldún. Los mongoles ya habían saqueado Bagdad en una incursión de 1258.[15]​


== El inicio de la Edad Media ==

Aunque se han propuesto varias fechas para el inicio de la Edad Media, de las cuales la más extendida es la del año 476, lo cierto es que no podemos ubicar el inicio de una manera tan exacta ya que la Edad Media no nace, sino que "se hace" a consecuencia de todo un largo y lento proceso que se extiende por espacio de cinco siglos y que provoca cambios enormes a todos los niveles de una forma muy profunda que incluso repercutirán hasta nuestros días. Podemos considerar que ese proceso empieza con la crisis del siglo III, vinculada a los problemas de reproducción inherentes al modo de producción esclavista, que necesitaba una expansión imperial continua que ya no se producía tras la fijación del limes romano. Posiblemente también confluyeran factores climáticos para la sucesión de malas cosechas y epidemias; y de un modo mucho más evidente las primeras invasiones germánicas y sublevaciones campesinas (bagaudas), en un periodo en que se suceden muchos breves y trágicos mandatos imperiales. Desde Caracalla la ciudadanía romana estaba extendida a todos los hombres libres del Imperio, muestra de que tal condición, antes tan codiciada, había dejado de ser atractiva. El Bajo Imperio adquiere un aspecto cada vez más medieval desde principios del siglo IV con las reformas de Diocleciano: difuminación de las diferencias entre los esclavos, cada vez más escasos, y los colonos, campesinos libres, pero sujetos a condiciones cada vez mayores de servidumbre, que pierden la libertad de cambiar de domicilio, teniendo que trabajar siempre la misma tierra; herencia obligatoria de cargos públicos —antes disputados en reñidas elecciones— y oficios artesanales, sometidos a colegiación —precedente de los gremios—, todo para evitar la evasión fiscal y la despoblación de las ciudades, cuyo papel de centro de consumo y de comercio y de articulación de las zonas rurales cada vez es menos importante. Al menos, las reformas consiguen mantener el edificio institucional romano, aunque no sin intensificar la ruralización y aristocratización (pasos claros hacia el feudalismo), sobre todo en Occidente, que queda desvinculado de Oriente con la partición del Imperio. Otro cambio decisivo fue la implantación del cristianismo como nueva religión oficial por el Edicto de Tesalónica de Teodosio I el Grande (380) precedido por el Edicto de Milán (313) con el que Constantino I el Grande recompensó a los hasta entonces subversivos por su providencialista ayuda en la batalla del Puente Milvio (312), junto con otras presuntas cesiones más temporales cuya fraudulenta reclamación (pseudodonación de Constantino) fue una constante de los Estados Pontificios durante toda la Edad Media, incluso tras la evidencia de su refutación por el humanista Lorenzo Valla (1440).

Ningún evento concreto —a pesar de la abundancia y concatenación de hechos catastróficos— determinó por sí mismo el fin de la Edad Antigua y el inicio de la Edad Media: ni los sucesivos saqueos de Roma (por los godos de Alarico I en el 410, por los vándalos en el 455, por las propias tropas imperiales de Ricimero en 472, por los ostrogodos en 546), ni la pavorosa irrupción de los hunos de Atila (450-452, con la batalla de los Campos Cataláunicos y la extraña entrevista con el papa León I el Magno), ni el derrocamiento de Rómulo Augústulo (último emperador romano de Occidente, por Odoacro el jefe de los hérulos -476-); fueron sucesos que sus contemporáneos consideraran iniciadores de una nueva época. La culminación a finales del siglo V de una serie de procesos de larga duración, entre ellos la grave dislocación económica, las invasiones y el asentamiento de los pueblos germanos en el Imperio romano, hizo cambiar la faz de Europa. Durante los siguientes 300 años, la Europa Occidental mantuvo un período de unidad cultural, inusual para este continente, instalada sobre la compleja y elaborada cultura del Imperio romano, que nunca llegó a perderse por completo, y el asentamiento del cristianismo. Nunca llegó a olvidarse la herencia clásica grecorromana, y la lengua latina, sometida a transformación (latín medieval), continuó siendo la lengua de cultura en toda Europa occidental, incluso más allá de la Edad Media. El derecho romano y múltiples instituciones continuaron vivas, adaptándose de uno u otro modo. Lo que se operó durante ese amplio periodo de transición (que puede darse por culminado para el año 800, con la coronación de Carlomagno) fue una suerte de fusión con las aportaciones de otras civilizaciones y formaciones sociales, en especial la germánica y la religión cristiana. En los siglos siguientes, aún en la Alta Edad Media, serán otras aportaciones las que se añadan, destacadamente el islam.


== Alta Edad Media (siglos V al X) ==


=== Los reinos germanorromanos (siglos V al VIII) ===


==== Bárbaros ====

 

El texto se refiere concretamente a Hispania y sus provincias, y los bárbaros citados son específicamente los suevos, vándalos y alanos, que en el 406 habían cruzado el limes del Rin (inhabitualmente helado) a la altura de Maguncia y en torno al 409 habían llegado a la península ibérica; pero la imagen es equivalente en otros momentos y lugares que el mismo autor narra, del periodo entre 379 y 468.
Los pueblos germánicos procedentes de la Europa del Norte y del Este, se encontraban en un estadio de desarrollo económico, social y cultural obviamente inferior al del Imperio romano, al que ellos mismos percibían admirativamente. A su vez eran percibidos con una mezcla de desprecio, temor y esperanza (retrospectivamente plasmados en el influyente poema Esperando a los bárbaros de Constantino Cavafis),[17]​ e incluso se les atribuyó un papel justiciero (aunque involuntario) desde un punto de vista providencialista por parte de los autores cristianos romanos (Orosio, Salviano de Marsella y San Agustín de Hipona).[18]​ La denominación de bárbaros (βάρβαρος) proviene de la onomatopeya bar-bar con la que los griegos se burlaban de los extranjeros no helénicos, y que los romanos —bárbaros ellos mismos, aunque helenizados— utilizaron desde su propia perspectiva. La denominación «invasiones bárbaras» fue rechazada por los historiadores alemanes del siglo XIX, momento en el que el término barbarie designaba para las nacientes ciencias sociales un estadio de desarrollo cultural inferior a la civilización y superior al salvajismo. Prefirieron acuñar un nuevo término: Völkerwanderung ("Migración de Pueblos"),[19]​ menos violento que invasiones, al sugerir el desplazamiento completo de un pueblo con sus instituciones y cultura, y más general incluso que invasiones germánicas, al incluir a hunos, eslavos y otros.
Los germanos, que disponían de instituciones políticas peculiares, en concreto la asamblea de guerreros libres (thing) y la figura del rey, recibieron la influencia de las tradiciones institucionales del Imperio y la civilización grecorromana, así como la del cristianismo (aunque no siempre del cristianismo católico o atanasiano, sino del arriano); y se fueron adaptando a las circunstancias de su asentamiento en los nuevos territorios, sobre todo a la alternativa entre imponerse como minoría dirigente sobre una mayoría de población local o fusionarse con ella.
Los nuevos reinos germánicos conformaron la personalidad de Europa Occidental durante la Edad Media, evolucionaron en monarquías feudales y monarquías autoritarias, y con el tiempo, dieron origen a los estados-nación que se fueron construyendo en torno a ellas. Socialmente, en algunos de estos países (España o Francia), el origen germánico (godo o franco) pasó a ser un rasgo de honor u orgullo de casta ostentado por la nobleza como distinción sobre el conjunto de la población.


==== Las transformaciones del mundo romano ====

El Imperio romano había pasado por invasiones externas y guerras civiles terribles en el pasado, pero a finales del siglo IV aparentemente, la situación estaba bajo control. Hacía escaso tiempo que Teodosio había logrado nuevamente unificar bajo un solo centro ambas mitades del Imperio (392) y establecido una nueva religión de Estado, el cristianismo niceno (Edicto de Tesalónica -380), con la consiguiente persecución de los tradicionales cultos paganos y las heterodoxias cristianas. El clero cristiano, convertido en una jerarquía de poder, justificaba ideológicamente a un Imperium Romanum Christianum (Imperio Romano Cristiano) y a la dinastía Teodosiana como había comenzado a hacer ya con la Constantiniana desde el Edicto de Milán (313).
Se habían encauzado los afanes de protagonismo político de los más ricos e influyentes senadores romanos y de las provincias occidentales. Además, la dinastía había sabido encauzar acuerdos con la poderosa aristocracia militar, en la que se enrolaban nobles germanos que acudían al servicio del Imperio al frente de soldados unidos por lazos de fidelidad hacia ellos. Al morir en 395, Teodosio confió el gobierno de Occidente y la protección de su joven heredero Honorio al general Estilicón, primogénito de un noble oficial vándalo que había contraído matrimonio con Flavia Serena, sobrina del propio Teodosio. Pero cuando en el 455 murió asesinado Valentiniano III, nieto de Teodosio, una buena parte de los descendientes de aquellos nobles occidentales (nobilissimus, clarissimus) que tanto habían confiado en los destinos del Imperio parecieron ya desconfiar del mismo, sobre todo cuando en el curso de dos decenios se habían podido dar cuenta de que el gobierno imperial recluido en Rávena era cada vez más presa de los exclusivos intereses e intrigas de un pequeño grupo de altos oficiales del ejército itálico. Muchos de estos eran de origen germánico y cada vez confiaban más en las fuerzas de sus séquitos armados de soldados convencionales y en los pactos y alianzas familiares que pudieran tener con otros jefes germánicos instalados en suelo imperial junto con sus propios pueblos, que desarrollaban cada vez más una política autónoma. La necesidad de acomodarse a la nueva situación quedó evidenciada con el destino de Gala Placidia, princesa imperial rehén de los propios saqueadores de Roma (el visigodo Alarico I y su primo Ataúlfo, con quien finalmente se casó); o con el de Honoria, hija de la anterior (en segundas nupcias con el emperador Constancio III) que optó por ofrecerse como esposa al propio Atila enfrentándose a su propio hermano Valentiniano.

Necesitados de mantener una posición de predominio social y económico en sus regiones de origen, reducidos sus patrimonios fundiarios a dimensiones provinciales, y ambicionando un protagonismo político propio de su linaje y de su cultura, los honestiores (los más honestos u honrados, los que tienen honor), representantes de las aristocracias tardorromanas occidentales habrían acabado por aceptar las ventajas de admitir la legitimidad del gobierno de dichos reyes germánicos, ya muy romanizados, asentados en sus provincias. Al fin y al cabo, estos, al frente de sus soldados, podían ofrecerles bastante mayor seguridad que el ejército de los emperadores de Rávena. Además, el avituallamiento de dichas tropas resultaba bastante menos gravoso que el de las imperiales, por basarse en buena medida en séquitos armados dependientes de la nobleza germánica y alimentados con cargo al patrimonio fundiario provincial de la que esta ya hacía tiempo se había apropiado. Menos gravoso tanto para los aristócratas provinciales como también para los grupos de humiliores (los más humildes, los rebajados en tierra -humus-) que se agrupaban jerárquicamente en torno a dichos aristócratas, y que, en definitiva, eran los que habían venido soportando el máximo peso de la dura fiscalidad tardorromana. Las nuevas monarquías, más débiles y descentralizadas que el viejo poder imperial, estaban también más dispuestas a compartir el poder con las aristocracias provinciales, máxime cuando el poder de estos monarcas estaba muy limitado en el seno mismo de sus gentes por una nobleza basada en sus séquitos armados, desde su no muy lejano origen en las asambleas de guerreros libres, de los que no dejaban de ser primun inter pares.
Pero esta metamorfosis del Occidente romano en romano-germano, no había sido consecuencia de una inevitabilidad claramente evidenciada desde un principio; por el contrario, el camino había sido duro, zigzagueante, con ensayos de otras soluciones, y con momentos en que parecía que todo podía volver a ser como antes. Así ocurrió durante todo el siglo V, y en algunas regiones también en el siglo VI como consecuencia, entre otras cosas, de la llamada Recuperatio Imperii o Reconquista de Justiniano.


==== Los distintos reinos ====

Las invasiones bárbaras desde el siglo III habían demostrado la permeabilidad del limes romano en Europa, fijado en el Rin y el Danubio. La división del Imperio en Oriente y Occidente, y la mayor fortaleza del imperio oriental o bizantino, determinó que fuera únicamente en la mitad occidental donde se produjo el asentamiento de estos pueblos y su institucionalización política como reinos.
Fueron los visigodos, primero como Reino de Tolosa y luego como Reino de Toledo, los primeros en efectuar esa institucionalización, valiéndose de su condición de federados, con la obtención de un foedus con el Imperio, que les encargó la pacificación de las provincias de Galia e Hispania, cuyo control estaba perdido en la práctica tras las invasiones del 410 por suevos, vándalos y alanos. De los tres, solo los suevos lograron el asentamiento definitivo en una zona: el Reino de Braga, mientras que los vándalos se establecieron en el norte de África y las islas del Mediterráneo Occidental, pero fueron al siglo siguiente eliminados por los bizantinos durante la gran expansión territorial de Justiniano I (campañas de los generales Belisario, del 533 al 544, y Narsés, hasta el 554). Simultáneamente los ostrogodos consiguieron instalarse en Italia expulsando a los hérulos, que habían expulsado a su vez de Roma al último emperador de Occidente. El Reino Ostrogodo desapareció también frente a la presión bizantina de Justiniano I.
Un segundo grupo de pueblos germánicos se instala en Europa Occidental en el siglo VI, de entre los que destaca el Reino franco de Clodoveo I y sus sucesores merovingios, que desplaza a los visigodos de las Galias, forzándolos a trasladar su capital de Tolosa (Toulouse) a Toledo. También derrotaron a burgundios y alamanes, absorbiendo sus reinos. Algo más tarde los lombardos se establecen en Italia (568-9), pero serán derrotados a finales del siglo VIII por los mismos francos, que reinstaurarán el Imperio con Carlomagno (año 800).
En Gran Bretaña se instalarán los anglos, sajones y jutos, que crearán una serie de reinos rivales que serán unificados por los daneses (un pueblo nórdico) en lo que terminará por ser el reino de Inglaterra.


==== Las instituciones ====

La monarquía germánica era en origen una institución estrictamente temporal, vinculada estrechamente al prestigio personal del rey, que no pasaba de ser un primus inter pares (primero entre iguales), que la asamblea de guerreros libres elegía (monarquía electiva), normalmente para una expedición militar concreta o para una misión específica. Las migraciones a que se vieron sometidos los pueblos germánicos desde el siglo III hasta el siglo V (encajonados entre la presión de los hunos al este y la resistencia del limes romano al sur y oeste) fue fortaleciendo la figura del rey, al tiempo que se entraba en contacto cada vez mayor con las instituciones políticas romanas, que acostumbraban a la idea de un poder político mucho más centralizado y concentrado en la persona del Emperador romano. La monarquía se vinculó a las personas de los reyes de forma vitalicia, y la tendencia era a hacerse monarquía hereditaria, dado que los reyes (al igual que habían hecho los emperadores romanos) procuraban asegurarse la elección de su sucesor, la mayor parte de las veces aún en vida y asociándolos al trono. El que el candidato fuera el primogénito varón no era una necesidad, pero se terminó imponiendo como una consecuencia obvia, lo que también era imitado por las demás familias de guerreros, enriquecidos por la posesión de tierras y convertidos en linajes nobiliarios que se emparentaban con la antigua nobleza romana, en un proceso que puede denominarse feudalización. Con el tiempo, la monarquía se patrimonializó, permitiendo incluso la división del reino entre los hijos del rey.
El respeto a la figura del rey se reforzó mediante la sacralización de su toma de posesión (unción con los sagrados óleos por parte de las autoridades religiosas y uso de elementos distintivos como orbe, cetro y corona, en el transcurso de una elaborada ceremonia: la coronación) y la adición de funciones religiosas (presidencia de concilios nacionales, como los Concilios de Toledo) y taumatúrgicas (toque real de los reyes de Francia para la cura de la escrófula). El problema se suscitaba cuando llegaba el momento de justificar la deposición de un rey y su sustitución por otro que no fuera su sucesor natural. Los últimos merovingios no gobernaban por sí mismos, sino mediante los cargos de su corte, entre los que destacaba el mayordomo de palacio. Únicamente tras la victoria contra los invasores musulmanes en la batalla de Poitiers el mayordomo Carlos Martel se vio justificado para argumentar que la legitimidad de ejercicio le daba méritos suficientes para fundar él mismo su propia dinastía: la carolingia. En otras ocasiones se recurría a soluciones más imaginativas (como forzar la tonsura —corte eclesiástico del pelo— del rey visigodo Wamba para incapacitarle).
Los problemas de convivencia entre las minorías germanas y las mayorías locales (hispanorromanas, galo-romanas, etc.) fueron solucionados con más eficacia por los reinos con más proyección en el tiempo (visigodos y francos) a través de la fusión, permitiendo los matrimonios mixtos, unificando la legislación y realizando la conversión al catolicismo frente a la religión originaria, que en muchos casos ya no era el paganismo tradicional germánico, sino el cristianismo arriano adquirido en su paso por el Imperio Oriental.
Algunas características propias de las instituciones germanas se conservaron: una de ellas el predominio del derecho consuetudinario sobre el derecho escrito propio del Derecho romano. No obstante los reinos germánicos realizaron algunas codificaciones legislativas, con mayor o menor influencia del derecho romano o de las tradiciones germánicas, redactadas en latín a partir del siglo V (leyes teodoricianas, edicto de Teodorico, Código de Eurico, Breviario de Alarico). El primer código escrito en lengua germánica fue el del rey Ethelberto de Kent, el primero de los anglosajones en convertirse al cristianismo (comienzos del siglo VI). El visigótico Liber Iudicorum (Recesvinto, 654) y la franca Ley Sálica (Clodoveo, 507-511) mantuvieron una vigencia muy prolongada por su consideración como fuentes del derecho en las monarquías medievales y del Antiguo Régimen.[20]​


==== La cristiandad latina y los bárbaros ====

La expansión del cristianismo entre los bárbaros, el asentamiento de la autoridad episcopal en las ciudades y del monacato en los ámbitos rurales (sobre todo desde la regla de San Benito de Nursia —monasterio de Montecassino, 529—), constituyeron una poderosa fuerza fusionadora de culturas y ayudó a asegurar que muchos rasgos de la civilización clásica, como el derecho romano y el latín, pervivieran en la mitad occidental del Imperio, e incluso se expandiera por Europa Central y septentrional. Los francos se convirtieron al catolicismo durante el reinado de Clodoveo I (496 o 499) y, a partir de entonces, expandieron el cristianismo entre los germanos del otro lado del Rin. Los suevos, que se habían hecho cristianos arrianos con Remismundo (459-469), se convirtieron al catolicismo con Teodomiro (559-570) por las predicaciones de San Martín de Dumio. En ese proceso se habían adelantado a los propios visigodos, que habían sido cristianizados previamente en Oriente en la versión arriana (en el siglo IV), y mantuvieron durante siglo y medio la diferencia religiosa con los católicos hispanorromanos incluso con luchas internas dentro de la clase dominante goda, como demostró la rebelión y muerte de San Hermenegildo (581-585), hijo del rey Leovigildo). La conversión al catolicismo de Recaredo (589) marcó el comienzo de la fusión de ambas sociedades, y de la protección regia al clero católico, visualizada en los Concilios de Toledo (presididos por el propio rey). Los años siguientes vieron un verdadero renacimiento visigodo[21]​ con figuras de la influencia de san Isidoro de Sevilla (y sus hermanos Leandro, Fulgencio y Florentina, los cuatro santos de Cartagena), Braulio de Zaragoza o Ildefonso de Toledo, de gran repercusión en el resto de Europa y en los futuros reinos cristianos de la Reconquista (véase cristianismo en España, monasterio en España, monasterio hispano y liturgia hispánica). Los ostrogodos, en cambio, no dispusieron de tiempo suficiente para realizar la misma evolución en Italia. No obstante, del grado de convivencia con el papado y los intelectuales católicos fue muestra que los reyes ostrogodos los elevaban a los cargos de mayor confianza (Boecio y Casiodoro, ambos magister officiorum con Teodorico el Grande), aunque también de lo vulnerable de su situación (ejecutado el primero -523- y apartado por los bizantinos el segundo -538-). Sus sucesores en el dominio de Italia, los también arrianos lombardos, tampoco llegaron a experimentar la integración con la población católica sometida, y su divisiones internas hicieron que la conversión al catolicismo del rey Agilulfo (603) no llegara a tener mayores consecuencias.
El cristianismo fue llevado a Irlanda por San Patricio a principios del siglo V y desde allí se extendió a Escocia, desde donde un siglo más tarde regresó por la zona norte a una Inglaterra abandonada por los cristianos britones a los paganos pictos y escotos (procedentes del norte de Gran Bretaña) y a los también paganos germanos procedentes del continente (anglos, sajones y jutos). A finales del siglo VI, con el papa Gregorio Magno, también Roma envió misioneros a Inglaterra desde el sur, con lo que se consiguió que en el transcurso de un siglo Inglaterra volviera a ser cristiana.
A su vez, los britones habían iniciado una emigración por vía marítima hacia la península de Bretaña, llegando incluso hasta lugares tan lejanos como la costa cantábrica entre Galicia y Asturias, donde fundaron la diócesis de Britonia. Esta tradición cristiana se distinguía por el uso de la tonsura céltica o escocesa, que rapaba la parte frontal del pelo en vez de la coronilla.
La supervivencia en Irlanda de una comunidad cristiana aislada de Europa por la barrera pagana de los anglosajones, provocó una evolución diferente al cristianismo continental, lo que se ha denominado cristianismo celta. Conservaron mucho de la antigua tradición latina, que estuvieron en condiciones de compartir con Europa continental apenas la oleada invasora se hubo calmado temporalmente. Tras su extensión a Inglaterra en el siglo VI los irlandeses fundaron en el siglo VII monasterios en Francia, en Suiza (Saint Gall), e incluso en Italia, destacándose particularmente los nombres de Columba y Columbano. Las islas británicas fueron durante unos tres siglos el vivero de importantes nombres para la cultura: el historiador Beda el Venerable, el misionero Bonifacio de Alemania, el educador Alcuino de York, o el teólogo Juan Escoto Erígena, entre otros. Tal influencia llega hasta la atribución de leyendas como la de Santa Úrsula y las Once Mil Vírgenes, bretona que habría efectuado un extraordinario viaje entre Britania y Roma para acabar martirizada en Colonia.[22]​


===== Otras cristianizaciones medievales =====

Por su parte, la extensión del cristianismo entre los búlgaros y la mayor parte de los pueblos eslavos (serbios, moravos y los pueblos de Crimea y estepas ucranianas y rusas —Vladimiro I de Kiev, año 988—) fue muy posterior, y a cargo del Imperio bizantino, con lo que se hizo con el credo ortodoxo (predicaciones de Cirilo y Metodio, siglo IX); mientras que la evangelización de otros pueblos de Europa Oriental (el resto de los eslavos —polacos, eslovenos y croatas—, bálticos y húngaros —San Esteban I de Hungría, hacia el año 1000—) y de los pueblos nórdicos (vikingos escandinavos) se hizo por el cristianismo latino partiendo de Europa Central, en un periodo todavía más tardío (hasta los siglos XI y XII); permitiendo (especialmente la conversión de Hungría) las primeras peregrinaciones por vía terrestre a Tierra Santa.[23]​

 


===== Jázaros =====

Los jázaros eran un pueblo turco procedente del Asia central (donde se había formado desde el siglo VI el imperio de los Köktürks) que en su parte occidental había dado origen a un importante estado que dominaba el Cáucaso y las estepas rusas y ucranianas hasta Crimea en el siglo VII Su clase dirigente se convirtió mayoritariamente al judaísmo, peculiaridad religiosa que lo convertía en un vecino excepcional entre el califato islámico de Damasco y el imperio cristiano de Bizancio.


=== El Imperio bizantino (siglos IV al XV) ===

La división entre Oriente y Occidente fue, además de una estrategia política (inicialmente de Diocleciano —286— y hecha definitiva con Teodosio I —395—), un reconocimiento de la diferencia esencial entre ambas mitades del Imperio. Oriente, en sí mismo muy diverso (península balcánica, Mezzogiorno, Anatolia, Cáucaso, Siria, Palestina, Egipto y la frontera mesopotámica con los persas), era la parte más urbanizada y con economía más dinámica y comercial, frente a un Occidente en vías de feudalización, ruralizado, con una vida urbana en decadencia, mano de obra esclava cada vez más escasa y la aristocracia cada vez más ajena a las estructuras del poder imperial y recluida en sus lujosas villae autosuficientes, cultivadas por colonos en régimen similar a la servidumbre. La lengua franca en Oriente era el griego, frente al latín de Occidente. En la implantación de la jerarquía cristiana, Oriente disponía de todos los patriarcados de la Pentarquía menos el de Roma (Alejandría, Antioquía y Constantinopla, a los que se añadió Jerusalén tras el concilio de Calcedonia de 451); incluso la primacía romana (sede pontificia de San Pedro) era un hecho discutido porque el Estado bizantino se operaba según el cesaropapismo (empezado por Constantino I[25]​ y fundado teológicamente por Eusebio de Cesarea).[26]​

La supervivencia de Bizancio no dependía de la suerte de Occidente, mientras que lo contrario sí: de hecho, los emperadores orientales optaron por sacrificar Roma —que ya ni siquiera era la capital occidental— cuando lo consideraron conveniente, abandonándola a su suerte o incluso desplazando hacia ella a los germanos (hérulos, ostrogodos y lombardos), lo que precipitó su caída. Sin embargo, la Ciudad Eterna, que tenía un valor simbólico, fue reconquistada e incluida en el efímero Exarcado de Rávena.


==== La restauración imperial de Justiniano ====

Justiniano I consolidó la frontera del Danubio y, desde 532 logró un equilibrio en la frontera con la Persia sasánida, lo que le permitió desplazar los esfuerzos bizantinos hacia el Mediterráneo, reconstruyendo la unidad del Mare Nostrum: En 533, una expedición del general Belisario aniquila a los vándalos (batallas de Ad Decimum y de Tricamerón) incorporando la provincia de África y las islas del Mediterráneo Occidental (Cerdeña, Córcega y las Baleares). En 535 Mundus ocupó Dalmacia y Belisario Sicilia. Narsés elimina a los ostrogodos de Italia en 554-555. Rávena volvió a ser una ciudad imperial, donde se conservarán los fastuosos mosaicos de San Vital. Liberio solo consiguió desplazar a los visigodos de la costa sureste de la península ibérica y de la provincia Bética.
En Constantinopla se iniciaron dos programas ambiciosos y de prestigio con el fin de asentar la autoridad imperial: uno de recopilación legislativa: el Corpus iuris civilis, dirigido por Triboniano (promulgado entre 529 y 534), y otro constructivo: la iglesia de Santa Sofía, de los arquitectos Antemio de Tralles e Isidoro de Mileto (levantada entre el 532 y el 537). Un símbolo de la civilización clásica fue clausurado: la Academia de Atenas (529).[Nota 6]​ Otro, las carreras de cuadrigas siguieron siendo una diversión popular que levantaba pasiones. De hecho, eran utilizadas políticamente, expresando el color de cada equipo divergencias religiosas (un precoz ejemplo de movilizaciones populares utilizando colores políticos). La revuelta de Niká (534) estuvo a punto de provocar la huida del emperador, que evitó la emperatriz Teodora con su famosa frase la púrpura es un glorioso sudario.[Nota 7]​


==== Crisis, supervivencia y helenización del Imperio ====

Los siglos VII y VIII representaron para Bizancio una edad oscura similar a la de occidente, que incluyó también una fuerte ruralización y feudalización en lo social y económico y una pérdida de prestigio y control efectivo del poder central. A las causas internas se sumó la renovación de la guerra con los persas, nada decisiva pero especialmente extenuante, a la que siguió la invasión musulmana, que privó al Imperio de las provincias más ricas: Egipto y Siria. No obstante, en el caso bizantino, la disminución de la producción intelectual y artística respondía además a los efectos particulares de la querella iconoclasta, que no fue un simple debate teológico entre iconoclastas e iconódulos, sino un enfrentamiento interno desatado por el patriarcado de Constantinopla, apoyado por el emperador León III, que pretendía acabar con la concentración de poder e influencia política y religiosa de los poderosos monasterios y sus apoyos territoriales (puede imaginarse su importancia viendo cómo ha sobrevivido hasta la actualidad el Monte Athos, fundado más de un siglo después, en 963).

La recuperación de la autoridad imperial y la mayor estabilidad de los siglos siguientes trajo consigo también un proceso de helenización, es decir, de recuperación de la identidad griega frente a la oficial entidad romana de las instituciones, cosa más posible entonces, dada la limitación y homogeneización geográfica producida por la pérdida de las provincias, y que permitía una organización territorial militarizada y más fácilmente gestionable: los temas (themata) con la adscripción a la tierra de los militares en ellos establecidos, lo que produjo formas similares al feudalismo occidental.
El periodo entre 867 y 1056, bajo la dinastía macedonia, se conoce con el nombre de Renacimiento macedónico, en que Bizancio vuelve a ser una potencia mediterránea y se proyecta hacia los pueblos eslavos de los Balcanes y hacia el norte del mar Negro. Basilio II Bulgaróctono que ocupó el trono en el período 976-1025 llevó al Imperio a su máxima extensión territorial desde la invasión musulmana, ocupando parte de Siria, Crimea y los Balcanes hasta el Danubio. La evangelización de Cirilo y Metodio obtendrá una esfera de influencia bizantina en Europa Oriental que cultural y religiosamente tendrá una gran proyección futura mediante la difusión del alfabeto cirílico (adaptación del alfabeto griego para la representación de los fonemas eslavos, que se sigue utilizando en la actualidad); así como la del cristianismo ortodoxo (predominante desde Serbia hasta Rusia).
Sin embargo, la segunda mitad del siglo XI presenciará un nuevo desafío islámico, esta vez protagonizado por los turcos selyúcidas y la intervención del Papado y de los europeos occidentales, mediante la intervención militar de las Cruzadas, la actividad comercial de los mercaderes italianos (genoveses, amalfitanos, pisanos y sobre todo venecianos)[28]​ y las polémicas teológicas del denominado Cisma de Oriente o Gran Cisma de Oriente y Occidente, con lo que la teórica ayuda cristiana se demostró tan negativa o más para el Imperio Oriental que la amenaza musulmana. El proceso de feudalización se acentuó al verse forzados los emperadores Comneno a realizar cesiones territoriales (denominadas pronoia) a la aristocracia y a miembros su propia familia.[29]​


=== La expansión del islam (desde el siglo VII) ===

En el siglo VII, tras las predicaciones de Mahoma y las conquistas de los primeros califas (a la vez líderes políticos y religiosos, en una religión —el islamismo— que no reconoce distinciones entre laicos y clérigos), se había producido la unificación de Arabia y la conquista del Imperio persa y de buena parte del Imperio bizantino. En el siglo VIII se llegó a la península ibérica, la India y el Asia Central (batalla del Talas —751— victoria islámica ante China tras la que no se profundizó en ese Imperio, pero que permitió un mayor contacto con su civilización, aprovechando los conocimientos de los prisioneros). En el occidente la expansión musulmana se frenó desde la batalla de Poitiers (732) ante los francos y la mitificada batalla de Covadonga ante los asturianos (722). La presencia de los musulmanes como una civilización rival alternativa asentada en la mitad sur de la cuenca del Mediterráneo, cuyo tráfico marítimo pasan a controlar, obligó al cierre en sí misma de Europa Occidental por varios siglos, y para algunos historiadores significó el verdadero comienzo de la Edad Media.[30]​

Desde el siglo VIII se produjo una difusión más lenta de la civilización islámica por sitios tan lejanos como Indonesia y el continente africano, y desde el siglo XIV por Anatolia y los Balcanes. Las relaciones con la India fueron también muy estrechas durante el resto de la Edad Media (aunque la imposición del imperio mogol no se produjo hasta el siglo XVI), mientras que el océano Índico se convirtió casi en un Mare Nostrum árabe, donde se ambientaron las aventuras de Simbad el marino (uno de los cuentos de Las mil y una noches de la época de Harún al-Rashid).[31]​ El tráfico comercial de las rutas marítimas y caravaneras unían el Índico con el Mediterráneo a través del mar Rojo o el golfo Pérsico y las caravanas del desierto. Esa llamada ruta de las especias (prefigurada por la ruta del incienso en la Edad Antigua) fue esencial para que llegaran a occidente retazos de la ciencia y la cultura de Extremo Oriente. Por el norte, la ruta de la seda cumplió la misma función atravesando los desiertos y las cordilleras del Turquestán. El ajedrez, la numeración indoarábiga y el concepto de cero, así como algunas obras literarias (Calila e Dimna) estuvieron entre los aportes hindúes y persas. El papel, el grabado o la pólvora, entre las chinas. La función de los árabes, y de los persas, sirios, egipcios y españoles arabizados (no solo islámicos, pues hubo muchos que mantuvieron su religión cristiana o judía —no tanto la zoroastriana—) distó mucho de ser mera transmisión, como testimonia la influencia de la reinterpretación de la filosofía clásica que llegó a través de los textos árabes a Europa Occidental a partir de las traducciones latinas desde el siglo XII, y la difusión de cultivos y técnicas agrícolas por la región mediterránea. En un momento en que estaban prácticamente ausentes de la economía europea, destacaron las prácticas comerciales y la circulación monetaria en el mundo islámico, animadas por la explotación de minas de oro tan lejanas como las del África subsahariana, junto con otro tipo de actividades, como el tráfico de esclavos.

La unidad inicial del mundo islámico, que se había cuestionado ya en el aspecto religioso con la separación de suníes y chiíes, se rompió también en lo político con la sustitución de los Omeyas por los Abbasíes al frente del califato en el 749, que además sustituyeron Damasco por Bagdad como capital. Abderramán I, el último superviviente Omeya, consiguió fundar en Córdoba un emirato independiente para al-Ándalus (nombre árabe de la península ibérica), que su descendiente Abderramán III convirtió en un califato alternativo en el 929. Poco antes, en el 909 los Fatimíes habían hecho lo propio en Egipto. A partir del siglo XI se producen cambios muy importantes: el desafío a la hegemonía árabe como etnia dominante dentro del islam a cargo de los islamizados turcos, que pasarán a controlar distintas zonas del Medio Oriente (mamelucos, otomanos), o de kurdos como Saladino; la irrupción de los cristianos latinos en tres puntos clave del Mediterráneo (reinos cristianos de la Reconquista en al-Ándalus, normandos en el sur de Italia y cruzados en Siria y Palestina); y la de los mongoles desde el centro de Asia.

 


==== Al-Ándalus (siglo VIII al XV) ====


=== Imperio carolingio (siglos VIII y IX) ===


==== Surgimiento y ascenso ====

Hacia el siglo VIII, la situación política europea se había estabilizado. En oriente, el Imperio bizantino era fuerte otra vez, gracias a una serie de emperadores competentes. En occidente, algunos reinos aseguraban relativa estabilidad a varias regiones: Northumbria a Inglaterra, el Reino visigodo a España, el Reino lombardo a Italia y el Reino franco a Galia y Alemania. En realidad, el Reino franco era un compuesto de tres reinos: Austrasia, Neustria y Aquitania.
El Imperio carolingio surge de las bases creadas por los predecesores de Carlomagno desde principios del siglo VIII (Carlos Martel y Pipino el Breve). La proyección de sus fronteras a través de una gran parte de la Europa Occidental permitió a Carlos la aspiración de reconstruir la extensión del antiguo Imperio romano occidental, siendo la primera entidad política de la Edad Media que estuvo en condiciones de convertirse en una potencia continental. Aquisgrán fue elegida como capital, en una situación central y suficientemente alejada de Italia, que a pesar de ser liberada del dominio de los longobardos y de las teóricas reivindicaciones bizantinas, conservó una gran autonomía que llegaba a la soberanía temporal con la cesión de unos incipientes Estados Pontificios (el Patrimonium Petri o Patrimonio de San Pedro, que incluía Roma y buena parte del centro de Italia). Como resultado de la estrecha vinculación entre el pontificado y la dinastía carolingia, que se legitimaban y defendían mutuamente ya por tres generaciones, el papa León III reconoció las pretensiones imperiales de Carlomagno con una coronación en extrañas circunstancias, el día de Navidad del año 800.

Se crearon las marcas para fijar las fronteras ante los enemigos exteriores (árabes en la Marca Hispánica, sajones en la Marca Sajona, bretones en la Marca Bretona, lombardos —hasta su derrota— en la Marca Lombarda y ávaros en la Marca Ávara; posteriormente también se creó una para los húngaros: la Marca del Friuli). El territorio interior fue organizado en condados y ducados (unión de varios condados o marcas). Los funcionarios que los dirigían (condes, marqueses y duques) eran vigilados por inspectores temporales (los missi dominici —enviados del señor—), y se procuraba que no se heredaran para evitar que quedaran patrimonializados en una familia (cosa, que con el tiempo, no pudo evitarse). La consignación de tierras junto con los cargos, pretendía sobre todo el mantenimiento de la costosa caballería pesada y los nuevos caballos de batalla (destreros, introducidos desde Asia en el siglo VII que se empleaban de una manera completamente distinta a la caballería antigua, con estribos, aparatosas sillas y que podían sostener armaduras).[33]​ Tal proceso estuvo en el origen del nacimiento de los feudos que había que ceder a cada militar de acuerdo con su rango, hasta la unidad básica: el caballero que ejercía de señor sobre un territorio, se quedaba para su mantenimiento con una reserva señorial y dejaba los mansos para sus siervos, que estaban obligados a cultivar la reserva con prestaciones gratuitas de trabajo a cambio de la protección militar y el mantenimiento del orden y la justicia, que eran las funciones del señor. Lógicamente, los feudos en sus distintos niveles sufrieron la misma transformación patrimonial que marcas y condados, estableciendo una red piramidal de fidelidades que es el origen del vasallaje feudal.
Carlomagno negoció de igual a igual con otras grandes potencias de la época, como el Imperio bizantino, el Emirato de Córdoba, y el Califato Abasida. Aunque él mismo, ya en edad adulta, no sabía escribir (cosa habitual en la época, en que únicamente algunos clérigos lo hacían), Carlomagno siguió una política de prestigio cultural y un notable programa artístico. Pretendió rodearse de una corte de sabios e iniciar un programa educativo basado en el trivium y el quadrivium, para lo que mandó llamar a la intelectualidad de su tiempo a sus dominios impulsando, con la colaboración de Alcuino de York, el llamado Renacimiento carolingio. Dentro de este empeño educativo ordenó a sus nobles aprender a escribir, cosa que él mismo intentó, aunque nunca consiguió hacerlo con soltura.[34]​


==== División y hundimiento ====

Muerto Carlomagno en 814, toma el poder su hijo Ludovico Pío. Los hijos de este: Carlos el Calvo (Francia occidental), Luis el Germánico (Francia oriental) y Lotario I (primogénito y heredero del título imperial), se enfrentaron militarmente disputándose los diferentes territorios del imperio, que, más allá de las alianzas aristocráticas, manifestaban distintas personalidades, interpretables desde una perspectiva protonacional (idiomas diferentes: hacia el sur y oeste se imponían las lenguas romances que se comenzaban a diferenciar del latín vulgar, hacia el norte y este las lenguas germánicas, como testimoniaban los previos Juramentos de Estrasburgo; costumbres, tradiciones e instituciones propias —romanas hacia el sur, germanas hacia el norte—). Esta situación no concluyó ni siquiera en el 843 tras el Tratado de Verdún, puesto que la posterior división del reino de Lotario entre sus hijos (la Lotaringia, franja central desde los Países Bajos hasta Italia, pasando por la región del Rin, Borgoña y Provenza) llevó a los tíos de estos (Carlos y Luis), a otro reparto (el Tratado de Mersen del 870) que simplificaba las fronteras (dejando únicamente Italia y Provenza en manos de su sobrino el emperador Luis II el Joven —cuyo cargo no suponía más primacía que la honorífica—, pero no condujo a una mayor concentración de poder en manos de esos monarcas, débiles y en manos de la nobleza territorial. En algunas regiones, el pacto no era más que una entelequia, puesto que la costa del mar del Norte estaba ocupada por los vikingos. Incluso en las zonas teóricamente controladas, las posteriores herencias y luchas internas entre los sucesivos reyes y emperadores carolingios subdividieron y reunificaron los territorios de manera casi aleatoria.
La división, sumada al proceso institucional de descentralización inherente al sistema feudal, en ausencia de fuertes poderes centrales, y al debilitamiento preexistente de las estructuras sociales y económicas, hizo que la siguiente oleada de invasiones bárbaras, sobre todo las protagonizadas por húngaros y vikingos, sumieran de nuevo a Europa Occidental en el caos de una nueva edad oscura.

		
			
			
		
		
			
			
		
		
			
			
		
		
			
			
		


=== El sistema feudal ===


==== Uso del término «feudalismo» ====
El fracaso del proyecto político centralizador de Carlomagno llevó, en ausencia de ese contrapeso, a la formación de un sistema político, económico y social que los historiadores han convenido en llamar feudalismo, aunque en realidad el nombre nació como un peyorativo para designar del Antiguo Régimen por parte de sus críticos ilustrados. La Revolución francesa suprimió solemnemente "todos los derechos feudales" en la noche del 4 de agosto de 1789 y "definitivamente el régimen feudal", con el decreto del 11 de agosto.
La generalización del término permite a muchos historiadores aplicarlo a las formaciones sociales de todo el territorio europeo occidental, pertenecieran o no al Imperio carolingio. Los partidarios de un uso restringido, argumentando la necesidad de no confundir conceptos como feudo, villae, tenure, o señorío lo limitan tanto en espacio (Francia, Oeste de Alemania y Norte de Italia) como en el tiempo: un «primer feudalismo» o «feudalismo carolingio» desde el siglo VIII hasta el año 1000 y un «feudalismo clásico» desde el año 1000 hasta el 1240, a su vez dividido en dos épocas, la primera, hasta el 1160 (la más descentralizada, en que cada señor de castillo podía considerarse independiente, y se produce el proceso denominado incastellamento); y la segunda, la propia de la "monarquía feudal"). Habría incluso "feudalismos de importación": la Inglaterra normanda desde 1066 y los estados latinos de oriente creados durante las Cruzadas (siglos XII y XIII).[35]​
Otros prefieren hablar de "régimen" o "sistema feudal", para diferenciarlo sutilmente del feudalismo estricto, o de síntesis feudal, para marcar el hecho de que sobreviven en ella rasgos de la Antigüedad clásica mezclados con contribuciones germánicas, implicando tanto a instituciones como a elementos productivos, y significó la especificidad del feudalismo europeo occidental como formación económico social frente a otras también feudales, con consecuencias trascendentales en el futuro devenir histórico.[Nota 8]​ Más dificultades hay para el uso del término cuando nos alejamos más: Europa Oriental experimenta un proceso de "feudalización" desde finales de la Edad Media, justo cuando en muchas zonas de Europa Occidental los campesinos se liberan de las formas jurídicas de la servidumbre, de modo que suele hablarse del feudalismo polaco o ruso. El Antiguo Régimen en Europa, el islam medieval o el Imperio bizantino fueron sociedades urbanas y comerciales, y con un grado de centralización política variable, aunque la explotación del campo se realizaba con relaciones sociales de producción muy similares al feudalismo medieval. Los historiadores que aplican la metodología del materialismo histórico (Marx definió el modo de producción feudal como el estadio intermedio entre el esclavista y el capitalista) no dudan en hablar de «economía feudal» para referirse a ella, aunque también reconocen la necesidad de no aplicar el término a cualquier formación social preindustrial no esclavista, puesto que a lo largo de la historia y de la geografía han existido otros modos de producción también previstos en la modelización marxista, como el modo de producción primitivo de las sociedades poco evolucionadas, homogéneas y con escasa división social —como las de los mismos pueblos germánicos previamente a las invasiones— y el modo de producción asiático o despotismo hidráulico —Egipto faraónico, reinos de la India o Imperio chino— caracterizado por la tributación de las aldeas campesinas a un estado muy centralizado.[36]​ En lugares aún más lejanos se ha llegado a utilizar el término feudalismo para describir una época. Es el caso de Japón y el denominado feudalismo japonés, dadas las innegables similitudes y paralelismos que la nobleza feudal europea y su mundo tiene con los samuráis y el suyo. También se ha llegado a aplicarlo a la situación histórica de los periodos intermedios de la historia de Egipto, en los que, siguiendo un ritmo cíclico milenario, decae el poder central y la vida en las ciudades, la anarquía militar rompe la unidad de las tierras del Nilo, y los templos y señores locales que alcanzan a controlar un espacio de poder gobiernan en él de manera independiente sobre los campesinos obligados al trabajo.


==== El vasallaje y el feudo ====

Dos instituciones eran claves para el feudalismo: por un lado el vasallaje como relación jurídico-política entre señor y vasallo, un contrato sinalagmático (es decir, entre iguales, con requisitos por ambas partes) entre señores y vasallos (ambos hombres libres, ambos guerreros, ambos nobles), consistente en el intercambio de apoyos y fidelidades mutuas (dotación de cargos, honores y tierras —el feudo— por el señor al vasallo y compromiso de auxilium et consilium —auxilio o apoyo militar y consejo o apoyo político—), que si no se cumplía o se rompía por cualquiera de las dos partes daba lugar a la felonía, y cuya jerarquía se complicaba de forma piramidal (el vasallo era a su vez señor de vasallos); y por otro lado el feudo como unidad económica y de relaciones sociales de producción, entre el señor del feudo y sus siervos, no un contrato igualitario, sino una imposición violenta justificada ideológicamente como un do ut des de protección a cambio de trabajo y sumisión.
Por tanto, la realidad que se enuncia como relaciones feudo-vasalláticas es realmente un término que incluye dos tipos de relación social de naturaleza completamente distinta, aunque los términos que las designan se empleaban en la época (y se siguen empleando) de manera equívoca y con gran confusión terminológica entre ellos:
El vasallaje era un pacto entre dos miembros de la nobleza de distinta categoría. El caballero de menor rango se convertía en vasallo (vassus) del noble más poderoso, que se convertía en su señor (dominus) por medio del Homenaje e Investidura, en una ceremonia ritualizada que tenía lugar en la torre del homenaje del castillo del señor. El homenaje (homage) —del vasallo al señor— consistía en la postración o humillación —habitualmente de rodillas—, el osculum (beso), la inmixtio manum —las manos del vasallo, unidas en posición orante, eran acogidas entre las del señor—, y alguna frase que reconociera haberse convertido en su hombre. Tras el homenaje se producía la investidura —del señor al vasallo—, que representaba la entrega de un feudo (dependiendo de la categoría de vasallo y señor, podía ser un condado, un ducado, una marca, un castillo, una población, o un simple sueldo; o incluso un monasterio si el vasallaje era eclesiástico) a través de un símbolo del territorio o de la alimentación que el señor debe al vasallo —un poco de tierra, de hierba o de grano— y del espaldarazo, en el que el vasallo recibe una espada (y unos golpes con ella en los hombros), o bien un báculo si era religioso.
La encomienda, encomendación o patrocinio (patrocinium, commendatio, aunque era habitual utilizar el término commendatio para el acto del homenaje o incluso para toda la institución del vasallaje) eran pactos teóricos entre los campesinos y el señor feudal, que podían también ritualizarse en una ceremonia o —más raramente— dar lugar a un documento. El señor acogía a los campesinos en su feudo, que se organizaba en una reserva señorial que los siervos debían trabajar obligatoriamente (sernas o corveas) y en el conjunto de las pequeñas explotaciones familiares (mansos) que se atribuían a los campesinos para que pudieran subsistir. Obligación del señor era protegerles si eran atacados, y mantener el orden y la justicia en el feudo. A cambio, el campesino se convertía en su siervo y pasaba a la doble jurisdicción del señor feudal: en los términos utilizados en la península ibérica en la Baja Edad Media, el señorío territorial, que obligaba al campesino a pagar rentas al noble por el uso de la tierra; y el señorío jurisdiccional, que convertía al señor feudal en gobernante y juez del territorio en el que vivía el campesino, por lo que obtenía rentas feudales de muy distinto origen (impuestos, multas, monopolios, etc.). La distinción entre propiedad y jurisdicción no era en el feudalismo algo claro, pues de hecho el mismo concepto de propiedad era confuso, y la jurisdicción, otorgada por el rey como merced, ponía al señor en disposición de obtener sus rentas. No existieron señoríos jurisdiccionales en los que la totalidad de las parcelas pertenecieran como propiedad al señor, siendo muy generalizadas distintas formas de alodio en los campesinos. En momentos posteriores de despoblamiento y refeudalización, como la crisis del siglo XVII, algunos nobles intentaban que se considerase despoblado completamente de campesinos un señorío para liberarse de todo tipo de cortapisas y convertirlo en coto redondo reconvertible para otro uso, como el ganadero.[37]​
Junto con el feudo, el vasallo recibe los siervos que hay en él, no como propiedad esclavista, pero tampoco en régimen de libertad; puesto que su condición servil les impide abandonarlo y les obliga a trabajar. Las obligaciones del señor del feudo incluyen el mantenimiento del orden, o sea, la jurisdicción civil y criminal (mero e mixto imperio en la terminología jurídica reintroducida con el Derecho Romano en la Baja Edad Media), lo que daba aún mayores oportunidades para obtener el excedente productivo que los campesinos pudieran obtener después de las obligaciones de trabajo —corveas o sernas en la reserva señorial— o del pago de renta —en especie o en dinero, de circulación muy escasa en la Alta Edad Media, pero más generalizada en los últimos siglos medievales, según fue dinamizándose la economía—. Como monopolio señorial solían quedar la explotación de los bosques y la caza, los caminos y puentes, los molinos, las tabernas y tiendas. Todo ello eran más oportunidades de obtener más renta feudal, incluidos derechos tradicionales, como el ius prime noctis o derecho de pernada, que se convirtió en un impuesto por matrimonios, buena muestra de que es en el excedente de donde se extrae la renta feudal de manera extraeconómica (en este caso en la demostración de que una comunidad campesina crece y prospera).


==== Los órdenes feudales ====

Con el tiempo, siguiendo la tendencia marcada desde el Bajo Imperio romano, que se consolidó en la época clásica del feudalismo y que pervivió durante todo el Antiguo Régimen, se fue conformando una sociedad organizada de manera estamental, en los llamados estamentos u ordines (órdenes): nobleza, clero y pueblo llano (o tercer estado): bellatores, oratores y laboratores los hombres que guerrean, los que rezan y los que trabajan, según el vocabulario de la época. Los dos primeros son privilegiados, es decir, no se les aplica la ley común, sino un fuero propio (por ejemplo, tienen distintas penas para el mismo delito, y su forma de ejecución es diferente) y no pueden trabajar (les están prohibidos los oficios viles y mecánicos), puesto que esa es la condición de no privilegiados. En época medieval, los órdenes feudales no eran estamentos cerrados y bloqueados, sino que mantenían una permeabilidad que permitía en casos extraordinarios el ascenso social debido al mérito (por ejemplo, a la demostración de un excepcional valor), que eran tan escasos que no se vivían como una amenaza, cosa que sí ocurrió a partir de las grandes convulsiones sociales de los siglos finales de la Baja Edad Media, en que los privilegiados se vieron obligados a institucionalizar su posición procurando cerrar el acceso a sus estamentos de los no privilegiados (en lo que tampoco tuvieron una eficacia total). Completamente impropia sería la comparación con la sociedad de castas de la India, en que guerreros, sacerdotes, comerciantes, campesinos y parias pertenecían a castas diferentes entendidas como linajes desconectados cuya mezcla se prohibía.
Las funciones de los órdenes feudales estaban fijadas ideológicamente por el agustinismo político (Civitate Dei -426-), en búsqueda de una sociedad que, aunque como terrena no podía dejar de ser corrupta e imperfecta, podía aspirar a ser al menos una sombra de la imagen de una "Ciudad de Dios" perfecta de raíces platónicas[Nota 9]​ en que todos tuvieran un papel en su protección, su salvación y su mantenimiento. Esta idea fue reformulada y perfilada a lo largo de la Edad Media, sucesivamente por autores como Isidoro de Sevilla (630), la escuela de Auxerre (Haimón de Auxerre -865- en la abadía borgoñona en la que trabajaban Erico de Auxerre y su discípulo Remigio de Auxerre, que seguían la tradición de Escoto Eriúgena), Boecio (892), Wulfstan de York (1010), Gerardo de Cambrai (1024) o Adalberón de Laon; y utilizada en textos legislativos como la llamada Compilación de Huesca de los Fueros de Aragón (Jaime I), y las Siete Partidas (Alfonso X el Sabio, 1265).[38]​
Los bellatores o guerreros eran la nobleza, cuya función era la protección física, la defensa de todos ante las agresiones e injusticias. Estaba organizada piramidalmente desde el emperador, pasando por los reyes y descendiendo sin solución de continuidad hasta el último escudero, aunque atendiendo a su rango, poder y riqueza puede clasificarse en dos partes diferenciadas: alta nobleza (marqueses, condes y duques) cuyos feudos tienen el tamaño de regiones y provincias (aunque la mayor parte de las veces no en continuidad territorial, sino repartido y difuso, lleno de enclaves y exclaves); y la baja nobleza o caballeros (barones, infanzones), cuyos feudos son del tamaño de pequeñas comarcas (a escala municipal o inferior a la municipal), o directamente no poseen feudos territoriales, viviendo en los castillos de señores más importantes, o en ciudades o poblaciones en las que no ejercen jurisdicción (aunque sí pueden ejercer su regimiento, es decir, participar en su gobierno municipal en representación del estado noble). A finales de la Edad Media y en la Edad Moderna, cuando la nobleza ya no ejercía su función militar, como era el caso de los hidalgos españoles, que aducían sus privilegios estamentales para evitar el pago de impuestos y obtener alguna ventaja social, alardeando de ejecutoria o de blasón y casa solariega, pero que al no disponer de rentas feudales suficientes para mantener la manera de vida nobiliaria, corrían el peligro de perder su condición por contraer un matrimonio desigual o ganarse la vida trabajando:

 

Además de la legitimación religiosa, a través de la cultura y el arte laicos (la épica de los cantares de gesta y la lírica del amor cortés de los trovadores provenzales) se difundía socialmente la legitimación ideológica de la forma de vida, la función social y los valores de la nobleza.[39]​

Los oratores o clérigos eran el clero, cuya función era facilitar la salvación espiritual de las almas inmortales: algunos formaban una élite poderosa llamada alto clero, (abades, obispos), y otros más humildes, el bajo clero (curas de pueblo o los hermanos legos de un monasterio). La extensión y organización del monacato benedictino a través de la Orden de Cluny, estrechamente vinculado a la organización de la red episcopal centralizada y jerarquizada, con cúspide en el papa de Roma, estableció la doble pirámide feudal del clero secular, destinado a la administración los de sacramentos (que controlaban toda la trayectoria vital de la población, desde el nacimiento hasta muerte); y el clero regular, apartado del mundo y sometido a una regla monástica (habitualmente la regla benedictina). Los tres votos monásticos del clero regular: pobreza, obediencia y castidad; así como el celibato eclesiástico que se fue imponiendo al clero secular, funcionaron como un eficaz mecanismo de vinculación de los dos estamentos privilegiados: los hijos segundones de la nobleza ingresaban en el clero, donde eran mantenidos sin estrecheces gracias a las numerosas fundaciones, donaciones, dotes y mandas testamentarias; pero no disputaban las herencias a sus hermanos, que podían mantener concentrado el patrimonio familiar. Las tierras de la Iglesia quedaban como manos muertas, cuya función era la de garantizar las misas y oraciones previstas por los donadores, de modo que los hijos rezaban por las almas de los padres. Todo el sistema garantizaba el mantenimiento del prestigio social de los privilegiados, asistiendo a misa en lugares destacados mientras vivían y enterrados en lugares principales de iglesias y catedrales cuando morían.[Nota 10]​ No faltaron los enfrentamientos: la evidencia de simonía y nicolaísmo (nombramientos de cargos eclesiásticos interferidos por las autoridades civiles o su pura compraventa) y la utilización de la principal amenaza religiosa al poder temporal, equivalente a una muerte civil: la excomunión. El Papa se atribuía incluso la autoridad de eximir al vasallo de la fidelidad debida a su señor y reivindicarla para sí mismo, lo que fue utilizado en varias ocasiones para la fundación de reinos que pasaban a ser vasallos del Papa (por ejemplo, la independencia que Afonso Henriques obtuvo para el condado convertido en reino de Portugal frente al reino de León).
Los laboratores o trabajadores, eran el pueblo llano, cuya función era el mantenimiento de los cuerpos, la función ideológicamente más baja y humilde —humiliores eran los cercanos al humus, la tierra, mientras que sus superiores eran honestiores, los que podían mantener la honra u honor—.[Nota 11]​ Necesariamente los más numerosos, y la inmensa mayoría de ellos dedicados a tareas agrícolas, dado la bajísima productividad y rendimiento agrícola, propios de la época preindustrial y del muy escaso nivel técnico (de ahí la identificación en castellano de laborator con labrador). Por lo común estaban sometidos a los otros estamentos. El pueblo llano estaba compuesto en su gran mayoría por campesinos, siervos de los señores feudales o campesinos libres (villanos), y por artesanos, que eran escasos y vivían, bien en las aldeas (aquellos de menor especialización, que solían compartir las tareas agrícolas: herreros, talabarteros, alfareros, sastres) o en las pocas y pequeñas ciudades (los de mayor especialización y de productos de necesidad menos apremiante o de demandada de las clases altas: joyeros, orfebres, cereros, toneleros, tejedores, tintoreros). La autosuficiencia de los feudos y los monasterios limitaba su mercado y capacidad de crecer. Los oficios de la construcción (cantería, albañilería, carpintería) y la misma profesión de maestro de obras o arquitecto son una notable excepción: obligados por la naturaleza de su trabajo al desplazamiento al lugar donde se construye el edificio, se transformaron en un gremio nómada que se desplazaba por los caminos europeos comunicándose novedades técnicas u ornamentales transformadas en secretos de oficio, lo que está en el origen de su lejana y mitificada vinculación con la sociedad secreta de la masonería, que desde su origen los consideró como los primitivos masones.[Nota 12]​
Las zonas sin dependencia intermedia de señores nobles o eclesiásticos se denominaban realengo y solían prosperar más, o al menos solían considerar como una desgracia el pasar a depender de un señor, hasta el punto de que en algunas ocasiones conseguían evitarlo con pagos al rey, o se incentivaba la repoblación de zonas fronterizas o despobladas (como ocurrió en el reino astur-leonés con la despoblada Meseta del Duero) donde podían aparecer figuras mixtas, como el caballero villano (que podía mantener con su propia explotación al menos un caballo de guerra y armarse y defenderse a sí mismo) o las behetrías, que elegían a su propio señor y podían cambiar de uno u a otro si les convenía, o con la oferta de un fuero o carta puebla que otorgaba a un población su propio señorío colectivo. Los privilegios iniciales no fueron suficientes para impedir que con el tiempo la mayor parte de ellos cayeran en la feudalización.
Los tres órdenes feudales no eran en la Edad Media aún unos estamentos cerrados: eran consecuencia básica de la estructura social que se había ido creando lenta pero inexorablemente con la transición del esclavismo al feudalismo desde la crisis del siglo III (ruralización y formación de latifundios y villae, reformas de Diocleciano, descomposición del Imperio romano, las invasiones, el establecimiento de los reinos germánicos, instituciones del Imperio carolingio, descomposición de este y nueva oleada de invasiones). Los señores feudales eran continuación de las líneas clientelares de los condes carolingios, y algunos pueden remontarse a los latifundistas romanos o los séquitos germanos, mientras que el campesinado provenía de los antiguos esclavos o colonos, o de campesinos libres que se vieron forzados a encomendarse, recibiendo a veces una parte de sus antiguas tierras propias en forma de manso "concedido" por el señor. El campesino heredaba su condición servil y su sujeción a la tierra, y rara vez tenía oportunidad de ascender de nivel como no fuera por su fuga a una ciudad o por un hecho todavía más extraordinario: su ennoblecimiento por un destacado hecho de armas o servicio al rey, que en condiciones normales le estaban completamente vedados. Lo mismo puede decirse del artesano o el mercader (que en algunos casos podía acumular fortuna, pero no alterar su origen humilde). El noble lo era generalmente por herencia, aunque en ocasiones podía alguien ennoblecerse como soldado de fortuna, después de una victoriosa carrera de armas (como fue el caso, por ejemplo, de Roberto Guiscardo). El clero, por su parte, era reclutado por cooptación, con un acceso distinto según el origen social: asegurado para los segundones de las casas nobles y restringido a los niveles inferiores del bajo clero para los del pueblo llano; pero en casos particulares o destacados, el ascenso en la jerarquía eclesiástica estaba abierto al mérito intelectual. Todo esto le daba al sistema feudal una extraordinaria estabilidad, en donde había "un lugar para cada hombre, y cada hombre en su lugar", al tiempo que una extraordinaria flexibilidad, porque permitía al poder político y económico atomizarse a través de toda Europa, desde España hasta Polonia.


=== El año mil ===
El legendario año mil, final del primer milenio, que se utiliza convencionalmente para el paso de la Alta a la Baja Edad Media, en realidad tan solo es una cifra redonda para el cómputo de la era cristiana, que no era de universal utilización: los musulmanes utilizaban su propio calendario islámico lunar que comienza en la Hégira (622); en algunas partes de la Cristiandad se utilizaban eras locales (como la era hispánica, que cuenta desde el 38 a. C.). Pero ciertamente, el milenarismo y los pronósticos del final de los tiempos estaban presentes; incluso el propio papa durante el cambio de milenio Silvestre II, el francés Gerberto de Aurillac, interesado en todo tipo de conocimientos, se ganó una reputación esotérica.[41]​ La astrología siempre pudo encontrar fenómenos celestes extraordinarios en los que apoyar su prestigio (como los eclipses), pero ciertamente otros eventos de la época estuvieron entre los más espectaculares de la historia: el cometa Halley, que se acerca a la Tierra periódicamente cada ocho décadas, alcanzó su brillo máximo en la visita de 837,[42]​ despidió el primer milenio en 989 y llegó a tiempo de la batalla de Hastings en 1066; mucho más visibles aún, las supernovas SN 1006 y SN 1054, que reciben el número del año en que se registraron, fueron más detalladamente reflejadas en fuentes chinas, árabes e incluso indoamericanas que en las escasas europeas (a pesar de que la de 1054 coincidió con la batalla de Atapuerca).
Todo el siglo X, más bien por las condiciones reales que por las imaginarias, puede considerarse parte de una época oscura, pesimista, insegura y presidida por el miedo a todo tipo de peligros, reales e imaginarios, naturales y sobrenaturales: miedo al mar, miedo al bosque, miedo a las brujas y los demonios y a todo lo que, sin entrar dentro de lo sobrenatural cristiano, quedaba relegado a lo inexplicable y al concepto de lo maravilloso, atribuido a seres de dudosa o quizá posible existencia (dragones, duendes, hadas, unicornios). El hecho no tenía nada de único: mil años más tarde, el siglo XX hizo nacer miedos comparables: al holocausto nuclear, al cambio climático (versiones contemporáneas del fin del mundo); al comunismo (la caza de brujas con la que se identificó al macarthismo), a la libertad (Miedo a la Libertad es la base del fascismo en la interpretación de Erich Fromm), comparación que ha sido puesta de manifiesto por los historiadores[43]​ e interpretada por los sociólogos (Sociedad del riesgo de Ulrich Beck).

 


==== La coyuntura del año mil ====
En la coyuntura histórica del año mil, las estructuras políticas más fuertes del periodo anterior se estaban demostrando muy débiles: el islam se descompuso en califatos (Bagdad, El Cairo y Córdoba), que para el año 1000 se estaban demostrando incapaces de contener a los reinos cristianos, especialmente al Reino de León, en la península ibérica (fracaso final de Almanzor) y al Imperio bizantino en el Mediterráneo Oriental. También sufre la expansión bizantina el Imperio búlgaro, que queda destruido. Los particularismos nacionales francés, polaco y húngaro dibujan fronteras protonacionales que, curiosamente, son muy similares a las del año 2000. En cambio, el Imperio carolingio se había disuelto en principados feudales ingobernables, que los Otónidas se proponían incluir en una segunda Restauratio Imperii (Otón I, en el 962), esta vez sobre bases germanas.[45]​


=== La persistencia del miedo y la función de la risa ===

 

Los miedos y la inseguridad no acabaron con el año mil, ni tampoco hubo que esperar para volver a encontrarlos a la terrible peste negra y a los flagelantes del siglo XIV Incluso en el óptimo medieval del expansivo siglo XIII lo más habitual era encontrar textos como el de Dante, o como los siguientes:
Este himno de autor desconocido, atribuido a muy diversos personajes (el papa Gregorio —que pudiera ser Gregorio Magno, a quien también se atribuye el canto gregoriano, u otro de los de ese nombre—, al fundador del Cister San Bernardo de Claraval, a los monjes dominicos Umbertus y Frangipani y al franciscano Tomás de Celano) e incorporado a la liturgia de la misa:

 

Pero también participa de la misma concepción pesimista del mundo este otro, proveniente de un ambiente totalmente opuesto, recogido en una colección de poemas goliardos (monjes y estudiantes de vida desordenada):[46]​

 

Lo sobrenatural estaba presente en la vida cotidiana de todos como un constante recordatorio de la brevedad de la vida y la inminencia de la muerte, cuyo radical igualitarismo se aplicaba, en contrapunto con la desigualdad de las condiciones, como un cohesionador social, al igual que la promesa de la vida eterna. La imaginación se excitaba con las imágenes más morbosas de lo que ocurriría en el juicio final, los tormentos del infierno y de los méritos que los santos habían obtenido con su vida ascética y sus martirios (que bien administrados por la Iglesia podían ahorrar las penas temporales del purgatorio). Esto no solo operaba en los amedrentados iletrados que únicamente disponían del evangelio en piedra de las iglesias; la mayor parte de los lectores cultos daban todo crédito a las escenas truculentas que llenaban los martirologios y a las inverosímiles historias de la Leyenda Áurea de Jacopo da Vorágine.
El miedo era inherente a la violencia estructural permanente del feudalismo, que aunque se encauzara por mecanismos aceptables socialmente y estableciera un orden estamental teóricamente perfecto, era un permanente recuerdo de la posibilidad de subversión del orden, periódicamente renovado con guerras, invasiones y sublevaciones internas. En particular, las sátiras contra el rústico eran manifestaciones de la mezcla de desprecio y desconfianza con que clérigos y nobles veían al siervo, reducido a un monstruo deforme, ignorante y violento, capaz de las mayores atrocidades, sobre todo cuando se agrupaba.[47]​

 

Pero al mismo tiempo, se sostenía, como parte esencial del edificio ideológico (era la justificación de la elección papal) que la voz del pueblo era la voz de Dios (Vox populi, vox Dei). El espíritu medieval debía asumir la contradicción de impulsar manifestaciones públicas de piedad y devoción y al tiempo permitir generosas concesiones al pecado. Los carnavales y otras parodias grotescas (la fiesta del asno o el charivari) permitían todo tipo de licencias, incluso la blasfemia y la burla a lo sagrado, invirtiendo las jerarquías (se elegían reyes de los tontos obispillos u obispos de la fiesta) haciendo triunfar todo lo que el resto del año estaba prohibido, era considerado feo, desagradable o daba miedo, como reacción saludable al terror cotidiano al más allá y garantía de que, pasados los excesos de la fiesta, se volvería dócilmente al trabajo y la obediencia. Seriedad y tristeza eran prerrogativas de quien practicaba un sagrado optimismo (hay que sufrir pues luego nos aguarda la vida eterna), mientras que la risa era la medicina del que vivía con pesimismo una vida miserable y difícil.[49]​ Frente al mayor rigorismo del cristianismo primitivo, los teólogos medievales especulaban sobre si Cristo río o no (la Epístola de Léntulo, uno de los evangelios apócrifos sostenía que no; mientras que algunos padres de la iglesia defendían el derecho a una santa alegría), lo que justificaba textos cómicos eclesiásticos, como la Coena Cypriani y la Joca monachorum.[50]​


== Plena Edad Media (siglos XI al XIII) ==

Se asigna el nombre de Plenitud de la Edad Media al periodo de la Historia de Europa que ocupa los siglos XI al XIII. Esa Plena Edad Media o Plenitud del Medievo terminaría en la crisis del XIV o crisis de la Edad Media, en la que se pueden apreciar procesos «decadentes», y es habitual calificarla de ocaso u otoño. No obstante, los últimos siglos medievales están llenos de hechos y procesos dinámicos, con enormes repercusiones y proyecciones en el futuro, aunque lógicamente son los hechos y procesos que pueden entenderse como "nuevos", que prefiguran los nuevos tiempos de la modernidad. Al mismo tiempo, los hechos, procesos, agentes sociales, instituciones y valores caracterizados como medievales han entrado claramente en decadencia; sobreviven, y sobrevivirán por siglos, en buena medida gracias a su institucionalización (por ejemplo, el cierre de los estamentos privilegiados o la adopción del mayorazgo), lo que no deja de ser un síntoma de que es entonces, y no antes, que se consideró necesario defenderlos tanto.

La justificación de esa denominación es lo excepcional del desarrollo económico, demográfico, social y cultural de Europa que tiene lugar en ese período, coincidente con un clima muy favorable (se ha hablado del "óptimo medieval") que permitía cultivar vides en Inglaterra. También se ha hablado, en concreto para el siglo XII, de la revolución del siglo XII o renacimiento del siglo XII
El simbólico año mil (cuyos terrores milenaristas son un mito historiográfico frecuentemente exagerado) no significa nada por sí mismo, pero a partir de entonces se da por terminada la Edad Oscura de las invasiones de la Alta Edad Media: húngaros y normandos están ya asentados e integrados en la cristiandad latina. La Europa de la Plena Edad Media es expansiva también en el terreno militar: las cruzadas en el Próximo Oriente, la dominación angevina de Sicilia y el avance de los reinos cristianos en la península ibérica (desaparecido el Califato de Córdoba) amenazan con reducir el espacio islámico a la ribera sur de la cuenca del Mediterráneo y el interior de Asia.
El modo de producción feudal se desarrolla sin encontrar de momento límites a su extensión (como ocurrirá con la crisis del siglo XIV). La renta feudal se distribuye por los señores fuera del campo, donde se origina: las ciudades y la burguesía crecen con el aumento de la demanda de productos artesanales y del comercio a larga distancia, nacen y se desarrollan las ferias, las rutas comerciales terrestres y marítimas e instituciones como la Hansa. Europa Central y Septentrional entran en el corazón de la civilización Occidental. El Imperio bizantino se mantiene entre el islam y los cruzados, extendida su influencia cultural por los Balcanes y las estepas rusas donde se resiste el empuje mongol.
El arte románico y el primer gótico son protegidos por las órdenes religiosas y el clero secular. Cluny y el Císter llenan Europa de monasterios. El camino de Santiago articula la península ibérica con Europa. Nacen las Universidades (Bolonia, Sorbona, Oxford, Cambridge, Salamanca, Coímbra). La escolástica llega a su cumbre con Tomás de Aquino, tras recibir la influencia de las traducciones del árabe (averroísmo). El redescubrimiento del derecho romano (Bártolo de Sassoferrato, Baldo degli Ubaldi) empieza a influir en los reyes que se ven a sí mismos como emperadores en su reino.
Los conflictos crecen a la par que la sociedad: herejías, revueltas campesinas y urbanas, la salvaje represión de todas ellas y las no menos salvajes guerras feudales son constantes.


=== La expansión del sistema feudal ===


==== Dinamismo interno: económico, social, tecnológico e intelectual ====

Lejos de ser un sistema social anquilosado (el cierre del acceso a los estamentos es un proceso que se produce como reacción conservadora de los privilegiados, tras la crisis final de la Edad Media, ya en el Antiguo Régimen), el feudalismo medieval demostró suficiente flexibilidad como para permitir el desarrollo de dos procesos, que se retroalimentaron mutuamente favoreciendo una rápida expansión. Por una parte, el asignar un lugar a cada persona dentro del sistema, permitió la expulsión de todos aquellos para quienes no había lugar, enviándolos como colonos y aventureros militares a tierras no ganadas para la Cristiandad Occidental, expandiendo así brutalmente sus límites. Por la otra, el asegurar un cierto orden y estabilidad social para el mundo agrario tras el fin del periodo de las invasiones; aunque ni mucho menos se acabaron las guerras —consustanciales al sistema feudal— el nivel habitual de violencia en periodos bélicos tendía a controlarse por las propias instituciones —código de honor, tregua de Dios, acogimiento a sagrado— y en periodos normales tendía a ritualizarse — desafíos, duelos, rieptos, justas, torneos, paso honroso—, aunque no desaparecía ni en las relaciones internacionales ni dentro de los reinos, con unas ciudades que basaban su seguridad y pax urbana en sus fuertes murallas, sus toques de queda y su expeditiva justicia, y unos inseguros campos en los que señores de horca y cuchillo imponían sus prerrogativas e incluso abusaban de ellas (malhechores feudales), no sin encontrar la resistencia antiseñorial de los siervos,[51]​ a veces mitificada (Robin Hood). A diferencia del modo de producción esclavista, el modo de producción feudal ponía en el productor —campesino— la responsabilidad en el aumento de la producción: sea buena o mala la cosecha, debe pagar unas mismas rentas. Es por ello que el sistema por sí solo estimula el trabajo y la incorporación de lo que la experiencia demuestre como buenas prácticas agrícolas, incluso la incorporación de nuevas técnicas que mejoren el rendimiento de la tierra. Si el aumento de la producción es permanente y no coyuntural (una sola buena cosecha por causas climáticas), quien empezará a recibir estímulos será el señor feudal, que detectará ese aumento de los excedentes cuya extracción es la base de su renta feudal (mayor uso del molino, mayor circulación por los caminos y puentes, mayor consumo en tiendas y tabernas; de todos los cuales cobra impuestos o aspirará a hacerlo), incluso se verá impulsado a subir la renta. Cuando lo que ocurre es que los campesinos, empujados por el aumento de sus familias, presionan los límites de los mansos roturando tierras antes incultas (eriales, pastos, bosques, humedales desecables), el señor podrá imponer nuevas condiciones, e incluso impedirlo, porque forman parte de su reserva o de sus usos monopolísticos (caza, alimento de sus caballos).

Esa dinámica lucha de clases entre siervos y señores dinamizaba la economía y hacía posible el inicio de una concentración de riquezas acumuladas a partir de las rentas agrícolas; pero nunca de manera comparable a la acumulación de capital propia del capitalismo, pues no se hacía con ellas inversión productiva (como hubiera ocurrido de disponer los campesinos del uso del excedente), sino atesoramiento en manos de nobleza y clero. Tal cosa, en última instancia, a través de los programas de construcción (castillos, monasterios, iglesias, catedrales, palacios) y el gasto suntuario en productos de lujo —caballos, armas sofisticadas, joyas, obras de arte, telas de calidad, tintes, sedas, tapices, especias— no pudo dejar de estimular el rudimentario comercio a larga distancia, la circulación monetaria y la vida urbana; en definitiva, el resurgimiento económico de Europa Occidental. Irónicamente, ambos procesos terminarían por minar las bases del feudalismo, y llevarlo hacia su destrucción.[Nota 13]​ No obstante, no hay que imaginar que se produjo nada parecido a la revolución agrícola previa a la revolución industrial: el hecho de que ni campesinos ni señores pudieran convertir en capital el excedente (unos porque se lo extraían y otros porque su posición social era incompatible con las actividades económicas) hacía lenta y costosa cualquier innovación, además del hecho de que cualquier innovación chocaba con prejuicios ideológicos y una mentalidad fuertemente tradicionalista, ambas cosas propias de la sociedad preindustrial. Solo en el transcurso de siglos, y debido al ensayo y error del buen hacer artesanal de anónimos herreros y talabarteros sin ningún tipo de conexión con la investigación científica, se produjo la incorporación de escasas pero decisivas mejoras técnicas como la collera (que posibilita el aprovechamiento eficaz de la fuerza de los caballos de tiro, que empiezan a sustituir a los bueyes) o el arado de vertedera (que sustituye al arado romano en las tierras húmedas y pesadas del norte de Europa, no así en las secas y ligeras del sur). El barbecho de año y vez siguió siendo el método de cultivo más utilizado; la rotación de cultivos era desconocida, el abonado era un recurso excepcional, dada la escasez de animales, cuyo estiércol era el único abono disponible; el regadío estaba limitado a algunas de las zonas mediterráneas de cultura islámica; se escatimaba la utilización de hierro en herramientas y aperos de labranza, dado su coste inasumible por los campesinos; el nivel técnico, en general, era precario. El molino de viento fue una transferencia tecnológica que, como tantas otras en otros campos (pólvora, papel, brújula, grabado), provenía de Asia. Aun con su alcance limitado, el conjunto de innovaciones y cambios se concentró especialmente en un periodo que algunos historiadores han venido en llamar el "Renacimiento" del siglo XII o la Revolución del XII, momento en el que el dinamismo económico y social, a partir del motor principal, que es el campo, produce el despertar de un mundo urbano hasta entonces marginal en Europa Occidental, y el surgimiento de fenómenos intelectuales como la universidad medieval y la escolástica.


==== La universidad ====

Siguiendo el precedente de la organización carolingia de las escuelas palatinas, catedralicias y monásticas (debida a Alcuino de York -787-), más que el de otras instituciones semejantes existentes en el mundo islámico,[Nota 14]​ las primeras universidades de la Europa cristiana fueron fundadas para el estudio del derecho, la medicina y la teología. La parte central de la enseñanza envolvía el estudio de las artes preparatorias (denominadas artes liberales por cuanto eran mentales o espirituales y liberaban del trabajo manual propio de las artesanías, consideradas oficios viles y mecánicos); estas artes liberales eran el trivium (gramática, retórica y lógica) y el quadrivium (aritmética, geometría, música y astronomía). Después, el alumno entraba en contacto con estudios más específicos. Además de centros de enseñanza, eran también el lugar de investigación y producción del saber, y foco de vigorosos debates y polémicas, lo que a veces requirió incluso las intervenciones del poder civil y eclesiástico, a pesar de los fueros de los que estaban dotadas y que las convertían en instituciones independientes, bien dotadas económicamente con una base patrimonial de tierras y edificios. La transformación cultural generada por las universidades ha sido resumida de este modo: En 1100, la escuela seguía al maestro; en 1200, el maestro seguía a la escuela.[54]​ Las más prestigiosas recibían el nombre de Studium Generale, y su fama se extendía por toda Europa, requiriendo la presencia de sus maestros, o al menos la comunicación epistolar, lo que inició un fecundo intercambio intelectual facilitado por el uso común de la lengua culta, el latín.
Entre 1200 y 1400 fueron fundadas en Europa 52 universidades; 29 de ellas de fundación papal, las demás de fundación imperial o real. La primera fue posiblemente Bolonia (especializada en Derecho, 1088), a la que siguió Oxford (antes de 1096), de la que se escindió su rival Cambridge (1209), París, de mediados del siglo XII (uno de cuyos colegios fue La Sorbona, 1275), Salamanca (1218, precedida por el Estudio General de Palencia de 1208), Padua (1222), Nápoles (1224), Coímbra (1308, trasladada desde el Estudio General de Lisboa de 1290), Alcalá de Henares (1293, refundada por el Cardenal Cisneros en 1499), La Sapienza (Roma, 1303), Valladolid (1346), la Universidad Carolina (Praga, 1348), la Universidad Jagellónica (Cracovia, 1363), Viena (1365), Heidelberg (1386), Colonia (1368) y, ya al final del periodo medieval, Lovaina (1425), Barcelona (1450), Basilea (1460) y Upsala (1477). En medicina gozaba de un gran prestigio la Escuela Médica Salernitana, con raíces árabes, que provenía del siglo IX; y en 1220 empezó a rivalizar con ella la Facultad de Medicina de Montpellier.


==== La escolástica ====
La escolástica fue la corriente teológico-filosófica dominante del pensamiento medieval, tras la patrística de la Antigüedad tardía, y se basó en la coordinación de fe y razón, que en cualquier caso siempre suponía la clara sumisión de la razón a la fe (Philosophia ancilla theologiae -la filosofía es esclava de la teología-). Pero también es un método de trabajo intelectual: todo pensamiento debía someterse al principio de autoridad (Magister dixit —lo dijo el Maestro—), y la enseñanza se podía limitar en principio a la repetición o glosa de los textos antiguos, y sobre todo de la Biblia, la principal fuente de conocimiento, pues representa la Revelación divina; a pesar de todo ello, la escolástica incentivó la especulación y el razonamiento, pues suponía someterse a un rígido armazón lógico y una estructura esquemática del discurso que debía exponerse a refutaciones y preparar defensas. Desde el comienzo del siglo IX al fin del XII los debates se centraron en la cuestión de los universales, que opone a los realistas encabezados por Guillermo de Champeaux, a los nominalistas representados por Roscelino y a los conceptualistas (Pedro Abelardo). En el siglo XII tiene lugar la recepción de textos de Aristóteles antes desconocidos en Occidente, primero indirectamente a través de los filósofos judíos y musulmanes, especialmente Avicena y Averroes, pero en seguida directamente traducido del griego al latín por san Alberto Magno y por Guillermo de Moerbeke, secretario de santo Tomás de Aquino, verdadera cumbre del pensamiento medieval y elevado al rango de Doctor de la Iglesia. El apogeo de la escolástica coincide con el siglo XIII en que se fundan las universidades y surgen las órdenes mendicantes: dominicos (que siguieron una tendencia aristotélica -los anteriormente citados-) y franciscanos (caracterizados por el platonismo y la tradición patrística -Alejandro de Hales o san Buenaventura-). Ambas órdenes coparán las cátedras y la vida de los colegios universitarios, y de ellas procederán la mayoría de los teólogos y filósofos de la época.
El siglo XIV representará la crisis de la escolástica a través de dos franciscanos británicos: el doctor subtilis Juan Duns Escoto y Guillermo de Occam. Precedente de ambos sería la Escuela de Oxford (Robert Grosseteste y Roger Bacon) centrada en el estudio de la naturaleza, defendiendo la posibilidad de una ciencia experimental apoyada en la matemática, contra el tomismo dominante. La polémica de los universales se terminó decantando por los nominalistas, lo que dejaba un espacio a la filosofía más allá de la teología.

 

 


==== El surgimiento de la burguesía ====

La burguesía es el nuevo agente social formado por los artesanos y mercaderes que surgen en el entorno de las ciudades, bien en las antiguas ciudades romanas que habían decaído, bien en nuevos núcleos creados en torno a castillos o cruces de caminos -los propiamente llamados burgos-. Muchas de estas ciudades incorporaron ese nombre - Hamburgo, Magdeburgo, Friburgo, Estrasburgo; en España Burgo de Osma o Burgos-.
La burguesía estaba interesada en presionar al poder político (imperio, papado, las diferentes monarquías, la nobleza feudal local o instituciones eclesiásticas -diócesis o monasterios- de las que dependieran sus ciudades) para que se facilitara la apertura económica de los espacios cerrados de las urbes, se redujeran los tributos de portazgo y se garantizaran formas de comercio seguro y una centralización de la administración de justicia e igualdad de las normas en amplios territorios que les permitieran desarrollar su trabajo, al tiempo que garantías de que los que vulnerasen dichas normas serían castigados con igual dureza en los distintos territorios.
Aquellas ciudades que abrían las puertas al comercio y a una mayor libertad de circulación, veían incrementar la riqueza y prosperidad de sus habitantes y las del señor, por lo que con reticencias pero de manera firme se fue difundiendo el modelo. Las alianzas entre señores eran más comunes, no ya tanto para la guerra, como para permitir el desarrollo económico de sus respectivos territorios, y el rey fue el elemento aglutinador de esas alianzas.
Los burgueses pueden considerarse como hombres libres en cuanto estaban parcialmente fuera del sistema feudal, que literalmente los asediaba -se ha comparado a las ciudades con islas en un océano feudal-,[58]​ porque no participaban directamente de las relaciones feudo-vasalláticas: ni eran señores feudales, ni campesinos sometidos a servidumbre, ni hombres de iglesia. La sujeción como súbdito del poder político era semejante a un lazo de vasallaje, pero más bien como señorío colectivo que hacía que la ciudad respondiera como un todo a las demandas de apoyo militar y político del rey o del gobernante a la que estuviera vinculada, y que a su vez participara en la explotación feudal del campo circundante (alfoz en España).
La expresión alemana Stadtluft macht frei "Los aires de la ciudad dan libertad", o "te hacen libre"[Nota 15]​ (paráfrasis de la frase evangélica "la verdad os hará libres"),[60]​ indicaba que quienes podían radicarse en las ciudades, a veces huyendo literalmente de la sujeción de la servidumbre. El siervo huido se consideraba libre de retornar con su señor si conseguía domiciliarse en una corporación urbana por un año y un día.[61]​ tenían todo un nuevo mundo de oportunidades que explotar, aunque no en régimen de libertad, entendida esta en su forma contemporánea. La sujeción a las normas gremiales y a las leyes urbanas podía ser más dura incluso que las del campo: la pax urbana significaba la rigidez en la aplicación de la justicia, que mantenía los caminos y las puertas de entrada flanqueados con cadáveres de ajusticiados y un severo toque de queda, con cierre de puertas al anochecer y rondas de vigilancia. Eso sí: concedía a los burgueses la oportunidad de ejercer parcela de poder, incluyendo el uso de las armas en la milicia urbana (como las hermandades castellanas que se unificaron en la Santa Hermandad ya en el siglo XV), que en no pocas ocasiones se utilizaron en contra de las huestes feudales, con el beneplácito de las emergentes monarquías autoritarias. En el caso más precoz y espectacular fueron las comunas italianas, que se independizaron de hecho del Sacro Imperio Romano Germánico a partir de la batalla de Legnano (1176).

En los burgos surgieron muchas instituciones sociales nuevas. El desarrollo del comercio llevó aparejado consigo el del sistema financiero y la contabilidad. Los artesanos se unieron en asociaciones llamadas gremios, ligas, corporaciones, cofradías, o artes, según el lugar geográfico. El funcionamiento interno de los talleres gremiales implicaba un aprendizaje de varios años del aprendiz a cargo de un maestro (el dueño del taller), que implicaba el paso de aquel a la condición de oficial cuando demostrara conocer el oficio, lo que implicaba su consideración como trabajador asalariado, una condición de por sí ajena al mundo feudal que incluso se trasladó al campo (en principio de manera marginal) con los jornaleros que no disponían de tierras propias ni concedidas por el señor. La asociación de los talleres en los gremios, funcionaba de manera completamente contraria al mercado libre capitalista: se procuraba evitar todo rasgo posible de competencia fijando los precios, las calidades, los horarios y condiciones de trabajo, e incluso las calles donde podían radicarse. La apertura de nuevos talleres y el paso del rango de oficial al de maestro estaban muy restringidos, de modo que en la práctica se incentivaban las herencias y los enlaces matrimoniales endogámicos dentro del gremio. El objetivo era conseguir la supervivencia de todos, no el éxito del mejor.
Más apertura demostró el comercio. Los buhoneros que iban de aldea en aldea, y los escasos aventureros que se atrevían a hacer viajes más largos eran los mercaderes más habituales de la Alta Edad Media, antes del año 1000. En tres siglos, para comienzos del siglo XIV las ferias de Champaña y de Medina habían creado rutas terrestres estables y más o menos seguras que (a lomos de mulas o con carretas en el mejor de los casos) recorrían Europa de norte a sur (en el caso castellano siguiendo las cañadas trashumantes de la Mesta, en el caso francés enlazando los emporios flamenco y norte-italiano a través de las prósperas regiones borgoñonas y renanas, todas ellas salpicadas de ciudades). La Hansa o liga hanseática estableció a su vez rutas marítimas de una estabilidad y seguridad similar (con mayor capacidad de carga, en barcos de tecnología innovadora) que unían el Báltico y el mar del Norte a través de los estrechos escandinavos, conectando territorios tan lejanos como Rusia y Flandes y rutas fluviales que conectaban todo el norte de Europa (ríos como el Rin y el Vístula), permitiendo el desarrollo de ciudades como Hamburgo, Lübeck y Danzing, y estableciendo consulados comerciales denominados kontor.[62]​ En el Mediterráneo se llamaron Consulado del Mar: el primero en Trani en 1063 y luego Pisa, Mesina, Chipre, Constantinopla, Venecia, Montpellier, Valencia (1283), Mallorca (1343) y Barcelona (1347).[63]​ Cuando el estrecho de Gibraltar fue seguro, se pudieron conectar marítimamente ambas Europas, con rutas entre las ciudades italianas (sobre todo Génova), Marsella, Barcelona, Valencia, Sevilla, Lisboa, los puertos del Cantábrico (Santander, Laredo, Bilbao), los del Atlántico francés y los del canal de la Mancha (ingleses y flamencos, sobre todo Brujas y Amberes). El contacto cada vez más fluido de gentes de distintas naciones (como comenzaron a llamarse a las agrupaciones de comerciantes de cercano origen geográfico que se entendían en la misma lengua vulgar, al igual que ocurría en las secciones de las órdenes militares) terminó produciendo que ambas instituciones funcionaran de hecho, como primitivas organizaciones internacionales.
Todo ello desarrolló un incipiente capitalismo comercial (véase también Historia del capitalismo) con el incremento o surgimiento ex novo de la economía monetaria, la banca (crédito, préstamos, seguros, letras de cambio), actividades que mantuvieron siempre recelos morales (pecado de usura para todas las que significara lucro indebido, y en que únicamente podían incurrir los judíos cuando prestaban a otros que no fueran de su religión, oficio prohibido tanto a los cristianos como a los musulmanes). La aparición de burgueses ricos y de una plebe urbana pobre originó un nuevo tipo de tensiones sociales, que produjeron revueltas urbanas.[64]​ En cuanto a los aspectos ideológicos, la expresión del inconformismo burgués con su puesto marginal en la sociedad feudal está en el origen de las herejías a lo largo de toda la Baja Edad Media (cátaros, valdenses, albigenses, dulcinianos, hussitas, wycliffianos). Los intentos de responder a esas demandas del mundo urbano por parte de la Iglesia, así como de controlarlas y en su caso reprimirlas, produjeron la aparición de las órdenes mendicantes (franciscanos y dominicos) y de la Inquisición. A veces, la imposibilidad de conseguir el control hizo optar por el exterminio, como ocurrió en Beziers en 1209, siguiendo la respuesta del legado pontificio Arnaud Amaury:[65]​

 


=== Nuevas entidades políticas ===


==== Poderes universales, monarquías feudales y ciudades-Estado ====
En la Plena Edad Media se observó una gran disparidad en la escala a que se ejercía el poder político: los poderes universales (Pontificado e Imperio) seguían reivindicando su primacía frente a las Monarquías feudales, que en la práctica funcionaban como estados independientes. Al mismo tiempo, entidades mucho más pequeñas en extensión demostraban ser muy dinámicas en las relaciones internacionales (las ciudades-estado italianas y las ciudades libres del Imperio Germánico), y el municipalismo demostró ser una fuerza muy a tener en cuenta en todos los territorios de Europa.[67]​
El redescubrimiento del Digesto justinianeo (Digestum Vetus) permitió el estudio autónomo del Derecho (Pepo e Irnerio) y el surgimiento de la Escuela de los Glosadores y de la Universidad de Bolonia (1088). Ese suceso, que permitirá el redescubrimiento paulatino del Derecho romano, llevará a la formación del llamado Corpus Iuris Civilis y a la posibilidad de plantear un Ius commune (Derecho común), y justificar la concentración de poder y capacidad reglamentaria en la institución imperial, o en los monarcas, cada uno de los cuales empezará a considerarse como imperator in regno suo ("emperador en su reino", definiciones de Bártolo de Sassoferrato y Baldo degli Ubaldi).

 

La difícil convivencia de Pontificado e Imperio (regnum et sacerdocium) a lo largo de los siglos dio origen entre 1073 y 1122 a la querella de las investiduras. Distintas formulaciones ideológicas (teoría de las dos espadas, Plenitudo potestatis, Dictatus papae, condenas de la simonía y el nicolaísmo) constituían un edificio levantado durante siglos por el que el papa pretendía marcar la supremacía de la autoridad religiosa sobre el poder civil (lo que se ha venido denominando agustinismo político), mientras que el Emperador pretendía hacer valer la legitimidad de su cargo, que pretendía derivar del antiguo Imperio romano (Translatio imperii), así como el hecho material de su capacidad militar para imponer su poder territorial e incluso tutelar la vida religiosa (tanto en los aspectos institucionales como los dogmáticos), a semejanza de su equivalente en Oriente. El acceso de distintas dinastías a la dignidad imperial debilitó el poder de los emperadores, sujetos a un sistema de elección que les hacía dependientes de un delicado juego de alianzas entre los dignatarios que alcanzaron el título de príncipe elector, unos laicos (príncipes territoriales, independientes en la práctica) y otros eclesiásticos (obispos de ciudades libres). No obstante, periódicamente se asistía a intentos de recuperar el poder imperial (Otón III y Enrique II entre los últimos otónidas), que en ocasiones llegaban a enfrentamientos espectaculares (Enrique IV, de la dinastía salia, o Federico I Barbarroja y Federico II de la dinastía Hohenstaufen). La oposición entre güelfos y gibelinos, cada uno asociado a uno de los poderes en liza (papa y emperador), presidió la vida política de Alemania e Italia desde el siglo XII hasta bien entrada la Baja Edad Media.
Ambas pretensiones distaron mucho de hacerse efectivas, agotadas en su propio debate y superadas por la mayor eficacia política de las entidades urbanas y los reinos del resto de Europa.[69]​


==== Parlamentarismo ====
Apareció el parlamentarismo, una forma de representación política que con el tiempo se convirtió en el precedente de la división de poderes consustancial a la democracia de la Edad Contemporánea. La primacía en el tiempo la tiene el Alþingi islandés (930), que seguía el modelo de los thing o asambleas de guerreros germanos; pero desde finales del siglo XI se fue gestando un nuevo modelo institucional, derivado de la obligación feudal de consilium, que implicaba a los tres órdenes feudales, y se generalizó por Europa occidental: las Cortes de León (1188), el Parlamento inglés (1258) -previamente las relaciones de poder entre rey y nobleza habían sido reguladas en la Carta EMagna, 1215, o las Provisiones de Oxford, 1258- y los Estados Generales franceses (1302).


=== La Reforma Gregoriana y las reformas monásticas ===

Hildebrando de Toscana, ya desde su posición bajo los pontificados de León IX y Nicolás II, y más tarde como papa Gregorio VII (con lo que cubre toda la segunda mitad del siglo XI), emprendió un programa de centralización de la Iglesia, con la ayuda de los benedictinos de Cluny, que se extendieron por toda Europa Occidental implicando a las monarquías feudales (||sdestacadamente en los reinos cristianos peninsulares, a través del Camino de Santiago).
Las siguientes reformas monásticas, como la cartuja (San Bruno) y sobre todo la cisterciense (San Bernardo de Claraval) significarán nuevos fortalecimientos de la jerarquía eclesiástica y su implantación dispersa en todo el territorio europeo como una impresionante fuerza social y económica ligada a las estructuras feudales, vinculada a las familias nobles y a las dinastías regias y con una base de riqueza territorial e inmobiliaria, a la que se añadía el cobro de los derechos propios de la Iglesia (diezmos, primicias, derechos de estola, y otras cargas locales, como el voto de Santiago en el noroeste de España).
El fortalecimiento del poder papal intensificó las tensiones políticas e ideológicas con el Imperio Germánico y con la Iglesia oriental, que en este caso terminarán llevando al Cisma de Oriente.
Las Cruzadas trajeron como consecuencia la creación de un tipo especial de órdenes religiosas, que, además de someterse a una regla monástica (habitualmente la cisterciense, incluyendo el cumplimiento teórico de los votos monásticos) exigían a sus componentes una vida castrense más que ascética: fueron las órdenes militares, fundadas tras la toma de Jerusalén en 1099 (caballeros del Santo Sepulcro, templarios -1104- y hospitalarios -1118-). También se constituyeron en otros contextos geográficos (órdenes militares españolas y caballeros teutónicos).
La adaptación a la pujante vida urbana de los siglos XII y XIII será misión de un nuevo ciclo de fundaciones en el clero regular: las órdenes mendicantes, cuyos miembros no eran monjes, sino frailes (franciscanos de San Francisco de Asís y dominicos de Santo Domingo de Guzmán, a las que siguieron otras, como los agustinos); y de nuevas instituciones: las Universidades y la Inquisición.


==== Innovaciones dogmáticas y devocionales ====

A partir del siglo XI y el siglo XII se introdujeron en el cristianismo latino innovaciones dogmáticas y devocionales de gran trascendencia:
La imposición del rito romano frente a la anterior multiplicidad de liturgias (rito hispánico, rito bracarense, rito ambrosiano, etc.)
La imposición del celibato sacerdotal en el Concilio de Letrán (1123).
El hallazgo del papel del purgatorio como estadio intermedio de las almas entre cielo e infierno, que intensificará la función intermediadora de la Iglesia a través de las oraciones y misas y los méritos de la Comunión de los Santos por ella administrados.


==== Mariología ====
La intensificación del papel de la Virgen María, que pasa a ser una corredentora con atributos investigados por la mariología y aún no dogmatizados (Inmaculada Concepción, Asunción de la Virgen), con nuevas devociones y oraciones (Avemaría, yuxtaposición de textos evangélicos que se introduce en occidente en el; Salve, adoptada por Cluny en 1135; y Rosario, introducido por Santo Domingo contra los albigenses), una fiebre de fundaciones de iglesias en su nombre, y con un amplísimo tratamiento artístico. En la época del amor cortés la devoción a la Virgen apenas podía distinguirse, al menos en las formas, de la que el caballero sentía por su dama.[Nota 16]​
La mariología había nacido en la Antigüedad tardía con la patrística, y el culto popular de la virgen fue uno de los factores clave de la suave transición del paganismo al cristianismo, que suele interpretarse como una adaptación del patriarcal monoteísmo del judaísmo al matriarcal panteón de las diosas-vírgenes-madre del Mediterráneo clásico: la cananea Astarté, la babilonia Istar, las griegas Rea y Gaia, la frigia Cibeles, la Artemisa de Éfeso, la Deméter de Eleusis, la egipcia Isis, etc., si bien "hay dos diferencias fundamentales entre el culto cristiano a María y los cultos paganos: la clara conciencia de la absoluta trascendencia de Dios, que opera como factor que elimina cualquier tendencia idolátrica y la oposición por parte del cristianismo a una divinización de la vida que ponga en peligro el carácter absolutamente libre de la decisión creadora de Dios".[Nota 17]​ La controversia Cristotokos-Theotokos (María como "Madre de Cristo" o "Madre de Dios"), y el amplio tratamiento de esta en el arte bizantino habían caracterizado a la iglesia oriental. El protagonismo de la Virgen quedaba ampliamente compensado con la misoginia del tratamiento de otras figuras femeninas, destacadamente Eva, la Magdalena y Santa María Egipcíaca. La renuncia al cuerpo (la carne enemiga del alma) y a las riquezas, que da oportunidad al arrepentimiento y la redención (y confía su gestión a la Madre Iglesia) solía ser el aspecto más destacable también en las vidas de otras santas y mártires.[71]​


==== Sacramentos y cohesión social. Minorías religiosas ====

Por último, la institucionalización de los sacramentos, especialmente la penitencia y la comunión pascual que se plantean como trámites anuales que el fiel ha de cumplir ante su párroco y confesor. La vivencia comunitaria de los sacramentos, sobre todo los que significan cambios vitales (bautismo, matrimonio, extrema unción), y los rituales funerarios, cohesionaban fuertemente a las sociedades locales tanto aldeanas como urbanas, sobre todo cuando se enfrentaban a la convivencia con otras comunidades religiosas —judíos en toda Europa y musulmanes en España—.
La celebración de las festividades en días distintos (viernes los musulmanes, sábados los judíos, domingos los cristianos), los distintos tabúes alimentarios (cerdo, alcohol, rituales de matanza que obligan a separar las carnicerías) y la separación física de las comunidades -guetos, aljamas o juderías y morerías- planteaban una situación que, incluso con tolerancia religiosa, distaba mucho de ser un trato igualitario. Los judíos cumplieron una función social de chivo expiatorio que dio salida a las tensiones sociales en determinados momentos, con el estallido de pogromos (revueltas antijudías, que tras la conversiones masivas dieron paso a revueltas anticonversas) o con las políticas de expulsión (Inglaterra -1290-, Francia -1394- y España -1492- y Portugal en 1496). La existencia de minorías religiosas dentro del cristianismo, en cambio, no podía ser aceptada, puesto que la comunidad política se identificaba con la unidad en la fe. Los definidos como herejes, por tanto, eran perseguidos por todos los medios.


==== Delito, pecado y sexo ====
En cuanto a las desviaciones del comportamiento que no supusieran desafíos de opinión sino delitos o pecados (conceptos identificables y de imposible deslindamiento), su tratamiento era objeto de las jurisdicciones civil (que aplicaba el fuero correspondiente, la legislación del reino o el derecho común) y religiosa (que aplicaba el Derecho Canónico en cuestiones ordinarias, o el procedimiento inquisitorial en caso necesario), cuya coordinación era a veces compleja, como ocurría con las desviaciones de la conducta sexual considerada correcta (masturbación, homosexualidad, incesto, estupro, amancebamiento, adulterio y otros asuntos matrimoniales).[72]​ En cualquier caso, la vivencia de la sexualidad y la desnudez del cuerpo tuvo tratamientos muy distintos en cada época y lugar; y diferentes expectativas para cada nivel social (se consideraba que era propio de los campesinos un comportamiento animal, es decir, natural, y se pretendía que los nobles y clérigos tuvieran más voluntad para controlar sus instintos).
También costumbres como los baños (conocidos desde las termas romanas y reintroducidos por los árabes) y prácticas como la prostitución fueron objeto de críticas morales y reglamentaciones más o menos permisivas, llegando en el caso de los baños progresivamente hasta la prohibición (se les acusaba de inmorales y de producir el afeminamiento de los guerreros), y en el de la prostitución al confinamiento en determinados barrios, la obligación de llevar determinadas prendas y la detención de sus actividades en determinadas fechas (Semana Santa). La erradicación de la prostitución no se concebía posible, dado lo inevitable del pecado, y su papel de mal menor que evitaba que el deseo irrefrenable de los varones fuera en contra del honor de las doncellas y las mujeres respetables. Por lo general, los historiadores suelen coincidir que el periodo de la Plena Edad Media fue una etapa de mayor libertad de costumbres que no tuvo que esperar a El Decamerón (1348), y que en algunas cuestiones, como la condición femenina, significó una verdadera promoción, tanto frente a la Alta Edad Media como frente a la Edad Moderna;[73]​ aunque el extendido mito de que se llegara a dudar si la mujer tenía alma es un error filológico.[74]​


=== Expansión geográfica de la Europa feudal ===

La expansión geográfica se llevó a cabo, o se intentó llevar a cabo, al menos, en varias direcciones, siguiendo no tanto un propósito determinado por concepciones nacionalistas inexistentes en la época, sino la dinámica propia de las casas feudales. Los normandos, vikingos asentados en Normandía, dieron origen a una de las casas feudales más expansivas de Europa, que se extendió por Francia, Inglaterra e Italia, enlazada con las de Anjou-Plantagenet y Aquitania. Las casas de Navarra y Castilla (dinastía Jimena), Francia, Borgoña y Flandes (Capetos, Casa de Borgoña —extendida por la península ibérica—, Valois) y Austria (casa de Habsburgo) son otros buenos ejemplos, y todas ellas se vieron vinculadas por alianzas, enlaces matrimoniales y enfrentamientos sucesorios o territoriales, consustanciales a las relaciones feudo-vasalláticas y expresión de la violencia inherente al feudalismo.[75]​ En el contexto espacial de la Europa nórdica y centro-oriental tuvieron un desarrollo similar la Casa de Sweyn Estridsson danesa, la Bjälbo noruega y los Sverker y Erik suecos; y más tarde la Dinastía Jogalia o Jagellón (Hungría, Bohemia, Polonia y Lituania).
En España, simultáneamente a la disolución del Califato de Córdoba (en guerra civil desde el 1010 y extinguido el 1031), se creó un vacío de poder que los reinos feudales cristianohispánicos de Castilla, León, Navarra, Portugal y Aragón (fusionado dinásticamente con el condado de Barcelona) intentaron aprovechar, expandiéndose frente a los reinos de taifas musulmanes en la llamada Reconquista. En las islas británicas, el reino de Inglaterra intentó repetidas veces invadir a Gales, Escocia e Irlanda, con mayor o menor éxito.

En Europa del Norte, acabadas las invasiones de los vikingos, las riquezas saqueadas por estos sirvieron para adquirir productos y servicios occidentales, creando en el mar Báltico una próspera red comercial que atrajo a los escandinavos a la civilización occidental, mientras su expansión hacia el oeste por el Atlántico (Islandia y Groenlandia) no pasó de la mítica Vinlandia (asentamiento fracasado en América del Norte, en torno al año 1000). Los vikingos orientales, (varegos), fundaron numerosos reinos en la Rusia europea y llegaron hasta Constantinopla. Los vikingos occidentales (normandos) se instalaron en Normandía, Inglaterra, Sicilia y el sur de la actual Italia, creando reinos centralizados y eficientes (Rolón, Guillermo el Conquistador y Roger I de Sicilia). En el este, en el año 955, Otón el Grande batió a los húngaros en la batalla del Río Lech y reincorporó Hungría a Occidente, al tiempo que comenzaba la germanización de Polonia, hasta entonces pagana. Posteriormente, desde tiempos de Enrique el León (siglo XII), los alemanes se fueron abriendo paso a través de las tierras de los vendos, hasta el mar Báltico, en un proceso de colonización conocido como Ostsiedlung (que será mitificado posteriormente con el romántico nombre de Drang nach Osten, o Afán de ir hacia el Este, lo que sirvió para justificar la teoría nazi del espacio vital alemán Lebensraum). Pero sin lugar a dudas, el movimiento de expansión más espectacular, aunque finalmente fallido, fueron las Cruzadas, en donde selectos miembros de la nobleza guerrera occidental cruzaron el mar Mediterráneo e invadieron el Medio Oriente, creando reinos de efímera duración.


==== Las Cruzadas ====

Las Cruzadas fueron expediciones emprendidas, en cumplimiento de un solemne voto, para liberar Tierra Santa de la dominación musulmana. El origen de la palabra remonta a la cruz hecha de tela y usada como insignia en la ropa exterior de los que tomaron parte en esas iniciativas, a partir de la petición del papa Urbano II y las predicaciones de Pedro el Ermitaño. Las sucesivas cruzadas tuvieron lugar entre los siglos XI y XIII. Fueron motivadas por los intereses expansionistas de la nobleza feudal, el control del comercio con Asia y el afán hegemónico del papado sobre las iglesias de Oriente.


==== Balance de la expansión geográfica ====

El balance de esta expansión fue espectacular, por comparación a la vulnerabilidad de la oscura época anterior: Tras medio siglo de instituciones carolingias, hacia 843 (Tratado de Verdún), los territorios que podían identificarse más o menos próximamente con ellas (lo que podría denominarse una formación social cristiano occidental) se extendían por Francia, el oeste y sur de Alemania, el sur de Gran Bretaña, las montañas septentrionales de España y el norte de Italia. Un siglo después, en la época de la batalla del Río Lech (955), no había región de Europa Occidental a salvo de las nuevas oleadas de invasores bárbaros, que parecían conducir a una nueva crisis de civilización.[Nota 18]​
Sin embargo, en los dos siglos siguientes al fatídico año mil el panorama había cambiado completamente: para la época de la batalla de Navas de Tolosa (1212), habían sido incorporadas a la civilización europea toda Italia hasta Sicilia, la Gran Bretaña no inglesa (Escocia y Gales), Escandinavia (que se expandía por el Atlántico Norte hasta Groenlandia), buena parte de Europa Oriental (Polonia, Bohemia, Moravia y Hungría, quedando los pueblos eslavos de los Balcanes y Rusia en la órbita del cristianismo oriental e institucionalizando sus propios reinos) y media península ibérica (en el transcurso del siglo XIII lo sería toda excepto el tributario reino nazarí de Granada, quedando marcado definitivamente el predominio cristiano sobre el estrecho de Gibraltar con la batalla del Salado -1340-). Otros territorios periféricos (como Lituania o Irlanda) estaban sometidos a una presión militar cada vez mayor por parte de los reinos centrales de la cristiandad latina. Más allá de los límites de Europa Occidental, las incursiones militares de huestes latinas de muy variada composición habían puesto en sus manos lugares tan lejanos como Constantinopla y los ducados Atenas y de Neopatria o Jerusalén y los Estados Cruzados.


=== Cristianos, musulmanes y judíos en la península ibérica ===

		
			
			
		
		
			
			
		
		
			
			
		


== Baja Edad Media (siglos XIV y XV) ==

La Baja Edad Media es un término que a veces produce confusión, pues procede de un equívoco etimológico entre alemán y castellano: baja no significa decadente, sino reciente; por oposición al alta de la Alta Edad Media, que significa antigua (en alemán alt: viejo, antiguo).[76]​ No obstante, es cierto que desde alguna perspectiva historiográfica puede verse al conjunto del periodo medieval como el ciclo de nacimiento, desarrollo, auge e inevitable caída de una civilización, modelo interpretativo que inició Gibbon para el Imperio romano (donde es más obvia la oposición entre Alto Imperio y Bajo Imperio) y que se ha aplicado con mayor o menor fortuna a otros contextos históricos y artísticos.[Nota 19]​
El símil astronómico de ocaso, que Johan Huizinga convierte en otoño, es utilizado con mucha frecuencia en la historiografía, con un valor analógico que más que una decadencia en lo económico o lo intelectual refleja un claro agotamiento de los rasgos específicamente medievales frente a sus sustitutos modernos.[77]​


=== La crisis del siglo XIV ===

El final de la Edad Media llega con el comienzo de la transición del feudalismo al capitalismo, otro periodo secular de transición entre modos de producción que no finalizará hasta el final del Antiguo Régimen y el comienzo de la Edad Contemporánea, con lo que tanto este último periodo medieval como la Edad Moderna entera cumplen un papel similar y cubren una similar extensión temporal (500 años) a lo que significó la Antigüedad Tardía para el comienzo de la Edad Media.
La ley de rendimientos decrecientes empezó a mostrar sus efectos a medida que el dinamismo de los campesinos forzó la roturación de tierras marginales y las lentas mejoras técnicas no podían sucederse a un ritmo semejante. La coyuntura climática cambió, acabando con el denominado óptimo medieval que permitió la colonización de Groenlandia y el cultivo de vides en Inglaterra. Las malas cosechas condujeron a hambrunas que debilitaron físicamente a las poblaciones, preparando el terreno para que la Peste negra de 1348 fuera una catástrofe demográfica en Europa. La repetición sucesiva de epidemias caracterizó un ciclo secular.


=== Consecuencias de la crisis ===

Las consecuencias no fueron negativas para todos. Los supervivientes acumularon inesperadamente capital en forma de herencias, que pudo en algunos casos invertirse en empresas comerciales, o acumularon inesperadamente patrimonios nobiliarios. Las alteraciones de los precios de mercado de los productos, sometidos a tensiones nunca vistas de oferta y demanda cambió la forma de percibir las relaciones económicas: los salarios (un concepto, como el de circulación monetaria ya de por sí disolvente de la economía tradicional) crecían al tiempo que las rentas feudales pasaron a ser inseguras, obligando a los señores a decisiones difíciles. Alternativamente primero tendieron a ser más comprensivos con sus siervos, que a veces estuvieron en situación de imponer una nueva relación, liberados de la servidumbre; mientras que en un segundo momento, sobre todo tras algunas rebeliones campesinas fracasadas y duramente reprimidas, impusieron en algunas zonas una nueva refeudalización, o cambios de estrategia productiva como el paso de la agricultura a la ganadería (expansión de la Mesta).[5]​
El negocio lanero produjo curiosas alianzas internacionales e interestamentales (señores ganaderos, mercaderes de la lana, artesanos de paños) que suscitaron verdaderas guerras comerciales (en ese sentido se ha podido interpretar las cambiantes alianzas y divisiones internas Inglaterra-Francia-Flandes durante la guerra de los Cien Años, en la que Castilla se implicó en su propia guerra civil).[78]​ Únicamente los nobles con más capacidad (demostrada la mayor parte de las veces por el despojo de nobles con menos capacidad) pudieron convertirse en una gran nobleza o aristocracia de grandes casas nobiliarias, mientras que la pequeña nobleza se empobrecía, reducida a la mera supervivencia o a la búsqueda de nuevos tipos de ingresos en la creciente administración de las monarquías, o a los tradicionales de la Iglesia.
En las instituciones del clero también se va abriendo un abismo entre el alto clero de obispos, canónigos y abades y los curas de parroquias pobres; y el bajo clero de frailes o clérigos vagabundos, de opiniones teológicas difusas, o bien supervivientes materialistas en la práctica, goliardos o estudiantes sin oficio ni beneficio.
En las ciudades, la alta burguesía y la baja burguesía viven un similar proceso de separación de fortunas, que hace imposible mantener que un aprendiz o incluso un oficial o un maestro de taller pobre tenga algo que ver con un mercader enriquecido por el comercio a larga distancia de la Hansa o las ferias de Champaña y de Medina, o un médico o un letrado salidos de la universidad para entrar en la alta sociedad. Se va abriendo paso la posibilidad (antes inaudita) de que la condición social dependa más de la capacidad económica (no necesariamente ligada siempre a la tierra) que del origen familiar.
Frente al mundo medieval de los tres órdenes, basado en una economía agraria y firmemente ligada a la posesión de la tierra, emerge un mundo de ciudades basado en una economía comercial. Los centros de poder se desplazan hacia los nuevos burgos. Estos reequilibrios se vieron reflejados en los campos de batalla, ya que los caballeros feudales empezaron a ser superados por el desarrollo de técnicas militares como el arco de tiro largo,[79]​ arma que los ingleses usaron para barrer a los franceses en la batalla de Agincourt, en 1415, o la pica, usada por la infantería de mercenarios suizos. Es en esta época cuando aparecen los primeros ejércitos profesionales, compuestos por soldados a los que no les une un pacto de vasallaje con su señor sino la paga. A partir del siglo XIII se registran en Occidente los primeros usos de la de pólvora, invención china extendida desde la India por los árabes, pero de forma muy discontinua. Roger Bacon la describe en 1216) y hay relatos del uso de armas de fuego en la defensa musulmana de Sevilla (1248) y Niebla (1262, véase El cañón en la Edad Media). Con el tiempo, el oficio militar se envilece, devaluando las funciones de la nobleza con las de la caballería y los castillos, que quedan obsoletos. El aumento de los costes y las tácticas de batallas y asedios traerá como consecuencia el aumento del poder del rey frente a la aristocracia. La guerra pasa a depender no de las huestes feudales, sino de los crecientes impuestos, pagados por los no privilegiados.


=== Nuevas ideas ===
Las nuevas ideas religiosas -que se adaptan mejor a la forma de vida de la burguesía que a la de los privilegiados- ya estuvieron en el fermento de las herejías que se habían producido previamente, a partir del siglo XII (cátaros, valdenses), y que habían encontrado eficaz respuesta en las nuevas órdenes religiosas mendicantes, insertas en el entorno urbano; pero en los últimos siglos medievales el husismo o el wycliffismo tienen una mayor proyección hacia lo que será la Reforma protestante del siglo XVI El milenarismo de los flagelantes convivía con el misticismo de Tomás de Kempis y con los desórdenes y corrupción de costumbres en la Iglesia que culminaron en el Cisma de Occidente. Fue devastador el impacto que tuvo en la cristiandad occidental el espectáculo de dos (y hasta tres) papas excomulgándose mutuamente (y a emperadores, reyes y obispos, y con ellos a todos sus sacerdotes y fieles), uno en la llamada cautividad de Aviñón a la que le sometía el rey de Francia (fille ainée de l'Eglise, hija mayor de la Iglesia), otro en Roma y un tercero elegido por el Concilio de Pisa (1409). La situación no se recondujo totalmente ni siquiera con el Concilio de Constanza (1413), que si hubieran prosperado las tesis conciliaristas se habría convertido en una especie de parlamento europeo supranacional, cuasi-soberano y competente en toda clase de temas. Hasta la humilde Peñíscola se llegó a convertir por algún tiempo en el centro del mundo cristiano -para los escasos seguidores del papa Luna-.
Los intentos de imprimir mayor racionalidad al catolicismo ya venían estando presentes desde la cumbre de la escolástica de los siglos XII y XIII con Pedro Abelardo, Tomás de Aquino o Roger Bacon; pero ahora esa escolástica se enfrenta a su propia crisis y cuestionamiento interno, con Guillermo de Ockham o Juan Duns Escoto. La mentalidad teocéntrica iba lentamente dando paso a una nueva antropocéntrica, en un proceso que culminará con el humanismo del siglo XV en lo que ya puede denominarse Edad Moderna. Ese cambio no se limitó únicamente a las élites intelectuales: personalidades extravagantes, como Juana de Arco, se convierten en héroes populares (con el contrapunto de otras terribles, como Gilles de Rais -Barba Azul-);[80]​ la mentalidad social va alejándose del conformismo temeroso para acoger otras concepciones que implican una nueva forma de afrontar el futuro y las novedades:

 

El anonimato conscientemente buscado en el que vivieron silenciosamente generaciones durante siglos

 

y que seguirá siendo la situación de los humildes durante los siglos siguientes, da paso a la búsqueda de la fama y de la gloria personal, no solo entre los nobles, sino en todos los ámbitos sociales: los artesanos comienzan a firmar sus productos (desde las obras de arte a las marcas artesanas), y cada vez es menos excepcional que cualquier acto de la vida deje su huella documental (libros parroquiales, registros mercantiles, escribanos, protocolos notariales, actos jurídicos).
El desafío al monopolio económico, social, político e intelectual de los privilegiados, creaba lentamente nuevos espacios de poder en beneficio de los reyes, así como un lugar cada vez más amplio para la burguesía. Aunque la mayor parte de la población siguió siendo campesina, lo cierto es que el impulso y las novedades ya no provenían del castillo o el monasterio, sino de la Corte y la ciudad. Entretanto, el amor cortés (procedente de la Provenza del siglo XI) y el ideal caballeresco se revitalizaron y pasaron a convertirse en una ideología justificativa del modo de vida nobiliario justo cuando este empezaba a estar en cuestión,[82]​ viviendo una época dorada, obviamente decadente, localizada en el período de esplendor del ducado de Borgoña, que reflejó Johan Huizinga en su magistral El otoño de la Edad Media.


=== El fin de la Edad Media en la península ibérica ===

Mientras que para el Mediterráneo Oriental el fin de la Edad Media supuso el avance imparable del islámico Imperio otomano, en el extremo occidental, los expansivos reinos cristianos de la península ibérica, tras un periodo de crisis y ralentización del avance secular hacia el sur, simplificaron el mapa político con la unión matrimonial de los Reyes Católicos (Fernando II de Aragón e Isabel I de Castilla), los acuerdos de estos con el de Portugal (Tratado de Alcáçovas, que suponían el reparto de influencias sobre el Atlántico) y la conquista de Granada. Navarra, dividida en una guerra civil entre bandos orientados e intervenidos por franceses y aragoneses, sería anexionada en su mayor parte a la creciente Monarquía Católica en 1512.

		
			
			
		
		
			
			
		
		
			
			
		
		
			
			
		


== Véase también ==
 Portal:Edad Media. Contenido relacionado con Edad Media.


== Notas ==


== Referencias ==


== Bibliografía ==


== Enlaces externos ==


=== Centros de investigación ===
Departament d'Història Medieval, Paleografia i Diplomàtica. Universitat de Barcelona. (en catalán)
Cuadernos de Historia Medieval. Universidad Autónoma de Madrid. Área de Historia Medieval.
Enlaces a webs de interés. Departamento de Historia Medieval. Universidad Complutense de Madrid.
Seminario de Estudios Medievales y Renacentistas. Universidad de Salamanca.
Departamento de Historia Medieval. Universidad de Sevilla
Revista d'Història Medieval, Departamento de Historia Medieval. Universidad de Valencia.
Departamento de Estudios Medievales. CSIC.
Instituto de Historia Antigua y Medieval "Prof. José Luis Romero" Archivado el 15 de septiembre de 2008 en Wayback Machine., Facultad de Filosofía y Letras, Universidad de Buenos Aires.
Edad Media: Revista de Historia, Departamento de Historia Antigua y Medieval, Universidad de Valladolid.


=== Artehistoria ===
Alta Edad Media.
Plena y Baja Edad Media.
Vida cotidiana en la Alta Edad Media.
Vida cotidiana en la Plena y Baja Edad Media.


=== Biblioteca Gonzalo de Berceo ===
Página principal
Florilegio medieval
Vida cotidiana en la Edad Media (Actas VIII Semana de Estudios Medievales, Nájera 1997)


=== Liceus ===
Repertorio de fuentes de la Edad Media Archivado el 7 de enero de 2009 en Wayback Machine.
Bibliografía general sobre la edad media Archivado el 28 de octubre de 2008 en Wayback Machine.
Bibliografía sobre economía medieval Archivado el 19 de septiembre de 2008 en Wayback Machine.
Bibliografía sobre el mundo rural en la edad media Archivado el 22 de junio de 2008 en Wayback Machine.
Bibliografía sobre concejos y ciudades Archivado el 4 de agosto de 2008 en Wayback Machine.
Bibliografía sobre señoríos y feudalismo Archivado el 31 de agosto de 2011 en Wayback Machine.
Bibliografía sobre sociedad medieval Archivado el 1 de diciembre de 2008 en Wayback Machine.
Bibliografía sobre cultura medieval Archivado el 7 de enero de 2009 en Wayback Machine.
Bibliografía sobre derecho medieval Archivado el 18 de junio de 2008 en Wayback Machine.
Bibliografía sobre la Iglesia en el medievo Archivado el 18 de junio de 2008 en Wayback Machine.
Bibliografía sobre instituciones medievales Archivado el 30 de agosto de 2008 en Wayback Machine.
Bibliografía sobre pueblos germánicos Archivado el 18 de junio de 2008 en Wayback Machine.
Bibliografía sobre Al-Andalus Archivado el 30 de julio de 2008 en Wayback Machine.


=== Foros y blogs ===
Sociedad Española de Estudios Medievales (SEEM)
MedWeb
Medievalismo.org Archivado el 10 de febrero de 2010 en Wayback Machine.
Medievalum.com
The Middle Ages Trust (en inglés)


=== Mapas ===
Mapa interactivo de la Edad Media Archivado el 4 de octubre de 2009 en Wayback Machine.


=== Otros ===
Curso "Historia Urbana Medieval" OCW Universidad de Cantabria
Curso "Historia de la Baja Edad Media" OCW Universidad de Cantabria
La Guerra Fría fue un enfrentamiento político, económico, social, ideológico, militar y propagandístico que tuvo lugar después de la Segunda Guerra Mundial entre dos bloques principales:  Occidental (capitalista) y Oriental (comunista). Estos bloques estaban liderados por los Estados Unidos y la Unión Soviética, respectivamente. El inicio de este periodo se remonta a 1945.
Después de la Segunda Guerra Mundial, los Estados Unidos temían la expansión del comunismo y buscaban frenar la influencia soviética en Europa. En 1949 crearon la alianza militar conocida como la Organización del Tratado del Atlántico Norte (OTAN). El objetivo principal de la OTAN era contrarrestar la influencia soviética y garantizar la seguridad de los países miembros.
En respuesta a la creación de la OTAN la Unión Soviética estableció el Pacto de Varsovia en 1955. Este pacto militar fue una respuesta directa al bloque occidental y buscaba fortalecer la cooperación entre los países comunistas.
A lo largo de la Guerra Fría, se produjeron varias crisis que aumentaron las tensiones entre ambos bloques. Algunas de las crisis más destacadas incluyeron el bloqueo de Berlín de 1948-1949, la segunda fase de la guerra civil china (1946-1949), la guerra de Corea (1950-1953), la crisis de Suez de 1956,  la insurrección húngara en el período del 23 de octubre al 10 de noviembre de 1956,  la crisis de Berlín de 1961 y la crisis de los misiles cubanos de 1962. 
Complementariamente al Pacto de Varsovia sus miembros constituyeron el CAME (Consejo de Ayuda Mutua Económica) y un mercado común (COMECOM). 
La Unión Soviética y Estados Unidos comenzaron a competir por la influencia en América, Oriente Próximo y los estados recién descolonizados de África y Asia, donde el comunismo tenía gran fuerza y donde se vivieron conflictos como la Emergencia Malaya o la guerra de Indochina, también conocida como guerra de Vietnam. 
Después de la crisis de los misiles cubanos, comenzó una nueva fase que vio cómo la ruptura sino-soviética —entre la República Popular China y la URSS— complicaba las relaciones dentro de la esfera comunista, mientras que Francia, aliado de los Estados Unidos, comenzó a exigir una mayor autonomía de acción, llegando incluso a abandonar la estructura militar de la OTAN.[1]​[2]​ La URSS invadió Checoslovaquia para reprimir la Primavera de Praga de 1968, mientras que Estados Unidos experimentó una agitación interna del movimiento de derechos civiles y oposición a la guerra de Vietnam. En las décadas de 1960 y 1970, un movimiento internacional por la paz se arraigó entre los ciudadanos de todo el mundo. Se produjeron movimientos contra las pruebas de armas nucleares y por el desarme nuclear, con grandes protestas contra la guerra. En la década de 1970 ambos comenzaron a hacer concesiones para la paz y la seguridad, marcando el comienzo de un período de distensión (o détente) que vio las conversaciones estratégicas de limitación de armas y las relaciones de apertura de los Estados Unidos con la República Popular China como un contrapeso estratégico para la URSS.  
Simultáneamente Estados Unidos desarrolló la Doctrina de la Seguridad Nacional, para prevenir "la expansión del comunismo" y promover en América Latina, a través del Plan Cóndor, la instalación de dictaduras militares que reprimieran mediante el terrorismo de Estado, los movimientos políticos, sociales, sindicales y estudiantiles de sus habitantes. 
La fase de estabilidad se derrumbó a finales de la década con la guerra de Afganistán de 1979. La década 1980 fue otro período de tensión elevada. Estados Unidos aumentó las presiones diplomáticas, militares y económicas contra la Unión Soviética, en un momento en que esta ya sufría un estancamiento económico. A mediados de la década de 1980, el nuevo líder soviético Mijaíl Gorbachov introdujo las reformas conocidas como Glásnost (1985) y Perestroika (1987) y puso fin a la participación soviética en Afganistán. Las presiones por la soberanía nacional se fortalecieron en Europa del Este, y Gorbachov se negó a apoyar militarmente a sus gobiernos por más tiempo en la llamada Doctrina Sinatra. El resultado en el 1989 fue una ola de revoluciones que (con excepción de Rumanía) derrocó pacíficamente los gobiernos comunistas de Europa Central y Oriental. El propio Partido Comunista de la Unión Soviética (PCUS) perdió el control del territorio y fue prohibido luego de un intento fallido de golpe de Estado en agosto de 1991 contra el gobierno anticomunista de Borís Yeltsin en la RSFS de Rusia. Esto a su vez condujo a la disolución formal de la URSS en diciembre del año 1991, con la declaración de independencia de sus repúblicas constituyentes y el colapso de los gobiernos comunistas en gran parte de África y Asia.


== Origen del término ==
A fines de la Segunda Guerra Mundial, el escritor inglés George Orwell usó «guerra fría» como un término general en su ensayo You and the Atomic Bomb (en español, «Tú y la bomba atómica»), publicado el 19 de octubre de 1945 en el periódico británico Tribune. En un mundo amenazado por la guerra nuclear, Orwell se refirió a las predicciones de James Burnham de un mundo polarizado y escribió:

 

El mismo Orwell escribió en el The Observer del 10 de marzo de 1946 que «después de la conferencia de Moscú en diciembre pasado, Rusia comenzó a hacer una guerra fría contra Reino Unido y el Imperio británico».[4]​
El primer uso del término para describir específicamente la confrontación geopolítica entre la Unión Soviética y los Estados Unidos de posguerra fue en un discurso de Bernard Baruch, un financiero e influyente asesor presidencial estadounidense, el 16 de abril de 1947.[5]​ En el discurso Baruch dijo: «no nos engañemos: estamos inmersos en una guerra fría». El término fue popularizado por el columnista Walter Lippmann con su libro The Cold War.[6]​ Cuando se le preguntó en 1947 sobre la fuente de la expresión, Lippmann lo remontó a la guerre froide, un término francés de los años treinta.[7]​


== Antecedentes ==

Existe un cierto desacuerdo sobre cuándo comenzó exactamente la Guerra Fría. Mientras que la mayoría de historiadores sostienen que empezó nada más acabar la Segunda Guerra Mundial, otros afirman que los inicios de la Guerra Fría se remontan al final de la Primera Guerra Mundial, en las tensiones que se produjeron entre el Imperio ruso, por un lado, y el Imperio británico y Estados Unidos, por el otro.[8]​ El choque ideológico entre el comunismo y el capitalismo empezó en 1917, tras el triunfo de la Revolución rusa, de la que Rusia emergió como el primer país socialista. Este fue uno de los primeros eventos que provocó erosiones considerables en las relaciones ruso-estadounidenses.[8]​
Algunos eventos previos al final de la I Guerra Mundial fomentaron las sospechas y recelos entre soviéticos y estadounidenses: la idea bolchevique en el cual el capitalismo debía ser derribado por la fuerza para ser reemplazado por un sistema comunista,[9]​ la retirada rusa de la I Guerra Mundial tras la firma del Tratado de Brest-Litovsk con el Segundo Reich, la intervención estadounidense en apoyo del Movimiento Blanco durante la guerra civil rusa y el rechazo estadounidense a reconocer diplomáticamente a la Unión Soviética hasta 1933.[10]​ Junto a estos diferentes acontecimientos durante el periodo de entreguerras agudizaron las sospechas: Acuerdos de Múnich, y la firma del pacto antikomintern esos dos son antecedentes de alianzas anticomunistas previas a la OTAN, la firma del Tratado de Rapallo y del Pacto germano-soviético de no agresión son otros ejemplos.[11]​


=== Segunda Guerra Mundial y la posguerra (1939-1947) ===
Para las etapas finales de la Segunda Guerra Mundial, los soviéticos comienzan a sospechar que británicos y estadounidenses (y viceversa), quienes habían optado por dejar a los rusos el grueso del esfuerzo bélico, forjarían una unión contra los soviéticos (Operación Impensable) una vez que la guerra estuviera decidida a favor de los Aliados, para forzar a la Unión Soviética a firmar un tratado de paz ventajoso para los intereses occidentales. Estas sospechas minaron las relaciones entre los aliados durante la fase final de la contienda.[12]​
Los Aliados no estaban de acuerdo en cómo deberían dibujarse las fronteras europeas tras la guerra.[13]​ El modelo estadounidense de estabilidad se basaba en la instauración de gobiernos y mercados económicos parecidos al estadounidense (capitalista), y la creencia de que los países así gobernados acudirían a organizaciones internacionales, como la recién creada ONU, para arreglar sus diferencias.[14]​
Sin embargo, los soviéticos creían que la estabilidad habría de basarse en la integridad de las propias fronteras de la Unión Soviética.[15]​ Este razonamiento nace de la experiencia histórica de los rusos, que habían sido invadidos desde el Oeste durante los últimos ciento cincuenta años.[16]​ El daño sin precedentes infligido a la Unión Soviética durante la invasión nazi (alrededor de veintisiete millones de muertos y una destrucción generalizada y casi total del territorio invadido)[17]​ conminó a los líderes soviéticos a asegurarse de que el nuevo orden europeo posibilitara la existencia a largo plazo del régimen soviético, y que este objetivo solo podría conseguirse mediante la eliminación de cualquier gobierno hostil a lo largo de la frontera occidental de la Unión, y el control directo o indirecto de los países limítrofes a esta frontera, para evitar la aparición de fuerzas hostiles en estos países.[13]​


==== Las conferencias ====

Durante la Conferencia de Yalta, en febrero de 1945, los aliados trataron de crear un marco sobre el que trabajar en la reconstrucción de la Europa de la posguerra, pero no se llegó a ningún consenso.[18]​ Tras el fin de la Segunda Guerra Mundial en Europa, los soviéticos ocuparon de facto las zonas de la Europa del Este que habían defendido, mientras que las fuerzas estadounidenses y sus aliados se mantenían en la Europa Occidental. En el caso de la Alemania ocupada, se crearon las zonas de ocupación aliada en Alemania y una difusa organización cuatripartita compartida con franceses y británicos. Para el mantenimiento de la paz mundial, los aliados crearon las Naciones Unidas, pero su capacidad de actuación estaba limitada por el Consejo de Seguridad, en el que las potencias victoriosas de la Segunda Guerra Mundial se aseguraron el poder de vetar aquellas acciones contrarias a sus intereses.[19]​ La ONU se convirtió así durante sus primeros años en un foro donde las potencias se enzarzaban en luchas retóricas, y que los soviéticos utilizaban con fines propagandísticos.[20]​
En la Conferencia de Potsdam, iniciada a finales de julio de 1945, emergieron las primeras diferencias relevantes acerca de Alemania y la Europa del Este;[21]​ Los participantes de la conferencia no ocultaron sus antipatías, y el uso de un lenguaje belicoso confirmó las intenciones mutuamente hostiles que defendían cada vez con más ahínco.[22]​ Durante esta conferencia, Truman informó a Stalin que los Estados Unidos habían creado una nueva arma. Stalin, que ya estaba al tanto de los avances estadounidenses en el desarrollo de la bomba atómica, expresó su deseo de que aquella nueva arma fuera usada contra Japón.[23]​ Una semana después de finalizar la conferencia, los Estados Unidos lanzaron la bomba atómica sobre Hiroshima y Nagasaki.


=== El Telón de Acero ===

En febrero de 1946, George Kennan escribió desde Moscú el conocido como Telegrama Largo, en el que se apoyaba una política de inflexibilidad con los soviéticos, y que se convertiría en una de las teorías básicas de los estadounidenses durante el resto de la Guerra Fría.[24]​ En septiembre de ese mismo año, los soviéticos respondieron con otro telegrama firmado por Nikolái Vasílievich Novikov, aunque escrito junto con Viacheslav Mólotov; en este telegrama se sostenía que Estados Unidos usaba su monopolio en el mundo capitalista para desarrollar una capacidad militar que creara las condiciones para la consecución de la supremacía mundial a través de una nueva guerra.[25]​
Semanas después de la recepción del «Telegrama Largo», el primer ministro británico Winston Churchill pronunció su famoso discurso sobre la Cortina de Hierro o Telón de Acero en una Universidad de Misuri.[26]​ El discurso trataba de promover una alianza anglo-estadounidense contra los soviéticos, a los que acusó de haber creado una «cortina de hierro» (iron curtain) desde Szczecin, en el Báltico, a Trieste, en el Adriático.[27]​


== De la teoría de la contención a la guerra de Corea (1947-1953) ==

Hacia 1947, los consejeros del presidente estadounidense Harry S. Truman le urgieron a tomar acciones para contrarrestar la creciente influencia de la Unión Soviética, citando los esfuerzos de Stalin para desestabilizar los Estados Unidos y azuzar las rivalidades entre los países capitalistas con el fin de provocar una nueva guerra.[28]​
En Asia, el ejército comunista chino había ocupado Manchuria durante el último mes de la Segunda Guerra Mundial y se preparaba para invadir la península coreana más allá del paralelo 38.[29]​ Finalmente, el ejército comunista de Mao Zedong, aunque fue poco receptivo a la escasa ayuda soviética, consiguió derrotar al prooccidental ejército nacionalista chino (Kuomintang), apoyado por Estados Unidos.[30]​


=== Europa ===
Desde finales de la década de 1940, la Unión Soviética consiguió instaurar gobiernos marioneta en Bulgaria, Checoslovaquia, Hungría, Polonia, Rumanía y Alemania Oriental, lo que le permitió mantener una fuerte presencia militar en estos países.[31]​ En febrero de 1947, el gobierno británico anunció que no podía seguir financiando al régimen militar griego contra los insurgentes comunistas en el contexto de la Guerra civil griega. El gobierno estadounidense puso en práctica por primera vez la Teoría de la Contención,[32]​ que tenía como objetivo frenar la expansión comunista, especialmente en Europa. Truman enmarcó esta teoría dentro de la Doctrina Truman, dada a conocer a través de un discurso del presidente en el que se definía el conflicto entre capitalistas y comunistas como una lucha entre «pueblos libres» y «regímenes totalitarios».[32]​


==== El Plan Marshall ====

En Estados Unidos, se extendió la idea de que el equilibrio de poder en Europa no se alcanzaría solo por la defensa militar del territorio, sino que también se necesitaba atajar los problemas políticos y económicos para evitar la caída de la Europa Occidental en manos comunistas.[31]​ Sobre la base de estas ideas, la Doctrina Truman sería complementada en junio de 1947 con la creación del Plan Marshall, un plan de ayudas económicas destinado a la reconstrucción de los sistemas político-económicos de los países europeos y, mediante el afianzamiento de las estructuras económicas capitalistas y el desarrollo de las democracias parlamentarias, frenar el posible acceso al poder de partidos comunistas en las democracias occidentales europeas (como en Francia o Italia). Asimismo, el Plan Marshall contribuyó a la remodelación de numerosas ciudades europeas que habían quedado destruidas por la Segunda Guerra Mundial.[33]​
Stalin vio en el Plan Marshall una táctica estadounidense para mermar el control soviético sobre la Europa Oriental. Creyó que la integración económica de ambos bloques permitiría a los países bajo órbita soviética escapar del control de Moscú, y que el Plan no era más que una manera que tenían los EE. UU. para «comprar» a los países europeos.[34]​ Por lo tanto, Stalin prohibió a los países de la Europa Oriental participar en el Plan Marshall. A modo de remiendo, Moscú creó una serie de subsidios y canales de comercio conocidos primero como el Plan Molotov, que poco después se desarrollaría dentro del COMECON.[10]​ Stalin también se mostró muy crítico con el Plan Marshall porque temía que dichas ayudas provocaran un rearme de Alemania, que fue una de sus mayores preocupaciones respecto al futuro de Alemania tras la guerra. Y parte de su control hacia el la parte oriental.


==== El bloqueo de Berlín ====

En 1948 como represalia por los esfuerzos de Estados Unidos por reconstruir la economía alemana, Stalin, quien temía que la población del Sector Soviético de Alemania se posicionase a favor del Bloque capitalista, cerró las vías terrestres de acceso a Berlín Oeste, imposibilitando la llegada de materiales y otros suministros a la ciudad.[35]​ Este hecho, conocido como el bloqueo de Berlín, precipitó una de las mayores crisis de principios de la Guerra Fría.
El puente aéreo organizado por Estados Unidos y el Reino Unido, destinado a proveer de suministros al bloqueado sector occidental de la ciudad, superó todas las previsiones, desbaratando la suposición soviética de que el sector occidental se rendiría ante el oriental por falta de suministros. Finalmente el bloqueo se levantó pacíficamente. Ambos bandos usaron este bloqueo con fines propagandísticos: los soviéticos para denunciar el supuesto rearme de Alemania favorecido por Estados Unidos, y los estadounidenses para explotar su imagen de benefactores. El mejor ejemplo de esto fue la llamada Operación Little Vittles, donde los aviones que contrarrestaban el bloqueo de Berlín lanzaron dulces entre los niños berlineses.
En julio, el presidente Truman anula el Plan Morgenthau, una serie de proposiciones acordadas con los soviéticos tras el fin de la guerra, que imponía severas condiciones a la reconstrucción alemana (entre ellas, la prohibición explícita de que los EE. UU. facilitaran ayudas a la reconstrucción del sistema económico alemán). Este plan fue sustituido por una nueva directiva (llamada JSC 1779) mucho más benévola con la reconstrucción alemana, y que enfatizaba la necesidad de crear una Alemania económicamente fuerte y estable para conseguir la prosperidad en toda Europa.[36]​


==== Kominform ====

En septiembre los soviéticos crean el Kominform, una organización cuyo propósito era mantener la ortodoxia ideológica comunista dentro del movimiento comunista internacional. En la práctica, se convirtió en un mecanismo de control sobre las políticas de los estados satélite soviéticos, coordinando el ideario y las acciones de los partidos comunistas del bloque del Este.[34]​ El Kominform tuvo que hacer frente a una inesperada oposición cuando, en junio del siguiente año, la ruptura Tito-Stalin obligó a expulsar a Yugoslavia de la organización, que mantuvo un gobierno comunista, pero se identificó como un país neutral dentro de la Guerra Fría.[37]​ Junto con el Kominform, la policía secreta soviética, el NKVD, se ocupaba de mantener una red de espionaje en los países satélite bajo el pretexto de acabar con elementos anticomunistas.[38]​ El NKVD (y sus sucesores) acabaron por convertirse en organizaciones parapoliciales encargadas de sesgar cualquier intento de alejarse de la órbita de Moscú y la ortodoxia soviético-comunista (ortodoxia: Conformidad con los principios de una doctrina o con las normas o prácticas tradicionales, aceptadas por la mayoría como las más adecuadas en un determinado ámbito).[39]​


==== La OTAN ====

En abril de 1949 se constituye la OTAN, con lo que los Estados Unidos tomaron formalmente la responsabilidad de defender la Europa Occidental, junto a los países europeos que se adhirieron a la OTAN.[38]​ En agosto de ese año, la Unión Soviética detona su primera bomba atómica.[10]​
En mayo de 1949, se establece la República Federal de Alemania como producto de la fusión de las zonas de ocupación aliada.[21]​ Como réplica, en octubre de ese año, los soviéticos proclaman su zona de ocupación como la República Democrática Alemana.[21]​ Desde el inicio de la existencia de la RFA, Estados Unidos ayuda a su desarrollo militar. Para evitar que la RFA acabe por convertirse en miembro de la OTAN, el primer ministro soviético, Lavrenti Beria, propone fusionar ambos países en una sola Alemania que se mantendría neutral.[40]​ La proposición no salió adelante y en 1955 se admite a la RFA como miembro de la OTAN.[21]​


=== Asia ===
Dentro de esta estrategia de generalización de la «contención», el teatro de operaciones se amplió de Europa a Asia, África y América Latina, con la intención de detener los movimientos revolucionarios, muchas veces financiados desde la Unión Soviética, como ocurría en el caso de las excolonias europeas del Sudeste Asiático.[41]​ A principios de la década de 1950, los EE. UU. formalizaron alianzas militares con Japón, Australia, Nueva Zelanda, Tailandia y Filipinas (alianzas englobadas en el ANZUS y el SEATO), garantizando a Estados Unidos una serie de bases militares a lo largo de la costa asiática del Pacífico.[21]​


==== Irán ====
En otoño de 1945 la Unión Soviética se negó a evacuar sus tropas del Azerbaiyán iraní, ocupado desde la Invasión anglosoviética de Irán en 1941 y donde el partido comunista Tudeh mantenía una república con gobierno propio. Debido a la influencia del Tudeh se declaró una huelga general en la refinería de Abadán, de la Anglo-Iranian Oil Company (anteriormente Anglo-Persian Oil Company). El gobierno se mantuvo firme y en octubre de 1946 caía Azerbaiyán. En enero de 1948 se suspendió la ley marcial tras siete años de aplicación. El 4 de febrero de 1949 se prohibió el Tudeh tras sufrir un atentado el sah Mohammad Reza Pahleví.


==== Guerra civil china ====

En 1949, el Ejército Rojo de Mao Zedong se proclama vencedor de la guerra civil china tras derrotar a los nacionalistas del Kuomintang, que contaban con el respaldo de Estados Unidos. Inmediatamente, la Unión Soviética establece una alianza con los vencedores, que habían creado un nuevo Estado comunista con la denominación de República Popular China.[42]​ Al coincidir en el tiempo la Revolución China con la pérdida del monopolio atómico de Estados Unidos (tras el inesperado éxito del RDS-1), la administración del presidente Truman trató de generalizar la Teoría de la Contención.[10]​ En un documento secreto fechado en 1950 (conocido como el NSC-68)[43]​ la administración de Truman proponía reforzar los sistemas de alianzas prooccidentales y cuadruplicar los gastos en Defensa.[10]​


==== Guerra de Corea ====

Uno de los ejemplos más significativos de la implementación de la contención fue la intervención estadounidense en la guerra de Corea. En junio de 1950, después de años de hostilidades mutuas, Corea del Norte, gobernada por Kim Il-sung invadió Corea del Sur a través del Paralelo 38. Stalin había sido reacio a apoyar la invasión, pero finalmente envió asesores y pilotos.[44]​ Para sorpresa de Stalin, las Resoluciones 82 y 83 del Consejo de Seguridad de las Naciones Unidas respaldaron la defensa de Corea del Sur, aunque los soviéticos estaban boicoteando reuniones en protesta por el hecho de que la República de China (Taiwán), no la República Popular de China, tenía un asiento permanente en el consejo.[45]​ Una fuerza de la ONU de dieciséis países[46]​ se enfrentó a Corea del Norte, aunque el 40 % de las tropas eran surcoreanas, y alrededor del 50 % eran de los Estados Unidos.[47]​
Estados Unidos inicialmente parecía seguir la contención cuando entró por primera vez en la guerra. Esto dirigió la acción de los EE. UU. Para hacer retroceder a Corea del Norte a través del paralelo 38 y restaurar la soberanía de Corea del Sur, permitiendo la supervivencia de Corea del Norte como estado. Sin embargo, el éxito del desembarco de Inchon inspiró a los Estados Unidos y las Naciones Unidas a adoptar una estrategia de reversión y derrocar a Corea del Norte comunista, lo que permitió elecciones a nivel nacional bajo los auspicios de la ONU.[48]​ El general Douglas MacArthur avanzó a través del paralelo 38 hasta Corea del Norte. Los chinos, temerosos de una posible presencia estadounidense en su frontera o incluso de una invasión de ellos, enviaron al Ejército Popular de Liberación y derrotaron a las fuerzas de la ONU, empujándolos nuevamente por debajo del paralelo 38. Truman insinuó públicamente que podría usar la bomba atómica, pero Mao no se conmovió. El episodio se usó para apoyar la sabiduría de la doctrina de la contención en oposición al retroceso. Los comunistas fueron empujados más tarde alrededor de la frontera original, con cambios mínimos. Entre otros efectos, la guerra de Corea impulsó a la OTAN a desarrollar una estructura militar unificada.[49]​


== Del aumento de las tensiones a la crisis de Cuba (1953-1962) ==

En 1953 se produjeron cambios en el liderazgo político de ambos bandos, que dieron comienzo a una nueva fase en la Guerra Fría.[50]​ En enero de 1953, Dwight D. Eisenhower fue investido presidente de EE. UU. Durante los últimos meses de la administración Truman, el presupuesto para Defensa se había cuadruplicado; Eisenhower pretendió reducir el gasto militar apoyándose en la superioridad nuclear estadounidense y en una gestión más efectiva de las situaciones provocadas por la Guerra Fría.[10]​
En marzo, muere Stalin, y Nikita Jrushchov se convierte en el nuevo líder de la Unión Soviética, tras haber depuesto y ejecutado al jefe de la NKVD, Lavrenti Beria, y finalmente al apartar del poder a Georgy Malenkov y Vyacheslav Molotov. El 25 de febrero de 1956, Jrushchov impresionó a los delegados del XX Congreso del PCUS al denunciar los crímenes cometidos por Stalin durante su discurso Acerca del culto a la personalidad y sus consecuencias. En el discurso se sostenía que la única manera de conseguir una reforma exitosa era siendo conscientes de los errores cometidos en el pasado apartándose de las políticas llevadas a cabo por Stalin.[50]​


=== Ruptura chino-soviética ===

Tras el cambio de líder en la Unión Soviética se produjeron numerosas fricciones con algunos de los aliados soviéticos más proclives al estalinismo o a la figura de Stalin. La más notable de estas discrepancias entre países comunistas se plasmó en la ruptura de la alianza chino-soviética. Mao Tse Tung defendió la figura de Stalin tras la muerte de este en 1953, y describió a Jrushchov como un arribista superficial, acusándolo de haber perdido el perfil revolucionario del Estado.[51]​
Jrushchov se obcecó en reconstruir la alianza chino-soviética, pero Mao consideró que sus propuestas eran inútiles y descartó cualquier tipo de proposición.[51]​ Chinos y soviéticos comenzaron un despliegue propagandístico dentro de la propia esfera comunista[52]​ que acabaría convirtiéndose en una lucha por el liderazgo del movimiento comunista internacional,[53]​ hasta llegar tres años más tarde al enfrentamiento militar directo en la frontera que ambas potencias compartían.[54]​


=== Aumento de las tensiones ===
El 18 de noviembre de 1956, durante un discurso frente a embajadores del bloque occidental en la embajada de Polonia, Jrushchov pronunció unas polémicas palabras que impresionaron a los presentes: «Os guste o no, la Historia está de nuestro lado. ¡Os enterraremos!»[55]​ Sin embargo, posteriormente aclaró que no se refería a la posibilidad de una guerra nuclear, sino a la inevitabilidad histórica de la victoria del comunismo sobre el capitalismo.[56]​
El Secretario de Estado de Eisenhower, John Foster Dulles, inició un nuevo giro en la Teoría de la Contención al enfatizar en el posible uso de armas nucleares contra los enemigos de EE. UU.[50]​ Agregó al discurso clásico de la «contención» un nuevo punto de apoyo al anunciar la posibilidad de una «represalia masiva», haciendo entender que cualquier agresión soviética sería respondida con todos los medios necesarios. Esta nueva teoría se puso en práctica durante la crisis de Suez, donde la superioridad nuclear de Estados Unidos, junto con la amenaza de usarla, retrajo a los soviéticos de comenzar una batalla abierta contra intereses estadounidenses.[10]​
Desde 1957 hasta 1961, Jrushchov mostró abiertamente su confianza en la superioridad nuclear de la Unión Soviética. Afirmaba que la capacidad destructiva de los misiles de la Unión Soviética era muy superior a la de Estados Unidos y que podrían alcanzar cualquier ciudad estadounidense o europea. Sin embargo, Jrushchov rechazaba la visión de Stalin de una guerra inevitable y declaró que su intención era abrir una nueva época de coexistencia pacífica.[57]​ Jrushchov trató de reformular la idea soviético-estaliniana, según la cual la lucha de clases a nivel mundial provocaría inevitablemente una gran guerra entre proletarios y capitalistas cuyo resultado final sería el triunfo del Comunismo. Jrushchov arguyó que la guerra era evitable, pues durante el tiempo de paz el capitalismo se colapsaría por sí mismo,[58]​ mientras que la paz dejaba tiempo y recursos disponibles para mejorar la capacidad económico-militar de la Unión Soviética.[59]​ Los EE. UU. se defendían mostrando su capacidad militar fuera de sus fronteras y el éxito del capitalismo liberal en todo el mundo.[60]​ A pesar del discurso de Kennedy que caracterizó a la Guerra Fría como una «lucha por las mentes de los hombres» entre dos sistemas de organización social, a mediados de la década de 1960 la lucha ideológica había quedado apartada frente a los objetivos geopolíticos de carácter militar y económico.[61]​


=== Estancamiento de la situación en Europa ===
Aunque ciertamente hubo una transitoria relajación de las tensiones tras la muerte de Stalin en 1953, la situación en Europa seguía siendo incómoda, con ambos bandos fuertemente armados, pero sin movimientos aparentes.[62]​ Las tropas estadounidenses seguían apostadas indefinidamente en la Alemania del Oeste y las tropas soviéticas continuaban estacionadas indefinidamente por toda la Europa del Este.
Para contrarrestar el rearme de la Alemania Occidental tras su entrada en la OTAN, los países de la órbita soviética sellaron una alianza militar conocida como el Pacto de Varsovia en 1955. Sin embargo, este movimiento fue más político que estratégico, pues la Unión Soviética ya había construido una red de defensa mutua con todos sus satélites antes incluso de que se formara la OTAN en 1949.[63]​
Así, el status quo de Europa se mantuvo inalterado. Los soviéticos reprimieron la Revolución Húngara de 1956[64]​ sin que ninguna de las potencias occidentales tratara de movilizar su ejército contra la invasión del Pacto de Varsovia en suelo húngaro. Igualmente, la ciudad de Berlín continuó dividida y disputada.[65]​


==== Berlín ====
Durante noviembre de 1958, Jrushchov trató de desmilitarizar la ciudad de Berlín. Planteó a estadounidenses, británicos y franceses abandonar sus respectivas zonas de ocupación bajo la amenaza de transferir el control de los accesos de las potencias occidentales a la Alemania Oriental (lo que significaría el aislamiento del sector occidental de Berlín). La OTAN rechazó el ultimátum y a mediados de diciembre, Jrushchov abandonó la idea a cambio de una conferencia en Ginebra para dilucidar la cuestión berlinesa.[66]​

La última gran crisis de la ciudad se vivió en 1961. Desde principios de la década de 1950, la Unión Soviética y después sus estados satélite comenzaron a restringir fuertemente los movimientos migratorios.[67]​ A pesar de ello, cientos de miles de alemanes orientales conseguían emigrar a Alemania Occidental a través del agujero en la frontera que existía en la ciudad de Berlín, donde la circulación entre sectores orientales y occidentales era libre, creando así un trampolín para la emigración a Europa Occidental.[68]​
Esta facilidad provocó una masiva fuga de cerebros de Alemania Oriental hacia Alemania Occidental de jóvenes cualificados: en 1961, el 20 % de la población activa en territorio oriental había emigrado a occidente.[69]​ En julio de ese año, la Unión Soviética volvió a plantear como ultimátum el abandono de la ciudad de todas las potencias ocupantes y la devolución de las zonas ocupadas de Berlín Occidental a Alemania Oriental, con lo que el agujero fronterizo sería eliminado.[70]​ Las potencias occidentales hicieron caso omiso del ultimátum.
Dos meses después del ultimátum soviético, Alemania Oriental comenzó la construcción de una barrera de cemento y alambre que separaba físicamente ambas zonas de la ciudad berlinesa, impidiendo la libre circulación entre las zonas oriental y occidental. La barrera fue creciendo hasta convertirse en el Muro de Berlín.[71]​


=== La descolonización ===
Aprovechando la aceleración de la descolonización durante la década de 1950 y primeros años de 1960, tanto EE. UU. como la Unión Soviética compitieron por aumentar su influencia en los países descolonizados.[72]​ Además, desde el punto de vista soviético, la desaparición de los grandes imperios coloniales era una señal inequívoca de la victoria de la ideología comunista.[73]​ Los movimientos nacionalistas en algunos países (especialmente en Guatemala, Irán, Filipinas e Indochina) fueron iniciados o apoyados en muchos casos por grupos comunistas autóctonos —o, equívocamente, fue la idea más extendida entre los aliados Occidentales—.[50]​
En este contexto, los EE. UU. usaron a la CIA para derrocar a ciertos gobiernos y favorecer a otros.[50]​ La CIA tuvo un papel clave en el derrocamiento de países sospechosos de ser procomunistas, como en el caso del primer gobierno electo democráticamente en Irán (Operación Ajax) en 1953 y la caída de Jacobo Arbenz Guzmán tras el Golpe de 1954 en Guatemala.[43]​ A su vez, EE. UU. trató de ayudar a gobiernos amigos con ayuda económica y militar, como en el caso de Vietnam del Sur.
La mayoría de naciones y gobiernos surgidos tras la descolonización en Asia, África y América Latina trataron de zafarse de la presión de elegir el bando procapitalista o procomunista. En 1955, durante la Conferencia de Bandung, decenas de países del Tercer Mundo acordaron mantenerse al margen de la dinámica de la Guerra Fría.[74]​ Este consenso se plasmó en la creación del Movimiento de Países No Alineados en 1961.[50]​ Como resultado de la aparición de un nuevo factor en la Guerra Fría, estadounidenses y soviéticos moderaron sus políticas y trataron de acercarse a estos nuevos países neutrales (sobre todo en caso de países clave como India o Egipto) de una manera menos agresiva que la sostenida hasta entonces. Los movimientos nacionalistas e independentistas consiguieron así crear un nuevo escenario más plural, superando la confrontación bipolar de la posguerra, y crearon las bases para las reivindicaciones nacionalistas en Asia y América Latina.[10]​


=== Carrera armamentista ===

Al terminar la Segunda Guerra Mundial, las dos potencias vencedoras disponían de una enorme variedad de armas, muchas de ellas desarrolladas y mejoradas durante el conflicto. Tanques, aviones, submarinos y otros avanzados diseños de navíos de guerra, constituían las llamadas armas convencionales. No obstante, la desigualdad resultaba patente, o por lo menos eso les parecía a los estadistas. Antes de la Segunda Guerra Mundial, la Unión Soviética contaba con el mismo número de carros de combate que el resto de las naciones juntas, y superaba en aviones de combate, al conjunto de todas las demás fuerzas aéreas.[75]​
Después del conflicto, la diferencia numérica no era tan abrumadora, pero aún resultaba ostentosa. Sin embargo, su flota no podía competir en condiciones de igualdad con la de Estados Unidos. Tras la batalla de Midway quedó demostrada la importancia del avión naval de ataque y el portaaviones en los conflictos marítimos. La armada soviética disponía de muchos menos barcos de este tipo que la estadounidense, y además, sus naves eran de menor tamaño, y no disponían de cubierta corrida para operar dos aeronaves simultáneamente, por lo que su inferioridad resultaba manifiesta.[76]​ Para la Unión Soviética, más problemático aún que la falta de portaaviones, era la falta de una red mundial de bases de aprovisionamiento abiertas durante todo el año. Mientras que Estados Unidos podía atracar sus buques en Nápoles, Rota, Hawái, Filipinas y muchos otros puertos más, la Unión Soviética no podía sacar sus barcos de puertos propios durante varios meses al año, pues sus puertos o estaban helados, o podían ser fácilmente bloqueados por los aliados. Era el caso de la flota del mar Negro, que debía atravesar los 35 kilómetros del estrecho del Bósforo, que Turquía podía bloquear fácilmente.
En la aviación convencional, tanto en número como en calidad, los nuevos cazas y bombarderos soviéticos, no solo estaban a la altura, sino por encima de los occidentales, los aviones bombarderos Tu-4 lanzaron la primera bomba atómica soviética. Pese a que el Pentágono siempre afirmaba poseer aparatos superiores a los de cualquier otro país, los enfrentamientos vividos durante la guerra de Corea, guerra de Vietnam y posteriormente, en la guerra de la Frontera de Sudáfrica demostraron la igualdad, cuando no la superioridad, de los aviones soviéticos.[cita requerida]
Pero eran las denominadas armas no convencionales las que llamaban poderosamente la atención: más poderosas, eficientes, difíciles de fabricar y extremadamente caras. La principal de estas armas era la bomba atómica. Al principio de la Guerra Fría solo Estados Unidos disponía de estas armas, lo que aumentaba significativamente su poder bélico. La Unión Soviética inició su propio programa de investigaciones, para producir también tales bombas, algo que consiguió en cuatro años; relativo poco tiempo, ayudándose de espionaje. En un principio, Estados Unidos centró sus investigaciones en perfeccionar el vector que transportara las bombas (misil o bombardero estratégico); pero fue cuando se supo que Moscú había detonado su primera bomba nuclear de fisión, cuando se dio luz verde al proyecto para fabricar la bomba de hidrógeno, arma que no tiene límite de potencia conocido. Esto se logró en 1952, y la Unión Soviética la obtuvo al año siguiente.[77]​ Pese a que la carrera iba muy pareja en el plano cualitativo no era lo mismo en el cuantitativo: contradiciendo a la preocupación occidental de aquella época, el ciudadano estadounidense y miembro del Instituto Thomas Watson, Serguéi Jrushchov afirma que en tiempo de la crisis de los misiles de Cuba el poder nuclear estadounidense superaba al oriental en 10 veces o más.[78]​
Esta carrera armamentística fue promovida por el llamado Equilibrio de Terror, según el cual, la potencia que se colocase al frente en la producción de armas, provocaría un desequilibrio en el escenario internacional: si una de ellas tuviera mayor número de armas, sería capaz de destruir a la otra. No obstante, ya en el siglo XXI fuentes como The Times consideran que el esfuerzo soviético no se encaminó a superar al otro adversario, sino a alcanzarlo para, seguidamente, obligarlo a poner en práctica una estrategia defensiva no ofensiva (arrebatarle cuantos aliados pudiese conseguir). De esta misma opinión es Serguéi Jrushchov, quien afirma que la carrera estaba solo en la mente de los occidentales, porque para los soviéticos se trataba de ir incrementando su arsenal y perfeccionando sus vectores (misiles, bombarderos y submarinos) según sus posibilidades, porque no podía igualar o superar a occidente.[78]​ Esta desproporción parecen confirmarla hechos como que los misiles intercontinentales (ICBM) solo comenzaron a estar a la altura de los estadounidenses, en lo que a operatividad y fiabilidad se refiere, hacia finales de los setenta. Tampoco los submarinos nucleares parecían poder medirse con los occidentales, como prueba la gran cantidad de accidentes que padecieron.[79]​


=== Carrera espacial ===

La carrera espacial se puede definir como una subdivisión del conflicto no declarado entre Estados Unidos y la Unión Soviética en el ámbito espacial. Entre 1957 y 1975, y como consecuencia de la rivalidad surgida dentro del esquema de la Guerra Fría, ambos países iniciaron una carrera en la búsqueda de hitos históricos que se justificaron por razones tanto de seguridad nacional como por razones ideológicas asociadas a la superioridad tecnológica.
La carrera se da por iniciada en 1957, cuando los soviéticos lanzaron el Sputnik, primer artefacto humano capaz de alcanzar el espacio y orbitar el planeta. Así mismo, los primeros hitos en la carrera espacial los alcanzaron los soviéticos: en noviembre de ese mismo año, lanzan el Sputnik II y, dentro de la nave, el primer ser vivo sale al espacio: una perra Kudriavka, de nombre Laika, que murió a las siete horas de salir de la atmósfera. El siguiente hito también sería obra de los soviéticos, al conseguir lanzar en 1961 la nave Vostok 1, tripulada por Yuri Gagarin, el primer ser humano en ir al espacio y regresar sano y salvo.
La llegada del hombre al espacio fue celebrado como un gran triunfo para la humanidad. En Estados Unidos, la ciudadanía recibió la noticia como un duro golpe a la creencia de la superior capacidad tecnológica estadounidense.[80]​ Como respuesta, el presidente Kennedy anunció, mes y medio después del viaje de Gagarin, que Estados Unidos sería capaz de poner un hombre en la Luna y traerlo sano y salvo a la Tierra antes de acabar la década.[81]​
A principios de 1969, Estados Unidos consiguió fabricar el primer artefacto humano que orbitó sobre la Luna (el Apolo 8) mientras que los soviéticos tenían graves problemas en su programa lunar. El 20 de julio de 1969 se alcanzaba el cénit en la exploración espacial cuando la misión Apolo 11 consiguió realizar con éxito su tarea y Armstrong y Edwin Aldrin se convirtieron en los primeros humanos en caminar sobre otro cuerpo celeste. Poco después, los soviéticos cancelaban su programa lunar.
Estados Unidos siguió mandando astronautas a la Luna, hasta que la falta de interés y presupuesto hicieron cancelar el programa. En 1975, la Misión Conjunta soviético-norteamericana Apolo-Soyuz dio por finalizada la carrera espacial.


=== Crisis de los misiles de Cuba ===

Al triunfar la Revolución cubana en 1959, se da un verdadero giro en la historia de América Latina, pues el naciente proceso de nacionalizaciones y reforma agraria afecta gravemente los intereses estadounidenses en la isla que se habían asegurado con la Enmienda Platt en 1902, esto conduce a fuertes roces entre Cuba y los Estados Unidos que desencadenan en la ruptura de relaciones diplomáticas y a la expulsión de Cuba de la OEA, debido al aislamiento del resto del hemisferio y el bloqueo económico, el país se convierte en un fuerte aliado de la Unión Soviética y el resto del bloque comunista, convirtiéndose posteriormente en miembro del COMECON. Esta crisis llevó al mundo al borde de la guerra nuclear. Después del fracasado intento de invasión de la Bahía de Cochinos en abril de 1961. En 1962, la Unión Soviética fue descubierta construyendo 40 silos nucleares en Cuba. Según Jrushchov, la medida era puramente defensiva, para evitar que los Estados Unidos intentaran una nueva embestida contra los cubanos. Por otro lado, era sabido que los soviéticos querían realmente responder ante la instalación estadounidense de misiles Júpiter II en la ciudad de Esmirna, Turquía, que podrían ser usados para bombardear el sudoeste soviético.
La Unión Soviética envió navíos de carga y submarinos transportando armas atómicas hacía Cuba. Un avión espía descubrió las rampas de lanzamiento, y Estados Unidos tomó inmediatamente decisiones dando inicio a la crisis de los misiles.
El 22 de octubre de 1962, Estados Unidos ordenó una cuarentena total sobre la isla, posicionando navíos militares en el mar Caribe y cerrando los contactos marítimos entre la Unión Soviética y Cuba. Kennedy dirigió un ultimátum a la Unión Soviética: demandó a la Unión Soviética que detuviera esos navíos bajo amenaza de emprender represalias masivas. Los soviéticos argumentaron que no entendían por qué Kennedy tomaba esta medida cuando varios misiles estadounidenses estaban instalados en territorios de países miembros de la OTAN contra los soviéticos, en distancias idénticas. Fidel Castro adujo que no había nada de ilegal en instalar misiles soviéticos en su territorio, y el primer ministro británico Harold Macmillan dijo no haber entendido por qué no fue propuesta siquiera la hipótesis de un acuerdo diplomático.
El 23 y 24 de octubre Jrushchov habría enviado mensaje a Kennedy señalando: «La URSS ve el bloqueo como una agresión y no instruirá a los barcos que se desvíen»; pero en las primeras horas de la mañana, los buques soviéticos disminuyeron la velocidad en sus desplazamientos hacía Cuba, con el fin de evitar algún conflicto mayor, mientras se abrían las posibilidades de una negociación entre las partes. El 26 de octubre informó que retiraría sus misiles de Cuba si Washington se comprometía a no invadir Cuba. Al día siguiente, pidió además la retirada de los misiles balísticos Júpiter de Turquía. Dos aviones espía estadounidenses U-2 fueron derribados en Cuba y Siberia el 27 de octubre, justo en el ápice de la crisis. El 28 de octubre, Kennedy aceptó retirar los misiles de Turquía y no agredir a Cuba. Así Nikita Jrushchov retiró sus misiles nucleares de la isla cubana.
Esta crisis dio nacimiento a un nuevo periodo: la distensión, señalada por la puesta en marcha del teléfono rojo —en realidad blanco—, línea directa entre Moscú y Washington, que aligeraría las comunicaciones en caso de otra crisis.


== Las détente (1962-1979) ==

En el transcurso de las décadas de 1960 y 1970, las superpotencias tuvieron que gestionar un nuevo modelo de geopolítica, en el que el mundo dejó de estar claramente dividido en dos bloques antagónicos.[50]​ Europa y Japón se recuperaron rápidamente de la destrucción de la Segunda Guerra Mundial y su renta per cápita se acercaba a la de Estados Unidos. Mientras tanto, la economía del Bloque del Este entraba en un ciclo de estancamiento económico.[50]​[82]​ A su vez, el Tercer Mundo conseguía establecerse como bloque independiente a través de organizaciones como el Movimiento de Países No Alineados y demostraron su fuerza de negociación con el papel fundamental que tuvo la OPEP durante la crisis del petróleo de 1973.[41]​
En la Unión Soviética, la gestión de los problemas económicos internos apartó la necesidad de extender la influencia soviética en el orden mundial.[50]​ Como consecuencia, líderes soviéticos como Alekséi Kosygin y el propio Leonid Brézhnev apostaron por una relajación en las relaciones internacionales abriendo un nuevo período conocido como la distensión o détente.[50]​


=== Europa ===


==== La Primavera de Praga y la invasión soviética de Checoslovaquia ====
En 1968, tuvo lugar un período de liberalización política en Checoslovaquia llamado Primavera de Praga. Las reformas incluyeron una mayor libertad de prensa y libertad de expresión junto con un énfasis económico en bienes de consumo, la posibilidad de un gobierno multipartidista, limitaciones en el poder de la policía secreta, y posible retirada del Pacto de Varsovia.[83]​[84]​
En respuesta a la Primavera de Praga, el 20 de agosto de 1968, el Ejército soviético, junto con la mayoría de sus aliados del Pacto de Varsovia, a excepción de la República Socialista de Rumania de Nicolae Ceaușescu invadieron Checoslovaquia.[85]​ La invasión fue seguida por un éxodo masivo de 70 000 checos y eslovacos[86]​


==== Mayo del 68 ====
El «Mayo del 68» es el nombre dado a una serie de protestas estudiantiles y huelgas generales que provocaron la caída del gobierno de De Gaulle en Francia. La gran mayoría de los protestantes seguía ideologías de izquierdas, aunque las organizaciones políticas y sindicalistas de la izquierda tradicional trataron de distanciarse del movimiento. Las protestas se dirigieron especialmente al sistema educativo y laboral imperante.
Aunque el Mayo del 68 acabó por ser un relativo fracaso político, el impacto social fue muy importante. Especialmente en Francia (y de manera menos evidente, en el resto del mundo occidental) la revuelta marcó el paso de una sociedad moralmente conservadora proveniente de aquellos que vivieron la II Guerra Mundial (basada en la religión, el patriotismo y el respeto por la autoridad) a una moral más liberal de la generación que nació tras la guerra (basada en la igualdad, la liberación sexual y el respeto por los derechos humanos).


=== Tensiones en el Tercer Mundo ===


==== América Latina ====


===== Doctrina de la Seguridad Nacional =====
La Doctrina de la Seguridad Nacional es un concepto utilizado por varios historiadores lationamericanos para definir ciertas acciones de política exterior, tendientes a que las fuerzas armadas de los países latinoamericanos modificaran su misión para dedicarse con exclusividad a garantizar el orden interno, con el fin de combatir aquellas ideologías, organizaciones o movimientos que, dentro de cada país, pudieran favorecer o apoyar al comunismo en el contexto de la Guerra Fría, legitimando la toma del poder por parte de las fuerzas armadas y la violación sistemática de los derechos humanos, mediante políticas de terrorismo de Estado.[87]​[88]​[89]​[90]​[91]​[92]​[93]​[94]​[95]​[96]​


===== Escuela de las Américas =====
En 1946 Estados Unidos instaló en la Zona del Canal de Panamá, por entonces bajo su poder, la Escuela de las Américas. La Escuela educó y entrenó a decenas de miles de militares latinoamericanos, con vistas a su actuación en la Guerra Fría. Surgió como iniciativa en el marco de la Doctrina de Seguridad Nacional,[97]​ para lograr que las naciones latinoamericanas cooperaran con los Estados Unidos, contrarrestando la influencia de las corrientes políticas de ideología marxista, socialista, antiimperialista, izquierdista y en general de asimiladas al llamado "populismo".[98]​


===== Guerra civil dominicana =====
A finales de abril de 1965, el presidente Lyndon B. Johnson ordenó el despliegue de 42 000 soldados en la República Dominicana para la ocupación del territorio dominicano durante un año, en una operación conocida como Operación Power Pack, escudándose en la posible aparición de una «nueva Revolución Cubana» en América Latina.[10]​ Durante las elecciones dominicanas de 1966, bajo ocupación estadounidense, se proclamó ganador al conservador Joaquín Balaguer. Aunque es cierto que Balaguer tenía el apoyo real de las élites del país, así como de los campesinos, las elecciones se vieron desprestigiadas por la negativa del anterior presidente Juan Bosch de disputarlas. Tras la victoria de Balaguer, los activistas del Partido Revolucionario Dominicano (PRD) del expresidente Bosch, comenzaron una campaña de ataques contra la policía y el ejército.[99]​


===== Chile =====
En Chile, el candidato del Partido Socialista de Chile Salvador Allende ganó las elecciones presidenciales de 1970, convirtiéndose en el primer marxista elegido democráticamente. La CIA apuntó a Allende para que lo expulsara y actuó para socavar su apoyo a nivel nacional, lo que contribuyó a un período de disturbios que culminó con el golpe de Estado del general Augusto Pinochet el 11 de septiembre de 1973 iniciando un periodo de dictadura militar. Debido a la crisis económica que atravesaba el país las reformas de la economía de Allende se pusieron en marcha atrás. La dictadura militar combatió a grupos armados de extrema izquierda como el MIR o la VOP y al mismo tiempo militantes de la oposición democrática izquierdista fueron asesinados o detenidos en campos de internamiento bajo la Dirección de Inteligencia Nacional (DINA). Los estados socialistas —con la excepción de China y Rumanía— rompieron relaciones con Chile.[100]​ El régimen de Pinochet se convertiría en uno de los principales participantes en la Operación Cóndor, una campaña internacional de asesinatos políticos y terrorismo de Estado organizada por dictaduras militares de derecha en el Cono Sur de América del Sur que fue encubiertamente respaldada por el gobierno de los Estados Unidos.[101]​[102]​[103]​


===== Argentina =====
En Argentina hubo varios intentos fracasados de implantación de grupos de guerrilleros con mayor o menor apoyo de la Cuba de Fidel Castro, aun antes de la creación de los luego muy conocidas bandas Montoneros y Ejército Revolucionario del Pueblo. Estos y otros grupos comenzaron a actuar en épocas del gobierno de facto llamado Revolución Argentina y luego de un breve período de inacción bélica durante el retorno al país de Perón, reanudaron su accionar durante el gobierno mayoritariamente elegido de este último, durante el gobierno de su sucesora legal y durante el gobierno de facto iniciado en 1976 que terminó derrotándolos en el plano militar.


===== Operación Cóndor =====

El terrorismo de Estado en América Latina fue parte de una operación continental. La Operación o Plan Cóndor fue el nombre con el que se designó el plan de inteligencia y coordinación entre los servicios de seguridad de los regímenes militares del Cono Sur (Argentina, Chile, Uruguay, Brasil, Paraguay y Bolivia), con conexiones con las fuerzas militares de Perú, Ecuador, Colombia y Venezuela, y cooperación y apoyo operativo de los Estados Unidos. La Operación Cóndor constituyó una organización clandestina internacional para la práctica del terrorismo de Estado a escala continental.
La Operación Cóndor ha podido ser descubierta básicamente a partir de los documentos secretos del gobierno estadounidense desclasificados en época del presidente Bill Clinton.
Fue concebida y diseñada por el entonces coronel chileno Manuel Contreras quien en 1975, redactó un extenso documento con las proposiciones para su funcionamiento. El primer paso hacia la organización se produjo a mediados de 1975 cuando el coronel chileno Mario Jahn, viajó a Paraguay y entregó al coronel paraguayo Benito Guanes, el documento de organización del mecanismo y lo invitó a participar en la Primera Reunión de Trabajo de Inteligencia Nacional, realizada en Santiago de Chile entre el 25 de noviembre y el 1 de diciembre de 1975. En esa reunión se decidió organizar la Operación Cóndor entre los seis países del Cono Sur (Argentina, Bolivia, Brasil, Chile, Paraguay y Uruguay). Luego se sumarían, con distintos grados de compromiso, Perú, Ecuador, Colombia y Venezuela. Tuvo su centro de operaciones en Santiago de Chile y su principal coordinador fue Manuel Contreras, quien era conocido como "Cóndor Uno".
Entre decenas de secuestros y atentados contra opositores, la Operación Cóndor concretó acciones de gran resonancia pública como:

el asesinato del excomandante en jefe del Ejército de Chile general de ejército Carlos Prats en Buenos Aires
el asesinato del expresidente de Bolivia Juan José Torres en Buenos Aires
el asesinato del senador uruguayo Zelmar Michelini y el diputado Héctor Gutiérrez Ruiz, también uruguayo, en Buenos Aires en 1974
el asesinato del exministro de relaciones exteriores del gobierno chileno de Salvador Allende, Orlando Letelier y su secretaria Ronni Moffitt en Washington D. C. en 1976
el atentado contra el exministro del Interior del gobierno del presidente chileno Eduardo Frei Montalva, Bernardo Leighton en Roma en 1975
la colaboración argentina en el golpe de García Meza en Bolivia en 1980.
El 26 de abril de 2000 el exgobernador de Río de Janeiro Leonel Brizola sostuvo que los expresidentes del Brasil, João Goulart y Juscelino Kubitschek, fueron supuestamente asesinados en el marco de la Operación Cóndor, simulándose un ataque cardíaco y un accidente, respectivamente y que ello debía ser investigado.[104]​[105]​
La Fuerza Aérea Uruguaya ha reconocido oficialmente la realización de vuelos de la muerte conjuntos con el régimen militar argentino.[106]​ Alrededor de 110 uruguayos fueron detenidos-desaparecidos en Argentina entre 1976 y 1983.[107]​
El gobierno de Estados Unidos participó activamente de la Operación Cóndor. El 22 de agosto de 1978 el servicio de inteligencia estadounidense envió a sus principales embajadas en Sudamérica la siguiente advertencia:

 

Orgánicamente, la Operación Cóndor comenzó a ser desmontada cuando cayó la dictadura argentina en 1983. Sin embargo, los contactos y los asesinatos coordinados continuaron. En abril de 1991, se puso en marcha la Operación Silencio para impedir el enjuiciamiento de los responsables.
El 31 de mayo de 2001, mientras Henry Kissinger se encontraba en París, fue notificado por el juez Roger Le Loire que debía presentarse a declarar sobre su participación en la Operación Cóndor, lo que provocó la inmediata salida del exsecretario estadounidense, de Francia. Pocos meses después, Kissinger debió cancelar una visita a Brasil, porque el gobierno no podía garantizarle inmunidad judicial.[108]​
El 22 de diciembre de 1992, se descubrió en una estación de policía de Lambaré, Asunción (Paraguay), los llamados Archivos del Terror, expedientes en los que existen constancias documentales sobre el terrorismo de Estado en el Cono Sur. Según los archivos descubiertos en Lambaré (Asunción) en 1992, la Operación Cóndor causó 50 000 muertos, 30 000 desaparecidos y 400 000 presos.[109]​[110]​
En febrero de 2004, el periodista estadounidense John Dinges, publicó Operación Cóndor: una década de terrorismo internacional en el Cono Sur,[111]​ donde entre otras cosas revela que los militares uruguayos intentaron asesinar al diputado estadounidense Edward Koch en 1976.


==== Asia ====


===== La guerra de Vietnam =====

Bajo la presidencia de John F. Kennedy, los niveles de tropas estadounidenses en Vietnam crecieron bajo el programa del Grupo Asesor de Asistencia Militar de poco menos de mil en 1959 a 16 000 en 1963. La fuerte represión del presidente vietnamita Ngo Dinh Diem contra los budistas los monjes en 1963 llevaron a los Estados Unidos a respaldar un golpe militar mortal contra Diem. La guerra se intensificó aún más en 1964 después del controvertido Incidente del Golfo de Tonkin, en el que se alega que un destructor estadounidense se enfrentó con una nave de ataque rápido norvietnamita. La Resolución del Golfo de Tonkin otorgó al presidente Lyndon B. Johnson una amplia autorización para aumentar la presencia militar de los EE. UU., Desplegando unidades de combate terrestre por primera vez y aumentando los niveles de tropas a 184 000.[112]​ El líder soviético Leonid Brézhnev respondió invirtiendo la política de retirada de Kruschev y aumentando la ayuda a los norvietnamitas, con la esperanza de atraer al norte de su posición prochina. Sin embargo, la URSS desalentó una nueva escalada de la guerra, proporcionando la asistencia militar suficiente para unir a las fuerzas estadounidenses. Desde este punto, el Ejército Popular de Vietnam (PAVN), también conocido como el Ejército de Vietnam del Norte (EVN), participó en una guerra más convencional con las fuerzas estadounidenses y de Vietnam del Sur.[113]​
La Ofensiva del Tet de 1968 resultó ser el punto de inflexión de la guerra. A pesar de los años de tutela y ayuda estadounidenses, las fuerzas de Vietnam del Sur no pudieron resistir la ofensiva comunista y la tarea recayó en las fuerzas estadounidenses. La Ofensiva del Tet demostró que el final de la participación de Estados Unidos no estaba a la vista, aumentando el escepticismo interno de la guerra y dando lugar a lo que se conoce como el Síndrome de Vietnam, una aversión pública a las implicaciones militares estadounidenses en el extranjero. No obstante, las operaciones continuaron cruzando las fronteras internacionales: Vietnam del Norte utilizó áreas limítrofes de Laos y Camboya como rutas de suministro, y fueron fuertemente bombardeadas por las fuerzas estadounidenses.[114]​
Al mismo tiempo, 1963-65, la política doméstica estadounidense vio el triunfo del liberalismo. Según el historiador Joseph Crespino:

Se ha convertido en un elemento básico de la historiografía del siglo XX que las preocupaciones de la Guerra Fría fueron la raíz de una serie de logros políticos progresistas en el período de posguerra: una tasa impositiva marginal progresiva alta que ayudó a financiar la carrera armamentista y contribuyó a una amplia igualdad de ingresos; apoyo bipartidista a la legislación de derechos civiles de gran alcance que transformó la política y la sociedad en el sur de los Estados Unidos, que durante mucho tiempo había mentido al ethos igualitario de Estados Unidos; apoyo bipartidista para revocar un sistema de inmigración explícitamente racista que existía desde la década de 1920; y atención médica gratuita para los ancianos y los pobres, un cumplimiento parcial de uno de los objetivos no cumplidos de la era del New Deal. La lista podría seguir.[115]​


===== China =====

Como resultado de la ruptura sino-soviética, las tensiones a lo largo de la frontera chino-soviética alcanzaron su punto máximo en 1969, con el estallido del llamado conflicto fronterizo sino-soviético. El presidente de los Estados Unidos, Richard Nixon, decidió utilizar el conflicto para cambiar el equilibrio de poder hacia Occidente en la Guerra Fría.[116]​ Los chinos habían buscado mejorar las relaciones con los estadounidenses para ganar ventaja sobre los soviéticos.
En febrero de 1972, Nixon logró un sorprendente acercamiento con China, viajando a Pekín, en plena Revolución Cultural, y reuniéndose con Mao Zedong y Zhou Enlai. En este momento, la URSS logró una paridad nuclear aproximada con los Estados Unidos; mientras tanto, la guerra de Vietnam debilitó la influencia de Estados Unidos en el Tercer Mundo.[117]​


===== Otros lugares de Asia Oriental =====

En Indonesia, el anticomunista general Suharto arrebató la presidencia a su predecesor, Sukarno, para imponer lo que se conoció como el Nuevo Orden (Orde Baru). Entre 1965 y 1966, los militares asesinaron a más de medio millón de personas simpatizantes del Partido Comunista de Indonesia y otras organizaciones de izquierda.[118]​
Durante la guerra de Vietnam, Vietnam del Norte utilizó las zonas fronterizas con Camboya para establecer bases militares, que el jefe de Estado camboyano Norodom Sihanouk toleró en un intento por preservar la neutralidad de Camboya. Tras la deposición de Sihanouk en marzo de 1970 por el general pro estadounidense Lon Nol, que ordenó a los norvietnamitas que abandonaran Camboya, Vietnam del Norte intentó invadir toda Camboya tras las negociaciones con Nuon Chea, el segundo al mando de los comunistas camboyanos (apodados Jemeres Rojos) luchando para derrocar al gobierno camboyano.[119]​ Sihanouk huyó a China con el establecimiento del GRUNK en Pekín. Las fuerzas estadounidenses y de Vietnam del Sur respondieron a estas acciones con una campaña de bombardeos y una breve incursión terrestre, lo que contribuyó a la violencia de la guerra civil que pronto envolvió a toda Camboya. El bombardeo con alfombra estadounidense duró hasta 1973, y aunque evitó que los jemeres rojos tomaran la capital, también aceleró el colapso de la sociedad rural, aumentó la polarización social y mató a decenas de miles de civiles[120]​.
Después de tomar el poder y distanciarse de los vietnamitas, el líder comunista Pol Pot mató entre 1,5 y 2 millones de camboyanos en los campos de trabajo, aproximadamente una cuarta parte de la población camboyana (un evento comúnmente etiquetado como genocidio camboyano).[121]​[122]​[123]​ Martin Shaw describió estas atrocidades como el genocidio más puro de la era de la Guerra Fría. [266] Respaldado por el Frente Unido Kampucheo para la Salvación Nacional, una organización de comunistas jemer prosoviéticos y desertores jemeres rojos liderados por Heng Samrin, Vietnam invadió Camboya el 22 de diciembre de 1978. La invasión logró depositar Pol Pot, pero el nuevo estado lucharía por obtener el reconocimiento internacional más allá de la esfera del Bloque Soviético, a pesar de la protesta internacional previa por las graves violaciones de los derechos humanos del régimen de Pol Pot, se permitió a los representantes de los Jemeres Rojos se sentará en la Asamblea General de la ONU, con un fuerte apoyo de China y las potencias occidentales, los países miembros de la ASEAN, y se estancará en una guerra de guerrillas liderada por campamentos de refugiados ubicados en la frontera con Tailandia. Tras la destrucción de Khmer Rouge, la reconstrucción nacional de Camboya se vería gravemente obstaculizada, y Vietnam sufriría un ataque punitivo chino.[124]​


===== Egipto y Asia Occidental =====
Si bien Egipto se declaraba neutral, la mayoría del armamento y la asistencia económica provenían de la Unión Soviética. Esta alianza, aunque de manera reacia, se comprobó con el apoyo técnico y militar de la Unión Soviética durante la guerra de los Seis Días y la guerra de Desgaste contra Israel, que se consideraba aliado de Estados Unidos.[125]​ Aunque con la llegada al poder de Anwar el Sadat en 1972 Egipto comenzara virar de prosoviético a prooccidental,[126]​ la amenaza de una posible intervención directa de la Unión Soviética en defensa de Egipto durante la guerra del Yom Kippur provocó la movilización de las fuerzas estadounidenses, en una serie de actos que pudieron desbaratar la noción de la «coexistencia pacífica».[127]​ Estratégicamente, los conflictos en Oriente Medio abrieron una nueva fase en la Guerra Fría, en la que la Unión Soviética podía amenazar los intereses de EE. UU. basándose en la paridad nuclear que habían conseguido los soviéticos.
Aunque Egipto fue el mayor foco de atención, las potencias también actuaron en otros países de la zona. Los soviéticos reforzaron sus relaciones con el gobierno comunista de Yemen del Sur y con el gobierno nacionalista de Irak.[126]​ Los soviéticos también apoyaron a la OLP de Yasir Arafat.[128]​ Por otro lado, entre 1973-1975, la CIA apoyó y conspiró con el gobierno de Irán para financiar y armar a los rebeldes kurdos durante la segunda guerra kurdo-iraquí, para debilitar el gobierno de Ahmed Hassan al-Bakr. El apoyo de la CIA finalizó cuando Irán e Irak firmaron el Acuerdo de Argel en 1975.[129]​


==== África ====

En 1974, estalló en Portugal la Revolución de los Claveles en contra de la dictadura del Estado Novo. Los cambios políticos en Portugal facilitaron la independencia de las colonias portuguesas de Angola y Timor Oriental. En Angola, donde las facciones rebeldes habían sostenido una guerra por la independencia contra Portugal desde 1961, tras la independencia en 1974 estas mismas facciones que habían luchado juntas contras las fuerzas colonialistas comenzaron una guerra civil al enfrentarse entre ellas. En una muestra de los equilibrios político-estratégicos de la Guerra Fría, la guerra civil angoleña enfrentó a tres facciones distintas: el MPLA, apoyado por cubanos y soviéticos, el FNLA, apoyado por EE. UU., China y Zaire y la UNITA apoyado también por Estados Unidos, el régimen del apartheid sudafricano y otra serie de países africanos. Finalmente, el MPLA, con tropas cubanas y apoyo soviéticos, vencerían a la UNITA a pesar del apoyo militar de Sudáfrica.[130]​ Igualmente, los soviéticos reforzaron sus relaciones con el gobierno nacionalista de Argelia.
Por otro lado oficiales del ejército somalí, encabezados por Mohamed Siad Barre, llevaron a cabo un golpe de Estado incruento, formando la República Democrática Somalí, de ideario socialista. La Unión Soviética prometió apoyo a Somalia. Cuatro años después, en el país vecino de Etiopía, el emperador Haile Selassie, prooccidental, fue derrocado por el Derg un grupo de oficiales radicales del ejército etíope, liderados por el prosoviético Mengistu Haile Mariam, que se apresuró a reforzar las relaciones con Cuba y la Unión Soviética.[130]​ Cuando estallaron las hostilidades entre Somalia y Etiopía (guerra de Ogaden) el somalí Siad Barre perdió el apoyo de los soviéticos, y a cambio buscó el la asistencia del conocido como Safari Club —una alianza de los servicios de inteligencia de Irán, Egipto y Arabia Saudí—. A través del Safari Club, Somalia consiguió armas soviéticas y tanques estadounidenses.[131]​[132]​ El ejército etíope estaba apoyado por soldados cubanos y asesores y armamento soviético.[130]​ La postura oficial de Estados Unidos era la de neutralidad en el conflicto, aunque defendiendo que fue Somalia la que violó la soberanía territorial de Etiopía. Aun así, la administración Carter comenzó a apoyar a Somalia desde 1980.[133]​


=== La «coexistencia pacífica» ===

Tras su vista a China, Nixon se reunió con los líderes soviéticos en Moscú[134]​ y como resultado de estas reuniones, se firmó el primero de los Acuerdos SALT (SALT I), el primer acuerdo completo de limitación de armas firmado entre las dos superpotencias,[135]​ y el Tratado sobre Misiles Antibalísticos (Tratado ABM), que prohibía el desarrollo de sistemas diseñados para la interceptación de misiles en el aire. Con ello se intentaba limitar el desarrollo de los costosos misiles antibalísticos y misiles con carga nuclear.[50]​
Tras los acuerdos alcanzados, Nixon y Brézhnev proclamaron una nueva era de «coexistencia pacífica» basada en una nueva política de «détente» (o cooperación) entre las dos superpotencias. Durante esta «coexistencia», Brézhnev trataría de revitalizar la economía soviética, que estaba en declive en parte por los grandes gastos militares que provocaban una situación de tensión continua.[10]​ Entre 1972 y 1974, ambas potencias también fortalecieron sus lazos económicos, con la firma de varios acuerdos para aumentar el comercio entre ellas. Como resultado de todos estos pactos y acuerdos, la hostilidad mutua se reemplazaba por un nuevo marco histórico donde ambas potencias podían convivir y desarrollarse.[134]​
A su vez, en Europa, la situación de división interna se relajaba con el desarrollo de la «Ostpolitik», llevada a cabo por el canciller de la RFA Willy Brandt y la firma de los Acuerdos de Helsinki en el marco de la Conferencia sobre la Seguridad y la Cooperación en Europa en 1975.[136]​


=== El fin de la «coexistencia pacífica» ===
A pesar de los llamamientos al acuerdo de ambas potencias, durante la década de 1970, el KGB, dirigido por Yuri Andrópov, continuó persiguiendo a personalidades disidentes como Aleksandr Solzhenitsyn y Andréi Sájarov, que criticaban duramente el régimen soviético.[137]​ Continuaron también los conflictos indirectos entre ambas superpotencias (guerras "proxy").[138]​ Aunque el presidente Jimmy Carter intentó frenar la carrera armamentística con la firma de un nuevo tratado de limitación de armas (SALT II) en 1979,[139]​ sus esfuerzos fueron socavados por los eventos que se produjeron ese año, como el triunfo de la Revolución Iraní y la Revolución Sandinista, apoyada por el KGB,[140]​ que derrocaron a los gobiernos prooccidentales de ambos países. Como represalia, EE. UU. se opuso a la invasión soviética de Afganistán que se produjo en diciembre, dando por finalizada la era de la «coexistencia pacífica».[10]​


== La etapa más tensa de la Guerra Fría: Reagan y su diplomacia con la URSS (1979-1989) ==


=== La intervención soviética de Afganistán ===

En abril de 1978, el comunista Partido Democrático Popular de Afganistán (PDPA) se hizo con el poder en Afganistán tras la Revolución de Saur. A los pocos meses, los opositores al gobierno comunista lanzaron una revuelta en el este del país, que se creció rápidamente hasta convertirse en una guerra civil que se extendía por todo el país, con los rebeldes muyahidín atacando a las fuerzas gubernamentales a lo largo y ancho del país. El gobierno de Pakistán proveía estos rebeldes de lugares donde esconderse y entrenamiento militar. En el otro bando, el PDPA era apoyado por los asesores militares mandados desde la Unión Soviética.[141]​ Mientras tanto, en el PDPA se luchaban guerras internas entre la mayoría Jalq y los moderados Parcham. Como resultado, los parchamíes renunciaron a sus cargos en el gobierno y los oficiales militares parchamíes fueron arrestados con la excusa de un supuesto golpe de Estado parchamí. Hacia 1979, Estados Unidos había comenzado un programa secreto para dar asistencia militar y armas a los muyahidines.[142]​
En septiembre de 1979 el presidente jalq, Nur Mohammad Taraki, fue asesinado en un golpe interno del PDPA orquestado por su primer ministro Hafizullah Amín, que asumió la presidencia. Los soviéticos, que desconfiaban de Amín, lo asesinaron en diciembre de 1979. Se formó un nuevo gobierno bajo las órdenes de los soviéticos, liderado por el parchamí Babrak Karmal y con la participación de ambas facciones. Se desplegaron más fuerzas soviéticas para estabilizar el país bajo el poder de Karmal, aunque los soviéticos no esperaban llevar el peso de las operaciones militares. Sin embargo, con su presencia y apoyo a uno de los bandos, los soviéticos se vieron envueltos en lo que debía haber sido una guerra doméstica.[143]​
El presidente Carter describió la intervención soviética como «la más seria amenaza para la paz desde la Segunda Guerra Mundial».[144]​ Como consecuencia, retiró el tratado SALT II de su aprobación en el Senado, impuso un embargo sobre los cereales y la transferencia de tecnología a la Unión Soviética, pidió un incremento significativo del gasto militar estadounidense y finalmente lideró el boicot de los Juegos Olímpicos de Moscú de 1980.


=== La doctrina Reagan ===
En enero de 1977, cuatro años antes de convertirse en presidente, Ronald Reagan reveló claramente en una entrevista su postura en relación con la Guerra Fría: «Mi idea de lo que debe ser la política estadounidense en lo que respecta a la Unión Soviética, es simple, y algunos dirán que simplista», dijo. «Es esta: nosotros ganamos y ellos pierden, ¿qué te parece?».[145]​ En 1980, Reagan ganó las elecciones, con la promesa de incrementar el gasto militar y enfrentarse a los soviéticos en cualquier lugar que fuera necesario.[146]​ Tanto Reagan, como la recién elegida primera ministra británica Margaret Thatcher, denunciaron tanto a la Unión Soviética como a la ideología comunista. Reagan calificó a la Unión Soviética como el «Imperio del mal» y señaló que el comunismo acabaría en «el montón de cenizas de la Historia».[147]​
A principios de 1985, el anticomunismo visceral de Reagan se desarrolló en una postura conocida como la Doctrina Reagan en la que, además de la Contención, abogaba por el derecho de los EE. UU. de subvertir y derrocar los gobiernos comunistas existentes.[148]​ Además de continuar con la política de la administración Carter de apoyar a los opositores islamistas de la Unión Soviética y del gobierno prosoviético del PDPA. La CIA también buscaba debilitar a la Unión Soviética promoviendo la aparición de un Islam político en aquellas Repúblicas Soviéticas de Asia Central de mayoría musulmana.[149]​ Además, la CIA alentó a la ISI pakistaní, de ideología anticomunista, a entrenar a musulmanes de todo el mundo para que participaran en la yihad contra la Unión Soviética.[149]​


=== Estancamiento económico soviético y reforzamiento militar estadounidense ===


==== Problemas estructurales de la economía soviética ====
A principios de la segunda mitad de la década de 1980, los gastos militares representaban el 25 % del PIB soviético, a costa del gasto en bienes de consumo para los ciudadanos y la inversión en sectores civiles.[150]​ Los gastos acumulados en la carrera armamentística y otros compromisos derivados de su implicación en la Guerra Fría, causaron y magnificaron los profundos problemas estructurales del sistema económico soviético,[151]​ que acabaron provocando una crisis económica permanente durante el mandato de Brezhnev.
La inversión soviética en el sector de la Defensa no estaba dirigida tanto por una necesidad militar real, sino por los intereses privados de los miembros de la Nomenklatura que dependían de las inversiones públicas en el sector para mantener su poder e influencia.[152]​ Las fuerzas armadas soviéticas se convirtieron en las más grandes en función de la cantidad y tipos de armas que poseían, en número de tropas y el tamaño de su complejo militar-industrial. Sin embargo, todas estas ventajas cuantitativas de bloque oriental se veían muchas veces superadas por las ventajas cualitativas de los ejércitos más modernos y tecnológicamente más avanzados del bloque occidental.[153]​
La escalada militar que comenzó Reagan no fue seguida de una escalada igual en la Unión Soviética, por falta de recursos económicos.[154]​ Los gastos militares soviéticos ya se consideraban excesivos, y junto con una economía planificada ineficiente y una agricultura colectivizada poco productiva, eran un lastre muy pesado para el desarrollo de la economía soviética[155]​ Al mismo tiempo, tanto Arabia Saudí como otros países no-OPEP comenzaron a incrementar su producción,[156]​ saturando el mercado del petróleo y empujando los precios hacia abajo. Esta bajada de precios afectó gravemente a la Unión Soviética, ya que la exportación de petróleo era su fuente principal de divisas.[150]​[155]​ Los problemas derivados de una economía centralizada,[157]​ la bajada del precio del crudo y el gasto militar descontrolado condujeron a la economía soviética a una crisis sistémica.[155]​


==== Aumento de la capacidad militar estadounidense ====
Desde 1980, EE. UU. comenzó una escalada militar con el desarrollo de armas como el bombardero Rockwell B-1 Lancer, el misil LGM-118A Peacekeeper,[158]​ y sobre todo, el desarrollo experimental de la Iniciativa de Defensa Estratégica, conocida como «La Guerra de las Galaxias» que pretendía, mediante unos satélites colocados en la órbita terrestre, tener la capacidad de interceptar los misiles enemigos en pleno vuelo.[159]​
La ciudadanía estadounidense todavía guardaba muchos recelos a la intervención militar directa desde el desastre de la guerra de Vietnam.[160]​ La administración Reagan optó por el uso de tácticas rápidas y de bajo coste para la intervención en los conflictos en el extranjero, como el uso de la contrainsurgencia.[160]​ Durante 1983, la administración Reagan intervino en la guerra civil libanesa, invadió Granada, bombardeó Libia y apoyó a los Contras, un grupo de paramilitares anticomunistas que buscaban derrocar al gobierno sandinista prosoviético de Nicaragua. Mientras que sus actuaciones en Granada y Libia fueron populares, su apoyo a los contrainsurgentes fue más controvertido, como en el caso del Irán-Contra.[161]​
Mientras tanto, los soviéticos seguían aumentando el gasto de sus intervenciones en el extranjero. Aunque Brezhnev afirmaba que la intervención soviética en Afganistán sería breve, las guerrillas musulmanas, con el apoyo de EE. UU., ofrecían una resistencia fiera al invasor.[162]​ La Unión Soviética llegó a movilizar 100 000 soldados en suelo afgano para sostener su gobierno-marioneta, lo que llevó a muchos observadores a calificar la guerra en Afganistán como «el Vietnam de los soviéticos».[162]​ La guerra de Afganistán tuvo unas repercusiones peores aún que la de Vietnam para los estadounidenses, pues el conflicto afgano coincidió con un periodo de desintegración interna y crisis económica en el sistema soviético.


=== Las reformas de Gorbachov ===
En el momento en el que el (comparativamente) joven Mijaíl Gorbachov se convirtió en secretario general en 1985,[147]​ la economía soviética estaba totalmente estancada y sin fondos de divisas extranjeras a causa de la caída de los precios del petróleo de la década de 1980.[163]​ Esta situación motivó a Gorbachov para buscar nuevas medidas que revivieran la economía y mejoraran la calidad de un Estado enfermo y podrido por la corrupción.[163]​
Tras unas reformas cosméticas, Gorbachov llegó a la conclusión de que eran necesarios cambios estructurales profundos, y en junio de 1987 anunció una serie de reformas económicas que se conocieron como la Perestroika[164]​ (reestructuración). La Perestroika relajó el sistema de producción soviético, permitió la actividad económica privada, y puso las primeras medidas para impulsar la inversión extranjera. Estas medidas pretendía redirigir los recursos del país de los costosos compromisos militares de la Guerra Fría a otras áreas más productivas de los sectores civiles.[164]​
A pesar del escepticismo inicial de Occidente, el nuevo líder soviético demostró estar más comprometido con el desarrollo económico de la Unión Soviética que de continuar con una costosa carrera armamentística con EE. UU.[62]​[165]​ Como medida para calmar a la oposición interna, Gorbachov introdujo la glásnost (apertura), que incrementaba la libertad de prensa y la transparencia de las instituciones del Estado.[166]​ La glásnost intentaba reducir la corrupción que se había instalado en las altas esferas del Partido Comunista y moderar los abusos del Comité Central.[167]​ La Glásnost también permitía un contacto más intenso de los ciudadanos soviéticos con el mundo occidental-capitalista, particularmente con los Estados Unidos, acelerando el proceso de «détente» entre ambas potencias.[168]​


=== El deshielo de las relaciones ===

Como respuesta a las concesiones militares y políticas del Kremlin, Reagan aceptó retomar las conversaciones sobre los asuntos económicos y el replanteamiento de la carrera armamentística.[169]​ La primera de estas reuniones tuvo lugar en Ginebra, en noviembre de 1985.[169]​ En la sala de deliberaciones sólo estuvieron presentes ambos mandatarios acompañados de un intérprete. En principio, acordaron reducir el arsenal nuclear de cada país en un 50 %.[170]​ La segunda reunión tuvo lugar en la Cumbre de Reikiavik. Las conversaciones marchaban por buen camino hasta que se discutió el asunto de la «Guerra de las Galaxias», que Gorbachov quería que se desmantelara, a lo que Reagan se negaba.[171]​ Las negociaciones fracasaron, pero en una tercera reunión en 1987 se produjo un gran avance con la firma del Tratado INF, que eliminó los misiles balísticos y de crucero nucleares o convencionales, cuyo rango estuviera entre 500 y 5500 kilómetros.
Las tensiones entre Occidente-Oriente iban desapareciendo rápidamente durante la segunda mitad de la década de 1980, hasta llegar a su punto máxima expresión en la cumbre final de Moscú, en 1989, para firmar los acuerdos START I[172]​ A lo largo de ese año, se hacía más aparente que los soviéticos no podrían mantener los subsidios con los que vendía gas y petróleo a precios bajos a sus aliados, ni soportar el coste de movilizar un gran número de tropas fuera de su frontera.[173]​ Además, con la proliferación de los misiles intercontinentales, la ventaja estratégica de una defensa basada en «países satélite» era irrelevante; por lo tanto, los soviéticos declararon oficialmente (Doctrina Sinatra) que no volverían a intervenir en los asuntos domésticos de sus aliados en la Europa del Este.[174]​ Las tropas soviéticas se retiraron de Afganistán[175]​ y ya en 1990, con el Muro de Berlín ya destruido, Gorbachov firmó el Tratado Dos más Cuatro que consagraba de iure la Reunificación alemana.[173]​
El 3 de diciembre de 1989, durante la Cumbre de Malta Gorbachov y el sucesor de Reagan, George H. W. Bush, declararon terminada la Guerra Fría.[176]​


== La caída del muro de Berlín y la disolución de la Unión Soviética (1989-1991) ==

A lo largo del verano de 1989, una serie de subterfugios legales permitieron a los ciudadanos de Alemania Oriental pasar a la Europa Occidental: la desaparición de controles en la frontera de Hungría con Austria permitía a los ciudadanos de Berlín Este salir como turistas a Hungría, y de allí a Austria.[177]​ El Gobierno de Alemania Oriental respondió prohibiendo los viajes a Hungría, solamente para encontrarse con que el mismo problema se reproducía en Checoslovaquia, desde donde los ciudadanos pasaba a Hungría y desde allí a Austria.

El 18 de octubre el presidente de Alemania Oriental Erich Honecker dimitía y asumía su cargo Egon Krenz. Mientras tanto, las protestas se sucedían a lo largo de toda Alemania Oriental, hasta llegar a su cénit el 4 de noviembre, cuando medio millón de personas se manifestaron en Alexanderplatz.[178]​
Los ciudadanos de Alemania Oriental seguían llegando en oleadas a Checoslovaquia para escapar a través de Hungría y Austria. La administración de Krenz acabó tolerando este subterfugio y finalmente, para facilitar las complicaciones aduaneras que se presentaban, el gobierno de Krenz decidió permitir a los ciudadanos de Berlín Este a salir directamente por los puestos fronterizos hacia Berlín Oeste. La nueva regulación que permitía los viajes privados entre ambas zonas se iba a presentar el 9 de noviembre, y entrarían en efecto al día siguiente.
Günter Schabowski, el portavoz del SED, tenía la tarea de anunciar estos cambios; sin embargo, Schabowski no participó en las conversaciones que dieron forma a la nueva regulación y no estaba enterado de todos los detalles.[179]​ Poco antes de la rueda de prensa que se daría para anunciar los cambios, se le pasó una nota con los cambios en la regulación, pero sin ofrecerle más información de cómo gestionar la noticia. En realidad, estas nuevas regulaciones se había completado solamente unas horas antes del anuncio, y deberían haber entrado en efecto al día siguiente para poder avisar a los guardas de los puestos fronterizos; pero nadie avisó a Schabowski de este detalle.[180]​
Schabowski, por lo tanto, no pudo hacer otra cosa que leer la nota en voz alta. Cuando comenzó el turno de preguntas, uno de los periodistas preguntó cuándo tendrían efecto las mencionadas regulaciones. Tras dudar unos segundos, respondió que la nueva regulación entraba en efecto de manera inmediata,[180]​ y siguiendo el turno de preguntas, afirmó que las regulaciones afectaban igualmente a los puestos fronterizos de Berlín Oeste, aunque en la nota que se había leído no se hacía referencia ninguna a la ciudad de Berlín.[181]​
Los extractos de esta rueda de prensa abrieron los informativos de Alemania Occidental (cuya señal llegaba también a la práctica totalidad de Alemania Oriental) el presentador de uno de los programas de la ARD, Hans Joachim Friedrichs, proclamó: «Este es un día histórico. Alemania Oriental ha anunciado que, con efecto inmediato, las fronteras han sido abiertas. La RDA está abriendo las fronteras... los puestos fronterizos de Berlín están abiertos».[179]​[180]​
Tras oír la retransmisión, los ossis (ciudadanos de Berlín Este) comenzaron a reunirse en los seis puestos fronterizos a lo largo del Muro de Berlín, exigiendo a los guardias fronterizos que abrieran inmediatamente los puestos de control.[179]​ Los guardias, sorprendidos y sobrepasados por la situación, comenzaron a llamar frenéticamente a sus superiores. En un principio, se ordenó controlar a las personas «más agresivas» y sellarles el pasaporte de manera que no pudieran volver a entrar a Alemania Oriental (lo que significaba revocarles la ciudadanía). Aun así, miles de personas seguían en los controles fronterizos, exigiendo pasar al otro lado «tal y como Schabowski ha dicho».[180]​
Al poco tiempo, estaba claro que ninguna autoridad del Berlín Oriental tomaría la responsabilidad de ordenar el uso de la fuerza letal, de manera que los guardias, superados claramente en número, se vieron impotentes ante las oleadas de ciudadanos. Finalmente, a las 22:45, los guardias cedieron y abrieron los puestos fronterizos dejando pasar a la gente sin apenas control, o directamente, sin pedir siquiera el pasaporte. Mientras transcurría la noche, cientos de personas empezaron a destruir varias zonas del muro fronterizo, lo que dio comienzo a la Caída del Muro de Berlín.[182]​
La división de la ciudad acabaría formalmente el 3 de octubre de 1990, culminando con la reunificación alemana.[183]​


=== La caída de las repúblicas socialistas en Europa del Este ===
En 1989, el sistema soviético de alianzas estaba al borde del colapso, y sin apoyo militar de la Unión Soviética, los líderes comunistas del Pacto de Varsovia perdieron gran parte de su poder.[175]​ Organizaciones de base, como el sindicato polaco Solidarność, aumentaron rápidamente su popularidad. En 1989, los gobiernos comunistas de Polonia y Hungría fueron los primeros en comenzar a negociar la organización de unas elecciones libres. En Checoslovaquia y Alemania Oriental las masivas protestas depusieron a los inmóviles líderes comunistas. También cayeron los regímenes de Bulgaria y Rumanía, siendo esta última la única en la que hubo derramamiento de sangre durante el cambio de régimen.


=== La ruptura interna de la Unión de Repúblicas Socialistas Soviéticas ===
Dentro de la Unión Soviética, la nueva política de glásnost acabó por romper los lazos que mantenían a las distintas Repúblicas de la Unión Soviética.[174]​ La libertad de prensa y la disidencia amparada bajo la glásnost provocó un resurgimiento de la «cuestión nacional» y provocó que varias repúblicas proclamaran su autonomía de los designios de Moscú. En febrero de 1990, meses antes de la disolución total de la Unión Soviética, el Partido Comunista de la Unión Soviética tuvo que ceder el monopolio centralista del poder estatal tras 73 años.[184]​ Las repúblicas bálticas fueron más allá y proclamaron su independencia total de la Unión Soviética.[185]​


=== Disolución final de la Unión Soviética ===

En un principio, la actitud tolerante que Gorbachov tenía hacia los cambios en Europa del Este, no significaba la misma tolerancia hacia los cambios radicales dentro del territorio de la Unión Soviética. La represión soviética que se ejerció en los países bálticos tras la declaración de su independencia, chocaban con la intención del presidente Bush de mantener unas relaciones normalizadas con la Unión Soviética, avisando a Gorbachov de que los lazos comerciales entre ambos países se verían gravemente afectados si la violencia continuaba.[186]​ Sin embargo, la realidad era que el Estado soviético se desmoronaba inexorablemente, hasta el golpe de gracia que supuso el fallido golpe de agosto de 1991. Un número cada vez mayor de Repúblicas soviéticas manifestaba su intención de independizarse de la Unión Soviética, especialmente la Rusia, lo que hubiese significado el hundimiento total y caótico de la Unión Soviética. El 21 de diciembre de 1991 se producía la disolución de la Unión Soviética firmándose el tratado que creaba la Comunidad de Estados Independientes, que debería ser la heredera legal de la Unión Soviética, en la que cada república sería independiente y libre de unirse, y se mantendría una unión muy laxa en una especie de confederación. La CEI acabó siendo el marco donde, según los líderes rusos, se llevaría a cabo «un divorcio civilizado» de las distintas repúblicas soviéticas.[187]​
La Unión de Repúblicas Socialistas Soviéticas, la Unión Soviética, se declaró oficialmente disuelta el 25 de diciembre de 1991.[188]​


== La Guerra Fría en otras latitudes ==


=== América Latina ===

La intervención estadounidense en la Guerra Fría se fraguó a través del apoyo político y económico a gobiernos (en su mayoría de corte militar) que se oponían a los procesos revolucionarios que apuntaban hacia el socialismo. Un ejemplo de esto lo encontramos en Guatemala, cuando por medio de una intervención de la CIA fue derrocado el presidente Jacobo Arbenz en 1954, interrumpiéndose así el proceso democratizador en Guatemala, iniciándose un período de dictaduras militares que duraría hasta 1985 y que sumiría al país en una guerra civil hasta 1996. Otro ejemplo es el de Chile; con el Gobierno de Salvador Allende, la Unidad Popular fue depuesta por el general Augusto Pinochet. En la Argentina la intervención armada de grupos inspirados ya en el comunismo chino, ya —mayoritariamente— en el castrismo o el llamado guevarismo fue abierta y sin ningún ocultamiento, con la acción de Montoneros y el Ejército Revolucionario del Pueblo, entre otros. Fieles a la táctica comunista de ampliar y explotar las diferencias (que por supuesto existían) en la sociedad, captaron inicialmente a una porción del peronismo y comenzaron su acción guerrillera ya desde los años 60. La prosiguieron durante gobiernos militares y durante los gobiernos democráticos de Perón y de su sucesora legal y también durante el gobierno militar comenzado en 1976. Este último, dio inicio al llamado terrorismo de Estado con el que aniquiló militarmente a estos grupos.
Del mismo modo, el intervencionismo del bloque oriental en asuntos más que todo sudamericanos se instauró a través del apoyo a diversos grupos guerrilleros en Bolivia, Colombia, Perú, Brasil y otras naciones centro y sudamericanas. Este proceso se inició con el apoyo soviético al gobierno socialista surgido en Cuba a raíz de la revolución dirigida por Fidel Castro en, quien a su vez dio apoyo a las guerrillas procomunistas así como a gobiernos de ideas afines como el de Allende, Peron o de los sandinistas en Nicaragua.

20 de diciembre de 1989: Fin de la dictadura de 21 años desde la época del general Omar Torrijos en Panamá hasta la caída del general Manuel Antonio Noriega con la Invasión estadounidense de Panamá de 1989.


=== Sudeste Asiático ===
(Cronología indicativa):

2 de octubre de 1949: El partido comunista chino gana la guerra civil y proclama la República Popular China. Independencia de facto de Taiwán proclamada República de China. Amenaza de un nuevo conflicto neutralizada por la presencia naval estadounidense.
25 de junio-agosto de 1950: Ofensiva de las tropas norcoreanas en Corea del Sur.
27 de junio de 1950: El presidente estadounidense Truman envía al ejército a socorrer a Corea del Sur después del llamado de la ONU
Septiembre-octubre de 1950: Contraofensiva estadounidense en Corea
Noviembre de 1950-enero de 1951: Respuesta de Corea del Norte, apoyada por China.
Marzo de 1951: El frente se estabiliza.
27 de julio de 1953: Las dos Coreas firman un armisticio.
agosto de 1954-mayo de 1955: Bombardeos intensivos a islas dependientes de Taiwán por China.
agosto-julio de 1958:Bombardeos intensivos de las islas de Quemoy y Matsu y enfrentamientos navales y aéreos entre la República Popular China y Taiwán; la presencia de la marina estadounidense impide el desembarco de tropas chinas continentales.
20 de diciembre de 1960: Creación del Frente Nacional de Liberación de Vietnam del Sur.
Agosto de 1964: Escaramuzas entre las flotas estadounidense y norvietnamitas en el Golfo de Tonkín.
Marzo de 1965: Las fuerzas estadounidenses deciden la intervención.
Enero-febrero de 1968: Los norvietnamitas introducen 70 000 hombres en Vietnam del Sur.
Mayo de 1968: tienen lugar negociaciones entre las diferentes partes.
1971: La República Popular China es admitida en la ONU y obtiene una plaza permanente en el consejo de seguridad, en reemplazo de Taiwán, que es excluido de la organización.
Febrero de 1972: Visita de Richard Nixon a China Popular.
27 de febrero de 1973: Acuerdos de París. Retirada de tropas estadounidenses.
17 de abril: Toma de Nom Pen por los Khmers rojos.
30 de abril de 1975: Saigón es tomada por los norvietnamitas.
25 de abril de 1976: Elección de una asamblea nacional vietnamita.
junio de 1978: 70 000 soldados vietnamitas ocupan una zona fronteriza en el interior de Camboya.
1 de enero de 1979:Estados Unidos reconoce a Pekín como capital de China al mismo tiempo que cierra su embajada en Taipéi.
7 de enero de 1979: Toma de Nom Pen por tropas vietnamitas.
Febrero de 1979: Ofensiva militar china en Vietnam.
Septiembre de 1989: Retirada de las fuerzas vietnamitas de Camboya.


=== Guerra Fría en África ===
A partir de 1975, las guerrillas comunistas toman el poder en los países recientemente independizados del antiguo imperio colonial portugués en África (Angola y Mozambique). Iniciaron acciones militares contra Sudáfrica con el apoyo del ejército cubano, que devinieron en auténticas batallas, especialmente en Namibia, ocupada por el régimen racista de Sudáfrica (Apartheid). A partir de 1976 en Etiopía, el ejército soviético y las fuerzas cubanas intervinieron contra movimientos opositores a la dictadura de Mengistu Haile Mariam. El ejército francés entabló acciones de desestabilización, como el salvamento de Kolwezi.


== La Guerra Fría en la historiografía occidental ==
Hay tres períodos definidos en el estudio de la Guerra Fría en Occidente:[cita requerida] tradicionalista, revisionista y postrevisionista. Durante más de una década tras del final de la Segunda Guerra Mundial, pocos historiadores estadounidenses discutieron la interpretación «tradicionalista» acerca del comienzo de la Guerra Fría; la que sostenía que la ruptura de las relaciones fue resultado directo de la violación de Stalin de los acuerdos de Yalta, la imposición de gobiernos adictos a Moscú en la devastada Europa Oriental, la intransigencia soviética y el agresivo expansionismo soviético.
Sin embargo, posteriormente los historiadores revisionistas, especialmente William Appleman Williams en su obra de 1959 The Tragedy of American Diplomacy y Walter LaFeber en su obra America, Russia, and the Cold War, 1945-1966 (1968), señalaron una preocupación pasada por alto: el interés estadounidense en mantener una «puerta abierta» para el comercio estadounidense en los mercados mundiales. Se ha señalado por los revisionistas que la política de contención estadounidense expresada en la Doctrina Truman era equivalente a un intento de culpar al otro. Se indicaba como fecha de inicio de la Guerra Fría a las explosiones nucleares de Hiroshima y Nagasaki, interpretando el uso de armas nucleares por parte de los Estados Unidos como una advertencia (o velada amenaza) dirigida a una Unión Soviética que estaba a punto de entrar en guerra contra el ya derrotado Imperio japonés. Pronto los historiadores perdieron interés en la pregunta sobre el responsable de la ruptura de las relaciones soviético-estadounidenses, para señalar que el conflicto entre las superpotencias era en cierto modo inevitable. Esta aproximación revisionista al fenómeno de la Guerra Fría alcanzó especial auge durante la guerra de Vietnam, en la que muchos observaron a los Estados Unidos y la Unión Soviética como dos imperios moralmente comparables.
En últimos años de la Guerra Fría se hicieron esfuerzos para llegar a una síntesis posrevisionista, y desde el final de la Guerra Fría, la escuela postrevisionista ha llegado a ser predominante. Entre los historiadores postrevisionistas más destacados encontramos a John Lewis Gaddis y Robert Grogin. Más que atribuir la responsabilidad del inicio de la Guerra Fría a alguna de las superpotencias de entonces, los historiadores postrevisionistas se centran en temas como la mutua desconfianza, las mutuas falsas percepciones y reactividades, y las responsabilidades compartidas entre las dos superpotencias. Tomando elementos de la escuela realista de las relaciones internacionales, los historiadores posrevisionistas aceptan la política estadounidense en Europa, como la ayuda a Grecia en 1947 y el Plan Marshall.
De acuerdo con esta síntesis, la actividad comunista no fue el origen de las dificultades en Europa, sino que fue una consecuencia de los destructivos efectos de la guerra en la estructura económica, política y social de Europa. En este contexto, el Plan Marshall reconstruyó un sistema económico capitalista, frustrando el llamamiento político al radicalismo izquierdista.
En Europa Occidental, la ayuda económica terminó con la escasez de divisas y estímulo la inversión privada para la reconstrucción de postguerra. En los Estados Unidos, el plan sacó a la economía de una crisis de superproducción, y mantuvo la demanda por las exportaciones estadounidenses. La OTAN sirvió para integrar a Europa Occidental en una red de pactos de mutua defensa. De este modo, proporcionó salvaguardas contra la subversión, o al menos la neutralidad en bloque. Rechazando la percepción del comunismo como un monolito internacional caracterizado por agresivas alusiones al «mundo libre», la escuela postrevisionista sostiene que la intervención de los Estados Unidos en Europa fue una reacción contra la inestabilidad que amenazaba con alterar el equilibrio de poder en favor de la Unión Soviética, modificando el sistema político y económico occidental.


== Factores latentes de la Guerra Fría ==
Este periodo vislumbró una guerra estratégica, política y científica. Se dio una disconformidad entre ambas naciones tanto en la creación de nuevas tecnologías y armamento, como en la conquista del espacio exterior. Si bien las condiciones en los tiempos de la Guerra Fría eran otras, la división geopolítica imperante en el mundo dependía del dominio de la extinta Unión Soviética (modelo de referencia para futuros estados socialistas) y Estados Unidos. La actualidad muestra que dicha atribución no está tan marcada como en aquella época, pero los hechos recientes muestran que el fin de la beligerancia dista mucho de ser un caso cerrado. Por otra parte, el fin de la Guerra Fría no resultó en la eliminación del conflicto en el sistema político internacional. En la era contemporánea, existe una tensión bastante pronunciada entre Estados Unidos y potencias revisionistas como China y Rusia.[189]​
Está claro que las diplomacias entre Rusia y Estados Unidos se encuentran en una posición delicada, los diferentes movimientos estratégicos dan a pensar que la guerra sigue latente, la tensión entre una nación y otra ha escalado más de la cuenta. El caso de Edward Snowden, la situación en Siria y la crisis de Ucrania han inducido a que las relaciones entre EE. UU. y Rusia comiencen a recordar a los años duros de la Guerra Fría; esperando ese momento que acabe con los años de pactos y negociaciones que han sostenido, pero sus intereses contrastados suelen impedirlo, y eso crea tanto riesgos como oportunidades para terceros.[cita requerida]


== Véase también ==
Guerras Mundiales
Bloque Occidental
Bloque del Este
Segunda Guerra Fría
Guerra Fría en la ficción
Pactomanía
Imperio estadounidense
Imperio soviético
Relaciones Estados Unidos-Unión Soviética


=== Conflictos regionales durante la Guerra Fría ===


==== Europa Occidental ====


==== Europa Oriental ====


==== Oriente Medio ====


==== Asia Central y Meridional ====


==== Asia Oriental ====


==== Sudeste Asiático y Oceanía ====


==== América del Norte, América Central y Antillas ====


==== América del Sur ====


==== Norte de África ====


==== África Subsahariana ====


== Bibliografía ==
En español
Leffler, Melvin P. (2008). La guerra después de la guerra. Estados Unidos, la Unión soviética y la Guerra Fría. Crítica. ISBN 978-84-8432-784-4. 
Robert J. McMahon (2009). La Guerra Fría. Una breve introducción. Alianza. ISBN 978-84-206-4967-2. 
Veiga, Francisco; Da Cal, Enrique U.; Duarte, Ángel. La paz simulada. Una historia de la Guerra Fría, 1941-1991, Madrid, Alianza Editorial, 2006 (2.ª edición)
Saunders, Frances Stonor. La CIA y la Guerra Fría cultural. 2002
Hernández Holgado, Fernando. Historia de la OTAN: de la Guerra Fría al intervencionismo humanitario. 2000.
Hobsbawm, Eric John. Primer mundo y tercer mundo después de la Guerra Fría. 1999.
Dobrynin, Anatoli. En confianza: el Embajador de Moscú ante los seis presidentes estadounidenses de la Guerra Fría (1962-1986). 1998.
Engelhardt, Tom. El fin de la cultura de la victoria: Estados Unidos, la Guerra Fría y el desencanto de una generación. 1997.
Pollard, Robert A. La seguridad económica y los orígenes de la Guerra Fría (1945-1950). 1990.
Hardt, John P. Los efectos económicos de la Guerra Fría: ¿la hegemonía americana en peligro? 1963.
Lorbés, María Rosa. Después de la Guerra Fría, la paz caliente. 1995
O'Sullivan, John. El Presidente, el Papa y la Primera Ministra. Un trío que cambió el mundo. 2007. ISBN 978-84-96729-06-3
limh. (2013). Siria, país con ubicación estratégica en Medio Oriente. Abril 13, 2015, de Notimex| El Universal Sitio web: http://www.eluniversal.com.mx/el-mundo/2013/siria-ubicacion-estrategica-949950.html Archivado el 16 de abril de 2015 en Wayback Machine.
EFE. (2015). Rusia aboga por la "no injerencia desde fuera" en Venezuela. Abril 13, 2015, de RPP Noticias Sitio web: http://www.rpp.com.pe/2015-03-25-rusia-aboga-por-la-no-injerencia-desde-fuera-en-venezuela-noticia_781472.html
EFE. (2015). ¿Qué busca el primer ministro griego en Rusia?. Abril 13, 2015, de Semana Sitio web: http://www.semana.com/mundo/articulo/que-busca-el-primer-ministro-griego-en-rusia/423346-3
Der Spiegel. (2014). Un pacto Rusia-China cambia el escenario geopolítico. Abril 13, 2015, de El Tribuno Sitio web: http://www.eltribuno.info/un-pacto-rusia-china-cambia-el-escenario-geopolitico-n386530
SÁNCHEZ, R. (2015). Rusia amenaza a Dinamarca con misiles. Abril 14, 2015, de El Mundo España Sitio web: http://www.elmundo.es/internacional/2015/03/23/550f0963ca474196758b456b.html
González R. (2015). Cuba y Estados Unidos, ganadores de reunión hemisférica en Panamá. Abril 14, 2015, de El Financiero México Sitio web: http://www.elfinanciero.com.mx/mundo/cuba-y-estados-unidos-ganadores-de-reunion-hemisferica-en-panama.html
Irina G. (2015). La OTAN justifica su postura hacia Rusia con Crimea y la crisis de Ucrania. abril 12, 2015, de Sputnik Sitio web: http://sptnkne.ws/cXj (enlace roto disponible en Internet Archive; véase el historial, la primera versión y la última).
Marcelo J. (2014). ¿Hasta dónde afecta la crisis de Rusia a América Latina? 30 de diciembre de 2014, de BBC Mundo Sitio web: http://www.bbc.co.uk/mundo/noticias/2014/12/141229_economia_crisis_rusa_america_latina_en
Carlos R. (2014). Rusia vs EE. UU.: Historia de una tensión constante. marzo 6, 2014, de Que! Sitio web: http://www.que.es/blogs/201403060800-rusia-eeuu-historia-tension-constante.html Archivado el 14 de septiembre de 2014 en Wayback Machine.
Ian B. (2013). La creciente tensión entre Rusia y EE UU. septiembre 30, 2013, de El país Sitio web: http://elpais.com/elpais/2013/09/26/opinion/1380187334_925561.html
Westad, Odd Arne (2018) [2017]. La Guerra Fría. Una historia mundial. Barcelona: Galaxia Gutenberg. ISBN 9788417355555. [190]​
En inglés
Ball, S. J. The Cold War: An International History, 1947-1991, 1998 - a British perspective
Brzezinski, Zbigniew. The Grand Failure: The Birth and Death of Communism in the Twentieth Century (1989);
Flory, Harriette y Jenike, Samual. The Modern World 16th century to present. New York: Pitman Publishing, 1992.
Gaddis, John Lewis, The Cold War: A New History, Penguin Press, 2005. ISBN 1-59420-062-9 (US edition). The Cold War, Allen Lane, 2005. ISBN 0-7139-9912-8 (UK edition)
Gaddis, John Lewis. Russia, the Soviet Union and the United States. An Interpretative History 2nd ed. ( 1990)
Gaddis, John Lewis. Long Peace: Inquiries into the History of the Cold War (1987)
Gaddis, John Lewis. Strategies of Containment: A Critical Appraisal of Postwar American National Security Policy (1982)
Isaacs, Jeremy y Downing, Taylor, Cold War: For 45 Years the World Held Its Breath, Bantam Press, 1998. ISBN 0-593-04309-X
LaFeber, Walter. America, Russia, and the Cold War, 1945-1992 7th ed. (1993)
Mitchell, George. The Iron Curtain: The Cold War in Europe (2004)
Ninkovich, Frank. Germany and the United States: The Transformation of the German Question since 1945 (1988)
Paterson, Thomas G. Meeting the Communist Threat: Truman to Reagan (1988)
Powaski, Ronald E. The Cold War: The United States and the Soviet Union, 1917-1991 (1998)
Sivachev, Nikolai and Nikolai Yakolev, Russia and the United States (1979), by Soviet historians
Ulam, Adam B. Expansion and Coexistence: Soviet Foreign Policy, 1917-1973, 2nd ed. (1974)
En francés
La guerre de Cinquante ans, de Georges-Henri Soutou, 2001-2016


== Referencias ==


== Enlaces externos ==
 Wikimedia Commons alberga una categoría multimedia sobre Guerra Fría.
La Revolución francesa (en francés: Révolution française) fue un conflicto social y político, con diversos periodos de violencia, que convulsionó la Francia del Antiguo Régimen, y a otros países por extensión de sus implicaciones. Se inició con la autoproclamación del Tercer Estado como Asamblea Nacional en 1789 y finalizó con el golpe de Estado de Napoleón Bonaparte en 1799, culminando un proceso de 10 años.
Si bien después de que la Primera República cayó tras el golpe de Estado de Napoleón, la organización política de Francia durante el siglo XIX osciló entre república, imperio y monarquía constitucional, la revolución marcó el final definitivo del feudalismo y del absolutismo en el país,[2]​ y dio a luz a un nuevo régimen donde la burguesía, que empleaba en ocasiones a las masas populares, se convirtió en la fuerza política dominante. La revolución, más allá de sus estertores, enfrentó las bases del sistema monárquico como tal, en la medida en que impuso con su discurso, iniciativas capaces de volverlo ilegítimo.[cita requerida] 
Según la historiografía clásica, la Revolución francesa marca el fin de la Edad Moderna y el inicio de la Edad Contemporánea al sentar las bases de la democracia moderna con base en la representación, lo que la sitúa en el corazón del siglo XIX. Abrió un nuevo horizonte político basado en el principio de la soberanía popular, que será el motor de las revoluciones de 1830, de 1848 y de 1871.[3]​


== Antecedentes ideológicos ==
Los escritores ilustrados del siglo XVIII, filósofos, politólogos, científicos y economistas, denominados philosophes, y a partir de 1751 los enciclopedistas, contribuyeron a minar las bases del derecho divino de los reyes. La filosofía de la Ilustración ha desempeñado pues un rol significativo en el giro que tomaron estos eventos históricos pero su influencia debe relatarse de modo más matizado: acordarle demasiada importancia a los preceptos filosóficos nacidos durante ese siglo se revelaría como una carencia mayúscula de fidelidad historiográfica.
La corriente de pensamiento vigente en Francia era la Ilustración, cuyos principios se basaban en la razón, la igualdad y la libertad. La Ilustración había servido de impulso a las Trece Colonias norteamericanas para la independencia de su metrópolis europea. Tanto la influencia de la Ilustración como el ejemplo de los Estados Unidos sirvieron de «trampolín» ideológico para el inicio de la revolución en Francia.


== Causas ==

Muchos historiadores ven las causas subyacentes de la Revolución Francesa como impulsadas por el fracaso del Antiguo Régimen para responder a la creciente desigualdad social y económica. El rápido crecimiento de la población y las restricciones causadas por la incapacidad de financiar de forma adecuada la deuda pública, dieron lugar a una depresión económica, desempleo y altos precios de los alimentos.[4]​ Combinado con un sistema fiscal regresivo y la resistencia a la reforma de la élite gobernante, el resultado fue una crisis que Luis XVI no pudo manejar.[5]​[6]​
Bajo Luis XIV, la corte de Versalles se había convertido en el centro de la cultura, la moda y el poder político. Las mejoras en la educación y la alfabetización a lo largo del siglo XVIII significaron audiencias más grandes para los periódicos y revistas, con logias masónicas, cafeterías y clubes de lectura que proporcionaron áreas donde la gente podía debatir y discutir ideas. El surgimiento de esta llamada "esfera pública" llevó a París a reemplazar a Versalles como centro cultural e intelectual, dejando a la Corte aislada y con menos capacidad de influir en la opinión.[7]​[8]​
Además de estos cambios sociales, la población francesa creció de 18 millones en 1700 a 26 millones en 1789, convirtiéndose en el Estado más poblado de Europa; París tenía más de 600 000 habitantes, de los cuales un tercio estaban desempleados o no tenían empleo regular. Los métodos agrícolas ineficientes significaban que los agricultores nacionales no podían mantener estos números, mientras que las redes de transporte primitivas dificultaban el mantenimiento de los suministros incluso cuando había suficientes. Como resultado, los precios de los alimentos aumentaron en un 65 % entre 1770 y 1790, pero los salarios reales aumentaron solo en un 22 %.[9]​ La escasez de alimentos fue perjudicial para el régimen, ya que muchos atribuyeron los aumentos de precios a la incapacidad del gobierno para evitar la especulación. En la primavera de 1789, una mala cosecha seguida de un invierno severo había creado un campesinado rural sin nada que vender y un proletariado urbano cuyo poder adquisitivo se había derrumbado.
El otro gran lastre para la economía fue la deuda estatal. Las visiones tradicionales de la Revolución francesa a menudo atribuyen la crisis financiera de la década de 1780 a los grandes gastos de la guerra anglo-francesa de 1778-1783, pero los estudios económicos modernos muestran que esto es incorrecto. En 1788, la relación entre la deuda y la renta nacional bruta en Francia era del 55,6 %, en comparación con el 181,8 % en Gran Bretaña. Aunque los costos de los préstamos en Francia eran más elevados, el porcentaje de los ingresos fiscales dedicados al pago de intereses era casi el mismo en ambos países.[10]​
Sin embargo, estos impuestos los pagaban los pobres de las zonas urbanas y rurales, y los parlamentos regionales que controlaban la política financiera bloquearon los intentos de repartir la carga de manera más equitativa. El impasse resultante frente a la angustia económica generalizada llevó a la convocatoria de los Estados Generales, que se radicalizaron por la lucha por el control de las finanzas públicas. Sin embargo, ni el nivel de la deuda estatal francesa en 1788, ni su historia previa, pueden considerarse una explicación del estallido de la revolución en 1789.[11]​ 
Aunque Luis no fue indiferente a la crisis, cuando se enfrentó a la oposición, tendió a retroceder. La Corte se convirtió en el blanco de la ira popular, en especial la reina María Antonieta, que fue vista como una espía austríaca derrochadora, y acusada de la destitución de ministros «progresistas» como Jacques Necker. Para sus oponentes, las ideas de la Ilustración sobre la igualdad y la democracia proporcionaron un marco intelectual para abordar estos problemas, mientras que la Revolución estadounidense fue vista como una confirmación de su aplicación práctica.[12]​


=== Estados Generales de 1789 ===

Los Estados Generales estaban formados por los representantes de cada estamento. Estos estaban separados a la hora de deliberar, y tenían solo un voto por estamento. La convocatoria de 1789 fue un motivo de preocupación para la oposición, por cuanto existía la creencia de que no era otra cosa que un intento, por parte de la monarquía, de manipular la asamblea a su antojo. La cuestión que se planteaba era importante. Estaba en juego la idea de soberanía nacional, es decir, admitir que el conjunto de los diputados de los Estados Generales representaba la voluntad de la nación.
El tercer impacto de los Estados Generales fue de gran tumulto político, en particular por la determinación del sistema de votación. El Parlamento de París propuso que se mantuviera el sistema de votación que se había usado en 1614, si bien los magistrados no estaban muy seguros acerca de cuál había sido en realidad tal sistema. Sí se sabía, en cambio, que en dicha asamblea habían estado representados (con el mismo número de miembros y con un solo voto) el clero (Primer Estado), la nobleza (Segundo Estado) y el resto de la población (Tercer Estado, la burguesía y el campesinado). De inmediato, un grupo de liberales parisinos denominado «Comité de los Treinta», compuesto por la nobleza, comenzó a protestar y agitar, reclamando que se duplicara el número de asambleístas con derecho a voto del Tercer Estado (es decir, los «Comunes»). El gobierno aceptó esta propuesta, pero dejó a la Asamblea la labor de determinar el derecho de voto. Este cabo suelto creó gran tumulto.
El rey Luis XVI y una parte de la nobleza no aceptaron la situación. Los miembros del Tercer Estamento se autoproclamaron Asamblea Nacional, y se comprometieron a escribir una constitución. Sectores de la aristocracia confiaban en que estos Estados Generales pudieran servir para recuperar parte del poder perdido, pero el contexto social ya no era el de 1614. Ahora existía una élite burguesa que tenía una serie de reivindicaciones e intereses que chocaban con los de la nobleza (y con los del pueblo, cosa que se demostraría en los años siguientes).


== La Asamblea Nacional Constituyente (1789-1791) ==

Cuando los Estados Generales de Francia se reunieron en Versalles el 5 de mayo de 1789 y se originaron las disputas respecto al tema de las votaciones, los miembros del Tercer Estado debieron verificar sus credenciales, comenzando a hacerlo el 28 de mayo y finalizando el 17 de junio, cuando los miembros del Tercer Estado se declararon como únicos integrantes de la Asamblea Nacional: ésta no representaría a las clases pudientes sino al pueblo en sí. Si bien invitaron a los miembros del Primer y Segundo Estado a participar en esta asamblea, dejaron en claro sus intenciones de proceder incluso sin esta participación.
La monarquía, opuesta a la Asamblea, cerró las salas donde se reunía. Los asambleístas se mudaron a un edificio cercano, donde la aristocracia acostumbraba a jugar el juego de la pelota, conocido como jeu de paume. Allí es donde procedieron con lo que se conoce como el Juramento del Juego de la Pelota el 20 de junio de 1789, prometiendo no separarse hasta tanto dieran a Francia una nueva constitución. La mayoría de los representantes del bajo clero se unieron a la Asamblea, al igual que 47 miembros de la nobleza. Ya el 27 de junio, los representantes de la monarquía se dieron por vencidos, y por esa fecha el rey mandó reunir grandes contingentes de tropas militares que comenzaron a llegar a París y Versalles. Los mensajes de apoyo a la Asamblea llovieron desde París y otras ciudades. El 9 de julio, se nombró a sí misma Asamblea Nacional Constituyente.


=== Toma de la Bastilla ===

El 11 de julio de 1789, el rey Luis XVI, bajo la influencia de los nobles conservadores al igual que la de su hermano, el conde D'Artois, despidió al ministro Necker y ordenó la reconstrucción del Ministerio de Finanzas. Gran parte del pueblo de París lo interpretó como un autogolpe de la realeza, y se lanzó a la calle en abierta rebelión. Algunos militares se mantuvieron neutrales; otros se unieron al pueblo.
El 14 de julio, el pueblo de París respaldó en las calles a sus representantes y, ante el temor de que las tropas reales los detuvieran, asaltaron la fortaleza de la Bastilla, símbolo del absolutismo monárquico, punto estratégico también del plan de represión de Luis XVI, pues sus cañones apuntaban a los barrios obreros. Tras cuatro horas de combate, los insurgentes tomaron la prisión y mataron a su gobernador, el marqués Bernard de Launay. Si bien solo cuatro presos fueron liberados, la Bastilla se convirtió en un potente símbolo de todo lo que resultaba despreciable en el Antiguo Régimen. Retornando al ayuntamiento, la multitud acusó al alcalde Jacques de Flesselles de traición, quien recibió un balazo mortal. Su cabeza fue cortada y exhibida en la ciudad clavada en una pica, naciendo desde entonces la costumbre de pasear en una pica las cabezas de los decapitados, lo que se volvió muy común durante la Revolución.


=== El Gran Miedo y la abolición del feudalismo ===

La Revolución se fue extendiendo por ciudades y pueblos, creándose nuevos ayuntamientos que no reconocían otra autoridad que la Asamblea Nacional Constituyente. La insurrección motivada por el descontento popular siguió extendiéndose por toda Francia. En las áreas rurales, para protestar contra los privilegios señoriales, se llevaron a cabo actos de quema de títulos sobre servidumbres, derechos feudales y propiedad de tierras, y varios castillos y palacios fueron atacados. Esta insurrección agraria se conoce como la Grande Peur (el Gran Miedo).
La noche del 4 de agosto de 1789, la Asamblea Nacional Constituyente actuó detrás de los nuevos acontecimientos, suprimió por ley las servidumbres personales (abolición del feudalismo), los diezmos y las justicias señoriales, instauró la igualdad ante el impuesto, ante penas y en el acceso a cargos públicos. En cuestión de horas, los nobles y el clero perdieron sus privilegios. El curso de los acontecimientos estaba ya marcado, si bien la implantación del nuevo modelo no se hizo efectiva hasta 1793. El rey, junto con sus seguidores militares, retrocedió de momento. Lafayette tomó el mando de la Guardia Nacional de París y Jean-Sylvain Bailly, presidente de la Asamblea Nacional Constituyente, fue nombrado alcalde de París. El rey visitó París el 27 de julio y aceptó la escarapela tricolor.
Después de estos actos de violencia, los nobles, no muy seguros del rumbo que tomaría la reconciliación temporal entre el rey y el pueblo, comenzaron a salir del país, algunos con la intención de fomentar una guerra civil en Francia y de llevar a las naciones europeas a respaldar al rey. Estos fueron conocidos como los émigrés (emigrados).


=== Pérdida de poder de la Iglesia ===
La revolución se enfrentó con dureza a la Iglesia católica, que pasó a depender del Estado. En 1790 se eliminó la autoridad de la Iglesia de imponer impuestos sobre las cosechas, se eliminaron los privilegios del clero y se confiscaron sus bienes. Bajo el Antiguo Régimen, la Iglesia era la mayor terrateniente del país. Más tarde se promulgó una legislación que convirtió al clero en empleados del Estado. Fueron años de dura represión para el clero, siendo comunes la prisión y masacre de sacerdotes en toda Francia. Este proceso finalizó con el Concordato de 1801 entre la Asamblea y la Iglesia que estableció normas de convivencia vigentes hasta el 11 de diciembre de 1905, cuando la Tercera República sentenció la separación definitiva entre la Iglesia y el Estado. El viejo calendario gregoriano, propio de la religión católica, fue anulado por Billaud-Varenne, en favor de un «calendario republicano» y una nueva era, que establecía como primer día el 22 de septiembre de 1792.


=== Composición de la Asamblea ===

En una Asamblea que se quería plural y cuyo propósito era la redacción de una constitución democrática, los 1200 constituyentes representaban las diversas tendencias políticas del momento.

La derecha representaba a las antiguas clases privilegiadas. Sus oradores más brillantes eran el aristócrata Cazalès, en representación de la nobleza, y el abad Jean-Sifrein Maury, en representación del alto clero. Se oponían a toda reforma y buscaban más sembrar la discordia que proponer medidas.[13]​
En torno al antiguo ministro Jacques Necker se constituyó un partido moderado, poco numeroso, que abogaba por el establecimiento de un régimen parecido al británico: Jean-Joseph Mounier, el conde de Lally-Tollendal, el conde de Clermont-Tonnerre y el conde de Vyrieu, formaron un grupo denominado «demócratas realistas».[cita requerida] Se les llamó más tarde «partido monárquico».[13]​
El resto (y mayoría) de la Asamblea conformaba lo que se llamaba el «partido de la nación». En él se dibujaban dos grandes tendencias, sin que ninguna tuviera homogeneidad ideológica. Mirabeau, Lafayette y Bailly representaban la alta burguesía, mientras que el triunvirato compuesto por Barnave, Duport y Lameth encabezaba los que defendían las clases más populares; los tres procedían del Club Bretón y eran portavoces de las sociedades populares y de los clubes. Representaban la franja más izquierdista de la Asamblea, dado que aún no se manifestaban los grupos radicales que iban a aparecer más adelante.[13]​
En ese primer periodo constituyente, los líderes indiscutibles de la Asamblea eran Mirabeau y el abad Sieyès.[13]​
El 27 de agosto de 1789, la Asamblea publicó la Declaración de los Derechos del Hombre y del Ciudadano inspirado en parte en la Declaración de Independencia de los Estados Unidos y estableciendo el principio de libertad, igualdad y fraternidad. Dicha declaración establecía una declaración de principios que serían la base ineludible de la futura Constitución.


=== Camino a la Constitución ===
La Asamblea Nacional Constituyente no era solo un órgano legislativo, sino la encargada de redactar una nueva constitución. Algunos, como Necker, favorecían la creación de una asamblea bicameral donde el Senado sería escogido por la Corona entre los miembros propuestos por el pueblo. Los nobles, por su parte, favorecían un Senado compuesto por miembros de la nobleza elegidos por los nobles. Prevaleció, sin embargo, la tesis liberal de que la Asamblea tendría una sola Cámara, quedando el rey sólo con poder de veto, pudiendo posponer la ejecución de una ley, pero no su eliminación.
El movimiento de los monárquicos para bloquear este sistema fue desmontado por el pueblo de París, compuesto sobre todo por mujeres (menospreciadas como «las Furias»), que marcharon el 5 de octubre de 1789 sobre Versalles, desde donde, tras varios incidentes, el rey y su familia se vieron obligados a trasladarse al palacio de las Tullerías, en París.


=== Desde la Fiesta de la Federación hasta la Fuga de Varennes ===

El período comprendido entre octubre de 1789 y la primavera de 1791 suele considerarse de relativa tranquilidad, cuando se promulgaron algunas de las reformas legislativas más importantes. Aunque muchas áreas provinciales experimentaron conflictos sobre la fuente de autoridad legítima, donde los oficiales del Antiguo Régimen habían sido barridos, pero aún no se habían establecido nuevas estructuras. Esto fue menos obvio en París, ya que la formación de la Guardia Nacional la convirtió en la ciudad mejor vigilada de Europa, pero el creciente desorden en las provincias afectó a los miembros de la Asamblea.[14]​
La Revolución provocó un cambio masivo de poder de la Iglesia Católica al Estado; aunque se ha cuestionado el alcance de las creencias religiosas, la eliminación de la tolerancia hacia las minorías religiosas que significaba que en 1789 eran francesas también significaba ser católicas.[15]​ La iglesia era el terrateniente individual más grande de Francia, controlando casi el 10 % de las propiedades y los diezmos, un impuesto del 10 % sobre la renta, recaudado de los campesinos en forma de cultivos. A cambio, proporcionó un nivel mínimo de apoyo social.[16]​ Los decretos de agosto abolieron los diezmos, y el 2 de noviembre la Asamblea confiscó todas las propiedades de la iglesia, cuyo valor se utilizó para respaldar un nuevo papel moneda conocido como assignats. A cambio, el Estado asumió responsabilidades como pagar al clero y cuidar a los pobres, los enfermos y los huérfanos. El 13 de febrero de 1790, se disolvieron las órdenes religiosas y los monasterios, mientras se animaba a los monjes y monjas a volver a la vida privada. La Constitución Civil del Clero del 12 de julio de 1790 los convirtió en empleados del Estado, además de establecer tarifas de pago y un sistema para elegir sacerdotes y obispos. El papa Pío VI y muchos católicos franceses se opusieron a esto porque negaba la autoridad del papa sobre la Iglesia francesa. En octubre, treinta obispos redactaron una declaración denunciando la ley, lo que avivó aún más la oposición.[17]​[18]​
Cuando se requirió que el clero jurara lealtad a la Constitución Civil en noviembre de 1790, menos del 24 % lo hizo; el resultado fue un cisma con los que se negaron, el "clero que no jura" o el "clero refractario". Esto endureció la resistencia popular contra la injerencia del Estado, en especial en áreas de tradición católica como Normandía, Bretaña y Vendée, donde sólo unos pocos sacerdotes prestaron juramento y la población civil se volvió contra la revolución. La negativa generalizada dio lugar a nuevas leyes contra el clero, muchos de los cuales fueron obligados a exiliarse, deportados o ejecutados.[19]​
A principios de 1791, la Asamblea consideró introducir una legislación contra los franceses que emigraron durante la Revolución (émigrés). Se pretendía coartar la libertad de salir del país para fomentar desde el extranjero la creación de ejércitos contrarrevolucionarios, y evitar la fuga de capitales. Mirabeau se opuso de forma rotunda. Sin embargo, el 2 de marzo de 1791 Mirabeau falleció, y la Asamblea adoptó esta medida draconiana.
El 20 de junio de 1791, Luis XVI, opuesto al curso que iba tomando la Revolución, huyó junto con su familia de las Tullerías. Sin embargo, al día siguiente cometió la imprudencia de dejarse ver; fue arrestado en Varennes por un oficial del pueblo y devuelto a París escoltado por la guardia. A su regreso, el pueblo se mantuvo en silencio y, tanto él como su esposa, María Antonieta, sus dos hijos (María Teresa y Luis-Carlos, futuro Luis XVII) y su hermana (Madame Elizabeth) permanecieron bajo custodia.

El 3 de septiembre de 1791, fue aprobada la primera constitución de la historia de Francia. Una nueva organización judicial dio características temporales a todos los magistrados y total independencia de la Corona. Al rey sólo le quedó el Poder Ejecutivo y el derecho de vetar las leyes aprobadas por la Asamblea Legislativa. La Asamblea, por su parte, eliminó todas las barreras comerciales y suprimió las antiguas corporaciones mercantiles y los gremios; en adelante, los individuos que quisieran desarrollar prácticas comerciales necesitarían una licencia, y se abolió el derecho a la huelga.
Aun cuando existía una fuerte corriente política que favorecía la monarquía constitucional, al final venció la tesis de mantener al rey como una figura decorativa. Jacques Pierre Brissot introdujo una petición insistiendo en que, a los ojos del pueblo, Luis XVI había sido depuesto por su huida. Una inmensa multitud se congregó en el Campo de Marte para firmar dicha petición. Georges-Jacques Danton y Camille Desmoulins pronunciaron discursos exaltados. La Asamblea pidió a las autoridades municipales guardar el orden. Bajo el mando de Lafayette, la Guardia Nacional se enfrentó a la multitud. Al principio, tras recibir una oleada de piedras, los soldados respondieron disparando al aire; dado que la multitud no cedía, Lafayette ordenó disparar a los manifestantes, ocasionando más de cincuenta muertos.
Tras esta masacre, las autoridades cerraron varios clubes políticos, así como periódicos radicales, tal el que editaba Jean-Paul Marat. Danton se fugó a Inglaterra; Desmoulins y Marat permanecieron escondidos.
Mientras tanto, la Asamblea había redactado la Constitución y el rey había sido mantenido en custodia, aceptándola. El rey pronunció ante la Asamblea un discurso acogido con un fuerte aplauso. La Asamblea Nacional Constituyente cesó en sus funciones el 29 de septiembre de 1791.


== La Asamblea Legislativa y la caída de la monarquía (1791-1792) ==

Bajo la Constitución de 1791, Francia funcionaría como una monarquía constitucional. El rey tenía que compartir su poder con la Asamblea, pero mantenía el poder de veto y la potestad de elegir a sus ministros.
La Asamblea Legislativa se reunió por primera vez el 1 de octubre de 1791. La componían 264 diputados situados a la derecha: feuillants (dirigidos por Barnave, Duport y Lameth), y girondinos, portavoces republicanos de la gran burguesía. En el centro figuraban 345 diputados independientes, carentes de programa político definido. A la izquierda 136 diputados inscritos en el club de los jacobinos o en el de los cordeliers, que representaban al pueblo llano parisino a través de sus periódicos L´Ami du Peuple y Le Père Duchesne, y con Marat y Hebert como portavoces. Pese a su importancia social y el apoyo popular y de la pequeña burguesía, en la Asamblea era escasa la influencia de la izquierda, pues la Asamblea estaba dominada por las ideas políticas que representaban los girondinos. Mientras los jacobinos tenían detrás a la gran masa de la pequeña burguesía, los cordeliers contaban con el apoyo del pueblo llano, a través de las secciones parisienses.
Este gran número de diputados se reunían en los clubes, germen de los partidos políticos. El más célebre de entre estos fue el partido de los jacobinos, dominado por Robespierre. A la izquierda de este partido se encontraban los cordeliers, quienes defendían el sufragio universal masculino (derecho de todos los hombres al voto a partir de una determinada edad). Los cordeliers querían la eliminación de la monarquía e instauración de la República. Estaban dirigidos por Jean-Paul Marat y Georges-Jacques Danton, representando al pueblo más humilde. El grupo de ideas más moderadas era el de los girondinos, que defendían el sufragio censitario y propugnaban una monarquía constitucional descentralizada. También se encontraban aquellos que formaban parte de «el Pantano», o «el Llano», los que no tenían un voto propio, y que se iban por las proposiciones que más les convenían, ya vinieran de los jacobinos o de los girondinos.
En los primeros meses de la Asamblea, el rey había vetado una ley que amenazaba con la condena a muerte a los émigrés, y otra que exigía al clero prestar juramento de lealtad al Estado. Desacuerdos de este tipo fueron los que llevaron más adelante a la crisis constitucional.


=== Guerra de Austria y Prusia contra Francia ===

Mientras tanto, dos potencias absolutistas europeas, Austria y Prusia, se dispusieron a invadir la Francia revolucionaria, lo que hizo que el pueblo francés se convirtiera en un ejército nacional, dispuesto a defender y a difundir el nuevo orden revolucionario por toda Europa. Durante la guerra, la libertad de expresión permitió que el pueblo manifestase su hostilidad hacia la reina María Antonieta (llamada la Austriaca por ser hija de un emperador de aquel país y Madame Déficit por el gasto que había representado al Estado, que no era mayor que la mayoría de los cortesanos) y contra Luis XVI, que casi siempre se negaba a firmar leyes propuestas por la Asamblea Legislativa.


=== La «segunda Revolución»: Primera República francesa ===
El 10 de agosto de 1792, las masas asaltaron el palacio de las Tullerías, y la Asamblea Legislativa suspendió las funciones constitucionales del rey. La Asamblea acabó convocando elecciones con el objetivo de configurar (por sufragio universal) un nuevo parlamento que recibiría el nombre de Convención. Aumentaba la tensión política y social en Francia, así como la amenaza militar de las potencias europeas. El conflicto se planteaba así entre una monarquía constitucional francesa en camino de convertirse en una democracia republicana, y las monarquías europeas absolutas. El nuevo Parlamento elegido ese año abolió la monarquía y proclamó la república. Creó también un nuevo calendario, según el cual 1792 se convertiría en el año 1 de su nueva era.
El gobierno pasó a depender de la Comuna Insurreccional. La Comuna envió grupos de sicarios a las prisiones, asesinando a 1400 personas, y cuando pidió a otras ciudades de Francia que hicieran lo mismo, la Asamblea no opuso resistencia. Esta situación persistió hasta el 20 de septiembre de 1792, en que se creó un nuevo cuerpo legislativo denominado Convención, que de hecho se convirtió en el nuevo gobierno de Francia.


== La Convención (1792-1795) ==

El poder legislativo de la nueva República estuvo a cargo de la Convención Nacional, mientras que el poder ejecutivo recayó sobre el Comité de Salvación Pública.


=== Ejecución del rey y Primera Coalición contra Francia ===

En el manifiesto de Brunswick, los Ejércitos Imperiales y de Prusia amenazaron con invadir Francia si la población se resistía al restablecimiento de la monarquía. Esto ocasionó que Luis XVI fuera visto como conspirador con los enemigos de Francia. El 17 de enero de 1793, la Convención condenó al rey a muerte por una pequeña mayoría, acusándolo de «conspiración contra la libertad pública y la seguridad general del Estado». El 21 de enero el rey fue ejecutado en público con la guillotina, lo cual encendió de nuevo la mecha de la guerra con otros países europeos. La reina María Antonieta, nacida en Austria y hermana del emperador, fue ejecutada el 16 de octubre, iniciándose una revolución en Austria para sustituir a la reina. Esto provocó la ruptura de toda relación entre ambos países.


=== El reinado del Terror ===

El día en que se reunía la Convención (20 de septiembre de 1792), las tropas francesas (formadas por tenderos, artesanos y campesinos de toda Francia) derrotaron por primera vez a un ejército prusiano en Valmy, lo cual señalaba el inicio de las llamadas guerras revolucionarias francesas.
La situación económica seguía empeorando, lo cual dio origen a revueltas de las clases más pobres. Los llamados sans-culottes expresaban su descontento por el hecho de que la Revolución francesa no solo no estaba satisfaciendo los intereses de las clases bajas, sino que algunas medidas liberales causaban un enorme perjuicio a estas (libertad de precios, libertad de contratación, Ley Le Chapelier, etcétera). Al mismo tiempo, comenzaron a gestarse luchas antirrevolucionarias en diversas regiones de Francia. En la Vandea, un levantamiento popular fue muy significativo: campesinos y aldeanos (apoyados en un principio por los émigrés, el Reino Unido y el clero refractario) se alzaron contra la leva en masa y la constitución civil del clero, por el rey y las tradiciones católicas, provocando la guerra de Vandea, reprimida de manera tan eficaz y cruenta por las autoridades revolucionarias parisinas que algunos historiadores y políticos franceses de la derecha y extrema derecha han llegado a calificarla de genocidio.[20]​
La guerra exterior amenazaba con destruir la Revolución y la república. Todo ello motivó la trama de un golpe de Estado por parte de los jacobinos, quienes buscaron el favor popular contra los girondinos. La alianza de los jacobinos con los sans-culottes se convirtió de hecho en el centro del gobierno.
Los jacobinos llevarían en su política algunas de las reivindicaciones de los sans-culottes y las clases bajas, pero no todas sus reivindicaciones serían aceptadas, y jamás se cuestionó la propiedad privada. Los jacobinos no pusieron nunca en duda el orden liberal, pero sí llevaron a cabo una democratización, pese a la represión que desataron contra los opositores políticos (tanto conservadores como radicales).

Se redactó en 1793 una nueva Declaración de los Derechos del Hombre y del Ciudadano, y una nueva constitución de tipo democrático que reconocía el sufragio universal. El Comité de Salvación Pública cayó bajo el mando de Maximilien Robespierre y los jacobinos desataron lo que se denominó el Reinado del Terror (1793-1794). No menos de 10 000 personas fueron guillotinadas ante acusaciones de actividades contrarrevolucionarias. La menor sospecha de dichas actividades podía hacer recaer sobre una persona acusaciones que la llevarían a la guillotina. El cálculo total de víctimas varía, pero se cree que llegarían a 40 000 víctimas del Terror.
En 1794, Robespierre[cita requerida] procedió a ejecutar a ultrarradicales y a jacobinos moderados. Su popularidad comenzó a erosionarse. El 27 de julio, ocurrió otra revuelta popular[cita requerida] contra Robespierre, apoyada por los moderados que veían peligroso el trayecto de la Revolución, cada vez más exaltada. El pueblo se rebelaba contra la condición burguesa de Robespierre que, revolucionario antes, ahora persigue a Verlet, Leclerc y Roux.[cita requerida] Los miembros de la Convención lograron convencer al Pantano, y derrocar y ejecutar a Robespierre junto con otros líderes del Comité de Salvación Pública.


== El Directorio (1795-1799) ==

La Convención aprobó una constitución el 17 de agosto de 1795, ratificada el 26 de septiembre en un plebiscito. La llamada Constitución del Año III, confería el poder ejecutivo a un Directorio, formado por cinco directores. El poder legislativo sería ejercido por una asamblea bicameral, compuesta por el Consejo de Ancianos (250 miembros) y el Consejo de los Quinientos. Esta Constitución suprimió el sufragio universal masculino y restableció el sufragio censitario.


=== Napoleón y la toma del poder ===

La nueva Constitución encontró la oposición de grupos monárquicos y jacobinos. Hubo revueltas, reprimidas por el ejército, lo cual motivó que el general Napoleón Bonaparte, retornado de su campaña en Egipto, diera el 9 de noviembre de 1799 un golpe de Estado (18 de Brumario), instalando el Consulado.


== El Consulado (1799-1804) ==

La Constitución del Año VIII, redactada por Pierre Daunou y promulgada el 25 de diciembre de 1799, estableció un régimen autoritario que concentraba el poder en manos de Napoleón, para la supuesta salvación de la república ante una posible restauración monárquica. Contraria las constituciones anteriores, no incluía ninguna declaración sobre los derechos fundamentales de los ciudadanos. El poder ejecutivo recaía en tres cónsules: el primero de ellos, designado por la Constitución, era Bonaparte; los otros dos solo tenían un poder consultivo. En 1802, Napoleón impuso la aprobación de un senadoconsulto, que lo convirtió en cónsul vitalicio, con derecho a designar su sucesor.
El cargo de cónsules lo ostentaron Napoleón Bonaparte, Sieyès y Ducos de momento hasta el 12 de diciembre de 1799. Sieyés y Ducos fueron reemplazados por Jean Jacques Régis de Cambacérès y Charles-François Lebrun, hasta el 18 de mayo de 1804 (28 de floreal del año XII), cuando un nuevo senadoconsulto proclamó el Primer Imperio y la extinción de la Primera República, cerrando con esto el capítulo histórico de la Revolución francesa.


== La bandera francesa y los símbolos de la Revolución ==

Los colores azul, blanco y rojo eran ya frecuentes en diversos pabellones, uniformes y banderas de Francia antes del siglo XVIII. El azul y el rojo eran los colores de la villa de París desde el siglo XIV,[21]​ y el blanco era en aquella época el color del reino de Francia, y por extensión de la monarquía borbónica.
Cuando Luis XVI visitó a la recién creada Guardia Nacional en el Ayuntamiento de París el 17 de julio de 1790, aparece por primera vez la escarapela tricolor, ofrecida al Rey por el comandante de la Guardia, el marqués de La Fayette. Unía la escarapela de la Guardia Nacional que llevaba los colores de la capital, con el color blanco del reino. No fue sin embargo hasta el 20 de marzo de 1790 que la Asamblea Nacional mencionó en un decreto los tres colores como "colores de la nación: azul, rojo y blanco".[22]​ Pero la escarapela no era aún un símbolo nacional, y el primer emblema nacional como tal fue la bandera diseñada para la popa de los buques de guerra, adoptada por decreto de la Asamblea Nacional el 24 de octubre de 1790. Constaba de una pequeña bandera roja, blanca y azul en la esquina superior izquierda de una bandera blanca. Esta bandera fue modificada por la Convención republicana el 15 de febrero de 1794, a petición de los marineros de la marina nacional que exigieron que se redujera la predominancia del blanco que simbolizaba todavía la monarquía.[23]​ La bandera adoptó entonces su diseño definitivo, y se cambió el orden de los colores para colocar el azul cerca del mástil y el rojo al viento por motivos cromáticos, según los consejos del pintor Louis David.
Otro símbolo de la Revolución francesa es el gorro frigio (o gorro de la libertad), llevado en particular por los Sans-culottes. Aparece en los Escudos Nacionales de Francia, Haití, Cuba, El Salvador, Nicaragua, Colombia, Bolivia, Paraguay y Argentina.
El himno «La Marsellesa», con letra y música de Rouget de Lisle, capitán de ingenieros de la guarnición de Estrasburgo, se popularizó a tal punto que el 14 de julio de 1795 fue declarado himno nacional de Francia; se llamaba «Chant de guerre pour l'armée du Rhin» («Canto de guerra para el ejército del Rin»), pero cuando los voluntarios del general François Mireur que salieron de Marsella entraron a París el 30 de julio de 1792 cantando dicho himno como canción de marcha, los parisinos los acogieron con gran entusiasmo y bautizaron el cántico como «La Marsellesa».
El lema Liberté, égalité, fraternité («Libertad, igualdad, fraternidad»), que procede del lema no oficial de la Revolución de 1789 Liberté, égalité ou la mort («Libertad, igualdad o la muerte»), fue adoptado de manera oficial después de la Revolución de 1848 por la Segunda República Francesa.


== La Declaración de los Derechos del Hombre y del Ciudadano ==

Uno de los acontecimientos con mayor alcance histórico de la revolución fue la declaración de los derechos del hombre y del ciudadano. En su doble vertiente, moral (derechos naturales inalienables) y política (condiciones necesarias para el ejercicio de los derechos naturales e individuales), condiciona la aparición de un nuevo modelo de Estado, el de los ciudadanos, el Estado de Derecho, democrático y nacional. Aunque la primera vez que se proclamaron de modo solemne los derechos del hombre fue en los Estados Unidos (Declaración de Derechos de Virginia en 1776 y Constitución de los Estados Unidos en 1787), la revolución de los derechos humanos es un puro fenómeno europeo. Será la Declaración de Derechos del Hombre y del Ciudadano francesa de 1789 la que sirva de base e inspiración a todas las declaraciones tanto del siglo XIX como del siglo XX.
El distinto alcance de ambas declaraciones es debido tanto a cuestiones de forma como de fondo. La declaración francesa es indiferente a las circunstancias en que nace y añade a los derechos naturales, los derechos del ciudadano. Sobre todo, es un texto atemporal, único, separado del texto constitucional y, por tanto, con un carácter universal, a lo que hay que añadir la brevedad, claridad y sencillez del lenguaje. De ahí su trascendencia y éxito tanto en Francia como en Europa y el mundo occidental.
La declaración, sin embargo, excluyó a las mujeres en su consideración de ciudadanas y se olvidó de las mujeres en su proyecto igualitario. Dos años más tarde de la redacción de la Declaración de Derechos del Hombre y del Ciudadano la activista política Olympe de Gouges escribió la Declaración de los Derechos de la Mujer y la Ciudadana (1793), que se convierte en uno de los primeros documentos históricos que plantea la equiparación jurídica y legal de las mujeres en relación con los varones.[24]​


== Las mujeres y la Revolución francesa ==

Las mujeres ocuparon las calles durante las semanas precedentes a la insurrección y tuvieron un papel protagonista en el inicio de la Revolución. El 5 de octubre de 1789 fueron ellas quienes iniciaron la marcha hacia Versalles a buscar al rey. Sin embargo, cuando las asociaciones revolucionarias dirigen el alzamiento las mujeres quedan excluidas del pueblo deliberante, del pueblo armado —la Guardia Nacional—, de los comités locales y de las asociaciones políticas.
Al no poder participar en las asambleas políticas toman la palabra en las tribunas abiertas al público y crean los clubes femeninos en los que leen y debaten las leyes y los periódicos. Entre los más reconocidos estaba la Sociedad Patriótica y de Beneficencia de las Amigas de la Verdad (1791-1792), fundada por Etta Palm, en el que se reclamaba educación para las niñas pobres, divorcio y derechos políticos.
Entre las revolucionarias más destacadas se encontraba la dramaturga y activista política, considerada precursora del feminismo, Olympe de Gouges, la cual escribió la Declaración de los Derechos de la Mujer y la Ciudadana (1793), reivindicando la equiparación de derechos entre hombres y mujeres. Olympe de Gouges se enfrentó a Robespierre y publicó la carta Pronostic de Monsieur Robespierre pour un animale amphibie,[25]​ que la llevó a ser acusada de intrigas sediciosas. Fue juzgada, condenada a muerte y guillotinada.[26]​
El 30 de septiembre de 1793, se prohibieron los clubes femeninos. En 1794, se insistió en la prohibición de la presencia femenina en cualquier actividad política, y en mayo de 1795 la Convención prohibió a las mujeres asistir a las asambleas política ordenando que se retiraran a sus domicilios bajo orden de arresto si no cumplían lo prescrito.[27]​ El Código Napoleónico aprobado en 1804 consagró la derrota femenina en la lucha por la igualdad, libertad y fraternidad que la revolución significó para los varones.[28]​


== Véase también ==
Cronología de la Revolución francesa
Debate historiográfico sobre la Revolución francesa
Descristianización de Francia durante la Revolución
Estados Generales
Guerras Napoleónicas
Historia de Francia
Ideologías de la Revolución francesa
Irreligión en Francia
Napoleón Bonaparte
Revoluciones burguesas
Anexo: Cronología de Francia


== Notas y referencias ==


== Fuentes ==
Este artículo incorpora material de las siguientes fuentes bajo dominio público:

Edición de 1911 de la Encyclopædia Britannica;
History of the French Revolution from 1789 to 1814, de François Mignet (1824), tal como es provista por el Proyecto Gutenberg.


== Bibliografía complementaria ==
Calatrava Escobar, Juan: Estudios sobre la Revolución Francesa y el final del Antiguo Régimen. Tres Cantos: Akal, 1980. ISBN 978-84-7339-504-5
Chartier, Roger: Espacio público, crítica y desacralización en el siglo XVIII. Los orígenes culturales de la Revolución Francesa. Barcelona: Editorial Gedisa, 1995. ISBN 978-84-7432-509-6
Cobban, Alfred: La interpretación social de la revolución francesa. Madrid: Narcea de Ediciones, 1971. ISBN 978-84-277-0003-1
Furet, François: La revolución a debate. Madrid: Encuentro, 2000. ISBN 978-84-7490-558-8
Kropotkin, Piotr: Historia de la Revolución Francesa
Reichardt, Rolf E.: La Revolución Francesa y la cultura democrática: la sangre de la libertad. Madrid: Siglo XXI, 2002. ISBN 978-84-323-1081-2
Soboul, Albert: La Francia de Napoleón. Barcelona. Crítica. 1993. ISBN 978-84-7423-564-7
Soboul, Albert: La revolución francesa. Vilassar de Mar: Oikos-Tau, 1981. ISBN 978-84-281-0485-2
Souchal, François (1993). Le vandalisme de la Révolution. Nouvelles Editions Latines. ISBN 9782723304764. 
Vovelle, Michel: Introducción a la historia de la Revolución Francesa. Barcelona: Editorial Crítica, 2000. ISBN 84-8432-086-3


== Enlaces externos ==
 Wikiquote alberga frases célebres sobre la Revolución francesa.
Análisis histórico sobre la Revolución francesa.
La Revolución francesa (en inglés)
La Revolución francesa, en el sitio web Histórico Digital.
Documental sobre la Revolución francesa.
La historia de la ciencia documenta el desarrollo histórico de la ciencia, la técnica y la tecnología, así como la interrelación que han tenido las tres entre sí y con el resto de los aspectos de la cultura a nivel mundial, como son la economía, la sociedad, la política, la religión, la ideología, etc. En un sentido amplio, la historia de la ciencia existía en muchas civilizaciones desde antes de la Edad Moderna.[1]​ La ciencia moderna es distinta en su enfoque a la ciencia antigua y es la que define ahora lo que se entiende como ciencia en el sentido más estricto del término.[2]​[3]​ La palabra ciencia se usaba para categorizar un tipo de conocimiento específico, más que para referirse a la búsqueda de dicho conocimiento. En particular, la ciencia era el tipo de conocimiento que las personas pueden comunicarse entre sí y compartir.
El conocimiento sobre el funcionamiento de las cosas naturales se acumuló mucho antes de que se registrara su historia y condujo al desarrollo de un pensamiento abstracto complejo. Lo demuestra la construcción de complejos calendarios, el uso de técnicas para hacer comestibles las plantas venenosas, la construcción de obras públicas a escala nacional —como las que aprovecharon el terreno inundable del Yangtsé con embalses,[4]​ presas y diques— y de edificios como las pirámides. Sin embargo, no se hizo una distinción consciente y consistente entre el conocimiento de tales cosas y otros tipos de conocimiento comunitario, como las mitologías y los sistemas legales.
El análisis histórico de la ciencia y la tecnología recurre a los contenidos y metodologías de las distintas subdivisiones de la historia, tanto temáticas (historia de las ideas, historia cultural, historia social, historia económica) como temporales y espaciales. La ciencia ha sido una gran ayuda para el ser humano.


== Marcos teóricos ==


=== Artesanos, filósofos y científicos ===

A lo largo de los siglos la ciencia viene a constituirse por la acción e interacción de tres grupos de personas: los artesanos, los filósofos y los científicos.[5]​
Los artesanos, constructores, los que abrían caminos, los navegantes, los comerciantes, etc. resolvían perfectamente las necesidades sociales según una acumulación de conocimientos cuya validez se mostraba en el conocimiento y aplicación de unas reglas técnicas precisas fruto de la generalización de la experiencia sobre un contenido concreto.[6]​
Los filósofos mostraban unos razonamientos que «extendían el dominio de las verdades demostrables y las separaba de la intuición. La uniformidad del Ser sobrevivió en la idea de que las leyes básicas han de ser independientes del espacio, del tiempo y de las circunstancias».[5]​ Platón postuló que las leyes del universo tenían que ser simples y atemporales. Las regularidades observadas no revelaban las leyes básicas, pues dependían de la materia, que es un agente de cambio. Los datos astronómicos no podrían durar siempre. Para hallar los principios de ellos hay que llegar a los modelos matemáticos y «abandonar los fenómenos de los cielos».[7]​ Aristóteles valoró la experiencia y la elaboración de conceptos a partir de ella mediante observaciones;[8]​ pero la construcción de la ciencia consiste en partir de los conceptos para llegar a los principios necesarios del ente en general.[9]​ Fue un hábil observador de «cualidades» a partir de las cuales elaboraba conceptos y definiciones, pero no ofreció ninguna teoría explícita sobre la investigación. Por eso su ciencia ha sido considerada «cualitativa» en cuanto a la descripción pero platónica en cuanto a su fundamentación deductiva.[5]​ Para Aristóteles el valor de la experiencia se orienta hacia teorías basadas en explicaciones «cualitativas», y a la búsqueda de principios (causas) cada vez más generales a la búsqueda del principio supremo del que se «deducen» todos los demás. Por eso el argumento definitivo está basado en la deducción y el silogismo.[10]​ Esta ciencia deductiva a partir de los principios,[11]​ es eficaz como exposición teórica del conocimiento considerado válido, pero es poco apta para el descubrimiento.[5]​ Los científicos difieren de los filósofos por favorecer lo específico y experimental, y difieren de los artesanos por su dimensión teórica. Su formación como grupo y eficacia viene marcada a partir de la Baja Edad Media, por una fuerte reacción antiaristotélica[12]​ y, en el Renacimiento, por un fuerte rechazo al argumento de autoridad y a la valoración de lo humano con independencia de lo religioso. Son fundamentales en este proceso, los nominalistas, Guillermo de Ockham y la Universidad de Oxford en el siglo XIV; en el Renacimiento Nicolás de Cusa, Luis Vives, Erasmo, Leonardo da Vinci etc.; los matemáticos renacentistas, Tartaglia, Stevin, Cardano o Vieta y, finalmente, Copérnico y Tycho Brahe en astronomía.[13]​ Ya en el XVII Francis Bacon y Galileo promovieron la preocupación por nuevos métodos y formas de estudio de la Naturaleza y valoración de la ciencia, entendida esta como dominio de la naturaleza[14]​ y comprendiéndola mediante el lenguaje matemático.[15]​
A partir del siglo XVII se constituye la ciencia tal como es considerada en la actualidad, con un objeto y método independizado de la filosofía.


=== Teorías y sociología ===

Los primeros problemas de la disciplina son la definición acerca de qué es la ciencia (un problema no historiográfico, sino epistemológico, de filosofía o sociología de la ciencia), su identificación o no con la ciencia moderna surgida de la revolución científica del siglo XVII (un cuerpo de conocimiento empírico y teórico, producido por una comunidad global de investigadores (la comunidad científica) que hacen uso de técnicas específicas y reproducibles para observar y explicar los fenómenos de la naturaleza) y cuáles serían sus objetivos (el puro conocimiento, el autoconocimiento, o la aplicación a finalidades prácticas que mejoren la vida humana —ciencia pura o ciencia aplicada—). Buena parte del estudio de la historia de la ciencia se ha dedicado a la historia del método científico, con la ayuda, en particular, de la sociología de la ciencia que, estudiando las condiciones sociales en que tiene lugar el trabajo concreto de los científicos, reconstruye la forma en que se «produce» y «construye» el conocimiento científico.

 

A partir de que, desde el primer tercio del siglo XX, la propia ciencia dejara de ser determinista (demonio de Laplace)[20]​ y se hiciera probabilística y consciente de sus propios límites (principio de incertidumbre o relación de indeterminación de Heisenberg, teoremas de incompletitud de Gödel y otras expresiones de impredecibilidad,[21]​ impredicatividad[22]​ e indecidibilidad en ciencia) y de la influencia decisiva del observador en la observación; cambió también la perspectiva sobre la teoría y la historia de la ciencia.
A mediados del siglo XX, tres filósofos de la ciencia presentaron tres opciones distintas en la consideración de la naturaleza progresiva o no del conocimiento científico y su forma histórica de producirse: Karl Popper (el conocimiento científico es progresivo y acumulativo, pero «falsable», con lo que únicamente se puede considerar ciencia lo que puede ser cuestionado), Thomas Kuhn (el conocimiento científico no es necesariamente progresivo, sino una respuesta a las demandas sociales, y en la mayor parte de los casos, la «ciencia normal» es únicamente el constante esfuerzo por confirmar el vigente paradigma, que únicamente cambiará por una revolución científica, de las que ha habido muy pocas históricamente), y Paul Feyerabend (el conocimiento científico no es acumulativo o progresivo, sino inconsistente y anárquico -anarquismo epistemológico-, no habiendo criterio de demarcación, en términos de método, entre lo que suele llamarse «ciencia» y cualquier otra forma de investigación).
En el último tercio del siglo se establecieron como disciplina específica los estudios de ciencia, tecnología y sociedad (CTS), que insisten en la importancia del factor humano[23]​ dentro del conocimiento científico, y de la subjetividad sobre la anteriormente pretendida objetividad de los datos científicos, incluso de los llamados «hechos» o datos más evidentes, resultado de la observación, que fuera de su contexto (las teorías que los explican -o no- y las hipótesis que confirman -o no-) carecen de valor. Especialmente desde la publicación y divulgación de los libros de Popper (La lógica de la investigación científica, 1934 y 1959), Kuhn (La estructura de las revoluciones científicas, 1962) y Feyerabend (Contra el método, 1975), se han generado constantes debates en las comunidades científicas y académicas, tanto en el ámbito de las llamadas «ciencias duras» como el de las llamadas «ciencias blandas», el de las ciencias físico-naturales y el de las humanidades y ciencias sociales (o humanas, o ciencias morales y políticas), sobre la naturaleza, significado, objetividad, subjetividad,[24]​ capacidad analítica, sintética y predictiva de la ciencia; el cuestionamiento del objeto[25]​ y la metodología propios de cada ciencia, las ventajas e inconvenientes de la especialización y el reduccionismo, las posibilidades de interdisciplinariedad y de perspectivas holísticas;[26]​ y la relación del conocimiento científico con los conceptos de verdad y de realidad.

 


=== Mujeres ===


== Periodos históricos ==


=== Prehistoria ===


=== Edad Antigua ===


=== Edad Media ===


=== Renacimiento ===


=== Edad Moderna ===


=== Edad Contemporánea ===


== Historia de la ciencia por disciplinas ==


=== Ciencias formales ===


==== Matemáticas ====


==== Lógica ====


=== Ciencias naturales ===


==== Física ====


==== Astronomía ====


==== Geología ====


==== Química ====


==== Biología ====


=== Ciencias humanas ===


==== Medicina ====


==== Sociología ====

Con todo, el pensamiento sociológico puede remontarse al menos hasta los antiguos griegos, viéndose observaciones proto-sociológicas en los textos fundadores de la filosofía occidental, como Heródoto, Tucídides, Platón, Polibio. Siglos más tarde, también se pueden observar las consideraciones sociológicas en San Agustín, Tomás de Aquino y Marsilio de Padua en la Edad Media, por Maquiavelo en el Renacimiento, así como filósofos no europeos, como la mayoría de Confucianistas. En la época musulmana temprana desde el siglo XIV, Ibn Jaldún (1332-1406), en su Muqaddima (después traducido como 'Prolegómenos' al latín), la introducción a un análisis de siete volúmenes de la historia universal, fue el primer que avanzó la filosofía social y las ciencias sociales en la formulación de las teorías de la cohesión social y el conflicto social.
La codificación de la sociología como palabra, concepto y terminología popular se identifica con Emmanuel Joseph Sieyès, quien lo introduce en algunas de sus obras[111]​[112]​, y figuras posteriores a partir de ese momento. Es importante tener en cuenta el presentismo, de introducir ideas del presente en el pasado, en torno a la sociología. A continuación, vemos figuras que desarrollaron fuertes métodos y críticas que reflexionan sobre lo que sabemos que es la sociología hoy que los sitúa como figuras importantes en el desarrollo del conocimiento en torno a la sociología. Sin embargo, el término "sociología" no existía en este período, lo que requería un lenguaje cuidadoso para incorporar estos esfuerzos anteriores a la historia más amplia de la sociología. Un término más apto para usar podría ser proto-sociología[113]​ que describe que los ingredientes aproximados de la sociología estaban presentes, pero no tenían una forma o etiqueta definida para entenderlos como sociología tal como la concebimos hoy.
Henri de Saint-Simon, en su obra Psicología social de 1813, dedica gran parte de su tiempo a la perspectiva de que la sociedad humana podría ser encaminada hacia el progreso si los científicos formaran una asamblea internacional para influir en su curso. Argumentó que los científicos podrían distraer a los grupos de la guerra y los conflictos, enfocando su atención en mejorar en general las condiciones de vida de sus sociedades. A su vez, esto uniría a múltiples culturas y sociedades y evitaría conflictos. Saint-Simon tomó la idea que todos habían alentado desde la Ilustración, que era la creencia en la ciencia, y la hizo girar para que fuera más práctica y práctica para la sociedad.[114]​


==== Arqueología ====
En la antigüedad, hubo casos como el del rey Nabonido (556–539 aC), el último rey del Imperio Neo-Babilónico, interesado en el pasado para poder asociarse con las glorias pasadas, quien irigió un movimiento de revitalización y reconstruyó templos antiguos.
En Europa, el interés por los restos de la civilización grecorromana y el redescubrimiento de la cultura clásica se inició en la Baja Edad Media. Los eruditos consideran generalmente que el coleccionismo de antigüedades surgió solo en la Edad Media. ​​ Flavio Biondo, un historiador humanista del Renacimiento italiano, creó una guía sistemática de las ruinas y la topografía de la antigua Roma a principios del siglo XV, por lo que se le llamó el primer fundador de la arqueología. El erudito itinerante Ciriaco de 'Pizzicolli o Ciriaco de Ancona (1391 – c.1455) también viajó por toda Grecia para registrar sus hallazgos en edificios y objetos antiguos. Ciriaco viajó por todo el Mediterráneo oriental, observando sus descubrimientos arqueológicos en un libro, Commentaria, que finalmente llegó atener seis volúmenes.
Los pasos provisionales hacia la sistematización de la arqueología como ciencia tuvieron lugar durante la era de la Ilustración en Europa en los siglos XVII y XVIII. ​Los anticuarios estudiaron la historia prestando especial atención a  objetos y manuscritos antiguos, así como a los sitios históricos.  El anticuario también se centró en la evidencia empírica que existía para la comprensión del pasado, resumida en el lema del anticuario del siglo XVIII Sir Richard Colt Hoare, "Hablamos de hechos y no de teoría". Los anticuarios, entre ellos John Leland y William Camden, realizaron estudios en la zona rural inglesa, dibujando, describiendo e interpretando los monumentos que encontraron. Estas personas frecuentemente eran clérigos: muchos vicarios registraron puntos de referencia locales dentro de sus parroquias, detalles del paisaje y monumentos antiguos como menhires, incluso aunque no siempre entendían el significado de lo que estaban viendo.
Desde finales del siglo XVIII hasta el siglo XIX, la arqueología se convirtió en un esfuerzo nacional cuando los gabinetes de curiosidades se convirtieron en museos nacionales, contratando personas para coleccionar artefactos y hacer más grande la colección de una nación y mostrar hasta dónde se extendía su historia. Por ejemplo, Giovanni Battista Belzoni fue contratado por Henry Salt, el cónsul británico en Egipto, para reunir antigüedades para Gran Bretaña. En el siglo XIX en México, la expansión del Museo Nacional de Antropología y la excavación de las principales ruinas arqueológicas por Leopoldo Batres formaron parte del régimen liberal de Porfirio Díaz para crear una imagen gloriosa del pasado prehispánico de México.[115]​
Entre los primeros sitios en someterse a excavaciones arqueológicas se encuentran Stonehenge y otros monumentos megalíticos en Inglaterra. Las primeras excavaciones conocidas realizadas en Stonehenge fueron realizadas por William Harvey y Gilbert North a principios del siglo XVII. Asimismo,  las antiguas ciudades de Pompeya y Herculano, ambas cubiertas por cenizas durante la erupción del Monte Vesubio en el año 79, comenzaron a ser redescubiertas y excavadas en 1748 en Pompeya, mientras que en Herculano comenzaron en 1738 bajo los auspicios del rey Carlos VII de Nápoles. En Herculano, el teatro, la basílica y la villa de los Papiros se descubrieron en 1768. El descubrimiento de pueblos enteros, completos, con utensilios e incluso seres humanos, así como el descubrimiento de frescos antiguos, tuvo un gran impacto en toda Europa. 
Johann Joachim Winckelmann fue uno de los fundadores de la arqueología científica al aplicar por primera vez categorías empíricas de estilo de manera amplia y sistemática a la historia clásica (griega y romana) del arte y la arquitectura. Su enfoque original se basó en exámenes empíricos detallados de artefactos a partir de los cuales se podían extraer conclusiones razonadas y desarrollar teorías sobre las sociedades antiguas.
En Estados Unidos, Thomas Jefferson, posiblemente inspirado por sus experiencias en Europa, supervisó la excavación sistemática de un túmulo de nativos americanos en su tierra en Virginia en 1784. Aunque los métodos de investigación de Jefferson estaban adelantados a su tiempo, eran primitivos para los estándares de hoy.
El ejército de Napoleón realizó excavaciones durante su campaña en Egipto, en 1798 – 1801, que también fue la primera expedición arqueológica importante en el extranjero. El emperador llevó consigo una fuerza de 500 científicos civiles, especialistas en campos como la biología, la química y los idiomas, para llevar a cabo un estudio completo de la antigua civilización. El trabajo de Jean-François Champollion descifrando la piedra de Rosetta para descubrir el significado oculto de los jeroglíficos fue la clave para el estudio de la egiptología.
En la primera mitad del siglo XIX se organizaron muchas otras expediciones arqueológicas; Giovanni Battista Belzoni y Henry Salt reunieron artefactos egipcios antiguos para el Museo Británico, Paul Émile Botta excavó el palacio del gobernante asirio Sargon II, Austen Henry Layard desenterró las ruinas de Babilonia y Nimrud y descubrió la Biblioteca de Ashurbanipal y Robert Koldeway y Karl Richard Lepsius excavó sitios en el Medio Oriente. 


==== Economía ====
En la Antigüedad, encontramos pocas ideas económicas en los pensadores griegos: Jenofonte, Pitágoras, Aristóteles, Platón y Homero. En uno de ellos se puede encontrar numerosas ideas en la obra de La República, de Platón, sobre cómo se organizaba la economía en la ciudad ideal, y se puede utilizar esta obra como un buen acercamiento a los pensadores de esa época.
Aristóteles hizo distinciones, por ejemplo en Oeconomicus (coescrito con colaboradores) entre el comercio lícito para el intercambio de mercaderías y el incorrecto que sólo buscaba la obtención de ganancias. Para Aristóteles, economía es «la ciencia que se ocupa de la manera en que se administran unos recursos o el empleo de los recursos existentes, con el fin de satisfacer las necesidades que tienen las personas y los grupos humanos». Aristóteles diferenció entre economía y crematística. Este último era utilizado para referirse al comercio, a la actividad de negociar y enriquecerse con el tráfico.
En el Medioevo europeo, pensadores como Santo Tomas de Aquino debatieron el problema del precio y de la ganancia, desde el punto de vista de si era correcto o pecaminoso obtener ganancias a partir del intercambio de mercaderías. En general, el interés de los estudiosos se centró en cuestiones éticas, como la pobreza y la caridad, el precio justo, la relación conceptual entre el beneficio, el interés y la usura.
Para el advenimiento de la Era Moderna,  se destacan dos escuelas de pensamiento en Europa. Por un lado, de forma paralela al proceso de consolidación de los estados-nación monárquicos se desarrolla durante los siglos XVII y XVIII el mercantilismo; afirmaba que gracias al intercambio de mercadería y a la acumulación de oro y plata se generaba la riqueza. Creían que la riqueza de un país estaba en la cantidad de oro que tenía, y pensaban que el comercio con otros países, si era favorable para un país, tenía que aumentar su cantidad de metales. Pedían al estado una política favorable a sus intereses, es decir, una política que favoreciera los productos nacionales y no la libre competencia. Asimismo, eran partidarios del proteccionismo frente al librecambismo. 
Por otro lado, como reacción surge en Francia, a mediados del siglo XVIII, la Fisiocracia, cuyo principal activista es Quesnay. Creían que la economía funcionaba por flujos entre los distintos componentes de la economía (grupos sociales). Decían que la riqueza solo se genera en las tareas agrícolas, y que el intercambio de mercadería, e incluso la industria, no agregaban ningún valor. Opinaban que los agricultores eran la clase productiva del país porque alimentaban al resto de las clases: las otras dos clases eran los dueños de la tierra y la clase estéril (obreros, artesanos, comerciantes, etc.), llamados así porque tomaban cosas del mundo natural y solo las transformaban, es decir que no creaban nada.
El siglo XVIII trajo el auge de la Economía Clásica, amén del paso del mercantilismo al capitalismo, destacando entre otros:

William Petty, quien escribió en el siglo XVII diferentes textos sobre economía moderna. Habló junto con Quesnay de anatomía y de fisiología social, estudiaron la renta a través de las clases sociales del mismo modo que la sangre entre los diversos órganos del cuerpo humano. Petty distinguió dos factores de producción: el trabajo y la tierra «el trabajo es el padre... de la riqueza y la tierra es su madre».
Adam Smith: considerado "el padre de la economía científica", desarrolló teorías de los sentimientos en su libro La Teoría de los Sentimientos Morales publicado en 1759: los individuos se mueven por el interés individual, amor propio y no solamente son movidos por interés individual sino que en el corazón humano tienen los sentimientos de simpatía. Su obra La riqueza de las naciones es considerado el primer tratado sobre economía política y texto fundacional de la economía clásica. Sus aportes a la teoría fueron muy amplios, y entre ellos destaca la diferenciación entre precio y valor de uso de los bienes. Consideró que la natural tendencia del hombre a enriquecerse es beneficiosa para el conjunto de la sociedad, que la división del trabajo y la especialización traen crecimiento en la producción. Su concepto de la mano invisible postula que el crecimiento y el desarrollo son procesos naturales provenientes de la ambición del hombre por enriquecerse y que el Estado no debería intervenir; cuanto más libre sea la competencia, mejor para el conjunto de la sociedad. Con todo, Smith aplica un papel al Estado, importante en la defensa y la justicia y en la financiación de obras e instituciones públicas que no se llevan a cabo por los individuos.
David Ricardo: Su obra más importante, Principios de economía política y tributación, constituye la exposición más madura y precisa de la economía clásica; en el prefacio afirma que «el principal problema de la economía política es determinar las leyes que regulan la distribución». Con ese fin, David Ricardo desarrolló una teoría del valor y una teoría de la distribución. Entre sus aportes destaca especialmente la teoría de la ventaja comparativa, que defiende las ventajas del comercio internacional y en esencia es una ampliación de la división del trabajo propuesta por Adam Smith. También se le atribuye la idea que afirma que el salario real de los trabajadores permanecerá cercano al nivel de subsistencia aunque haya intentos de incrementarlos, conocida como la ley de hierro de los salarios. Además propuso la que actualmente se conoce como equivalencia ricardiana, una teoría que sugiere que en algunas circunstancias la decisión de un gobierno de cómo financiarse (utilizando impuestos o mediante la emisión de deuda pública) puede no tener efecto en la economía.
El siglo XIX, si bien fue la época de mayor vigencia de las teorías clásicas, dio también origen a otras de orden crítico. La más importante y reconocida de este tiempo fue la obra de Karl Marx, base del marxismo o socialismo científico. Marx labora la teoría llamada materialismo histórico, en la cual postula que la sociedad humana evoluciona porque se encuentra en permanente movimiento, tanto económica como culturalmente. Así, para Marx la sociedad humana evolucionó de las comunidades primitivas al esclavismo, de ahí al feudalismo, después al capitalismo y pronosticaba que de ahí iría a una nueva sociedad. Su obra más conocida es El Capital, en la cual analiza el funcionamiento del sistema económico capitalista, tanto en la producción como en la circulación. Marx es considerado un revolucionario que denuncia el mutismo de los economistas ante la lucha de clases y la explotación. Asimismo, desarrolla la teoría del plusvalor (o plusvalía), en la que el trabajador, al transformar con su trabajo las materias primas, crea una plusvalía, esto es, genera más valor del que tiene esta materia, también llamado valor agregado. Es por ello que, por ejemplo, una mesa tiene más valor que una tabla o pedazo de madera. Para Marx esta plusvalía es la ganancia de los capitalistas.


==== Antropología ====


== Historia de la ciencia por país ==


=== Argentina ===


=== China ===


=== España ===


=== Estados Unidos ===


=== India ===
Las aplicaciones más antiguas que se conocen de la ciencia en la India se desarrollaron en el ámbito de la medicina, la metalurgia, la construcción (por ejemplo, la construcción naval, la producción de cementos y pinturas) y la producción textil. Esto llevó al desarrollo de ciencias primigenias sobre la química y la física.[139]​ A pesar de carecer de una posición social específicamente orientada a la ciencia dentro del sistema indio de castas,[140]​ la casta privilegiada de los brahmani pronto se interesó por el valor y  potencial de la innovación durante el tiempo del Raj británico. El primer medio de comunicación científica en India, Asiatick Researches, se fundó en 1788.[141]​ Las primeras publicaciones científicas en idiomas indios aparecieron hacia finales del mismo siglo, y la publicación a gran escala de libros científicos y libros de texto comenzó a principios del siglo XIX.[142]​
Muchos conceptos matemáticos usados hoy provienen del trabajo de matemáticos indios como Aryabhata. Multitud de científicos indios han conseguido reconocimiento y fama internacional, entre ellos figuras como Satyendra Nath Bose, Meghnad Saha, Jagdish Chandra Bose y C. V. Raman.
En el ámbito de las ciencias sociales, desde los años 1980 se ha detectado un abandono significativo en comparación con los recursos financieros dedicados a las ciencias naturales y la ingeniería, constituyendo apenas un 8% del presupuesto nacional para ciencia y tecnología.[143]​ Este declive, que ha tenido impactos diferentes en diferentes regiones y disciplinas, empobrece las condiciones de trabajo académico y ha tenido un impacto negativo en la capacidad de internacionalización de la investigación social en India.[144]​[145]​


=== México ===


=== Reino Unido ===


=== Venezuela ===


== Véase también ==


== Bibliografía ==
Comellas García-Llera, José Luis (2007). Historia sencilla de la ciencia. Ediciones Rialp. ISBN 978-84-321-3626-9. 
Peter Bowler; Ian Morus (2007). Panorama general de la ciencia moderna. Editorial Crítica. ISBN 978-84-8432-862-9. 
A. C. Crombie (1987). Historia de la ciencia: De San Agustín a Galileo. Alianza Universidad. ISBN 978-84-206-2994-0. 
Alistair Cameron Crombie (1993). Estilos de pensamiento científico a comienzos de la Europa moderna. Universitat de València. ISBN 978-970-07-7189-2. 
Patricia Fara (2009). Breve historia de la ciencia. Ariel. ISBN 978-84-344-8830-4. 
Alfonso Pérez de Laborda (2005). Estudios filosóficos de historia de la ciencia. Encuentro. ISBN 9788474907698. 
Jacob Bronowski (Manuel Carbonell, trad.) (1978). El sentido común de la ciencia. Península (Colección Historia/Ciencia/Sociedad 146). ISBN 84-297-1380-8. 
Miguel Artola y José Manuel Sánchez Ron, Los pilares de la ciencia, Madrid: Espasa, 2012, ISBN 9788467008494.
Antonio Mingote (ilustraciones) y José Manuel Sánchez Ron (texto), ¡Viva la ciencia!, Barcelona: Crítica, 2008, ISBN 9788474238785.
Miguel Ángel Quintanilla y José Manuel Sánchez Ron, Ciencia, tecnología y sociedad, Madrid: Santillana, 1998, ISBN 84-294-4976-0.
Ward English, Paul (21 June 1968). «The Origin and Spread of Qanats in the Old World». Proceedings of the American Philosophical Society (JSTOR) 112 (3): pp 170–181. JSTOR 986162. «Riddle of 'Baghdad's batteries'». BBC News. 27 February 2003. Retrieved 23 May 2010. Fuentes citadas en en:Science and technology in Iran#Ancient technology in Persia. Véase también Qanat, Batería de Bagdad, etc.
Biblical Conception of the Universe
Lloyd, G. E. R. Magic Reason and Experience: Studies in the Origin and Development of Greek Science. Cambridge: Cambridge Univ. Pr, 1979. Stahl, William H. Roman Science: Origins, Development, and Influence to the Later Middle Ages. Madison: Univ. of Wisconsin Pr, 1962. Fuentes citadas en en:History of science in classical antiquity
Lindberg, David C. The Beginnings of Western Science: The European Scientific Tradition in Philosophical, Religious, and Institutional Context, 600 BC. to AD. 1450. Chicago: University of Chicago Press, 1992. Needham, Joseph, Science and Civilization in China, volume 1. (Cambridge University Press, 1954). Fuentes citadas en en:History of science in early cultures


== Documentales ==
Jacob Bronowski y otros, El ascenso del hombre, 1973.
Carl Sagan y otros, Cosmos: un viaje personal, 1980.
Neil deGrasse Tyson y otros, Cosmos: una odisea de tiempo y espacio, 2014.


== Notas ==


== Referencias ==


== Enlaces externos ==
Instituto de Historia de la Medicina y de la Ciencia López Piñero, CSIC-Universidad de Valencia
Fundación Canaria Orotava de Historia de la Ciencia
Sociedad Española de Historia de las Ciencias y de las Técnicas (SEHCYT)
Mil años de historia de la ciencia en Italia
El gran Metro de la ciencia (mapa visual de la historia de la ciencia en forma de plano de Metro)
Bibliografía española de Historia de la ciencia y de la técnica: Base de datos en línea, elaborada por el Instituto de Historia de la Ciencia y Documentación López Piñero. Recoge referencias bibliográficas de las publicaciones sobre Historia de la ciencia y la técnica aparecidas en España o realizadas por autores españoles a partir de 1988 (enlace actualizado).
Colección "Historia de la ciencia y la técnica", Akal
Renacimiento es el nombre dado en el siglo XIX a un amplio movimiento cultural que se produjo en Europa Occidental durante los siglos XV y XVI.[1]​ Fue un periodo de transición entre la Edad Media y los inicios de la Edad Moderna. Sus principales exponentes se hallan en el campo de las artes, aunque también se produjo una renovación en las ciencias, tanto naturales como humanas. La ciudad de Florencia, en Italia, fue el lugar de nacimiento y desarrollo de este movimiento, que se extendió después por toda Europa.
El Renacimiento fue fruto de la difusión de las ideas del humanismo, que determinaron una nueva concepción del hombre y del mundo. El término «Renacimiento» se utilizó reivindicando ciertos elementos de la cultura clásica griega y romana, y se aplicó originariamente como una vuelta a los valores de la cultura grecolatina y a la contemplación libre de la naturaleza tras siglos de predominio de un tipo de mentalidad más rígida y dogmática establecida en la Europa medieval. En esta nueva etapa se planteó una nueva forma de ver el mundo y al ser humano, con nuevos enfoques en los campos de las artes, la política, la filosofía y las ciencias, sustituyendo el teocentrismo medieval por el antropocentrismo.
El historiador y artista Giorgio Vasari fue el primero que utilizó la palabra "Renacimiento" (rinascita) para describir la ruptura con la tradición artística medieval, a la que calificaba como un estilo de bárbaros, que más tarde recibirá el calificativo de Gótico. Vasari opinaba que las artes habían entrado en decadencia al hundirse el Imperio romano y solo habían sido rescatadas por los artistas de la Toscana a partir del siglo XIII.[2]​
El concepto actual de Renacimiento (del francés Renaissance) fue formulado a mediados del siglo XIX por el historiador francés Jules Michelet, en su obra Renaissance et Réforme, publicada en 1855.[3]​ Por primera vez, Michelet usó el término en el sentido de un periodo histórico, que abarcaría desde el descubrimiento de América hasta Galileo, y lo consideró más importante por sus desarrollos científicos que por el arte o la cultura. Michelet, que era nacionalista francés y republicano, le atribuyó al Renacimiento unos valores democráticos opuestos a los de la Edad Media precedente y un protagonismo francés.[4]​
El otro historiador que tuvo gran influencia en dar forma al concepto de Renacimiento fue el suizo Jacob Burckhardt, quien lo definió como el periodo entre Giotto y Miguel Ángel, es decir, del siglo XIV a mediados del xvi. Buckhardt destacaba del Renacimiento el surgimiento del espíritu individualista moderno, que la Edad Media habría cohibido.[5]​
Desde una perspectiva de la evolución artística general de Europa, el Renacimiento significó una «ruptura» con la unidad estilística que hasta ese momento había sido «supranacional». El Renacimiento no fue un fenómeno unitario desde los puntos de vista cronológico y geográfico: su ámbito se limitó a la cultura europea y a los territorios americanos recién descubiertos, a los que las novedades renacentistas llegaron tardíamente. Su desarrollo coincidió con el inicio de la Edad Moderna, marcada por la consolidación de los estados europeos, los viajes transoceánicos que pusieron en contacto a Europa y América, la descomposición del feudalismo, el ascenso de la burguesía y la afirmación del capitalismo. Sin embargo, muchos de estos fenómenos rebasan por su magnitud y mayor extensión en el tiempo el ámbito renacentista.[6]​


== Aspectos generales ==


=== Contexto histórico ===

El Renacimiento marca el inicio de la Edad Moderna, un período histórico que por lo general se suele establecer entre el descubrimiento de América en 1492 y la Revolución francesa en 1789, el cual, en el terreno artístico, engloba estilos como el Renacimiento y el manierismo (siglos xv y xvi), el Barroco, el rococó y el Neoclasicismo (siglos xvii y xviii). Otros historiadores sitúan la fecha de inicio en 1453, caída de Constantinopla, o bien remarcan un hecho trascendental como la invención de la imprenta (hacia 1440 aproximadamente, de la mano de Johannes Gutenberg).[7]​ 
Los antecedentes históricos del Renacimiento cabe situarlos en la decadencia del mundo medieval ocurrida a lo largo del siglo XV por diversos factores, como el declive del Sacro Imperio Romano Germánico, el debilitamiento de la Iglesia católica a causa de los cismas y los movimientos heréticos —que darían origen a la Reforma protestante—, la profunda crisis económica derivada del anquilosamiento del sistema feudal y la decadencia de las artes y las ciencias, lastradas por una teología escolástica sumida en el escepticismo.[8]​
Frente a esta decadencia, los principales centros académicos europeos buscaron regenerarse a través del retorno a los valores de la cultura clásica grecorromana. A su vez, comenzó a fraguarse una nueva sociedad fundamentada en el auge de los nuevos estados centralizados, con poderosos ejércitos y administraciones burocratizadas —inicio del autoritarismo monárquico preconizado por Maquiavelo—, así como en el crecimiento demográfico y una economía centrada en una nueva clase social emergente, la burguesía, que puso los cimientos del capitalismo y una economía mercantil y preindustrial; todo ello coadyuvado por el progreso técnico y científico experimentado durante este período, fundamentado en la imprenta y la consiguiente velocidad de difusión de las novedades.[9]​ Surgió así una visión del mundo más antropocéntrica, desligada de la religión y el teocentrismo medieval, en la que el hombre y los avances científicos supondrán la nueva forma de valorar el mundo: el humanismo, un término inicialmente aplicado a los especialistas en disciplinas grecolatinas (derecho, retórica, teología y arte), que se haría extensivo a filósofos, artistas, científicos y cualquier estudioso de las diversas ramas del conocimiento que comenzaron entonces a aglutinarse en un concepto de cultura general.[8]​
En Italia, el epicentro de la cultura renacentista, la división del territorio en ciudades-estado con diferentes regímenes políticos —repúblicas como Florencia o Venecia, estados monárquicos como Milán y Nápoles o el dominio papal en Roma— propició el ascenso de una élite económica que patrocinó la cultura y el arte como instrumentos de propaganda del estado, cada uno rivalizando con los demás en magnificencia y esplendor. La educación se volvió más accesible, dejando de estar circunscrita al clero, y se favoreció el debate intelectual, con la fundación de universidades y el patrocinio de la literatura.[10]​ 
Por su parte, el siglo XVI estuvo marcado por los grandes descubrimientos geográficos iniciados con la llegada de Colón a América en 1492, como el establecimiento de la ruta del Cabo por Vasco da Gama en 1498, la vuelta al mundo de Magallanes entre 1519 y 1521, el desembarco de Cortés en México, 1519, y la conquista del Perú por Pizarro (1530-1533); así como por la ruptura de la unidad cristiana causada por la Reforma protestante de Martín Lutero (1520), el desarrollo de la ciencia y la técnica (Nova Scientia de Tartaglia, 1538; De revolutionibus de Copérnico, 1543; Anatomía de Vesalio, 1543) y la expansión del humanismo (Erasmo de Róterdam, Giovanni Pico della Mirandola, Ludovico Ariosto, Tomás Moro, Juan Luis Vives, François Rabelais).[8]​


=== Definición ===

El término «Renacimiento» procede del italiano Rinascita y fue acuñado por el artista e historiador Giorgio Vasari en sus Vidas (1550/1568), en alusión al renacer de la cultura clásica tras el oscurantismo medieval. Como tal, supone un fenómeno tanto social como político y cultural que abarcó todo el continente europeo durante los siglos xv y xvi.[8]​ En la historiografía moderna, la primera definición del Renacimiento procede del historiador francés Jules Michelet (La Renaissance, 1855),[11]​ mientras que la visión actual del mundo renacentista fue forjada por Jacob Burckhardt en su ensayo La cultura del Renacimiento en Italia (1860).[9]​
Aunque se suele situar el inicio del Renacimiento en el siglo XV numerosos historiadores lo retrotraen al siglo XIV o aún al xiii, a la obra de algunos artistas considerados precursores, como Cimabue y Giotto en pintura o Nicola Pisano en escultura. Estos sentaron las bases de los primeros artistas plenamente renacentistas en la Florencia del primer cuarto del siglo XV, como el pintor Masaccio, el escultor Donatello o el arquitecto Brunelleschi, todos ellos interesados en el naturalismo, la armonía y las proporciones matemáticas.[12]​
En este clima cultural de renovación, basado en modelos de la antigüedad clásica, surgió a principios del siglo XV un movimiento artístico en Italia de gran vitalidad, que se extendería de inmediato a otros países de Europa.[13]​ El artista tomó conciencia de individuo con valores intrínsecos, se sintió atraído por la cultura y el saber en general, y comenzó a estudiar los modelos de la antigüedad, a la vez que estudiaba disciplinas como la anatomía e investigaba nuevas técnicas, como el claroscuro y la perspectiva, desarrollándose enormemente las formas de representar el mundo natural con fidelidad. El paradigma de esta nueva actitud es Leonardo da Vinci, quien se interesó por múltiples ramas del saber, pero del mismo modo Miguel Ángel Buonarroti, Rafael Sanzio, Sandro Botticelli y Bramante fueron artistas conmovidos por la imagen de la antigüedad y preocupados por desarrollar nuevas técnicas escultóricas, pictóricas y arquitectónicas, así como por la música, la poesía y la nueva sensibilidad humanística.[14]​
No cabe duda de que el Renacimiento evolucionó en buena medida del arte medieval, una parte del cual no había dejado de valorar e imitar el arte clásico; pero el artista renacentista buscó imperiosamente distanciarse de la etapa anterior, a la que menospreciaban por su supeditación a los valores religiosos y por su estilo antinaturalista, proveniente no de una falta de habilidad técnica en imitar a la naturaleza, sino de una voluntad propia de eludirla para enfatizar otros valores más subjetivos, ligados a la espiritualidad. Sin embargo, el propio artista renacentista no valoró este hecho y se sintió distinto, «renacido»; así, Lorenzo Valla llegó a afirmar que no sabía por qué las artes «habían decaído hasta tal punto, y casi muerto; ni tampoco por qué habían resurgido en esa época; apareciendo y triunfando tantos buenos artistas y escritores».[15]​ 

Buena parte del surgimiento de esta nueva escala de valores, en que artistas y literatos serán exaltados por encima de personajes de noble cuna, proviene del sistema de ciudades-estado italianas de tipo republicano, alejadas así de los modos autoritarios de la aristocracia y el clero, con sociedades en que se valoraba más el mérito propio que no el proveniente del nacimiento en una determinada estirpe. En esta nueva sociedad se valora más la virtud cívica que la caballeresca o contemplativa, el talento personal —fuese en los negocios, la ciencia o el arte— que el rancio abolengo.[16]​
Conviene remarcar que un factor que coadyuvó enormemente al éxito de las nuevas teorías artísticas fue el mecenazgo, tanto de ciudades y entidades de diversa índole como de personajes provenientes tanto de la aristocracia y el clero como de la nueva burguesía emergente. Para estos personajes, el patronazgo de la cultura era una señal de poder y estatus social, que otorgaba a quien lo ejercía prestigio y ostentación frente a sus semejantes. Algunos de los mecenas más distinguidos fueron: el florentino Lorenzo de Médicis, apodado «el Magnífico»; Federico da Montefeltro, duque de Urbino; Ludovico Gonzaga, marqués de Mantua; Alfonso el Magnánimo, rey de Nápoles; Francesco y Ludovico Sforza, duques de Milán; además de los papas y cardenales de la Iglesia.[17]​
El artista renacentista es heredero de los preceptos de la cultura clásica, pero los reinterpreta a través del humanismo, reafirmando los valores intrínsecos del mundo perceptible y del ser humano como parte de esa realidad sensible. Aunque no renuncia a la religión y los valores de la realidad cristiana, da preponderancia a esta nueva visión humanística por encima de la trascendencia religiosa. Así, a la visión estática del universo preponderante durante la Edad Media se sucede una visión dinámica que se sustenta en la experimentación y en la revalidación del método científico como fuente de conocimiento.[18]​ Por otro lado, los nuevos valores supremos del artista serán la belleza y la armonía, desligadas de la religión y sustentadas en el estudio de la naturaleza, que a través de la medida y la proporción otorgan al artista nuevas herramientas para realizar sus obras.[19]​ 
Mientras surgía en Florencia el Quattrocento o Primer Renacimiento italiano —así llamado por desarrollarse durante los años 1400 (siglo XV)—, originado por la búsqueda de los cánones de belleza clásicos y de las bases científicas del arte, se produjo un fenómeno similar y coetáneo en Flandes —especialmente en pintura—, basado principalmente en la observación de la naturaleza. Este Primer Renacimiento tuvo gran difusión en la Europa Oriental: la fortaleza moscovita del Kremlin, por ejemplo, fue obra de artistas italianos.[14]​
La segunda fase del Renacimiento, o Cinquecento (siglo XVI), estuvo marcada por la hegemonía artística de Roma, cuyos papas (Julio II, León X, Clemente VII y Paulo III, algunos de ellos pertenecientes a la familia florentina de los Médici) apoyaron fervorosamente el desarrollo de las artes, así como la investigación de la antigüedad clásica. Sin embargo, con las guerras de Italia (saco de Roma en 1527), muchos de estos artistas emigraron y propagaron las teorías renacentistas por toda Europa.[14]​
Así, a lo largo del siglo XVI el Renacimiento italiano se extendió por toda Europa, desde Portugal hasta Escandinavia, y desde Francia hasta Rusia. Muchos artistas viajaron en busca de formación o mecenazgo, y las grandes cortes europeas —como Fontainebleau, Madrid, Praga o Dresde— se llenaron de artistas de múltiples nacionalidades. Se valoraba especialmente a los artistas italianos, pero numerosos extranjeros que fueron a formarse a Italia adquirieron así una nueva reputación. Un factor coadyuvante de la difusión del nuevo arte fue el grabado, cuya fabricación en serie permitió expandir las obras de los artistas por todo el continente.[20]​ También aumentó considerablemente el mercado del arte, y la labor de los marchantes fue esencial para conectar a artistas y compradores; uno de los mayores centros de mercado del arte de la época fue Amberes.[21]​ También creció el coleccionismo, y aparecieron las llamadas «cámaras de arte» (Kunstkammern), generalmente pertenecientes a personajes de la aristocracia y la realeza, unas estancias donde se exponían objetos de arte de todo tipo, libros y objetos de toda clase, e incluso minerales o muestras naturales, de la flora y la fauna; una de las más afamadas fue la de Rodolfo II en Praga.[22]​ 

Características
De forma genérica se pueden establecer las características del Renacimiento en: 

La «vuelta a la antigüedad»: resurgieron tanto las antiguas formas arquitectónicas como el orden clásico y la utilización de motivos formales y plásticos antiguos. Asimismo, se tomaron como motivos temáticos la mitología clásica y la historia, así como la adopción de antiguos elementos simbólicos. Con ello el objetivo no era efectuar una copia servil, sino la penetración y el conocimiento de las leyes que sustentan el arte clásico. Buena parte de esta revalorización del arte clásico vino por los hallazgos arqueológicos de piezas como monedas, camafeos o esculturas romanas, así como la recuperación de tratados clásicos como los de Vitruvio, esenciales en la renovación de la arquitectura.[13]​
Surgimiento de una nueva «relación con la naturaleza», que iba unida a una concepción ideal y realista de la ciencia. La matemática se va a convertir en la principal ayuda de un arte que se preocupa incesantemente en fundamentar racionalmente su ideal de belleza. La aspiración de acceder a la verdad de la naturaleza, como en la antigüedad, no se orienta hacia el conocimiento de fenómeno casual, sino hacia la penetración de la idea.[13]​
El Renacimiento hace al «hombre» medida de todas las cosas. Presupone en el artista una formación científica, que le hace liberarse de las actitudes gremiales y mecanicistas más propias del medievo y elevarse en la escala social. Esto supone revestir al artista de una nueva consideración, la de «creador». La figura humana es el nuevo centro de interés del artista, que estudia con detenimiento la anatomía para hacer una representación fidedigna, al tiempo que valora aspectos como el movimiento y la expresión.[13]​
El «mecenazgo»: las clases altas patrocinaban y encargaban obras constantemente, ya que el arte era visto como un instrumento de prestigio y refinamiento, lo que condujo a un momento de gran brillantez en todas las disciplinas artísticas. Los principales centros de mecenazgo fueron la Florencia de los Médicis en el Quattrocento y la Roma papal en el Cinquecento, particularmente Julio II y León X.[13]​ En otras ciudades, otras grandes familias fomentaron el mecenazgo: los Este en Ferrara, los Gonzaga en Mantua, los Sforza en Milán, los Colonna en Nápoles, etc.


=== Estética ===

La cultura renacentista supuso el retorno al racionalismo, al estudio de la naturaleza, la investigación empírica, con especial influencia de la filosofía clásica grecorromana. La estética renacentista se basó tanto en la antigüedad clásica como en la estética medieval, por lo que a veces resultaba algo contradictoria: la belleza oscilaba entre una concepción realista de imitación de la naturaleza y una visión ideal de perfección sobrenatural, siendo el mundo visible el camino para ascender a una dimensión suprasensible.[23]​
Uno de los primeros teóricos del arte renacentista fue Cennino Cennini: en su obra Il libro dell'arte (1400) sentó las bases de la concepción artística del Renacimiento, defendiendo el arte como una actividad intelectual creadora, y no como un simple trabajo manual. Para Cennini el mejor método para el artista es retratar de la naturaleza (ritrarre de natura), defendiendo la libertad del artista, que debe trabajar «como le place, según su voluntad» (come gli piace, secondo sua volontà). También introdujo el concepto de «diseño» (disegno), el impulso creador del artista, que forja una idea mental de su obra antes de realizarla materialmente, concepto de vital importancia desde entonces para el arte moderno.[24]​
En ese contexto surgieron varios tratados más acerca del arte, como los de Leon Battista Alberti (De Pictura, 1436-1439; De re aedificatoria, 1450; y De Statua, 1460), o Los Comentarios (1447) de Lorenzo Ghiberti. Alberti recibió la influencia aristotélica, pretendiendo aportar una base científica al arte. También habló de decorum, el tratamiento del artista para adecuar los objetos y temas artísticos a un sentido mesurado, perfeccionista.[25]​ Fue Alberti quien agrupó a la arquitectura, la escultura y la pintura en el grupo de las artes liberales, ya que hasta entonces eran consideradas como artesanía; con ello, elevó al artista a la categoría de creador intelectual.[26]​ Ghiberti fue el primero en periodificar la historia del arte, distinguiendo antigüedad clásica, período medieval y lo que llamó «renacer de las artes» (Renacimiento).[27]​
El Renacimiento puso especial énfasis en la imitación de la naturaleza, lo que consiguió a través de la perspectiva o de estudios de proporciones, como los realizados por Luca Pacioli sobre la sección áurea: en De Divina Proportione (1509) habló del número áureo —representado por la letra griega φ (fi)—, el cual posee diversas propiedades como relación o proporción, que se encuentran tanto en algunas figuras geométricas como en la naturaleza, en elementos tales como caracolas, nervaduras de las hojas de algunos árboles, el grosor de las ramas, etc. Asimismo, atribuyó un carácter estético especial a los objetos que siguen la razón áurea, así como les otorgó una importancia mística.[28]​
Por otro lado, Giorgio Vasari, en Vida de los más excelentes arquitectos, pintores y escultores italianos desde Cimabue hasta nuestros tiempos (1542–1550), fue uno de los predecesores de la historiografía del arte, al confeccionar una crónica de los principales artistas de su tiempo, poniendo especial énfasis en la progresión y el desarrollo del arte.[29]​


== Arte ==


=== Etapas ===

Diferentes etapas históricas marcan el desarrollo del Renacimiento: la primera tiene como espacio cronológico todo el siglo XV: es el denominado Quattrocento, y comprende el Primer Renacimiento —también llamado «Renacimiento temprano» o «Bajo Renacimiento»—, que se desarrolla en Italia; la segunda surge en el siglo XVI y se denomina Cinquecento: su dominio artístico queda referido al clasicismo o Alto Renacimiento —también llamado «Renacimiento pleno»—, que se centra en el primer cuarto del siglo. En esta etapa surgen las grandes figuras del Renacimiento en las artes: Leonardo, Miguel Ángel, Rafael. Es el apogeo del arte renacentista. Este período desemboca hacia 1520-1530 en una reacción anticlásica que conforma el manierismo, que dura hasta el final del siglo XVI. Mientras que en Italia se estaba desarrollando el Renacimiento, en el resto de Europa se mantiene el arte gótico en sus formas tardías, situación que se iba a mantener, exceptuando casos concretos, hasta comienzos del siglo XVI.[30]​
En Italia el enfrentamiento y convivencia con la antigüedad grecorromana, considerada como un legado nacional, proporcionó una amplia base para una evolución estilística homogénea y de validez general. Por ello, allí fue posible su surgimiento y precedió a todas las demás naciones. Fuera de Italia, el desarrollo del Renacimiento dependería constantemente de los impulsos marcados por Italia: artistas importados desde Italia o formados allí harían el papel de verdaderos transmisores. Monarcas como Francisco I en Francia o Carlos I y Felipe II en España impusieron el nuevo estilo en las construcciones que patrocinaban, influyendo en los gustos artísticos predominantes y convirtiendo el Renacimiento en una «moda».


=== Italia ===


==== Arquitectura ====

La arquitectura renacentista tuvo un carácter marcadamente profano en comparación con la época anterior. Surgió en una ciudad en donde la arquitectura gótica apenas había penetrado, Florencia. A pesar de ello, muchas de las obras más destacadas fueron edificios religiosos.
Con el nuevo gusto, se buscaba ordenar y renovar los viejos burgos medievales e incluso se proyectaban ciudades de nueva planta. La búsqueda de la «ciudad ideal», opuesta al modelo caótico y desordenado del medievo, sería una constante preocupación de artistas y mecenas. Así, el papa Pío II reordenó su ciudad natal, Pienza, convirtiéndola en un auténtico muestrario del nuevo urbanismo renacentista. En sí, las ciudades se convertirían en el escenario ideal de la renovación artística, oponiéndose al concepto medieval en el que lo rural tenía un papel preferente gracias al monacato. 
Al tomar elementos de la arquitectura clásica, los arquitectos renacentistas lo hacían de forma selectiva, así por ejemplo en lugar de utilizar la columna dórica clásica se prefirió el orden toscano. Igualmente se crearon formas nuevas, como la columna abalaustrada, nuevos órdenes de capiteles o decoraciones que si bien se inspiraban en la antigüedad habían de adaptarse al uso religioso de las iglesias. Así, los amorcillos clásicos que acompañaban a Venus en las representaciones griegas o romanas pasan a ser angelotes (putti).
Los arquitectos emplean las proporciones modulares y la superposición de órdenes que aparecía en los edificios romanos; las cúpulas se utilizaron mucho como elemento monumental en iglesias y edificios públicos. A partir de este momento, el arquitecto abandona el carácter gremial y anónimo que había tenido durante la Edad Media y se convierte en un intelectual, un investigador. Muchos de ellos escribieron tratados y obras especulativas de gran trascendencia, como en el caso de Leon Battista Alberti o Sebastiano Serlio.
Los elementos constructivos más característicos del estilo renacentista fueron:

Estructurales: arco de medio punto, columnas, cúpula semiesférica, bóveda de cañón y cubierta plana con casetones.[31]​ Todos ellos habían sido usados en la antigüedad, especialmente por el arte romano, y se recuperan ahora, modificándolos. Decae paulatinamente el tradicional método de construcción del gótico, y se abandona en gran medida las bóvedas de crucería, el arco apuntado, las naves escalonadas y, sobre todo, la impresión de colosalismo y multiplicidad de los edificios medievales. Predominarían ahora valores como la simetría, la claridad estructural, la sencillez y, sobre todo, la adaptación del espacio a la medida del hombre.
Decorativos: pilastras, frontones, pórticos, motivos heráldicos, almohadillados, volutas, grutescos, guirnaldas, motivos de candelieri (candelabros o pebeteros) y tondos o medallones. Algunos de estos ya se habían utilizado en el gótico, otros son creaciones originales y la mayoría se inspiraron en modelos romanos y griegos. En cuanto a la decoración, el Renacimiento preconizó el despojamiento, la austeridad, el orden. Solo a finales del siglo XVI esta tendencia se rompería en favor de la fantasía y la riqueza decorativa con el manierismo.
Por etapas, se pueden distinguir dos grandes momentos:

El Quattrocento tuvo su centro neurálgico en Florencia y la Toscana. La sencillez y claridad estructural y decorativa fue el rasgo fundamental de la arquitectura de este momento. Los modelos clásicos se someten a un proceso de estilización y se adaptan al templo cristiano. Fue frecuente recurrir a los órdenes clásicos, con columnas y pilastras adosadas, capiteles (con preferencia el corintio, aunque sustituyendo los caulículos por figuras fantásticas o de animales), fustes lisos y casi omnipresencia del arco de medio punto. Se usa también la bóveda de cañón y de arista, y cubiertas de madera con casetones. Lo que fundamentalmente distingue a la arquitectura del Quattrocento de la del Alto Renacimiento es la decoración menuda (putti, guirnaldas de flores o frutos, grutescos, etc.), las cúpulas con nervios, con ciertos resabios góticos (catedral de Florencia, de Filippo Brunelleschi) y las fachadas simétricas de pisos superpuestos (palacio Medici−Riccardi, de Michelozzo) o con sillares almohadillados (palacio Rucellai, de Bernardo Rossellino, proyecto de Alberti, palacio Pitti). En general, la arquitectura cuatrocentista da la impresión de orden, sencillez, ligereza y simetría, predominando en el interior de los edificios la luminosidad y la desnudez. Los arquitectos más destacados de este período fueron Brunelleschi (Basílica de San Lorenzo, 1420; Basílica del Santo Spirito, 1436) y Leon Battista Alberti (San Andrés de Mantua, 1460); y la principal obra fue la catedral de Santa María del Fiore de Florencia y su famosa cúpula, obra de Brunelleschi.[32]​ Del resto de Italia destacan: la Cartuja de Pavía, de Giovanni Antonio Amadeo (1475); la iglesia de San Zacarías de Venecia, de Mario Codussi (1470); y el Castel Nuovo de Nápoles, de Francesco Laurana (1453).[33]​
El Cinquecento tuvo como centro Roma: en 1506 Donato Bramante terminaba su célebre proyecto para la Basílica de San Pedro en el Vaticano, que sería el edificio que marcaría la pauta en lo restante del siglo XVI.[34]​ En esta etapa, los edificios tienden más a la monumentalidad y la grandiosidad. Miguel Ángel introdujo el «orden gigante» en su proyecto para la basílica vaticana, lo que rompió con el concepto de «arquitectura hecha a la medida del hombre».[35]​ Los palacios se adornaban con elaborados bajorrelieves (palacio Grimani de Venecia, 1549, obra de Michele Sanmicheli) o de esculturas exentas (Biblioteca de San Marcos, 1537–1550, Venecia, obra de Jacopo Sansovino). Predominaría de este modo la idea de riqueza, monumentalidad y lujo en las construcciones. A medida que avanza el siglo, el manierismo se introdujo en la arquitectura, con edificios cada vez más suntuosos, rebuscadas decoraciones y elementos que pretenden captar la atención del espectador por su originalidad o extravagancia (palacio del Té, en Mantua, de Giulio Romano). Podemos distinguir, de este modo, como en las demás disciplinas artísticas, dos periodos: el «clasicismo» de principios de siglo, con autores como Bramante, Miguel Ángel, Antonio da Sangallo el Viejo, o Jacopo Sansovino;[36]​ y el «manierismo», que se da a partir de 1530, siendo sus principales autores Andrea Palladio, Giorgio Vasari, Giulio Romano, Jacopo Vignola y Vincenzo Scamozzi.[37]​ Hay que apuntar que la ruptura del manierismo no fue radical puesto que ya en la obra de Miguel Ángel aparecen elementos que la preludian.[38]​


==== Pintura ====

En pintura, las novedades del Renacimiento se introdujeron de forma paulatina pero irreversible a partir del siglo XV. Un antecedente de las mismas fue Giotto, pintor aún dentro de la órbita del gótico, pero que desarrolló en sus pinturas conceptos como volumen tridimensional, perspectiva y naturalismo, que alejaban su obra de los rígidos modos de la tradición bizantina y gótica y preludiaban el Renacimiento pictórico.
En el Quattrocento (siglo XV) se recogieron todas estas novedades y se adaptaron a la nueva mentalidad humanista y burguesa que se expandía por las ciudades-estado italianas. Los pintores, aún tratando temas religiosos la mayoría de ellos, introdujeron también en sus obras la mitología, la alegoría y el retrato, que se desarrollarían a partir de ahora enormemente. Una búsqueda constante de los pintores de esta época sería la perspectiva, objeto de estudio y reflexión para muchos artistas: se trató de llegar a la ilusión de espacio tridimensional de una forma científica y reglada. La pintura cuatrocentista es una época de experimentación; las pinturas abandonan lenta y progresivamente la rigidez gótica y se aproximan cada vez más a la realidad. Aparece la naturaleza retratada en los fondos de las composiciones, y se introducen los desnudos en las figuras.[39]​
Los pintores más destacados de esta época fueron: en Florencia, Fra Angélico, Masaccio, Benozzo Gozzoli, Piero della Francesca, Filippo Lippi y Paolo Uccello; en Umbría, Perugino; en Padua, Andrea Mantegna; y, en Venecia, Giovanni Bellini. Por encima de todos ellos destaca Sandro Botticelli, autor de alegorías, delicadas madonnas y asuntos mitológicos. Su estilo dulce, muy atento a la belleza y sensibilidad femeninas, y predominantemente dibujístico, caracterizan la escuela florentina de pintura y toda esta época. Otros autores del Quattrocento italiano son Andrea del Castagno, Antonio Pollaiuolo, Pinturicchio, Domenico Ghirlandaio, Cima da Conegliano, Luca Signorelli, Cosimo Tura, Vincenzo Foppa, Alessio Baldovinetti, Vittore Carpaccio y, en el sur de la península, Antonello da Messina.[40]​
El Cinquecento (siglo XVI) fue la etapa culminante de la pintura renacentista, y denominada por ello a veces como «clasicismo». Los pintores asimilan las novedades y la experimentación cuatrocentistas y las llevan a nuevas cimas creativas. En este momento aparecen grandes maestros, cuyo trabajo servirá de modelo a los artistas durante siglos. El primero de ellos fue Leonardo da Vinci, uno de los grandes genios de todos los tiempos. Fue el ejemplo más acabado de artista multidisciplinar, intelectual y obsesionado con la perfección, que le llevó a dejar muchas obras inconclusas o en proyecto. Poco prolífico en su faceta pictórica, aportó sin embargo muchas innovaciones que condujeron a la historia de la pintura hacia nuevos rumbos. Quizá su principal aportación fue el sfumato o claroscuro, delicada gradación de la luz que otorga a sus pinturas una gran naturalidad, a la vez que ayuda a crear espacio. Estudiaba cuidadosamente la composición de sus obras, como en la Última Cena, donde las figuras se ajustan a un esquema geométrico. Supo unir en sus trabajos la perfección formal a ciertas dosis de misterio, presente, por ejemplo, en la celebérrima Gioconda, La Virgen de las Rocas o el San Juan Bautista.[41]​

 
Miguel Ángel es, cronológicamente, la segunda gran figura. Fundamentalmente escultor, se dedicó a la pintura de forma esporádica, a petición de algunos admiradores de su obra, sobre todo el papa Julio II. Los frescos de la Capilla Sixtina muestran el atormentado mundo interior de este artista, poblado de figuras monumentales, sólidas y tridimensionales como si fueran esculturas, y de llamativa presencia física. En su obra cobra mucha importancia el desnudo, aun cuando la casi totalidad de la misma fue hecha para decorar iglesias.[42]​
Rafael Sanzio completa la tríada de genios del clasicismo. Su estilo tuvo un enorme éxito y se puso de moda entre los poderosos. La pintura de Rafael buscaba ante todo la grazia, o belleza equilibrada y serena. Sus madonnas recogen las novedades de Leonardo en lo que se refiere a composición y claroscuro, añadiendo una característica dulzura. Anticipa claramente la pintura manierista en sus últimas obras, cuyo estilo agitado y dramático copiarán y difundirán sus discípulos.[43]​
Con la aparición de estos tres grandes maestros, los artistas contemporáneos asumen que el arte ha llegado a su culmen —concepto recogido en la obra de Giorgio Vasari Las Vidas—[44]​ y se afanarán por tanto en incorporar estos logros, por un lado, y en la búsqueda de un estilo propio y original como forma de superarlos. Ambas cosas, junto con el ambiente pesimista que se respiraba en la Cristiandad en la década de 1520 (Saco de Roma, Reforma protestante, guerras), hizo surgir con fuerza a partir de los años 1530 una nueva corriente, el Manierismo. Se buscaría a partir de entonces lo extravagante, lo extraño, lo exagerado y lo irreal. Pertenecen a esta corriente pictórica Jacopo Pontormo, Bronzino, Parmigianino, Rosso Fiorentino o Francesco Salviati. Otros autores tomarían algunas novedades manieristas pero siguiendo una línea más personal y clasicista. Entre ellos podemos citar a Sebastiano del Piombo, Correggio, Andrea del Sarto o Federico Barocci.[45]​
Dentro de las diferentes escuelas que surgen en Italia en el Cinquecento, la de Venecia presenta especiales características. Si los florentinos ponían el acento en el disegno, es decir, en la composición y la línea, los pintores venecianos se centrarían en el color. Las especiales características del estado veneciano pueden explicar algo de esta particularidad, puesto que se trataba de una sociedad elitista, amante del lujo y muy relacionada con Oriente. La escuela veneciana reflejaría esto mediante una pintura refinada, hedonista, menos intelectual y más vital, muy decorativa y colorista. Precursores de la escuela veneciana del Cinquecento fueron Giovanni Bellini y, sobre todo, Giorgione, pintor de alegorías, paisajes y asuntos religiosos, melancólicos y misteriosos. Deudor de su estilo fue Tiziano, el mayor pintor de esta escuela, excelente retratista, quizá el más demandado de su tiempo; autor de complejas y realistas composiciones religiosas, llenas de vida y colorido. En la última etapa de su vida deshace los contornos de las figuras, convirtiendo sus cuadros en puras sensaciones de luz y color, anticipo del impresionismo.[46]​ Tintoretto, Paolo Veronese y Palma el Viejo continuaron esta escuela llevándola hacia el manierismo y anticipando en cierta manera la pintura barroca.[47]​


==== Escultura ====

Como en las demás manifestaciones artísticas, los ideales de vuelta a la antigüedad, inspiración en la naturaleza, humanismo antropocéntrico e idealismo fueron los que caracterizaron la escultura de este período. Ya el gótico había preludiado en cierta manera algunos de estos aspectos, pero algunos hallazgos arqueológicos (el Laocoonte, hallado en 1506, o el Torso Belvedere) que se dieron en la época supusieron una auténtica conmoción para los escultores y sirvieron de modelo e inspiración para las nuevas realizaciones.

 
Aunque se siguieron haciendo obras religiosas, en las mismas se advierte un claro aire profano; se reintrodujo el desnudo y el interés por la anatomía con fuerza, y aparecieron nuevas tipologías técnicas y formales, como el relieve en stiacciato (altorrelieve con muy poco resalte, casi plano) y el tondo, o composición en forma de disco; también la iconografía se renovó con temas mitológicos, alegóricos y heroicos. Apareció un inusitado interés por la perspectiva, derivado de las investigaciones arquitectónicas coetáneas, y el mismo se plasmó en relieves, retablos, sepulcros y grupos escultóricos. Durante el Renacimiento decayó en cierta manera la tradicional talla en madera policromada en favor de la escultura en piedra —mármol preferentemente— y se recuperó la escultura monumental en bronce, caída en desuso durante la Edad Media. Los talleres de Florencia fueron los más reputados de Europa en esta técnica, y surtieron a toda Europa de estatuas de este material.[48]​
Los dos siglos que dura el Renacimiento en Italia dieron lugar, igual que en las demás artes, a dos etapas:

El Quattrocento (siglo XV): el centro escultórico principal fue Florencia, donde la familia Médicis y, con posterioridad, la República, ejercieron de mecenas de numerosas obras. Lorenzo el Magnífico era aficionado a las esculturas griegas y romanas y había formado una interesante colección de las mismas, poniendo de moda el gusto clásico. Los autores más destacados de la época fueron Lorenzo Ghiberti (Puerta del Paraíso del Baptisterio de Florencia), Andrea Verrocchio (Monumento al condotiero Colleoni), Donatello, el taller de los hermanos Della Robbia —que introdujeron la cerámica vidriada y policromada como novedad, utilizándola en decoraciones de edificios—, Jacopo della Quercia, Desiderio da Settignano y Bernardo Rossellino. El más importante de ellos es Donatello, gran creador que, partiendo de los supuestos del gótico, estableció un nuevo ideal inspirado en la grandeza clásica. Suyo es el mérito de rescatar el monumento conmemorativo público —su Condotiero Gattamelata es una de las primeras estatuas ecuestres de bronce desde la antigüedad—, la utilización heroica del desnudo (David) y la intensa humanización de las figuras, llegando al retrato en ocasiones, pero sin abandonar nunca una orientación claramente idealista.[49]​

El Cinquecento (siglo XVI): esta época está marcada por la aparición estelar de uno de los escultores más geniales de todos los tiempos, Miguel Ángel.[50]​ Hasta tal punto marcó la escultura de todo el siglo que muchos de sus continuadores no fueron capaces de recoger todas sus novedades y estas no se desarrollaron hasta varios siglos después. Miguel Ángel fue, como tantos otros en esta época, un artista multidisciplinar. Sin embargo, él se consideraba preferentemente escultor. En sus primeras obras recoge el interés arqueológico surgido en Florencia: así, su Baco ebrio fue realizado con intención de que aparentara ser una escultura clásica. Igual espíritu se aprecia en la Piedad, realizada entre 1498 y 1499 para la basílica vaticana. Protegido primero por los Médicis, para los que creó las Tumbas Mediceas, soberbio ejemplo de expresividad, marchó luego a Roma, donde colaboró en los trabajos de construcción de la nueva basílica. El pontífice Julio II lo tomó bajo su protección y le encomendó la creación de su Mausoleo, denominado por el artista como «la tragedia de la sepultura» por los cambios y demoras que sufrió el proyecto. En las esculturas hechas para este sepulcro, como el célebre Moisés, aparece lo que se ha venido denominando terribilitá miguelangelesca: una intensa a la vez que contenida emoción que se manifiesta en anatomías sufrientes, exageradas y nerviosas —músculos en tensión—, posturas contorsionadas y escorzos muy rebuscados. Los rostros, sin embargo, suelen mostrarse contenidos. En sus obras finales el artista desdeña de la belleza formal de las esculturas y las deja inacabadas, adelantando un concepto que no volvería al arte hasta el siglo XX. Miguel Ángel continuó con la tradición de monumentos públicos heroicos y profanos que inició Donatello y la llevó a una nueva dimensión con su conocido David, esculpido para la Piazza della Signoria de Florencia.[51]​ En los años finales de la centuria, la huella de Miguel Ángel tuvo sus réplicas en Benvenuto Cellini (Perseo de la Loggia dei Lanzi de Florencia, espacio concebido como museo de escultura al aire libre), Bartolomeo Ammannati, Giambologna y Baccio Bandinelli, que exagerarían los elementos más superficiales de la obra del maestro, situándose plenamente todos ellos en la corriente manierista. Destaca en esta época también la saga familiar de los Leoni, broncistas milaneses al servicio de los Habsburgo españoles, auténticos creadores de la imagen áulica, un tanto estereotipada, de estos monarcas. Su presencia en España llevó allí de primera mano las novedades renacentistas, extendiendo su influjo hasta la escultura barroca.[52]​


=== España ===

En España el cambio ideológico no es tan extremo como en otros países; no se rompe abruptamente con la tradición medieval, por ello se habla de un Renacimiento español más original y variado que en el resto de Europa. Así, la literatura acepta las innovaciones italianas (Dante y Petrarca), pero no olvida la poesía del Cancionero y la tradición anterior. En cuanto a las artes plásticas, el Renacimiento hispano mezcló elementos importados de Italia —de donde llegaron algunos artistas, como Paolo de San Leocadio, Pietro Torrigiano o Domenico Fancelli— con la tradición local, y con algunos otros influjos —lo flamenco, por ejemplo, estaba muy de moda en la época por las intensas relaciones comerciales y dinásticas que unían estos territorios a España—. Las innovaciones renacentistas llegaron a España de forma muy tardía: hasta la década de 1520 no se encuentran ejemplos acabados de las mismas en las manifestaciones artísticas, y tales ejemplos son dispersos y minoritarios. No llegaron a España plenamente, pues, los ecos del Quattrocento italiano —solo por obra de la familia Borja aparecen artistas y obras de esa época en el área levantina—, lo que determina que el arte renacentista español pase casi abruptamente del gótico al manierismo.

En el campo de la arquitectura, tradicionalmente se distinguen tres periodos: plateresco (siglo XV-primer cuarto del siglo XVI), purismo o estilo italianizante (primera mitad del siglo XVI) y estilo herreriano (a partir de 1559-mediados del siglo siguiente). En el primero de ellos, lo renaciente aparece de forma superficial, en la decoración de las fachadas, mientras que la estructura de los edificios sigue siendo gotizante en la mayoría de los casos. Lo más característico del plateresco es un tipo de decoración menuda, detallista y abundante, semejante a la labor de los plateros, de donde deriva el nombre. El núcleo fundamental de esta corriente fue la ciudad de Salamanca, cuya Universidad y su fachada son el paradigma del estilo. Arquitectos destacados del mismo fueron Rodrigo Gil de Hontañón y Juan de Álava. El purismo representa una fase más avanzada de la italianización de la arquitectura. El palacio de Carlos V en la Alhambra de Granada, obra de Pedro de Machuca, es ejemplo de ello. El foco principal de este estilo se situó en Andalucía, donde además del citado palacio destacaron los núcleos de Úbeda y Baeza y arquitectos como Andrés de Vandelvira y Diego de Siloé.[53]​ Finalmente, apareció el estilo escurialense o herreriano, original adaptación del manierismo romano caracterizada por la desnudez y el gigantismo arquitectónico. La obra fundamental fue el palacio-monasterio de El Escorial, trazado por Juan Bautista de Toledo y Juan de Herrera, sin duda la obra más ambiciosa del Renacimiento hispano. Lo escurialense traspasó el umbral cronológico del siglo XVI llegando con gran vigencia a la época barroca.[54]​
En escultura, la tradición gótica mantuvo su hegemonía durante buena parte del siglo XVI. Los primeros ecos del nuevo estilo corresponden por lo general a artistas venidos de fuera, como Felipe Vigarny o Domenico Fancelli, que trabajó al servicio de los Reyes Católicos, esculpiendo su sepulcro (1517). No obstante, pronto surgieron artistas locales que asimilaron las novedades italianas, adaptándolas al gusto hispano, como Bartolomé Ordóñez y Damián Forment. En una fase más madura del estilo surgieron grandes figuras, creadoras de un peculiar manierismo que sentó las bases de la posterior escultura barroca: Juan de Juni y Alonso Berruguete son los más destacados.[55]​
La pintura renacentista española está determinada igualmente por el pulso que mantiene la herencia del gótico con los nuevos modos venidos de Italia. Esta dicotomía se aprecia en la obra de Pedro Berruguete, que trabajó en Urbino al servicio de Federico de Montefeltro, y Alejo Fernández. Posteriormente aparecieron artistas conocedores de las novedades italianas coetáneas, como Vicente Macip o su hijo Juan de Juanes —influidos por Rafael—, Luis de Morales, Juan Fernández de Navarrete o los leonardescos Fernando Yáñez de la Almedina y Hernando de los Llanos.[56]​ Pero la gran figura del Renacimiento español, y uno de los pintores más originales de la historia, se inscribe ya en el manierismo, aunque rebasando sus límites al crear un universo estilístico propio: El Greco.[57]​


=== Francia ===

En Francia la influencia italiana se dejó sentir desde muy temprano, favorecida por la cercanía geográfica, los vínculos comerciales y la monarquía, que ambicionaba anexionar los territorios limítrofes de la península italiana, y lo consiguió en algunos momentos. Sin embargo, el impulso definitivo a la adopción de las formas renacentistas se dio bajo el reinado de Francisco I. Este monarca, gran mecenas de las artes y aficionado a todo lo que procediera de Italia, protegió a importantes maestros, solicitando sus servicios para la corte francesa —entre ellos el mismo Leonardo da Vinci, que murió en el castillo de Cloux—, a la vez que emprendió un ambicioso programa de revitalización cultural que revolucionó el desarrollo de las artes en el país. Conviene tener presente que Francia fue la cuna del gótico y que, por tanto, este estilo estaba fuertemente arraigado y podía ser visto como un estilo nacional. De ahí que las formas góticas continuaran presentes durante un tiempo, a pesar del nuevo estilo impuesto por la corte.
En cuanto a la arquitectura, la monarquía, fortalecida y en período de expansión territorial, había patrocinado ya desde el siglo XV la remodelación de los viejos châteaux medievales y la creación de nuevas residencias más acordes con los tiempos. Pero fue precisamente Francisco I el que dio un impulso definitivo a esta operación renovadora, que tuvo varios focos. El primer edificio renacentista en Francia fue el castillo de Saint-Germain-en-Laye, imponente fortaleza de ladrillo y piedra en la que aparecen pequeños detalles renacentistas, dentro de una general sobriedad de aire militar. De estilo más avanzado fueron los castillos del valle del Loira, conjunto de mansiones para la realeza y la nobleza que muestran los rasgos más característicos del Renacimiento francés: decorativismo de raigambre manierista, recuerdos goticistas en las estructuras, y quizá lo más novedoso: una perfecta integración de los edificios en la naturaleza circundante, como se ve en el Castillo de Montsoreau o en el grácil puente del castillo de Chenonceau. El más célebre dentro de este conjunto es el castillo de Chambord, que presenta grandes audacias estilísticas, como una escalera interna helicoidal. Otros ejemplos de estas residencias suburbanas son los castillos de Amboise, Blois y Azay-le-Rideau.[58]​
Además de todas estas realizaciones, Francisco I se embarcó en la que quizá fue la obra fundamental de este período: el palacio de Fontainebleau, vieja mansión de los reyes franceses que se renovó totalmente. En el edificio en sí se aprecia ya el triunfo de las formas italianas, aunque adaptadas al gusto francés con sus típicas chimeneas y mansardas. Incluye fragmentos de desbordante creatividad, como la célebre Escalera Imperial, anticipo de soluciones barrocas. No obstante, quizá lo más destacado del proyecto fue que involucró a creadores de prácticamente todas las disciplinas artísticas, algunos venidos expresamente de Italia, como los pintores Francesco Primaticcio o Rosso Fiorentino, el famoso escultor Benvenuto Cellini o el arquitecto Sebastiano Serlio, importante autor de tratados de arquitectura del que apenas se conocen obras salvo este palacio. Las novedades que se fraguaron aquí trapasarían el ámbito local y darían origen a todo un estilo, el «estilo de Fontainebleau», un manierismo refinado al servicio de los gustos aristocráticos.[59]​
Tras Francisco I, las formas «a la italiana» acabaron imponiéndose definitivamente en la arquitectura bajo Enrique II, cuya esposa, Catalina de Médicis, pertenecía a la familia florentina más poderosa. Bajo su mandato (1547-1559) se reformó la antigua sede de la corte en París, el palacio del Louvre, convirtiéndolo en un moderno edificio de estética plenamente manierista. La reforma fue dirigida por uno de los arquitectos franceses más destacados del momento, Pierre Lescot, que diseñó el gran patio central (Cour Carrée), con características fachadas en las que utiliza el módulo de arco de triunfo clásico.[60]​ Asimismo, estos monarcas iniciaron la construcción de un nuevo palacio, enfrente del Louvre, el palacio de las Tullerías, en el que intervino el otro gran arquitecto francés del Renacimiento, Philibert Delorme.[61]​

La escultura del Renacimiento en Francia fue también al compás de lo dictado por Italia. Francia dejó de ser ya a finales del siglo XIV el gran centro escultórico de Europa que fue gracias a los talleres catedralicios, situación que continuaría durante el siglo XV, y aún más en el xvi. Es paradójico y a la vez revelador que esta situación coincida con la consolidación progresiva de la institución monárquica, evidentemente deseosa de renovar su imagen y dispuesta a usar el arte como instrumento propagandístico de primer orden. No obstante de la pérdida de hegemonía en este campo, que de todas formas nunca había sido definitiva, surgieron grandes figuras al calor de los proyectos reales; es de destacar el carácter ornamental y decorativo que tuvieron las esculturas, subordinándose al proyecto general de los edificios e integrándose en estos. Dos fueron los autores más sobresalientes: Germain Pilon y Jean Goujon.[62]​
La pintura también experimentó el progresivo declive de las formas góticas tradicionales y la llegada del nuevo estilo. Como se ha señalado, se conocieron en Francia de primera mano las formas pictóricas italianas en el siglo XVI gracias a la llegada de autores muy innovadores, como Leonardo o Rosso Fiorentino. Francisco I impulsó la formación de artistas franceses bajo la dirección de maestros italianos, como Niccolò dell'Abbate o Primaticcio, siendo este último el responsable de la decoración del palacio de Fontainebleau y la organización de las fiestas de la corte, y teniendo por tanto a sus órdenes a muchos artesanos y artistas. Esta convivencia de talentos, escuelas, disciplinas y géneros dio origen a la llamada «escuela pictórica de Fontainebleau», una derivación del manierismo pictórico italiano que incide en el erotismo, el lujo, los temas profanos y las alegorías, todo ello muy del gusto de su clientela principal, la aristocracia. La mayor parte de los artistas de Fontainebleau fueron anónimos, precisamente por esa integración de las artes que se propugnaba y por el magisterio de los artistas consagrados. No obstante, conocemos los nombres de algunos pintores, figurando Jean Cousin el Viejo o Antoine Caron entre los más destacados. Sin embargo, el pintor francés más importante de la época, a la vez que uno de los grandes retratistas de todos los tiempos, aunque gran parte de su obra se haya perdido, fue François Clouet, que superó a su padre, el también apreciable Jean Clouet, en la fiel plasmación de la vida de los poderosos de la época, con una profundidad psicológica y brillantez formal cuyo precedente hay que buscarlo en Jean Fouquet, gran pintor del siglo XV aún en la órbita del gótico.[63]​


=== Alemania ===

El Renacimiento artístico no fue en Alemania una tentativa de resurrección del arte clásico, sino una renovación intensa del espíritu germánico, motivado por la Reforma protestante. Alberto Durero fue la figura dominante del Renacimiento alemán. Su obra universal, que ya en vida fue reconocida y admirada en toda Europa, impuso la impronta del artista moderno, uniendo la reflexión teórica con la transición decisiva entre la práctica medieval y el idealismo renacentista. Sus pinturas, dibujos, grabados y escritos teóricos sobre arte ejercieron una profunda influencia en los artistas del siglo XVI de su propio país y de los Países Bajos. Durero comprendió la imperiosidad de adquirir un conocimiento racional de la producción artística, e introdujo el idealismo de raigambre italiana en el arte alemán.[64]​
La pintura germánica conoció en esta época uno de sus mayores momentos de esplendor. Junto a la figura fundamental de Durero surgieron otros grandes autores, como Lucas Cranach el Viejo, pintor por antonomasia de la Reforma protestante; Hans Baldung Grien, introductor de temáticas siniestras y novedosas, deudoras en cierto modo del arte medieval; Matthias Grünewald, uno de los precursores del expresionismo; Albrecht Altdorfer, excelente paisajista; o Hans Holbein el Joven, que desarrolló casi toda su producción, centrada en el retrato, en Inglaterra.[65]​
En escultura pervivieron las formas góticas hasta bien entrado el siglo XVI. Destaca la obra de Peter Vischer, autor de las tumbas imperiales de Innsbruck (1513) y de la tumba de San Sebaldo en Núremberg (1520). También trabajaron aquí algunos artistas flamencos, como Hubert Gerhard, autor del San Miguel de la fachada de la iglesia de San Miguel de Múnich.[66]​
En arquitectura, los primeros exponentes de relevancia fueron los edificios patrocinados por la familia Fugger en Augsburgo, como la Capilla Fugger en la iglesia de Santa Ana (1509-1518) o el barrio de casas obreras llamado Fuggerei (1519-1523).[67]​ Tras la Reforma, el mecenazgo de la nobleza alemana se centró en primer lugar en la arquitectura, por la capacidad de esta para mostrar el poder y prestigio de los gobernantes. Así, a mediados del siglo XVI se amplió el castillo de Heidelberg, siguiendo las directrices clásicas. Sin embargo, la mayoría de los príncipes alemanes prefirieron conservar las obras góticas, limitándose a decorarlas con ornamentación renacentista.[68]​


=== Flandes y Países Bajos ===

A la par que se desarrollaba en Italia el Cinquecento la escuela flamenca de pintura alcanzó un desarrollo notable, como heredera y continuadora de la tradición tardogótica anterior representada por Jan van Eyck, Rogier van der Weyden y otros grandes maestros. Se caracterizó por su naturalismo, rasgo que comparte con los maestros italianos, aunque se llegó más a él por la experimentación que por la teoría o los avances científicos, como en Italia. Los modos del gótico pervivieron con mayor fuerza, aunque matizados con características singulares, como cierta vena caricaturesca y fantástica y una mayor sensibilidad a la realidad del pueblo llano y sus costumbres. Se recoge ese interés en obras de carácter menos idealizado que las italianas, con una marcada tendencia por el detallismo casi microscópico que aplican a las representaciones —influjo de los maestros tardogóticos ya mencionados y la miniatura—, y tendencia hacia lo decorativo, sin demasiado interés por disquisiciones teóricas. Por otro lado, la gran aportación del arte flamenco en esta época fue la técnica de la pintura al óleo.[69]​
A mediados del siglo XVI el clasicismo italiano entra con fuerza en la pintura flamenca, manifestándose en la llamada Escuela de Amberes y en pintores como Jan van Scorel o Mabuse, algunos de los cuales permanecieron en Italia estudiando a los grandes maestros. A la difusión de los nuevos modelos contribuyó sobremanera el grabado, que puso al alcance de prácticamente cualquier artista las obras producidas en otras escuelas y lugares, poniendo muy de moda en toda Europa el estilo italianizante. Algunos grandes nombres de la época fueron Joachim Patinir, uno de los creadores del paisaje como género autónomo de la pintura, aunque apegado todavía al gótico; Quentin Metsys, que se inspiró en los dibujos caricaturescos de Leonardo y en las clases populares para retratar vicios y costumbres; el retratista Antonio Moro; el Bosco, uno de los pintores más originales de la historia, apegado formalmente a la tradición de la vieja escuela flamenca, pero a la vez innovador, creador de un universo fantástico, casi onírico que lo sitúan como uno de los precedentes del surrealismo (El jardín de las delicias, 1500-1505); y Pieter Brueghel el Viejo, uno de los grandes maestros del paisaje y las costumbres populares, quizá el más moderno de todos ellos, aun cuando en su pintura glose sentencias morales y de crítica social que tienen algo de medieval (El triunfo de la Muerte, 1563).[70]​
En el campo de la escultura destacó Adriaen de Vries, autor de expresivas obras —generalmente de bronce— en las que el movimiento, la línea ondulada o serpentinata y el desnudo heroico las caracterizan como excelentes ejemplos de manierismo escultórico fuera de Italia.
En arquitectura el gótico siguió teniendo una gran preponderancia hasta bien entrado el siglo XVI, en que se recibió la influencia de la arquitectura renacentista francesa, como se denota en el Ayuntamiento de Amberes (1561-1565), obra de Cornelis Floris de Vriendt.[68]​


=== Suiza ===
Con la llegada de la familia Holbein, Basilea se convirtió en el centro más importante del arte del Renacimiento en Suiza. Más tarde, en 1661, la primera colección de arte público del mundo también se fundó aquí. Una de las colecciones más importantes de arte renacentista de la región del Alto Rin se encuentra aún hoy aquí.[71]​ La influencia italiana se notó especialmente en el cantón de Ticino, como se evidencia en las catedrales de San Lorenzo de Lugano (1514) y San Francisco de Locarno (1528). En pintura destacó la obra de Niklaus Manuel, aún cercana al gótico tardío.[72]​


=== Otros países ===

Inglaterra: en arquitectura, durante prácticamente todo el siglo XVI pervivió el estilo Tudor de origen gótico, mientras que las novedades renacentistas fueron adoptadas únicamente en algunos elementos ornamentales; así, por ejemplo, en la tumba de Enrique VII en la abadía de Westminster, realizada arquitectónicamente en el más puro estilo gótico, se contrató al artista italiano Pietro Torrigiano para realizar la decoración escultórica.[73]​ Otros ejemplos de estilo Tudor serían los palacios de Sutton (1523), Nonsuch (1530) y Hampton Court (1514-1540).[74]​ Más adelante se recibió la influencia palladiana, que se desarrolló especialmente en la construcción de palacios.[68]​
Portugal: en arquitectura, el gótico pervivió hasta bien entrado el siglo XVI en el llamado estilo manuelino. A mediados de siglo se recibió la influencia de arquitectos italianos como Serlio o Palladio, como se denota en la iglesia de Nuestra Señora de Gracia en Évora (1536) o en el claustro del convento de Cristo de Tomar (1554-1562), obras de Diogo de Torralva.[68]​ En este país trabajó el arquitecto italiano Filippo Terzi, autor de la iglesia de San Vicente de Fora en Lisboa (1582).[75]​
Austria y Bohemia: unidos por el imperio de los Habsburgo, estos países contaron con la labor patrocinadora del emperador Rodolfo II, un gran coleccionista que atesoró en su corte de Praga una gran variedad de obras de arte y objetos de todo tipo (joyas, minerales, relojes, autómatas, instrumentos científicos), ya que también era un gran amante de la ciencia. Adquirió cuadros de artistas como Brueghel, Tiziano, Leone Leoni o Durero, y acogió a artistas como Giuseppe Arcimboldo, un original pintor de retratos confeccionados con elementos propios de los bodegones.[76]​ En Bohemia se construyeron diversos palacios, como el Comunal de Pilsen y el de Schwarzenberg en Praga; y castillos, como los de Litomyšl, Černý y Kostelec.[77]​
Hungría: este país contó con el gran mecenazgo del rey Matías Corvino, un gran amante del arte italiano, quizá por influjo de su esposa, Beatriz de Nápoles.[78]​ El monarca compró numerosas obras de arte italianas, y contrató artistas y arquitectos italianos para reformar y decorar sus palacios, como Benedetto da Maiano, Clemente Camicia y Giovanni Dalmata; el miniaturista Attavante degli Attavanti fue autor del Breviario de Matías Corvino y del Códice de Marciano Capella; el escultor Andrea Ferracci realizó el altar de la Anunciación de la catedral de Esztergom.[79]​
Polonia: como en otros países, las novedades renacentistas llegaron de la mano de artistas italianos llegados al país, como los arquitectos Franciscus Italus y Bartolomeo Berecci (Palacio Real de Cracovia), Gian Maria Mosca (Palacio Episcopal de Cracovia) y Giovanni Battista di Quadro (Palacio Municipal de Poznań); y los escultores Santi Gucci (capilla de Segismundo de la catedral de Cracovia), Girolamo Canavesi (monumento de Gorka, catedral de Poznań) y Domenico Veneziano (monumento sepulcral de Esteban I Báthory, catedral de Cracovia). En cambio, en pintura trabajaron mayormente artistas alemanes, como Hans Sues von Kulmbach, Louz von Kitzingen y Martin Koeber. También se desarrolló notablemente la miniatura, en la que destacan el Códice de Baltasar Behem y el Libro de preces de Segismundo I.[80]​

Rusia: durante esta época continuó la tradicional arquitectura rusa de influencia bizantina, pero se recibió alguna influencia del Renacimiento italiano a través del arquitecto boloñés Aristotele Fioravanti, que viajó en 1475 a Rusia invitado por Iván III, donde construyó la catedral de la Dormición en el Kremlin de Moscú (1475-1479); otro arquitaliano, Aloisio Nuovo, fue el encargado de construir la catedral del Arcángel Miguel también en el Kremlin (1505-1508). La influencia italiana se denota igualmente en la catedral de San Basilio de Moscú, obra de Póstnik Yákovlev (1555-1560).[81]​


=== Arte colonial hispanoamericano ===

Las primeras muestras de arquitectura colonial en América tuvieron, al igual que en la metrópoli, cierta pervivencia de rasgos góticos, si bien pronto empezaron a llegar las nuevas corrientes que se producían en España, como el purismo y el plateresco (catedral de Santo Domingo). Al iniciarse la colonización, la arquitectura que se desarrolló principalmente fue de signo religioso: por orden real, el primer edificio que se debía construir en cualquier nueva ciudad debía ser una iglesia. Durante la primera mitad del siglo XVI fueron las órdenes religiosas las encargadas de la edificación de numerosas iglesias en México, preferentemente un tipo de iglesias fortificadas, en un conjunto almenado con iglesia, convento, un atrio y una capilla abierta —llamadas «capillas de indios»—, como el Convento de Tepeaca, el de Huejotzingo y el de San Gabriel en Cholula.[82]​ A mediados de siglo se empezaron a construir las primeras grandes catedrales, como las de México, Puebla y Guadalajara. Se sigue por lo general la planta rectangular con testero plano, tomando como modelos la Catedral de Sevilla, la de Jaén y la de Valladolid. En Perú, en 1582 se inició la catedral del Cuzco y, en 1592, la de Lima, ambas obras del extremeño Francisco Becerra. En Argentina destaca la catedral de Córdoba, obra del jesuita Andrés Blanqui.[83]​
Las primeras muestras de pintura colonial fueron las de escenas religiosas elaboradas por maestros anónimos, realizadas con medios precolombinos, con tintas vegetales y minerales y telas de trama áspera e irregular. Destacaron las imágenes de la Virgen con el Niño, con una iconografía de raíces autóctonas donde, por ejemplo, se representaban los arcángeles como arcabuceros contemporáneos. La producción artística hecha en Nueva España por indígenas en el siglo XVI es denominada arte indocristiano. Adentrado el siglo XVI surgieron los grandes frescos murales, de carácter popular. Desde mediados de siglo empezaron a llegar, procedentes de Sevilla, maestros españoles (Alonso Vázquez, Alonso López de Herrera), flamencos (Simon Pereyns) e italianos (Mateo Pérez de Alesio, Angelino Medoro).[84]​
En escultura, las primeras muestras fueron nuevamente en el terreno religioso, en tallas exentas y retablos para iglesias, confeccionadas generalmente en madera recubierta con yeso y decorada con encarnación —aplique directo del color— o estofado —sobre un fondo de plata y oro—. A principios del siglo XVII nacieron las primeras escuelas locales, como la quiteña, la cuzqueña y la chilota, destacando la labor patrocinadora de la orden jesuita.


=== Artes gráficas y decorativas ===

Las artes industriales tuvieron un gran auge debido al gusto por el lujo de las nuevas clases adineradas: se desarrolló la ebanistería, sobre todo en Italia y Alemania, destacando la técnica de la intarsia, embutidos de madera de varios tonos para producir efectos lineales o de ciertas imágenes. La tapicería destacó en Flandes, con obras basadas en bocetos desarrollados por pintores como Bernard van Orley. La cerámica se elaboró en Italia con barnices vidriados, consiguiendo tonos brillantes de gran efecto. El vidrio se desarrolló notablemente en Venecia (Murano), decorado a veces con hilos de oro o con filamentos de vidrios de colores. La orfebrería fue cultivada por escultores como Lorenzo Ghiberti o Benvenuto Cellini, con piezas de gran virtuosismo y elevada calidad, destacando especialmente los esmaltes y camafeos.[85]​ 
En esta época se desarrollaron notablemente las artes gráficas, especialmente gracias a la invención de la imprenta, apareciendo o perfeccionándose la mayoría de las técnicas de grabado: calcografía (aguafuerte, aguatinta, grabado al buril, grabado a media tinta o grabado a punta seca), linograbado, xilografía, etc. En Italia se desarrolló el grabado en metal, practicado especialmente por los orfebres florentinos durante los siglos xv y xvi, mientras que en el Cinquecento se perfeccionó el aguafuerte gracias a la obra del Parmigianino. En Alemania destacó la obra de Durero, especialista de la técnica del buril, aunque también realizó xilografías. En Francia, el grabado fue practicado por la escuela de Fontainebleau, en la que destacó Jean Duvet, famoso por su serie del Apocalipsis (1561). En Flandes surgieron notables grabadores en la ciudad de Amberes, como los hermanos Wierix, autores de estampas de excelente técnica y detallismo, aunque basadas en composiciones ajenas; o Hieronymus Cock, que reprodujo numerosas obras de Brueghel.[86]​


=== Jardinería ===

En el Renacimiento la jardinería cobró una especial relevancia, en paralelo al impulso otorgado a todas las artes en esta época, principalmente gracias al mecenazgo de nobles, príncipes y altos cargos de la Iglesia. El jardín renacentista se inspiró en el romano, en aspectos como la decoración escultórica o la presencia de templetes, ninfeos y estanques. Los primeros ejemplos surgieron en Florencia y Roma, regiones con una orografía accidentada y grandes desniveles de terreno, lo que originó el efectuar estudios previos de índole arquitectónica para planificar la estructura del jardín, originando la arquitectura paisajística. Un ejemplo de ello son los Jardines del Belvedere en Roma, proyectados por Bramante en 1503, el cual resolvió los desniveles con un sistema de terrazas, a las que se accede por amplias escalinatas y que están rodeadas de balaustradas, esquema que pasaría a ser típico del jardín italiano, que se convertiría en el prototipo de jardín renacentista. Se otorgó una especial importancia a la obra hidráulica, con estanques y fuentes de gran complejidad, como los de la Villa de Este en Tivoli, diseñados por Bernini. Estos diseños pasaron al resto de Europa, donde destacan por su magnificencia los jardines franceses, como los de los castillos de Amboise, Chambord y Villandry. En Francia era costumbre subdividir el jardín en diversas zonas especializadas (jardín geométrico, medicinal, silvestre), así como la construcción de canales que permitían el paseo en barca. En esta época comenzó la costumbre de recortar los setos, apareciendo los primeros jardines en forma de laberinto. También hay que resaltar la llegada de nuevas especies gracias al descubrimiento de América, lo que favoreció la apertura de jardines botánicos dedicados al estudio y catalogación de las plantas.[87]​
La teoría jardinística renacentista se nutrió especialmente de la concepción elaborada por Leon Battista Alberti de la casa y el jardín como una unidad artística basada en formas geométricas (De Re Aedificatoria, IX, 1443-1452), así como en el modelo expuesto por Francesco Colonna en su Hypnerotomachia Poliphili (1499), que introducía el uso de parterres y el empleo del arte topiario para dar formas caprichosas a los árboles, o el diseño de las eras a partir de formas axiales, expuesto por Sebastiano Serlio en Tutte l'opere d'architettura (1538).[88]​


== Literatura ==

La literatura renacentista se desarrolló en torno al humanismo, la nueva teoría que destacaba el papel primordial del ser humano sobre cualquier otra consideración, especialmente la religiosa. En esta época el mundo de las letras recibió un gran impulso con la invención de la imprenta por Gutenberg, hecho que propició el acceso a la literatura por un público más mayoritario. Ello conllevó a una mayor preocupación por la ortografía y la lingüística, surgiendo los primeros sistemas de gramática en lenguas vernáculas (como la española de Elio Antonio de Nebrija) y apareciendo las primeras academias de lenguas nacionales.[89]​ Es por ello que muy posiblemente, la participación de filólogos en la época fue de gran ayuda y necesidad para el estudio, análisis y comprensión de textos antiguos (principalmente clásicos) durante el siglo XV hasta el siglo XVI.   
La nueva literatura se inspiró como el arte en la tradición clásica grecolatina, aunque también recibió una gran influencia de la filosofía neoplatónica desarrollada contemporáneamente en Italia. Por otro lado, refleja el nuevo ideal de hombre renacentista, que se ejemplifica en la figura del «cortesano» definida por Baldassare Castiglione: debía de dominar las armas y las letras por igual, y tener «buena gracia» o naturalidad sin artificio.[90]​ En su naturaleza, la esencia renacentista nace en Italia, es en este territorio en donde nace un pensamiento basado en la dignidad y libertad humana, en la que claro está, un pensamiento liberal basado en la crítica educativa, fomentando un ideal meramente formativo. Un movimiento que al igual que la Paideia clásica, fomentara principios y valores semejantes. El humanismo, con sus valores clarificadores sobre el valor y esencia humana, viene también a profundizar y recrear la importancia y necesidad de comprender los textos clásicos, limpiándolos de toda mancha de corrupción o manipulación intencional, o bien de la simple malinterpretación literal o literaria. De esta manera, y con estos principios, surge una sociedad laboral y académica, misma que es satisfecha con labor filológica. De manera que en el Renacimiento Occidental del siglo XV y del mismo Humanismo Italiano, el que le da vivacidad y seguimiento al estudio crítico de la cultura griega. Es por ende, que el paso de la cultura Helenística a Italia fue un proceso enriquecedor tanto en la enseñanza y copiado de textos y manuscritos antiguos como también el aprendizaje de las lenguas latín y griego y la misma recolección de textos esparcidos alrededor del territorio. Muchos de estas personas preocupadas por la difusión de la literatura helénica fueron Planudes, Moscópulo, Magister y Demetrio Triclinio. Lorenzo Valla y sus emendationes en la traducción marcaron un antes y un después al entendimiento Heródoto y Tucidides. Erasmo de Rotterdam, también reconocido como uno de los mejores críticos textuales de la era moderna, analizó las Sagradas Escrituras y los textos clásicos por su puesto, de modo que publicó traducciones de Aristóteles, Demócrito y Juan Crisóstomo. (Morocho, pags 4-9)
Con el paso del tiempo la importancia de la actividad crítica textos grecolatinos va incrementando. Su importancia se puede asociar con la necesidad de entender de aspectos históricos, ciencias naturales, geografía, astronomía, y muchos más. De manera que la labor filológica tiene auge y una importancia sinigual. A pesar de la intervención eclesiástica, haciendo mención sobre aquellos que corrigen o trabajan con textos no religiosos, cometen herejía y pecado.  
En Italia, cuna del nuevo estilo, perduraban aún los ecos de tres grandes autores medievales considerados a veces precursores del nuevo movimiento: Dante, Petrarca y Boccaccio. Entre los literatos surgidos en esta era conviene destacar a: Angelo Poliziano, Matteo Maria Boiardo, Ludovico Ariosto, Jacopo Sannazaro, Pietro Bembo, Baldassare Castiglione, Torquato Tasso, Nicolás Maquiavelo y Pietro Aretino. Su influencia se denotó en Francia, donde desarrollaron François Rabelais, Pierre de Ronsard, Michel de Montaigne y Joachim du Bellay. En Alemania, la reforma protestante impuso una mayor austeridad y una temática religiosa, cultivada por Ulrich von Hutten, Sebastian Brant y Hans Sachs. En Inglaterra, cabe citar a Tomás Moro, Edmund Spenser, Michael Drayton, Henry Constable, George Chapman, Henry Howard y Thomas Wyatt. En Portugal se halla la figura predominante de Luís de Camões.[90]​  
Pero de algo que se puede afirma es que Italia, en su apogeo renacentista, fue, ciertamente la cuna del humanismo, por consiguiente del mismo Renacimiento occidental. por ende, más que ciudad o país comerciante, es un museo viviente, en el que se desenvuelve una riqueza cultural y un apogeo históricamente fecundo. ya que bien se sabe, que Roma, capital Italiana, fue en su época de gloria la capital del Imperio Romano. Por ello la formación y naturalización del latín no viene siendo algo novedoso.  
En contra del clero católico y el papado, la crítica textual posee un afluente muy fuerte, cuya necesidad erudita y percepción literal es vital para la comprensión de lo que acontece en la antigüedad. Aporte que se le puede asociar, según Quirós, (1994) a los bizantinos, quienes trajeron consigo un importante número de manuscritos griegos al territorito Italiano. Paralelamente, Francesco Petrarca, como ya se ha mencionado anteriormente, ha fomentado el espíritu crítico y el valor literario de autores y textos clásicos,. Se concluye, siendo más que claro, que será el humanismo nacido en Italia el fundador y promotor del pensamiento crítico y el que se encargará de reivindicar el valor de la cultura griega.  
En España comenzó una edad dorada de las letras, que se prolongaría hasta el siglo XVII: la poesía, influida por la italiana del stil nuovo, contó con las figuras de Garcilaso de la Vega, fray Luis de León, San Juan de la Cruz y Santa Teresa de Jesús; en prosa surgieron los libros de caballería (Amadís de Gaula, 1508) y se inició el género de la picaresca con el Lazarillo de Tormes (1554), mientras que despuntó la obra de Miguel de Cervantes, el gran genio de las letras españolas, autor del inmortal Don Quijote (1605). 
Por otra parte el renacimiento español (iniciado o promovido por la llegada de Antonio de Nebrija y aceptado por los mismos reyes de España), claramente posee una línea ética basada en el pensamiento italiano, cuales antes de iniciar los estudios y acercamientos del grecoromance, incorporan modelos de enseñanza literario italiana. (Dante, Boccaccio, Petrarca). Los pocos filólogos de la época utilizaban la valoración de textos basado en su antigüedad y mayor veracidad y calidad de la lectura. Es así, que como afirma la Apología de Nebrija, que la germana lectio no debe direccionarse hacia el consensus codicum, sino siempre enfocado en la calidad de la lectura. (Morocho, p. 10)
Ahora bien, como se mencionó anteriormente, con los aportes de Antonio de Nebrija, inicia una de las más grandes labores filológicas españolas. La traducción de textos de latín al romance. Labora que se hace posible ya que una de las manifestaciones del Renacimiento Español consistía en la recuperación de escritos latinos, litterae humanitas sobre obras ciceronianas. Que, bajo el dominio de Cicerón, y por la imitatio y emulatio, en consorcio con el pensamiento de Lorenzo Valla, nace la gramática castellana, proveniente del latín.


== Teatro ==
El teatro renacentista también acusó el paso del teocentrismo al antropocentrismo, con obras más naturalistas, de aspecto histórico, intentando reflejar las cosas tal como son. Se buscaba la recuperación de la realidad, de la vida en movimiento, de la figura humana en el espacio, en las tres dimensiones, creando espacios de efectos ilusionísticos, en trompe-l'œil. Surgió la reglamentación teatral basada en tres unidades (acción, espacio y tiempo), basándose en la Poética de Aristóteles, teoría introducida por Lodovico Castelvetro. En torno a 1520 surgió en el norte de Italia la Commedia dell'arte, con textos improvisados, en dialecto, predominando la mímica e introduciendo personajes arquetípicos como Arlequín, Colombina, Pulcinella (llamado en Francia Guignol), Pierrot, Pantalone, Pagliaccio, etc. Como principales dramaturgos destacaron Niccolò Machiavelli, Pietro Aretino, Bartolomé Torres Naharro, Lope de Rueda y Fernando de Rojas, con su gran obra La Celestina (1499). En Inglaterra descolló el teatro isabelino, con autores como Christopher Marlowe, Ben Jonson, Thomas Kyd y, especialmente, William Shakespeare, gran genio universal de las letras (Romeo y Julieta, 1597; Hamlet, 1603; Otelo, 1603; Macbeth, 1606).[91]​


== Música ==

La música renacentista supuso la consagración de la polifonía, así como el afianzamiento de la música instrumental, que iría evolucionando hacia la orquesta moderna. Apareció el madrigal como género profano que aunaba texto y música, siendo la expresión paradigmática de la música renacentista. En 1498 Ottaviano Petrucci ideó un sistema de imprenta adaptado a la música, en pentagrama, con lo que se empezó a editar música. Las primeras novedades se produjeron en Flandes, donde se desarrolló la llamada polifonía «a la flamenca», cultivada por Guillaume Dufay, Johannes Ockeghem y Josquin des Prés. También cultivaron el madrigal Orlandus Lassus, Luca Marenzio, Carlo Gesualdo, Claudio Monteverdi, Cristóbal de Morales y Tomás Luis de Victoria, mientras que en polifonía religiosa destacó Giovanni Pierluigi da Palestrina. En música instrumental descolló Giovanni Gabrieli, quien experimentó con diversos timbres de instrumentos de viento y con efectos de sonido cruzado y de relieve.[92]​
En los países protestantes la música cobró gran relevancia, ya que el propio Lutero defendía la importancia de la música en la liturgia religiosa. Aquí se cultivó especialmente el coral, un género musical a capella o con acompañamiento instrumental, generalmente a cuatro voces mixtas. Algunos de los compositores que lo cultivaron fueron Johann Walther y Valentin Bapst.[93]​
A finales del siglo XVI nació la ópera, iniciativa de un círculo de eruditos (la Camerata Fiorentina) que, al descubrir que el teatro griego antiguo era cantado, tuvieron la idea de musicalizar textos dramáticos. La primera ópera fue Dafne (1594), de Jacopo Peri, a la que siguió Euridice (1600), del mismo autor; en 1602 Giulio Caccini escribió otra Euridice; y, en 1607, Claudio Monteverdi compuso La favola d'Orfeo, donde añadió una introducción musical que denominó sinfonía, y dividió las estructuras cantadas en arias.[94]​


== Danza ==

La danza renacentista tuvo una gran revitalización, debido de nuevo al papel preponderante del ser humano sobre la religión, de tal manera que muchos autores consideran esta época el nacimiento de la danza moderna. Se desarrolló sobre todo en Francia –donde fue llamado ballet-comique–, en forma de historias bailadas, sobre textos mitológicos clásicos, siendo impulsado principalmente por la reina Catalina de Médicis. Se suele considerar que el primer ballet fue el Ballet comique de la Reine Louise (1581), de Balthazar de Beaujoyeulx. Las principales modalidades de la época eran la gallarda, la pavana y el tourdion. En esta época surgieron los primeros tratados sobre danza: Domenico da Piacenza escribió De arte saltandi et choreas ducendi, siendo considerado el primer coreógrafo de la historia; Thoinot Arbeau hizo una recopilación de danzas populares francesas (Orchesographie, 1588).[95]​


== Filosofía ==

La filosofía renacentista estuvo marcada en su origen por el declive de la teología, en un mundo abocado a la modernidad que, sin renunciar aún a la religión, la circunscribe al ámbito espiritual y personal del individuo. La nueva forma de afrontar los problemas del ser humano será el racionalismo, el uso de la razón aplicada a la sociedad y a la naturaleza.[96]​ Aun así, la religión siguió presente en buena medida durante esta época, aunque derivó de la teología escolástica hacia el misticismo, hacia una relación con Dios basada más en el sentimiento que en el conocimiento, así como en la acción, la obra de acercamiento a Dios, como se percibe en la obra de Jan van Ruusbroec, Dionisio Cartujano y Tomás de Kempis.[97]​
La nueva corriente de estos tiempos será el humanismo, más interesado en el hombre y la naturaleza que en las cuestiones divinas y espirituales. El naturalismo impregna todos los ámbitos del saber, y así se habla no solo de la ciencia natural, sino también del derecho natural, la moral natural e, incluso, la religión natural, una religión que abandona todo lo sobrenatural (revelación, dogma) para ser fiel reflejo de la posición del ser humano en el mundo.[98]​ El humanismo se fundamenta, como el arte, en la oposición a la cultura medieval y el retorno a la antigüedad clásica; sin embargo, buena parte de la filosofía renacentista evoluciona de la medieval en una línea continua que llega hasta Descartes, no en vano la escolástica medieval estaba fundamentada en la filosofía griega platónica y aristotélica.[99]​ Aun así, numerosos humanistas despreciaron el aristotelismo escolástico por ser excesivamente teologizado, y abordaron a Platón desde la obra de sus seguidores posteriores, el llamado neoplatonismo, especialmente desde el terreno de la filosofía estoica que, como la renacentista, incidía más especialmente en el ser humano como medida de todas las cosas. Sin embargo, muchos de estos autores abordaron el tema desde una postura superficial y poco rigurosa, sin profundizar en los aspectos ontológicos y metafísicos de los clásicos griegos, sin analizar la nueva situación intelectual del ser humano alejado de Dios, cuestión que no llegará hasta el cartesianismo.[100]​
El pensamiento humanístico nació en Italia, especialmente en torno a la Academia Platónica Florentina patrocinada por Cosme de Médici, que aglutinó a pensadores como Marsilio Ficino, Giovanni Pico della Mirandola, Cristoforo Landino, Angelo Poliziano o Benedetto Varchi. Otros se encaminaron más hacia la política, como Nicolás Maquiavelo, forjador del autotitarismo monárquico como seña de identidad de las nuevas naciones-estado surgidas en esta época; o hacia el naturalismo, como Leonardo Da Vinci y Bernardino Telesio.[101]​ En Francia, el humanismo tuvo un componente más escéptico, representado por Michel de Montaigne o Pierre Charron, mientras que algunas figuras se adhirieron a la reforma protestante, como Pierre de la Ramée o Henri Estienne.[102]​ En Inglaterra destacó la figura de Tomás Moro, canciller de Enrique VIII, quien lo decapitó por oponerse a la reforma anglicana; fue autor de Utopía, un esbozo de estado ideal de reminiscencias platónicas.[103]​ Pero el más afamado humanista surgió en Países Bajos: Erasmo de Róterdam, que escribió en latín, con un estilo vivo y elegante, fiel al dogma católico, pero de mentalidad abierta y comprensiva, reflejo de un espíritu de concordia; fue autor del Elogio de la locura (1511).[103]​
En Alemania no recaló tanto el humanismo de carácter marcadamente literario como en otros países europeos, y la filosofía se encaminó más a la mística especulativa, heredera del Maestro Eckhart; otras figuras mezclaron esta tendencia con elementos de las ciencias naturales o aun de la alquimia y la astrología, como Agrippa von Nettesheim o Paracelso. Por otro lado, la Reforma protestante contó con figuras como Martín Lutero, Zwinglio, Philipp Melanchthon, Sebastian Franck y Jakob Böhme.[104]​
En España el pensamiento filosófico no rompió del todo con el pasado medieval, y mostró un especial interés por la lingüística, tanto clásica como vernácula (Antonio de Nebrija, Benito Arias Montano). La corriente escéptica estuvo representada por Francisco Sánchez, mientras que el humanismo antiescolástico —pero heredero de la tradición católica— contó con la figura de Juan Luis Vives, preocupado especialmente por la moral y la educación. Por otro lado, una reacción escolástica estuvo originada por la Contrarreforma tridentina que revivió el misticismo y contó con figuras como santa Teresa de Jesús y san Juan de la Cruz.[105]​
Por otro lado, además del humanismo hay otras corrientes de pensamiento que a través de diversas vías, aparentemente dispares, convergerán en la filosofía cartesiana y en los fundamentos de la filosofía moderna: una es heredera del pensamiento medieval, representada por Nicolás de Cusa o por la escolástica española; otra está más preocupada por la naturaleza y dará origen a la ciencia física moderna.[106]​ Nicolás de Cusa, cardenal y obispo de Bresanona, intentó conciliar la doctrina católica con la teoría platónica, a través de una noción de Dios infinito y trascendente en el que se aglutinan la verdad y la realidad (De docta ignorantia, 1440).[107]​ La escolástica española estuvo muy ligada a la Contrarreforma, y se asoció especialmente con la orden de los jesuitas; de influencia tomista, estuvo representada por Francisco de Vitoria, Alfonso Salmerón, Luis de Molina y, especialmente, Francisco Suárez.[108]​ El estudio de la naturaleza dio en el terreno filosófico la relevante figura de Giordano Bruno, autor de una doctrina panteísta por la que fue quemado por hereje, y defensor de la razón y la experiencia como única vía para conocer el mundo.[109]​ También influyeron en la filosofía las nuevas teorías científicas de Nicolás Copérnico, Johannes Kepler y Galileo Galilei.[110]​


== Ciencia ==


== Vida y costumbres ==

Con el Renacimiento y su cultura más humanista e individualista, así como el despegue económico y su consecuente grado de ostentación social, y unido a los avances tecnológicos, se desarrollaron notablemente todos los aspectos relacionados con el aspecto individual y el cuidado personal, como la peluquería y la moda. La peluquería sufrió una profunda transformación y un gran auge en cuanto a establecimientos y productos dedicados al cuidado del cabello. Se puso de moda la depilación de las cejas, así como de la frente, a veces hasta medio cráneo. Aumentó el gusto por el teñido, siendo el rubio el color preferido. Por lo general, los peinados incluían un tocado, con cinco tipos principales: las tocas, las cofias o albanegas, los bonetes, los rollos y los sombreros. Desde el siglo XVI los peinados, especialmente los femeninos, fueron ganando en complejidad, con sofisticadas estructuras de rizos, encajes, cintas y muselinas.[135]​
En el Renacimiento surgió el concepto de moda tal como lo entendemos hoy día: se introdujeron nuevos géneros y la costura adquirió un alto grado de profesionalización. En la Italia renacentista aparecieron los trajes más ricos y espectaculares de la historia, de vivos colores y formas imaginativas y originales, que otorgaban gran relevancia a las mangas, a los pliegues y a las caídas de tela de forma vertical, con finos bordados y rica pasamanería. En el siglo XVI el calzón corto era a modo de bombacho, y continuó usándose el jubón medieval, junto a capas de diverso tipo y adornos como la gorguera, una tela de encajes fruncidos que cubría el cuello. En el atuendo femenino apareció el corsé, que ceñía la cintura, sobre una falda en forma de campana llamada crinolina, hecha de tela y crin de caballo, y reforzada con aros metálicos.[136]​
También cobró una especial relevancia la gastronomía, que llegó a altas cotas de refinamiento y sofisticación. Destacó la cocina veneciana, que gracias a su comercio con Oriente favoreció la importación de todo tipo de especias: pimienta, mostaza, azafrán, nuez moscada, clavo, canela, etc. Un factor determinante para una nueva gastronomía fue el descubrimiento de América, de donde llegaron nuevos alimentos como el maíz, la patata, el tomate, el cacao, los frijoles, el cacahuete, el pimiento, la vainilla, la piña, el aguacate, el mango o el tabaco.[137]​


== Véase también ==
Prerrenacimiento
Alto Renacimiento
Bajo Renacimiento
Renacimiento italiano
Renacimiento español
Renacimiento francés
Renacimiento nórdico
Renacimiento alemán
Renacimiento flamenco
Renacimiento inglés
Renacimiento en Hungría
Arte de la Edad Moderna
Historia de la estética
La cultura del Renacimiento en Italia
Historia de la ciencia en el Renacimiento
Hallazgos médicos en el Renacimiento
Literatura del Renacimiento
Música del Renacimiento
Humanismo renacentista
Filosofía renacentista
Polimatía


== Referencias ==


== Bibliografía ==
AA. VV. (2003). Diccionario de Arte II. Barcelona: Spes. ISBN 84-8332-391-5. 
AA. VV. (2003). Diccionario de Historia. Barcelona: Spes. ISBN 84-8332-387-7. 
AA. VV. (2003). Diccionario de Literatura. Barcelona: Spes. ISBN 84-8332-389-3. 
AA. VV. (1990). Diccionario Enciclopédico Larousse. Barcelona: Planeta. ISBN 84-320-6070-4. 
AA. VV. (2008). El arte en la Italia del Renacimiento. Köln: Tandem Verlag GmbH. ISBN 978-3-8331-5102-6. 
AA. VV. (1991). Enciclopedia del Arte Garzanti. Barcelona: Ediciones B. ISBN 84-406-2261-9. 
AA. VV. (1997). Enciclopedia Salvat. Barcelona: Salvat. ISBN 84-345-9707-1. 
Abad Carlés, Ana (2004). Historia del ballet y de la danza moderna. Madrid: Alianza Editorial. ISBN 84-206-5666-6. 
Albert de Paco, José María (2007). El arte de reconocer los estilos arquitectónicos. Barcelona: Optima. ISBN 978-84-96250-72-7. 
Asimov, Isaac (1975). Breve historia de la química. Madrid: Alianza. ISBN 84-206-1580-3. 
Azcárate Ristori, José María de; Pérez Sánchez, Alfonso Emilio; Ramírez Domínguez, Juan Antonio (1983). Historia del Arte. Madrid: Anaya. ISBN 84-207-1408-9. 
Beardsley, Monroe C.; Hospers, John (1990). Estética. Historia y fundamentos. Madrid: Cátedra. ISBN 84-376-0085-5. 
Beltrando-Patier, Marie-Claire (1996). Historia de la música. Madrid: Espasa. ISBN 84-239-9610-7. 
Bozal, Valeriano (et al.) (2000). Historia de las ideas estéticas y de las teorías artísticas contemporáneas (vol. I). Madrid: Visor. ISBN 84-7774-580-3. 
Chilvers, Ian (2007). Diccionario de arte. Madrid: Alianza Editorial. ISBN 978-84-206-6170-4. 
Eco, Umberto (2004). Historia de la belleza. Barcelona: Lumen. ISBN 84-264-1468-0. 
Fernández Arenas, José (1988). Arte efímero y espacio estético. Barcelona: Anthropos. ISBN 84-7658-078-9. 
Honour, Hugh; Fleming, John (2002). Historia mundial del arte. Madrid: Akal. ISBN 84-460-2092-0. 
Kluckert, Ehrenfried (2007). Grandes jardines de Europa. Colonia: Ullmann. ISBN 978-3-8331-6225-1. 
Lladó, Mariantònia; García, Montserrat (1999). Breu història de la literatura universal (en catalán). Barcelona: La Magrana. ISBN 84-8264-198-0. 
Marías, Julián (2001). Historia de la filosofía. Madrid: Alianza Editorial. ISBN 84-206-8183-0. 
Nieto, Víctor; Cámara, Alicia (1989). El Quattrocento italiano. Madrid: Historia 16. 
Oliva, César; Torres Monreal, Francisco (2002). Historia básica del arte escénico. Madrid: Cátedra. ISBN 84-376-0916-X. 
Onians, John (2008). Atlas del arte. Barcelona: Blume. ISBN 978-84-9801-293-4. 
Suárez Quevedo, Diego (1989). El Renacimiento y Manierismo en Europa. Madrid: Historia 16. 
Tatarkiewicz, Władysław (1991). Historia de la estética III. La estética moderna 1400-1700. Madrid: Akal. ISBN 84-7600-669-1. 


== Enlaces externos ==
 Wikimedia Commons alberga una categoría multimedia sobre Renacimiento.
 Wikcionario  tiene definiciones y otra información sobre renacimiento.
 Wikiquote alberga frases célebres de o sobre Renacimiento.
La literatura en español es la suma de las obras escritas en español o castellano en el conjunto de los países hispanohablantes, entre los que se incluyen aquellos donde el español, a pesar de no ser idioma oficial, es utilizado como lengua literaria, como es el caso de Estados Unidos o  Marruecos. Es una de las más importantes del mundo, no solo porque la lengua en la que se ha escrito y escribe sea una de las más difundidas, sino por la calidad y el volumen de sus aportaciones al elenco de la literatura universal.[cita requerida]


== Rasgos distintivos ==
Caracteriza a la literatura en español cierta tendencia al realismo, la perduración y vitalidad de la tradición autóctona a través de una riquísima tradición oral (los temas del Romancero y de la épica medieval perduraron en el Siglo de Oro a través del teatro clásico y todavía en la actualidad) y cierta desintonía respecto al resto de las estéticas literarias europeas, creada por la extensión y desarrollo excesivo que tuvo en la tradición hispánica el movimiento conocido como Barroco, que caracteriza la época clásica de la cultura española de la misma manera que el academicismo a la francesa. Por otra parte, la literatura en español ha venido a enriquecerse con todo tipo de tendencias autóctonas nacidas en Hispanoamérica gracias al mestizaje. La tradición de la literatura hispánica es de una complejidad y riqueza difícilmente comparable con otras tradiciones menos respetuosas con la diversidad cultural.[cita requerida]


== Géneros específicos ==
La literatura en español, posesora de uno de los más ricos acervos del mundo[cita requerida], ha creado géneros originales y específicos narrativos como el romance, los libros de caballerías[cita requerida], la novela sentimental, la celestinesca, la novela picaresca, la novela polifónica, la nivola, fórmulas teatrales como el auto sacramental, el entremés, el esperpento, la tragedia grotesca y la astracanada. Anticipó el simbolismo en la obra de algunos poetas como San Juan de la Cruz y Gustavo Adolfo Bécquer y el parnasianismo en poetas como Luis de Góngora y creó algunas estéticas particulares tales como el Barroco, que aunque originado en Italia se desarrolló en su forma máxima en España, y el Modernismo, primer movimiento de muchos de origen hispanoamericano; maduró los frutos más logrados de la mística europea con la obra de San Juan de la Cruz, tan cercana a veces al Surrealismo y a otras estéticas de Vanguardia.


== Obras clásicas ==
Se consideran obras clásicas de la literatura en castellano: el Cantar de mio Cid, el Romancero, El Libro de Alexandre, los Milagros de Nuestra Señora de Gonzalo de Berceo, el Libro de buen amor, la obra poética de Garcilaso de la Vega, la Historia verdadera de la conquista de la Nueva España de Bernal Díaz del Castillo, el Lazarillo de Tormes, la obra de San Juan de la Cruz y de Francisco de Aldana, La Araucana de Alonso de Ercilla y el Bernardo del Carpio de Bernardo de Balbuena, el Guzmán de Alfarache de Mateo Alemán, las Novelas ejemplares y el Don Quijote de la Mancha de Miguel de Cervantes, una veintena de comedias (El caballero de Olmedo, El castigo sin venganza, Peribáñez y el Comendador de Ocaña, etc.) y la poesía lírica de Lope de Vega; la poesía metafísica y amorosa, el Marco Bruto, los Sueños y Providencia de Dios de Francisco de Quevedo; las Soledades, los romances, las letrillas y los sonetos de Luis de Góngora; la lírica en arte menor y los sonetos del Conde de Villamediana; la Epístola moral a Fabio; El Criticón de Baltasar Gracián, unas treinta comedias de Pedro Calderón de la Barca, entre ellas El alcalde de Zalamea, La vida es sueño y El príncipe constante; las Cartas marruecas de José Cadalso, la poesía de José María de Heredia, José Martí y Julián del Casal; la poesía de José Asunción Silva, la obra entera de Gustavo Adolfo Bécquer; el Don Juan Tenorio de José Zorrilla; Peñas arriba de José María de Pereda; Pepita Jiménez y el Epistolario de Juan Valera; La novela de un novelista de Armando Palacio Valdés; Los Episodios Nacionales, Doña Perfecta, Misericordia y Fortunata y Jacinta de Benito Pérez Galdós; La Regenta y los cuentos de Leopoldo Alas Clarín; la Historia de los heterodoxos españoles de Marcelino Menéndez Pelayo; el Martín Fierro de José Hernández; las Memorias de un hombre de acción y algunas novelas sueltas (César o nada, Camino de Perfección, El árbol de la ciencia) de Pío Baroja; A fuego lento de Emilio Bobadilla; la poesía, Niebla y San Manuel Bueno, mártir de Miguel de Unamuno; el teatro de Ramón María del Valle-Inclán; Flor de greguerías de Ramón Gómez de la Serna; Espacio y una antología de la poesía de Juan Ramón Jiménez, Manuel Machado, Vicente Aleixandre, Federico García Lorca, Luis Cernuda, Jaime Gil de Biedma y Ángel Crespo; Historia de una escalera, La fundación y Las meninas de Antonio Buero Vallejo; San Camilo 1936 de Camilo José Cela; Crónica del Alba de Ramón J. Sender; La forja de un rebelde de Arturo Barea; La voluntad, Antonio Azorín y Las confesiones de un pequeño filósofo de Azorín; la poesía y los ensayos de Octavio Paz; Cien años de soledad, El otoño del patriarca y el resto de la obra de Gabriel García Márquez; El siglo de las Luces de Alejo Carpentier; Rayuela, cuentos e Historias de cronopios y de famas de Julio Cortázar; la poesía completa de Pablo Neruda; la obra completa de Jorge Luis Borges; la poesía completa de Dulce María Loynaz; los cuentos de Alfredo Bryce Echenique; la poesía completa de Mario Benedetti; las obras completas de César Vallejo; las obras maestras de Mario Vargas Llosa (La ciudad y los perros, La casa verde, Conversación en La Catedral, La guerra del fin del mundo, La fiesta del chivo, etc.), entre muchas otras.


== Literatura contemporánea ==
Se consideran obras importantes de la literatura contemporánea las novelas de Roberto Bolaño;[1]​ los cuentos completos de Cristina Peri Rossi;[2]​ las novelas de Fernando Vallejo;[3]​ Corazón tan blanco y Mañana en la batalla piensa en mí de Javier Marías;[4]​[5]​ la poesía completa de Giannina Braschi;[6]​[7]​ los cuentos de Jorge Volpi;[8]​ y Mala Onda de Alberto Fuguet,[9]​[10]​ entre muchas otras.


== Literaturas nacionales ==
Literatura de Argentina
Literatura de Bolivia
Literatura de Chile
Literatura de Costa Rica
Literatura de Colombia
Literatura de Cuba
Literatura de Ecuador
Literatura de El Salvador
Literatura de España
Literatura de Estados Unidos en español
Literatura de las Filipinas en español
Literatura de Guinea Ecuatorial en español
Literatura de Guatemala
Literatura de Honduras
Literatura de Marruecos en español
Literatura de México
Literatura de Nicaragua
Literatura de Panamá
Literatura de Paraguay
Literatura del Perú
Literatura de Puerto Rico
Literatura de la República Dominicana
Literatura de Uruguay
Literatura de Venezuela
Literatura hispanoamericana


== Premios Nobel de Literatura ==


=== Número de galardonados por país ===
El país con más ganadores del Premio Nobel de Literatura en español es España, seguido por Chile:


== Referencias ==


== Enlaces externos ==
Escritores destacados
La pintura renacentista abarca el período de la historia del arte europeo entre el arte de la Edad Media y el barroco. Como todo el arte del Renacimiento, la pintura de esta época está relacionada con la idea de volver a la antigüedad clásica, el impacto que tuvo el humanismo sobre artistas y sus patronos, gracias a la adquisición de nuevas sensibilidades y técnicas artísticas.


== Historia ==
Se considera a Italia la cuna de la pintura renacentista al confluir allí las nuevas técnicas (como el descubrimiento de la perspectiva) con una nueva ideología humanista. Allí se conservaban a la vista los monumentos de la Antigüedad a la que se quería hacer renacer, buscando modelos de armonía y belleza.[1]​
Se fue perfeccionando a lo largo del siglo XV en las ciudades estado italianas, comenzando por Florencia, bajo el mecenazgo de los Médici. El papel de defensores de las artes que rivalizaban entre sí por dar más brillo a sus estados, fue desempeñado por los Montefeltro en Urbino, los Sforza y los Visconti en Milán, los Gonzaga en Mantua y los Este en Ferrara. En Roma fueron los papas quienes llamaron a los distintos artistas de la época para trabajar en los palacios papales.[1]​
En un primer momento, en el quattrocento (siglo XV) se investigaron distintos aspectos técnicos. Así, Piero della Francesca estudió la luz. Masaccio destacó por la figura humana. En Fray Angélico adquieren importancia el color y una cierta sensibilidad, si bien su temática sigue siendo religiosa, con composiciones que enlazan directamente con los modelos medievales precedentes. La perspectiva y la composición son el punto de atención de Mantegna y Paolo Ucello
Los grandes maestros de la pintura renacentista aparecerán a finales de siglo, principios del XVI, el cinquecento: Leonardo da Vinci, Rafael y Miguel Ángel. En el siglo XVI, al clasicismo del Alto Renacimiento le seguirán, en la segunda mitad del siglo, el manierismo de autores como Parmigianino o El Greco quienes, sin dejar de ser renacentistas, adoptan unas formas alargadas con cierta exageración que preludia el Barroco.
A partir del surgimiento en Italia, se va extendiendo progresivamente por Europa en torno a 1490-1500, con mayor o menor calado, según los países. A excepción de España, el Renacimiento no dominó la estética de los demás países, debiendo considerarse como un movimiento artístico predominantemente italiano. Es cierto que en el caso de la pintura, la divulgación de sus modelos fue más fácil que en la escultura o la arquitectura, debido a la facilidad de transportar las pinturas, ahora en lienzo, o de reproducir mediante la técnica del grabado.[2]​
Fue sustituida por la sensibilidad barroca en diferentes momentos, según los países, observándose que en lugares como Inglaterra se recibe más tardíamente y perdura cuando ya el resto del Continente está en pleno Barroco.


== Características ==

Hay una serie de características que distinguen la pintura renacentista de su inmediata antecesora, la pintura medieval...

Evocación de lo antiguo, cuya belleza idealizada pretendían tomar como ejemplo.
Observación viva de la naturaleza. Los cuadros se sitúan en paisajes naturales que se intentan recrear con fidelidad, o en marcos arquitectónicos, en los que columnas, frontones, palacios y templos sirven de excusa a alardes de perspectiva.
La figura humana se convierte en centro y medida de todas las cosas. El estudio de la anatomía, incluso la realización de autopsias, ayuda a los artistas a comprender la realidad del cuerpo humano y sus mecanismos de movimiento, de manera que lo representan de forma más realista pero normalmente, idealizada.
Dominio de la perspectiva, y de las técnicas compositivas.
Los efectos de luces y sombras como el claroscuro o la grisalla. De ahí técnicas nuevas como el esfumado (efecto brumoso, técnica en la que destacó Leonardo da Vinci).
Continúan realizándose decoraciones murales al temple y al fresco.
Se extiende el uso del lienzo, que es más económico que la tabla. Los grandes retablos, en que cada cuadro es parte de un tema más amplio, pierde presencia, en favor del cuadro único, bien como tabla de altar, bien como lienzo. Se adopta de manera casi exclusiva la pintura al óleo. Jan Van Eyck sin haberla inventado, mejora la técnica de la pintura con este material. En Italia, sin embargo, se conserva la pintura sobre tabla y la técnica del temple en la pintura llamada «de caballete». Es principalmente en Venecia donde, por influencia flamenca, se introduce el uso del óleo.[3]​
Si en la Edad Media la pintura fue de manera casi exclusiva religiosa, en el Renacimiento se introducen nuevos temas, como los mitológicos, alegorías y temas históricos. Aparece el desnudo, no por sí mismo sino en el marco de una pintura de naturaleza por ejemplo mitológica. Siendo la iglesia católica uno de los principales mecenas de la época, no dejan por ello de pintarse cuadros religiosos. Se cultiva con extraordinario vigor el retrato con maestros como Tiziano o Antonio Moro. En esta época empiezan, tímidamente, otros géneros considerados menores, como el paisaje o el bodegón, entendidos en el Renacimiento como un elemento subordinado frente a la historia, algo accesorio del renacimiento.[4]​


== Pintura renacentista italiana ==

El Renacimiento italiano creó una verdadera revolución en la pintura. Italia fue el foco primero y principal del Renacimiento en todas sus manifestaciones, del siglo XV al XVI. Un directo antecesor de esta nueva sensibilidad fue Giotto, maestro que rompió con el estilo bizantino. Sustituyó el típico fondo dorado por escenarios naturales.[5]​

 
[6]​
La pintura del Quattrocento se desarrolló primero con la obra de Fra Angelico y sobre todo de Masaccio (1401-1428), que creó una nueva sensibilidad, totalmente ajena al gótico. Logra la sensación de espacio a través del uso metódico de la perspectiva lineal, como puede verse en la Trinidad de Santa María Novella (h. 1420-1425). Con el Humanismo, el hombre se sitúa en el centro de todas las cosas, y es la medida de referencia. La perspectiva debe entonces respetar las leyes físicas del mundo, y la relación entre luz y sombra en los cuerpos. Masaccio quiere representar en sus cuadros la realidad «objectiva». Tradicionalmente es considerado el primer pintor moderno. Introdujo en el arte occidental la noción de verdad óptica, de perspectiva y de volumen.
Esta investigación sobre la geometría y la matemática fue seguida por Paolo Ucello, Andrea del Castagno y Fra Filippino Lippi. Conviene destacar a Piero della Francesca (1416-1492), quien se interesó por los tratados de Vitrubio, pensador latino del siglo I, que desarrolló en sus escritos el arte de la razón, el sentido de la medida y del equilibrio (desarrolla un modelo de ciudad romana con las proporciones "ideales"). La pintura exige la adecuación entre la visión de la imagen pintada y la de los objetos en el espacio. Este principio se traduce en la representación de los objetos más distantes de menor tamaño que los que están más cercanos. Piero della Francesca estudió el realismo visual y la perspectiva lineal, como puede verse en su Flagelación de Cristo, 1477-1479, Urbino.
La siguiente generación de artistas florentinos logró un mayor refinamiento: Benozzo Gozzoli, Domenico Ghirlandaio y, sobre todo, Sandro Botticelli.
En la segunda mitad del siglo XV surge una escuela pictórica en el centro de Italia, preocupada ante todo por crear el espacio en el que se mueven los personajes de sus cuadros, esforzándose por crear sobre todo paisajes ordenados y realistas. En Umbría se destacó Perugino, maestro de Rafael, así como Pinturicchio y Luca Signorelli. En la misma época, el renacimiento alcanzó el norte de Italia, surgiendo escuelas regionales de marcada personalidad: Andrea Mantegna es el pintor más importante de Padua, cuya influencia llega a la refinada corte de Ferrara, donde trabajaron Cosme Tura y Francesco del Cossa.
Carácter especial presenta Venecia, en contacto constante con oriente, lo que da a este centro artístico un aire diferente, en el que el color predomina sobre la línea y el paisaje sobre la persona humana, justo a la inversa de lo que ocurre en Florencia. Los más sobresalientes pintores venecianos de la época fueron los Bellini, en particular Giovanni Bellini. Trascendente en la evolución del renacimiento veneciano es la obra de Antonello da Messina, pintor siciliano que se formó en Flandes y que acabó viviendo en Venecia, aportando la minuciosidad flamenca. Una destacada figura veneciana de principios del siglo XVI fue Giorgione, al que se pueden atribuir cuadros como la Venus dormida, La tempestad y Los tres filósofos.

La segunda fase del renacimiento italiano es el Cinquecento, en el que destacan los tres grandes nombres de la pintura renacentista: Leonardo da Vinci (1452-1519), Rafael (1483-1520) y Miguel Ángel (1475-1564).
De Leonardo sobre todo destaca su asimilación de novedades gráficas como los claroscuros o el esfumado. Se trata de un principio de perspectiva que da a las formas lejanas un aspecto más difuso y a las cercanas una imagen más nítida. El dibujo, como en toda la escuela florentina, prima sobre el color.
Rafael, por su parte, destacó en la pintura religiosa y también en el retrato de nobles. De 1504 a 1508, pintó numerosas Vírgenes con Niño (Madonas). Basa su composición en el mensaje que desea transmitir, que no es otro que el del amor maternal. También destaca sus Estancias del Vaticano, pinturas murales realizadas en los apartamentos del Papa Julio II.

Miguel Ángel, escultor, poeta y arquitecto, pintó en los frescos de la Capilla Sixtina una de las obras cumbres del Renacimiento. Representan numerosos episodios relatados en el Antiguo Testamento (el Génesis) y en el Nuevo Testamento (el Juicio Final, que realizó en un momento posterior de su vida). Esta obra maestra del Renacimiento es considerada como los frescos más famosos del mundo. El estilo pictórico, que imprime un gran dinamismo y una distorsión del cuerpo, hacen del Miguel Ángel el padre del manierismo.
A mediados de siglo, tras la muerte de los grandes maestros, y en medio de una crisis social generalizado, la pintura se hace manierista, notándose primero en Florencia y Roma con Andrea del Sarto, Pontormo, Vasari y Volterra. Pontormo puede ser considerado como un modelo de pintor manierista del Renacimiento tardío. El objetivo es sorprender y afectar emocionalmente al espectador. Los pintores manieristas deforman el cuerpo de los personajes. Los cuerpos son completamente desproporcionados. Es el maestro de otro célebre pintor florentino, Bronzino, el pintor a quien más se relaciona con La Bella Maniera florentina.
En Parma surge una escuela particularísima cuya figura más sobresaliente es Antonio Allegri da Correggio, precursor del ilusionismo barroco con su decoración de la cúpula de la iglesia de San Juan Evangelista de Parma (1520–1523). Su discípulo Parmigianino representa obras con figuras elongadas, como la llamada Madonna del cuello largo (1540).
Venecia siguió dando grandes pintores, con obras plenas de sensualidad y colorido. Tiziano destacó en el retrato, temas mitológicos (Venus, Baco y Ariadna) y religiosos. Veronés destacó pintando grandes cuadros de conjunto, dentro de arquitecturas como las Bodas de Caná y, ya a finales de siglo, Tintoretto, con movimientos y escorzos violentos que prefigura el barroco.
Finalmente, los Bassano son una familia con la que se cierra el renacimiento pictórico en Venecia.


== Pintura flamenca ==

En el siglo XVI, la reforma protestante provoca una progresiva separación entre las provincias meridionales, católicas, de las septentrionales, protestantes e iconoclastas, en las que se produce destrucción de pintura religiosa y la autonomía de géneros como el paisaje, el bodegón o la escena de género. Este proceso que culminó en el siglo XVII se inicia durante el renacimiento.
En Bélgica se produce la paulatina decadencia de Brujas, apreciándose influencia leonardesca en pintores como Adriaen Isenbrandt y Ambrosius Benson. Creció la Escuela de Amberes, con las obras de Quintín Metsys, que es el pintor que mejor refleja la influencia de Leonardo da Vinci,[2]​ Bernard van Orley y Jan Gossaert, llamado Mabuse, quien tuvo un período de Italia aunque sin alcanzar la elegancia de los modelos italianos.[2]​ Pueden diferenciarse dos tendencias:

romanistas o italianistas, del siglo XVI.
reaccionarios, del siglo XVI.


=== Escuela de italianistas ===
La escuela de los italianistas se forma con los maestros que habiendo estudiado en las escuelas de Italia amalgamaron el estilo idealista de ella con el realismo flamenco sin lograr una fusión verdadera y sin obtener ventajas para uno y otro. Se destacan:

Jan Gossaert, llamado Juan de Mabuse de quien es una Virgen con el Niño en el Museo del Prado y otra semejante en el de Berlín
Bernard van Orley, que tiene una Sagrada Familia en el mencionado Museo de Madrid, quizás demasiado realista.
Michel Coxcie, discípulo de Orley, autor del Tránsito de la Virgen y de otros cuadros en la misma colección española.
Joachim Patinir, pues concede gran importancia al reflejo naturalista del paisaje en sus obras. Un manierismo de influencia miguelangelesca se encuentra en pintores como Hemessen y Marinus. Cabe mencionar, finalmente, dentro del género del retrato a Antonio Moro.


=== Escuela de reaccionarios ===
Contrarios a los italianistas por sistema, surgieron los que por lo mismo pueden llamarse reaccionarios, artistas llenos de ingenio, poesía y originalidad y muy populares en sus asuntos.
Sobresale la familia de los Brueghel, sobre todo, el primero de este nombre Pieter Brueghel el Viejo, pintor de costumbres aldeanas y que sirve de puente entre la fantasía del Bosco y la escena de género barroca. Este mismo reflejo realista de la vida cotidiana se puede ver en los cuadros religiosos de Pieter Aertsen y Joachim Beuckelaer.


== Pintura holandesa ==

Las escuelas holandesas empiezan con Lucas van Leyden (1494-1533) quien se formó en el estilo de los flamencos italianistas como lo revelan sus cuadros del Sermón en el Museo de Ámsterdam y el San Jerónimo y la Virgen con el Niño en el de Berlín. Muy pronto la invasión del protestantismo disipó el verdadero ideal en la pintura holandesa y aunque sigue italianizante en el siglo XVI se limitan los asuntos a pintar las costumbres y paisajes del país.
Martin van Heemskerck fue uno de los principales retratistas, aunque también se dedicó a la pintura de historia. En Utrecht nació el retratista Antonio Moro (h. 1519 - h. 1576-78), considerado creador de un tipo de retrato cortesano que se difundió por toda Europa.
La organización democrática de Holanda dio lugar a que se realizaran los primeros retratos colectivos, en los que se destacará Frans Hals (1580-1666), de la ciudad de Haarlem.


== Pintura española ==

En España, por proximidad geográfica y lazos de todo tipo (históricos, comerciales, etc.), los modelos del Renacimiento italiano llegaron por la Corona de Aragón, difundiéndose más tardíamente en Castilla, donde prevalecía la influencia del gótico flamenco. Lafuente Ferrari habla de cierta resistencia española al estilo renacentista, que explica por la fidelidad a la pintura hispanoflamenca, los escasos pintores españoles que realmente viajaron a Italia y cierta desconfianza hacia unos modelos que se percibían como paganizantes.[7]​
A diferencia de Alemania o Italia, aquí había un fuerte poder centralizado, por lo que era escasa la iniciativa cultural y artística de los municipios. Los mecenas del Renacimiento español fueron la Corte, la Iglesia y la nobleza.[8]​ Siendo la iglesia católica uno de los principales, si no el más importante, de los mecenas, los temas fueran predominantemente religiosos. Sólo en las colecciones reales y en las de algún noble podía verse otro tipo de pintura, generalmente obra de autores italianos.
No es fácil determinar, en España, cuándo las formas del gótico internacional dieron paso a las formas renacentistas. No hay una ruptura clara. Autores como Jaime Huguet (1414-95) ya habían sentido la influencia italiana, pero el italianismo y el alejamiento de los modelos flamencos no se produjo hasta el siglo XVI.[9]​
Se suele dividir la pintura renacentista de España en tres períodos diferentes, todos del siglo XVI:

Primer tercio
Sobre una base de estilo gótico flamenco, se empiezan a adoptar algunos modos italianizantes.

El cuatrocentismo italiano penetra en España a través de Valencia, con los Osona: Rodrigo de Osona, conocido por el Calvario de San Nicolás de Valencia y La adoración de los Reyes (National Gallery, Londres), y a su hijo Francisco Osona, quien incorpora los fondos de arquitecturas propios del renacimiento; y Paolo de San Leocadio, pintor italiano en un estilo cuatrocentista.
La influencia de los grandes maestros renacentistas se refleja en dos pintores manchegos de Valencia: Fernando Yáñez de la Almedina, cuya influencia leonardesca es evidente y Fernando de los Llanos. Se les puede considerar puristas, en el sentido de que importan directamente el Renacimiento puro, a diferencia de otros autores que seguían con el medieval espíritu hispanoflamenco.[10]​ Trabajaron juntos en las puertas del retablo mayor de la catedral de Valencia, considerada una de las más importantes obras del Renacimiento en España.[9]​

En Castilla, destaca Pedro Berruguete (c.1450-1504) a quien se considera figura que representa especialmente bien la transición del estilo gótico internacional al italiano, quien combina las novedades romanas como el uso de arquitecturas, o la preocupación por la luz, con elementos flamencos;[9]​ y el flamenco Juan de Flandes quien trabajó para Isabel I de Castilla.
En la catedral de Toledo se encuentra la obra de otro extranjero, Juan de Borgoña, de formación italiana, quien realizó las pinturas de la sala capitular de la Catedral.
Finalmente, Alejo Fernández trabaja en Andalucía, en un estilo ecléctico que se muestra, en unos cuadros, más flamenco, y en otros más italianizante.[9]​ Produce algunas obras «delicadas un tanto arcaicas»[11]​ como la Virgen de los Navegantes para la Casa de Contratación (Alcázar de Sevilla).
Segundo tercio
A la influencia de autores como Rafael y los del manierismo se une la de pintores flamencos de la época.

En Valencia, Vicente Macip y su hijo Juan de Juanes (1523-1579), en quienes se denota la influencia de Rafael. Sus modelos iconográficos fueron posteriormente muy imitados, como la Santa Cena de Juan de Juanes que puede verse en el museo del Prado.
En Castilla, Alonso de Berruguete y en Toledo, Juan Correa de Vivar.
En Granada, pintó el arquitecto Pedro Machuca, con obras como las que se guardan en el Museo del Prado, Virgen del sufragio y un Descendimiento que evidencian un estilo purista;[10]​ y en Sevilla, Luis de Vargas (1506-1568), y los flamencos Pedro de Campaña (1503-1563), autor del Descendimiento de la catedral de Sevilla[12]​ y Hernando Sturmio (1539-1557).[13]​
El extremeño Luis de Morales (1509-1586) destaca por sus pinturas religiosas de Vírgenes, que crean un modelo posteriormente muy repetido. En él confluyen no solo el estilo manierista, sino algunos resabios flamentos, y anticipa el tenebrismo del primer Barroco.[14]​

Último tercio
Predomina la influencia de la pintura veneciana, por la que los dos monarcas de este siglo (Carlos V y Felipe II) mostraron preferencia. Se cultiva particularmente el retrato. Considera Lafuente Ferrari que el cromatismo de la escuela veneciana, y su carácter nórdico eran más apropiados a la sensibilidad artística hispana, por lo que su influencia fue más fecunda.[15]​
Ejemplo de influencia miguelangelesca de figuras musculosas es Gaspar Becerra (1520-1570), autor de uno de los pocos ejemplos de temática mitológica: la historia de Perseo pintada al fresco en una de las torres del Palacio del Pardo.
La magna obra de El Escorial atrae a pintores italianos como Luca Cambiasso, Federico Zuccaro o Pellegrino Tibaldi (bóveda de la Biblioteca). Entre los pintores españoles cuya obra se puede relacionar con el monasterio, se encuentran Juan Fernández Navarrete (1526-1579) llamado El Mudo, influido por autores de la escuela veneciana como Tiziano o Tintoretto[16]​ y Luis de Carvajal.
Pero la figura más destacada de la época, y uno de los grandes maestros de la pintura universal, fue El Greco (1541-1614) que, venido a trabajar en el monasterio, no gustó a Felipe II y terminó trabajando en Toledo desde 1579 hasta su muerte en 1614. Allí pintó obras destacadas como el retablo mayor de Santo Domingo el Antiguo y el Expolio en la sacristía de la catedral.[17]​ En su obra maestra, el Entierro del Conde de Orgaz, consigue una fusión entre el mundo real y el más allá, relacionando ambos espacios.[18]​
En la corte trabajaron retratistas notables: Antonio Moro que retrató a María Tudor y al emperador Maximiliano II, entre otros; influido por él estuvo Alonso Sánchez Coello (1531-1588) quien pintó a Felipe II, a su medio hermano Don Juan de Austria o a la infanta Isabel Clara Eugenia, entr otros, con realismo, pero también una soltura de pincel propia de la escuela veneciana;[19]​ Juan Pantoja de la Cruz (1553-1608) más tardío, se va acercando a la sensibilidad barroca; y Bartolomé González (1564-1627).


== Pintura alemana ==
En Alemania existía una poderosa escuela gótica de gran patetismo, violencia y expresionismo. Las formas del Renacimiento italiano llegan a principios del siglo XVI.[20]​

El pintor más destacado del Renacimiento alemán, y uno de los grandes maestros de la Pintura occidental fue Alberto Durero (1471-1528). Visitó Venecia donde conoció la obra de autores como Bellini; este autor, junto con Mantegna fueron sus influencias más directas. Tras un viaje por los Países Bajos, adoptó ciertos rasgos de la pintura flamenca como el plegado de los paños. Inclinado al dibujo y a una realista representación de la naturaleza, destacó como grabador, uno de los mejores de todos los tiempos, usando la técnica de la xilografía y también la calcografía (grabados en cobre).[21]​ Destaca toda su serie de autorretratos y el estudio de desnudo que hace en los muy clásicos Adán y Eva (1507) que se conservan en el Museo del Prado.

Principales pintores alemanes
Matthias Grünewald (c.1470-1528) el más cercano a la tradición gótica. Destaca su retablo de Isemheim (1510)
Hans Holbein el Joven (c.1497–1543) hijo de un pintor que se sitúa más en el estilo del gótico, destacó como retratista en la corte de Enrique VIII de Inglaterra.
Lucas Cranach el Viejo (1472-1553) aunque realiza algunos temas mitológicos, es rcordado sobre todo por sus retratos de los líderes de la Reforma, pues se considera que este artista es "el más directamente comprometido con el protestantismo".[22]​
Albrecht Altdorfer (c.1480-1538) destacó por su dedicación al paisaje, inaugurando la que vino a ser conocida como escuela del Danubio.
De la época manierista cabe citar las extrañas pinturas de Giuseppe Arcimboldo, un italiano que trabajó en la corte del emperador Rodolfo II en Praga.


== Pintura francesa ==

En Francia se inicia el renacimiento con autores de clara influencia flamenca, como Jean Bellegambe (1470-1534), que se inspira en los artistas de Amberes. En torno a las cortes de Francisco I y Enrique IV se dan dos escuelas llamadas de Fontainebleau, que siguen modelos italianizantes.
Francisco I llamó a su corte a Leonardo da Vinci y Andrea del Sarto. Pero fueron artistas italianos posteriores los que dominaron la primera escuela de Fontainebleau. En el palacio de Fontainebleau trabajaron decoradores italianos como Rosso, Primaticcio y Niccolò dell'Abbate. Muchas de estas decoraciones de Fontainebleau se divulgaron gracias a la labor de diversos grabadores, como el francés Jean Mignon.
En esta época alcanza gran esplendor el género del retrato, con Jean Clouet y su hijo François. El primero realiza lienzos mitológicos y retratos dibujados o a lápiz. François busca la caracterización social de sus modelos, aproximándose más a los modelos italianos y flamencos.
Otro retratista predominante que trabaja en Francia, más próximo a Jean Clouet que a su hijo, es Corneille de Lyon, también conocido como Cornelys, llamado de Lyon o de la Haya, posiblemente holandés.
En París trabajan los Cousin, padre e hijo. Jean Cousin padre, llamado el Viejo para diferenciarlo de su hijo, Jean Cousin el Joven, realizó el primer gran desnudo pintado por un artista francés: Eva Prima Pandora (Museo del Louvre).
A finales de siglo, recuperada cierta paz social tras las guerras de religión, el rey Enrique IV reemprende los grandes trabajos decorativos, naciendo así una «segunda escuela de Fontainebleau» que agrupa a los diversos artistas que trabajaron en el castillo.


== Notas ==


== Enlaces externos ==
 Wikimedia Commons alberga una galería multimedia sobre Pintura renacentista.
Sitio de pintura Renacentista
La pintura del Renacimiento
La música clásica occidental es un tipo de música académica producida o derivada de las tradiciones de la música litúrgica y profana en Occidente, teniendo históricamente su foco mayoritario en Europa Occidental. Posee un referente de transmisión fundamentalmente de tipo escrito lo cual suele vincularse al carácter riguroso de su reproducción e interpretación.  
Si bien, las principales características del género fueron codificadas principalmente entre 1550 y 1900, que es habitualmente considerado como el período característico de producción de la música clásica, su desarrollo se extiende a todo el siglo XX y XXI.[1]​ 
En un sentido historiográfico, la música clásica antigua se ha dividido tradicionalmente en varios periodos, ante los cuales la musicología del último medio siglo ha mostrado crecientes reticencias:[2]​ música medieval, que abarca el periodo comprendido por la Baja Edad Media en Europa (1000-1400); la música renacentista (1400-1600); la música barroca, que coincide con desarrollo del arte barroco (1600-1750); el clasicismo (1750-1820), que en la Historia de la música y la musicología es a veces llamado «música clásica»;[3]​ el Romanticismo (1820-1900); y la música contemporánea, que comprende las distintas corrientes de música clásica del siglo XX, que adopta la composición atonal y otras tendencias opuestas a corrientes anteriores. 
Debido a sus características técnicas, a la creciente profesionalización de la ocupación de músico y compositor, y al contexto sociocultural en el que se desarrolla (bajo el patronazgo de aristocracia, iglesia y burguesía), la música clásica es habitualmente definida como la «música de tradición culta».[4]​ 
La música clásica en general se caracteriza principalmente por el tipo de lenguaje utilizado, el cual tiene su fundamento en el desarrollo amplio y variado de ideas musicales a partir de temas, motivos, sujetos, contrasujetos, frases, estructuras contrapuntísticas, pasajes modulantes, secciones de reexposición, variaciones temáticas, etc., las cuales se organizan con el objetivo de crear una «narrativa» sonora particular. Con ello el compositor crea un entorno descriptivo de ideas abstractas o concretas convertidas en melodía, armonía y ritmo, encaminadas a dar forma a una estructura sonora con algún sentido específico.  
En ese sentido, la música clásica se distingue de la música popular y de otras tradiciones clásicas no europeas por su apego a la notación musical simbólica, en uso desde aproximadamente el siglo XVI.[5]​ Dicha notación permite a los compositores prescribir de forma detallada el tempo, la métrica, el ritmo, la altura y la ejecución precisa de cada pieza musical. Esto limita el espacio para la improvisación o la ornamentación ad libitum, que son frecuentes en la música artística no europea y en la música popular.[6]​[7]​[8]​ Otra característica es que mientras la mayoría de los estilos «populares» tienden a desarrollarse alrededor del género de las canciones, la música clásica se ha caracterizado por el desarrollo de formas y géneros musicales altamente sofisticados y muy elaborados, basados en desarrollos complejos y en el empleo de una muy variada y perfeccionada instrumentación.[9]​ Por ello, la música clásica suele requerir, tanto de los músicos como de los compositores, de un alto grado de profesionalización y especialización. 
El término música clásica aparece por primera vez a principios del siglo XIX, en un intento para destacar el valor duradero de tradiciones anteriores, y muy especialmente la época de J. S. Bach y G. F. Händel, vista ya entonces como una edad dorada de la música.[10]​[1]​[11]​ En la actualidad dicho término está asociado a la tradición descrita arriba, y es a veces sustituido precisamente por los términos música culta o música académica para resaltar su importancia y carácter frente a la músicas populares que han adquirido estatus "clásico" como exaltación de un valor particular (jazz clásico, rock clásico, salsa clásica, bolero clásico, tango clásico, etc.). En tal sentido, para la música clásica o académica del siglo XX se ha reservado el término "música contemporánea". Sin embargo, de forma popular, el término música clásica suele reservarse casi en exclusiva para referirse al contenido de este artículo.


== Formalización y contenido ==
La música clásica está hecha exclusivamente para ser escuchada, a diferencia de otras músicas adjuntas a otras formas de entretenimiento (la música de cine a veces se ejecuta en salas de conciertos). Los conciertos de música clásica suelen tener una atmósfera solemne, se espera que el público esté en silencio para evitar distraer al músico y los oyentes. Los intérpretes de ordinario visten de manera formal, una práctica vista como un gesto de respeto para la música y el público; y tampoco interactúan directamente o bromean con el público.
Como en las bellas artes, la música clásica aspira a comunicar una cualidad trascendental de la emoción, que expresa algo universal acerca de la condición humana. Si bien la expresión emocional no es una propiedad exclusiva de la música clásica, esta honda de exploración en la emoción permite que la mejor música clásica alcance lo que ha sido denominado lo «sublime» en el arte. Muchos ejemplos pueden citarse para demostrar esto. Por ejemplo, la musicalización del poema de Friedrich Schiller «Oda a la Alegría» en la Novena sinfonía de Ludwig van Beethoven, que suele interpretarse en actos de independencia nacional o de celebración, como aquella famosa ocasión en que la dirigió Leonard Bernstein para celebrar la caída del Muro de Berlín, y la tradición japonesa de tocarla para celebrar el Año Nuevo. Sin embargo, otros compositores, como Iannis Xenakis, argumentan que el efecto emocional de la música en los oyentes es arbitrario y que, por lo tanto, la complejidad objetiva o el contenido de información de la pieza es lo supremo.
A lo largo de la historia, los padres se aseguraron de que sus hijos fuesen instruidos en la música culta desde muy temprana edad. Una experiencia musical temprana daba las bases para un estudio serio posterior. Para aquellos que deseaban ser ejecutantes, cualquier instrumento es prácticamente imposible de aprender a nivel profesional si, o al menos un instrumento similar, no eran aprendidos desde la infancia. Algunos padres buscaban la enseñanza musical por razones sociales o en un esfuerzo por impartirles un útil sentido de la autodisciplina; las lecciones parecen mostrar también un incremento en el desempeño académico. Se considera además, que el conocimiento de las obras de la música clásica es parte de una buena cultura general.


== Interpretación ==
Los compositores clásicos aspiran a su música de una relación muy profunda entre su contenido afectivo (emocional), y los medios con los que lo logra. Muchas de las obras clásicas más elogiadas hacen uso del desarrollo musical, el proceso por el que un germen, idea o motivo musical es repetido en distintos contextos, o alterados de tal manera que la mente del oyente, conscientemente o no, compara las diferentes versiones. Los géneros clásicos de la forma sonata y la fuga emplean rigurosamente formas de desarrollo musical.
Generalmente, las obras de música clásica muestran una gran complejidad musical gracias al uso que hace el compositor del desarrollo, modulación (cambios de tonalidad), variación antes que la exacta repetición, frases musicales que no siempre tienen la misma longitud, contrapunto, polifonía y una armonía sofisticada. Además, muchas obras clásicas bastante largas (de 30 minutos a 3 horas) son construidas a partir de jerarquías de unidades más pequeñas: las frases, los períodos, las secciones y los movimientos. El análisis schenkeriano es una rama de la música que intenta distinguir estos niveles estructurales.
Su transmisión escrita, junto con la veneración dada a ciertas obras clásicas, ha llevado a la expectativa de que el ejecutante tocará la obra de tal modo que realizará en detalle las intenciones originales del compositor. Por lo tanto, las desviaciones de las instrucciones del compositor a veces son condenadas como fallas completas éticas. Durante el siglo XIX, los detalles que los compositores colocaban en sus partituras fueron incrementándose. Así vemos un opuesto rechazo-admiración por los ejecutantes que ofrecen nuevas «interpretaciones» de la obra de un compositor, y no es desconocido que un compositor le pida al intérprete una mejor realización de sus intenciones originales que la que él mismo pudo lograr. De este modo, los ejecutantes de música clásica alcanzan a menudo reputaciones muy altas por su musicalidad, aunque ellos mismos no compongan. Otra consecuencia de la primacía de la partitura escrita del compositor es que la improvisación juega una menor presencia, en marcado contraste con otras tradiciones como el jazz, en donde la improvisación es básica. La improvisación en la música clásica era mucho más frecuente en el Barroco que en los siglos XIX y XX, y recientemente la interpretación de aquella música por músicos clásicos modernos ha sido enriquecida por el resurgimiento de antiguas prácticas improvisatorias. Durante el periodo clásico, Mozart y Beethoven improvisaban a veces las cadencias de sus conciertos para piano (y animaban a otros a hacer lo mismo), pero también tendían a dar cadencias escritas para que otros solistas pudiesen usarlas.


== Influencias de la música popular ==
La música académica siempre ha sido influida por la música popular, o ha tomado material de ella. Los ejemplos incluyen música ocasional, como el uso por Brahms de canciones estudiantiles para la bebida en su Obertura para un festival académico, géneros ejemplificados por la Ópera de los tres centavos de Kurt Weill y la influencia del jazz en la música de compositores de inicios y mediados del siglo XX, como Maurice Ravel. Ciertos compositores clásicos posmodernos y postminimalistas reconocen su deuda con la música popular. También hay muchos ejemplos de influencia en el otro sentido, incluyendo canciones populares basadas en música clásica, el uso que se hizo del Canon de Pachelbel desde los años setenta, el fenómeno del musical crossover, en el que los músicos clásicos adquieren gran éxito en el terreno de la música popular (un notable ejemplo es la serie de grabaciones Hooked on Classics hechas por la Orquesta Filarmónica Real a inicios de los años ochenta). De hecho, puede argumentarse que el género completo de la música de cine puede ser considerada parte de esta influencia, dado que brinda la música orquestal a vastos públicos de cine meros que de otra manera no escucharían semejante música (no obstante, la mayoría la escuchan inconscientemente). Compositores de música clásica han hecho uso de la música folclórica (música creada por músicos autodidactas, la mayoría de una pura tradición oral). Algunos lo han hecho con una ideología nacionalista explícita, otros simplemente la han explotado como parte de su material temático. Algunos fragmentos de música clásica son frecuentemente usados comercialmente (es decir, en la publicidad o como parte de las bandas sonoras de películas de entretenimiento). En la publicidad televisiva, algunos pasajes orquestales poderosos o rítmicos se han convertido en clichés, pudiendo mencionar el inicio «O Fortuna» de Cármina Burana de Carl Orff por la fuerte presencia de la percusión y el coro brindando un pasaje de carácter épico. Se puede mencionar también el «Dies Irae» del Réquiem de Mozart y selecciones Rodeo de Aaron Copland. Similarmente, en las películas a menudo se recurre a pasajes clichés de música clásica para representar el refinamiento o la opulencia: probablemente la obra más escuchada en esta categoría es Eine Kleine Nachtmusik de Mozart.


== Notación musical ==

Desde la antigua Grecia (en lo que respecta a música occidental) existen formas de notación musical. Sin embargo, es a partir de la música de la Edad Media (principalmente canto gregoriano) que se comienza a emplear el sistema de notación musical que evolucionaría al actual. En el Renacimiento cristalizó con los rasgos más o menos definitivos con que lo conocemos hoy, aunque ―como todo lenguaje― ha ido variando según las necesidades expresivas de los usuarios.
El sistema se basa en dos ejes: uno horizontal, que representa gráficamente el transcurrir del tiempo, y otro vertical que representa gráficamente la altura del sonido. Las alturas se leen en relación con un pentagrama (un conjunto de cinco líneas horizontales) que al comienzo tiene una «clave» que tiene la función de atribuir a una de las líneas del pentagrama una determinada nota musical. En un pentagrama encabezado por la clave de sol en segunda línea nosotros leeremos como sol el sonido que se escribe en la segunda línea (contando desde abajo), como la del sonido que se escribe en el espacio entre la segunda y la tercera líneas, como si el sonido en la tercera línea, etc. Para los sonidos que quedan fuera de la clave se escriben líneas adicionales. Las claves más usadas son las de Do en tercera línea (clave que toma como referencia al Do de 261,63 Hz, el do central del piano), la de Sol en segunda (que se refiere al Sol que está una quinta por encima del do central), y la de fa en cuarta (referida al fa que está una quinta por debajo del do central).
El discurso musical está dividido en unidades iguales de tiempo llamadas compases: cada línea vertical que atraviesa el pentagrama marca el final de un compás y el comienzo del siguiente. Al comienzo del pentagrama habrá una fracción con dos números; el número de arriba indica la cantidad de tiempos que tiene cada compás; el número de abajo nos indica cuál será la unidad de tiempo.
Para escribir las duraciones se utiliza un sistema de figuras musicales: la redonda (representada como un círculo blanco), la blanca (un círculo blanco con un palito vertical llamado plica), la negra (igual que la blanca pero con un círculo negro), la corchea (igual que la negra pero con un palito horizontal que comienza en la punta de la plica), la semicorchea (igual que la corchea pero con dos palitos horizontales), etc. Cada una vale la mitad de su antecesora: la blanca vale la mitad que una redonda y el doble que una negra, etc.
Las figuras son duraciones relativas; para saber qué figura es la unidad de tiempo en determinada partitura, debemos fijarnos en el número inferior de la indicación del compás: si es 1, cada redonda corresponderá a un tiempo; si es 2, cada blanca corresponderá a un tiempo; si es 4, cada tiempo será representado por una negra, etc. Así, una partitura encabezada por un 3/4 estará dividida en compases en los que entren tres negras (o seis corcheas, o una negra y cuatro corcheas, etc.); un compás de 4/8 tendrá cuatro tiempos, cada uno de ellos representados por una corchea, etc.
Para representar los silencios, el sistema posee otros signos que representan un silencio de redonda, de blanca, etc.
Como se ve, las duraciones están establecidas según una relación binaria (doble o mitad), lo que no prevé la subdivisión por tres, que será indicada con «tresillos». Cuando se desea que a una nota o silencio se le agregue la mitad de su duración, se le coloca un punto a la derecha (puntillo). Cuando se desea que la nota dure, además de su valor, otro determinado valor, se escriben dos notas y se las une por medio de una línea arqueada llamada ligadura de prolongación.
En general, las incapacidades del sistema son subsanadas apelando a palabras escritas más o menos convencionales, generalmente en italiano. Así, por ejemplo, las intensidades se indican mediante el uso de una f (forte, fuerte) o una p (piano, suave), o varias efes y pes juntas. La velocidad de los pulsos o tempo se indica con palabras al comienzo de la partitura que son, en orden de velocidad: largo, lento, adagio, moderato, andante, allegro, presto.


== Instrumentación ==
La música clásica también se distingue por los instrumentos que utilizan. Los instrumentos usados en la práctica común de la música clásica fueron inventados antes de la mitad del siglo XIX (la mayoría mucho antes), y codificados en los siglo XVIII y siglo XIX. Consisten en los instrumentos que encontramos en la orquesta sinfónica, junto a otros pocos instrumentos solistas (como el piano, el clavicémbalo y el órgano). Los instrumentos electrónicos, como la guitarra eléctrica y el violín eléctrico, juegan un papel predominante en la música popular, pero de hecho no tienen ninguno en la música clásica antes del siglo XX, y sólo aparecen ocasionalmente en la música clásica del siglo XX y XXI. Tanto los músicos populares como los clásicos han experimentado en las últimas décadas con instrumentos eléctricos, como el sintetizador, con técnicas electrónicas y digitales, como el uso de sonidos sampleados o generados por computador, y el sonido de instrumentos otras culturas, como el gamelan. Es importante notar que todos los instrumentos bajos no existían antes del Renacimiento. En la música medieval, los instrumentos estaban divididos en dos categorías: instrumentos fuertes para usar en exteriores o en la Iglesia e instrumentos más suaves para uso en interiores. Muchos de los instrumentos que son asociados hoy con la música popular tuvieron un papel importante en la música clásica antigua, tales como la gaita, la vihuela, la zanfona y otros instrumentos de viento. Por otro lado, la guitarra acústica, asociada a la música popular, ha empezado a ganar preponderancia en la música clásica a lo largo de los siglo XIX y XX. La voz humana es también un instrumento musical privilegiado de la música clásica, aunque también es usado en la música popular. Diversos géneros utilizan las voces, solas o bien con acompañamiento instrumental: la ópera, la música coral y el lied.
Mientras que el temperamento igual fue gradualmente aceptado como el sistema de afinación en el siglo XVIII, otros tipos de temperamento, de origen histórico, se emplean a menudo en la música de períodos anteriores al Barroco tardío; El clave bien temperado de Johann Sebastian Bach es utilizado como referencia temporal para indicar el comienzo de ese cambio de temperamento. Por ejemplo, la música del Renacimiento inglés se acostumbra a ejecutar con el temperamento medio.


== Historia de la música clásica ==


=== Orígenes ===
Los siglos XVII y XVIII fueron el periodo formativo de la música clásica y vieron nacer la opera y el oratorio, la sonata, el concierto y la sinfonía. Los italianos fueron los primeros en desarrollar estos géneros, pero les siguieron pronto los franceses, alemanes e ingleses. La música clásica surgió tomando elementos de otras tradiciones musicales occidentales, tanto litúrgicas como seculares, por caso la música de la Antigua Grecia o la Música de la Antigua Roma (sobre todo por sus contribuciones teóricas), o la música de la Iglesia católica (principalmente el canto gregoriano).
Los hitos que definieron su rumbo, fue el descubrimiento y posterior desarrollo de la polifónica, así como el posterior desarrollo de la armonía, la revolución musical conocida como el Ars nova y la evolución de la notación musical, además del estudio de la estética musical. Con la era de los descubrimientos que comenzó en el siglo XV y posterior colonialismo, la música clásica llegó a otros continentes y sufrió una síntesis con las tradiciones musicales de los nuevos territorios. Encontramos expresiones de la música clásica en Brasil (por ejemplo, Heitor Villa-Lobos), Estados Unidos (por ejemplo, Charles Ives), Hispanoamericano (por ejemplo, Alberto Ginastera, José Ángel Montero), Asia (por ejemplo, Takemitsu, Tan Dun), África y Oceanía, pero que están conectadas a la música clásica de tradición europea.


=== Períodos de hace años ===
Existe un sistema de división de la historia de la composición de la música clásica en distintos períodos que es ampliamente aceptado. Las fechas son generalizaciones, ya que los períodos se sobreponen unos a otros. Algunas voces autorizadas subdividen los periodos, la fecha o el género. Sin embargo, debe notarse que estas categorías son arbitrarias; por ejemplo, el uso del contrapunto y la fuga, que es considerada una característica del Barroco, fue continuado por Mozart, a quien se considera un compositor clásico, y por Beethoven, a quien normalmente se le describe como en medio del periodo clásico y romántico; y también por Brahms, quien es clasificado como romántico. De acuerdo a este sistema, las principales divisiones son:

Música renacentista: El concepto de Renacimiento fue empleado por el pintor Vasari en el año de 1500 y se le emplea habitualmente para referirse al arte de los siglos XV y XVI en Italia. Este término significa un renacimiento del hombre a partir de un encuentro deliberado con la Antigüedad. La nueva imagen del hombre lleva asimismo hacia un nuevo tipo de artista (con precursores en el siglo XVI): el genio, quien se siente una fuerza creadora en un orden divino. Así mismo, la nueva conciencia de sí mismo del hombre se refleja en los disturbios eclesiásticos y en las guerras religiosas, en los numerosos concilios celebrados en el siglo XV, en la obra reformadora sobre todo de Martín Lutero y en la Contrarreforma con el Concilio de Trento. Las características estilísticas que definen la música renacentista son su textura polifónica, que sigue las leyes del contrapunto, y está regida por el sistema modal heredado del canto gregoriano. Entre sus formas musicales más difundidas se encuentran la misa y el motete en el género religioso, el madrigal, el villancico y la chanson en el género profano, y las danzas, el ricercare y la canzona en la música instrumental. Entre los compositores más destacados de este periodo se hallan Josquin Desprez, Giovanni Pierluigi da Palestrina, Orlando di Lasso y Tomás Luis de Victoria.
Música barroca: Entre 1600 y 1750. Surge el uso de tonalidades más complejas, en lugar de la modalidad y el contrapunto. Se popularizan los instrumentos de teclado (el clavicémbalo y el órgano). Los compositores más destacados del periodo barroco son Georg Friedrich Händel y Johann Sebastian Bach.
Música clásica: Entre 1750 y 1820, fue una era importante que estableció varias de las normas de composición y estructura. El período clásico también está marcado por la desaparición del clavicémbalo y el clavicordio en favor del nuevo piano, que a partir de ese momento se convirtió en el instrumento predominante para la interpretación en teclado y la composición.
Música romántica: Entre 1820 y 1900. Período en que se codificó la práctica, se extendió el papel de la música en la vida cultural y se crearon instituciones para la enseñanza, ejecución y conservación de las obras musicales.
Música moderna: Entre 1900 y 1985. Representó una crisis en los valores de la música clásica y su rol dentro de la vida intelectual, y la extensión de la teoría y la técnica. Algunos teóricos, como Arnold Schoenberg en su ensayo Brahms, el progresivo, insisten en que el Modernismo representa una progresión lógica de las tendencias en la composición del siglo XIX. Otros sostienen un punto de vista opuesto, que indica que el modernismo representa el rechazo o la negación del método de composición clásica.
Música del siglo XX: Usado normalmente para describir la amplia variedad de subgéneros posteriores al Romanticismo empleados hasta el año 2000, incluyendo a los compositores posrománticos, modernistas y posmodernos.
Música clásica contemporánea: El término es utilizado a veces para describir la música compuesta en los últimos años del siglo XX hasta el presente.
El prefijo neo suele emplearse para describir a una composición del siglo XX o contemporánea escrita en un género perteneciente a un periodo anterior, como el clásico, romántico o moderno, pero con un lenguaje moderno. Por ejemplo, la Sinfonía clásica de Prokófiev ―que acude a los modelos de la sinfonía del clasicismo de Haydn― es considerada una composición neoclásica.
El siguiente gráfico muestra una selección resumida de los más famosos compositores de música clásica:


== Véase también ==
 Portal:Música clásica. Contenido relacionado con Música clásica.
Terminología musical


== Referencias ==


== Bibliografía ==


== Enlaces externos ==
MusicaAntigua.com, sitio web de música antigua
Radio Clásica, de Radio Nacional de España.
Doce Notas, revista de música y danza.
Emisoras de música clásica por Internet.
Music World Archivado el 7 de julio de 2022 en Wayback Machine., línea de tiempo, compositores e instrumentos
